{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune Nous Hermes 2 Mistral 7B DPO model using Axolotl framework\n",
    "\n",
    "How to install dependencies (in HPC environment):\n",
    "\n",
    "- load Python and cuDNN modules\n",
    "- create a Python venv and activate it\n",
    "- install dependencies from requirements.txt (e.g. torch)\n",
    "- install Axolotl from git clone (pip won't work, see [this issue](https://github.com/OpenAccess-AI-Collective/axolotl/issues/945)):\n",
    "\n",
    "```\n",
    "git clone git@github.com:OpenAccess-AI-Collective/axolotl.git\n",
    "cd axolotl\n",
    "pip install -e '.[flash-attn,deepspeed]'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n",
      "BF16 is supported? True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print('GPU available?', torch.cuda.is_available())\n",
    "print('BF16 is supported?', torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name etc.\n",
    "\n",
    "MODEL_NAME = \"NousResearch/Nous-Hermes-2-Mistral-7B-DPO\"\n",
    "MODEL_SHORT_NAME = MODEL_NAME.split('/')[-1]\n",
    "SUFFIX = \"FinGreyLit\"\n",
    "#SLICE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 620 train records\n",
      "Wrote 180 test records\n",
      "Wrote 32 eval records\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare fine-tuning dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of test set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "EVAL_SIZE = 32  # how many documents to evaluate (i.e. calculate loss) on during fine-tuning\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    output = json.dumps(sample[\"ground_truth\"])\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    # ShareGPT format\n",
    "    conversations = [\n",
    "        {'from': 'system', 'value': SYSTEM_PROMPT},\n",
    "        {'from': 'user', 'value': INSTRUCTION + \"\\n\\n\" + input_},\n",
    "        {'from': 'gpt', 'value': output}\n",
    "    ]\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "def write_jsonl(records, filename):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for record in records:\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "train_recs = dataset_to_records(train_files)\n",
    "random.shuffle(train_recs)\n",
    "write_jsonl(train_recs, \"axolotl-train.jsonl\")\n",
    "print(f\"Wrote {len(train_recs)} train records\")\n",
    "\n",
    "test_recs = dataset_to_records(test_files)\n",
    "write_jsonl(test_recs, \"axolotl-test.jsonl\")\n",
    "print(f\"Wrote {len(test_recs)} test records\")\n",
    "\n",
    "eval_recs = random.sample(test_recs, EVAL_SIZE)\n",
    "write_jsonl(eval_recs, \"axolotl-eval.jsonl\")\n",
    "print(f\"Wrote {len(eval_recs)} eval records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Axolotl configuration file\n",
    "\n",
    "CONFIG_FILE = f\"config-{MODEL_SHORT_NAME}.yml\"\n",
    "\n",
    "\n",
    "CONFIG = f\"\"\"\n",
    "base_model: {MODEL_NAME}\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: false\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: axolotl-train.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "test_datasets:\n",
    "  - path: axolotl-eval.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "output_dir: ./out-{MODEL_SHORT_NAME}\n",
    "\n",
    "#chat_template: chatml\n",
    "\n",
    "#peft_use_dora: true\n",
    "adapter: lora\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "eval_batch_size: 2\n",
    "num_epochs: 5\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: true\n",
    "fp16: false\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true  # true: saves VRAM but is slower to train\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 2\n",
    "eval_table_size:\n",
    "eval_table_max_new_tokens: 128\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "special_tokens:\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as outfile:\n",
    "    print(CONFIG, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-12 14:27:12,590] [INFO] [datasets.<module>:58] [PID:4017307] PyTorch version 2.3.1 available.\n",
      "[2024-08-12 14:27:22,680] [INFO] [axolotl.utils.config.models.input.check_eval_packing:958] [PID:4017307] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "\u001b[33m[2024-08-12 14:27:22,681] [WARNING] [axolotl.utils.config.models.input.hint_lora_8bit:1044] [PID:4017307] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2024-08-12 14:27:23,101] [INFO] [axolotl.normalize_config:183] [PID:4017307] [RANK:0] GPU memory usage baseline: 0.000GB (+0.818GB misc)\u001b[39m\n",
      "                                 dP            dP   dP \n",
      "                                 88            88   88 \n",
      "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
      "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
      "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
      "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
      "                                                       \n",
      "                                                       \n",
      "\n",
      "****************************************\n",
      "**** Axolotl Dependency Versions *****\n",
      "  accelerate: 0.32.0         \n",
      "        peft: 0.11.1         \n",
      "transformers: 4.43.0.dev0    \n",
      "         trl: 0.9.6          \n",
      "       torch: 2.3.1          \n",
      "bitsandbytes: 0.43.1         \n",
      "****************************************\n",
      "\u001b[33m[2024-08-12 14:27:23,124] [WARNING] [axolotl.scripts.check_accelerate_default_config:468] [PID:4017307] [RANK:0] accelerate config file found at /home/oisuomin/.cache/huggingface/accelerate/default_config.yaml. This can lead to unexpected errors\u001b[39m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-08-12 14:27:23,855] [DEBUG] [axolotl.load_tokenizer:280] [PID:4017307] [RANK:0] EOS: 32000 / <|im_end|>\u001b[39m\n",
      "[2024-08-12 14:27:23,855] [DEBUG] [axolotl.load_tokenizer:281] [PID:4017307] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
      "[2024-08-12 14:27:23,855] [DEBUG] [axolotl.load_tokenizer:282] [PID:4017307] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
      "[2024-08-12 14:27:23,855] [DEBUG] [axolotl.load_tokenizer:283] [PID:4017307] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
      "[2024-08-12 14:27:23,855] [INFO] [axolotl.load_tokenizer:294] [PID:4017307] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2024-08-12 14:27:23,856] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:4017307] [RANK:0] Unable to find prepared dataset in last_run_prepared/5203375280c8da1f5d6781f9ac2922d0\u001b[39m\n",
      "[2024-08-12 14:27:23,856] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:4017307] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2024-08-12 14:27:23,856] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:4017307] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2024-08-12 14:27:23,856] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:4017307] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 620 examples [00:00, 16647.47 examples/s]\n",
      "[2024-08-12 14:27:24,619] [INFO] [axolotl.get_dataset_wrapper:540] [PID:4017307] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "Tokenizing Prompts (num_proc=64): 100%|█| 620/620 [00:02<00:00, 234.63 examples/\n",
      "[2024-08-12 14:27:27,793] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:4017307] [RANK:0] merging datasets\u001b[39m\n",
      "Dropping Long Sequences (num_proc=128): 100%|█| 620/620 [00:01<00:00, 510.31 exa\n",
      "Add position_id column (Sample Packing) (num_proc=128): 100%|█| 603/603 [00:02<0\n",
      "[2024-08-12 14:27:33,470] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:4017307] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/5203375280c8da1f5d6781f9ac2922d0\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|█| 603/603 [00:00<00:00, 11228.56 examples\n",
      "[2024-08-12 14:27:33,553] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:4017307] [RANK:0] Unable to find prepared dataset in last_run_prepared/76534b743fc441b9a8c00e3969d95df8\u001b[39m\n",
      "[2024-08-12 14:27:33,554] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:4017307] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2024-08-12 14:27:33,554] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:4017307] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2024-08-12 14:27:33,554] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:4017307] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 32 examples [00:00, 9476.65 examples/s]\n",
      "[2024-08-12 14:27:34,102] [INFO] [axolotl.get_dataset_wrapper:540] [PID:4017307] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-08-12 14:27:34,102] [WARNING] [datasets.arrow_dataset.map:3087] [PID:4017307] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Tokenizing Prompts (num_proc=32): 100%|██| 32/32 [00:01<00:00, 28.71 examples/s]\n",
      "[2024-08-12 14:27:35,474] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:4017307] [RANK:0] merging datasets\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-08-12 14:27:35,478] [WARNING] [datasets.arrow_dataset.map:3087] [PID:4017307] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 32/32 [00:00<00:00, 117.64 exampl\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-08-12 14:27:36,025] [WARNING] [datasets.arrow_dataset.map:3087] [PID:4017307] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "[2024-08-12 14:27:36,728] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:4017307] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/76534b743fc441b9a8c00e3969d95df8\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|█| 32/32 [00:00<00:00, 1406.25 examples/s]\n",
      "[2024-08-12 14:27:36,769] [DEBUG] [axolotl.calculate_total_num_steps:297] [PID:4017307] [RANK:0] total_num_tokens: 959_022\u001b[39m\n",
      "[2024-08-12 14:27:36,777] [DEBUG] [axolotl.calculate_total_num_steps:310] [PID:4017307] [RANK:0] `total_supervised_tokens: 77_904`\u001b[39m\n",
      "[2024-08-12 14:27:42,717] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 959022\u001b[39m\n",
      "[2024-08-12 14:27:42,718] [DEBUG] [axolotl.calculate_total_num_steps:362] [PID:4017307] [RANK:0] data_loader_len: 28\u001b[39m\n",
      "[2024-08-12 14:27:42,718] [INFO] [axolotl.calc_sample_packing_eff_est:368] [PID:4017307] [RANK:0] sample_packing_eff_est across ranks: [0.8802113927396616]\u001b[39m\n",
      "[2024-08-12 14:27:42,718] [DEBUG] [axolotl.calculate_total_num_steps:380] [PID:4017307] [RANK:0] sample_packing_eff_est: 0.89\u001b[39m\n",
      "[2024-08-12 14:27:42,718] [DEBUG] [axolotl.calculate_total_num_steps:388] [PID:4017307] [RANK:0] total_num_steps: 140\u001b[39m\n",
      "[2024-08-12 14:27:42,723] [DEBUG] [axolotl.train.train:66] [PID:4017307] [RANK:0] loading tokenizer... NousResearch/Nous-Hermes-2-Mistral-7B-DPO\u001b[39m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-08-12 14:27:43,191] [DEBUG] [axolotl.load_tokenizer:280] [PID:4017307] [RANK:0] EOS: 32000 / <|im_end|>\u001b[39m\n",
      "[2024-08-12 14:27:43,191] [DEBUG] [axolotl.load_tokenizer:281] [PID:4017307] [RANK:0] BOS: 1 / <s>\u001b[39m\n",
      "[2024-08-12 14:27:43,191] [DEBUG] [axolotl.load_tokenizer:282] [PID:4017307] [RANK:0] PAD: 2 / </s>\u001b[39m\n",
      "[2024-08-12 14:27:43,191] [DEBUG] [axolotl.load_tokenizer:283] [PID:4017307] [RANK:0] UNK: 0 / <unk>\u001b[39m\n",
      "[2024-08-12 14:27:43,191] [INFO] [axolotl.load_tokenizer:294] [PID:4017307] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2024-08-12 14:27:43,192] [DEBUG] [axolotl.train.train:95] [PID:4017307] [RANK:0] loading model and peft_config...\u001b[39m\n",
      "[2024-08-12 14:27:43,195] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:4017307] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "Loading checkpoint shards: 100%|██████████████████| 3/3 [00:00<00:00,  5.51it/s]\n",
      "[2024-08-12 14:27:44,437] [INFO] [axolotl.load_model:824] [PID:4017307] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-08-12 14:27:44,532] [INFO] [axolotl.load_lora:986] [PID:4017307] [RANK:0] found linear modules: ['o_proj', 'down_proj', 'gate_proj', 'up_proj', 'v_proj', 'q_proj', 'k_proj']\u001b[39m\n",
      "trainable params: 41,943,040 || all params: 7,283,691,520 || trainable%: 0.5758\n",
      "[2024-08-12 14:27:44,905] [INFO] [axolotl.load_model:869] [PID:4017307] [RANK:0] GPU memory usage after adapters: 0.000GB ()\u001b[39m\n",
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-08-12 14:27:45,452] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:4017307] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[2024-08-12 14:27:50,010] [INFO] [axolotl.train.train:136] [PID:4017307] [RANK:0] Pre-saving adapter config to ./out-Nous-Hermes-2-Mistral-7B-DPO\u001b[39m\n",
      "[2024-08-12 14:27:50,054] [INFO] [axolotl.train.train:173] [PID:4017307] [RANK:0] Starting trainer...\u001b[39m\n",
      "[2024-08-12 14:27:50,252] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 0.89 total_num_tokens per device: 959022\u001b[39m\n",
      "[2024-08-12 14:27:50,253] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 0.89 total_num_tokens per device: 959022\u001b[39m\n",
      "  0%|                                                   | 0/160 [00:00<?, ?it/s][2024-08-12 14:27:50,314] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 0.89 total_num_tokens per device: 959022\u001b[39m\n",
      "You're using a LlamaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.3912, 'grad_norm': 21.875, 'learning_rate': 2e-05, 'epoch': 0.03}    \n",
      "  1%|▎                                          | 1/160 [00:10<28:11, 10.64s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.94it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.70it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.56it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.46it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.44it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.42it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.42it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.42it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:28:12,403] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.2849810123443604, 'eval_runtime': 11.4829, 'eval_samples_per_second': 2.787, 'eval_steps_per_second': 1.393, 'epoch': 0.03}\n",
      "  1%|▎                                          | 1/160 [00:22<28:11, 10.64s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "                                                                                \u001b[A[2024-08-12 14:28:22,542] [INFO] [axolotl.callbacks.on_step_end:128] [PID:4017307] [RANK:0] GPU memory usage while training: 13.662GB (+7.215GB cache, +1.326GB misc)\u001b[39m\n",
      "{'loss': 1.326, 'grad_norm': 22.0, 'learning_rate': 4e-05, 'epoch': 0.06}       \n",
      "{'loss': 1.1007, 'grad_norm': 12.0, 'learning_rate': 6e-05, 'epoch': 0.09}      \n",
      "{'loss': 0.7323, 'grad_norm': 7.25, 'learning_rate': 8e-05, 'epoch': 0.12}      \n",
      "{'loss': 0.515, 'grad_norm': 5.9375, 'learning_rate': 0.0001, 'epoch': 0.16}    \n",
      "{'loss': 0.2951, 'grad_norm': 4.0625, 'learning_rate': 0.00012, 'epoch': 0.19}  \n",
      "{'loss': 0.1775, 'grad_norm': 3.09375, 'learning_rate': 0.00014, 'epoch': 0.22} \n",
      "{'loss': 0.1704, 'grad_norm': 2.40625, 'learning_rate': 0.00016, 'epoch': 0.25} \n",
      "{'loss': 0.1494, 'grad_norm': 3.421875, 'learning_rate': 0.00018, 'epoch': 0.28}\n",
      "{'loss': 0.122, 'grad_norm': 1.4296875, 'learning_rate': 0.0002, 'epoch': 0.31} \n",
      "{'loss': 0.0967, 'grad_norm': 1.6171875, 'learning_rate': 0.00019997806834748456, 'epoch': 0.34}\n",
      "{'loss': 0.0729, 'grad_norm': 1.1171875, 'learning_rate': 0.00019991228300988585, 'epoch': 0.37}\n",
      "{'loss': 0.109, 'grad_norm': 1.8828125, 'learning_rate': 0.00019980267284282717, 'epoch': 0.4}\n",
      "{'loss': 0.0911, 'grad_norm': 0.96875, 'learning_rate': 0.00019964928592495045, 'epoch': 0.43}\n",
      "{'loss': 0.0568, 'grad_norm': 0.86328125, 'learning_rate': 0.00019945218953682734, 'epoch': 0.47}\n",
      "{'loss': 0.101, 'grad_norm': 1.46875, 'learning_rate': 0.0001992114701314478, 'epoch': 0.5}\n",
      " 10%|████▏                                     | 16/160 [02:53<24:23, 10.16s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.93it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:30:55,700] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.14425180852413177, 'eval_runtime': 11.5146, 'eval_samples_per_second': 2.779, 'eval_steps_per_second': 1.39, 'epoch': 0.5}\n",
      " 10%|████▏                                     | 16/160 [03:05<24:23, 10.16s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "{'loss': 0.0996, 'grad_norm': 1.1875, 'learning_rate': 0.00019892723329629887, 'epoch': 0.53}\n",
      "{'loss': 0.0491, 'grad_norm': 0.453125, 'learning_rate': 0.0001985996037070505, 'epoch': 0.56}\n",
      "{'loss': 0.0725, 'grad_norm': 0.703125, 'learning_rate': 0.0001982287250728689, 'epoch': 0.59}\n",
      "{'loss': 0.1097, 'grad_norm': 1.3203125, 'learning_rate': 0.00019781476007338058, 'epoch': 0.62}\n",
      "{'loss': 0.1008, 'grad_norm': 1.046875, 'learning_rate': 0.00019735789028731604, 'epoch': 0.65}\n",
      "{'loss': 0.0369, 'grad_norm': 0.498046875, 'learning_rate': 0.0001968583161128631, 'epoch': 0.68}\n",
      "{'loss': 0.0702, 'grad_norm': 0.54296875, 'learning_rate': 0.00019631625667976583, 'epoch': 0.71}\n",
      "{'loss': 0.1289, 'grad_norm': 0.97265625, 'learning_rate': 0.00019573194975320673, 'epoch': 0.74}\n",
      "{'loss': 0.044, 'grad_norm': 0.625, 'learning_rate': 0.00019510565162951537, 'epoch': 0.78}\n",
      "{'loss': 0.0587, 'grad_norm': 0.9453125, 'learning_rate': 0.00019443763702374812, 'epoch': 0.81}\n",
      "{'loss': 0.0437, 'grad_norm': 0.6796875, 'learning_rate': 0.00019372819894918915, 'epoch': 0.84}\n",
      "{'loss': 0.0447, 'grad_norm': 0.671875, 'learning_rate': 0.00019297764858882514, 'epoch': 0.87}\n",
      "{'loss': 0.0816, 'grad_norm': 0.87890625, 'learning_rate': 0.00019218631515885006, 'epoch': 0.9}\n",
      "{'loss': 0.0864, 'grad_norm': 1.078125, 'learning_rate': 0.0001913545457642601, 'epoch': 0.93}\n",
      "{'loss': 0.0481, 'grad_norm': 2.25, 'learning_rate': 0.00019048270524660196, 'epoch': 0.96}\n",
      "{'loss': 0.0556, 'grad_norm': 0.578125, 'learning_rate': 0.0001895711760239413, 'epoch': 0.99}\n",
      " 20%|████████▍                                 | 32/160 [05:47<21:35, 10.12s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.93it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.33it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.37it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.37it/s]\u001b[A[2024-08-12 14:33:49,073] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1152811050415039, 'eval_runtime': 11.645, 'eval_samples_per_second': 2.748, 'eval_steps_per_second': 1.374, 'epoch': 0.99}\n",
      " 20%|████████▍                                 | 32/160 [05:58<21:35, 10.12s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.37it/s]\u001b[A\n",
      "{'loss': 0.0607, 'grad_norm': 0.70703125, 'learning_rate': 0.00018862035792312147, 'epoch': 1.02}\n",
      " 21%|████████▋                                 | 33/160 [06:10<29:34, 13.98s/it][2024-08-12 14:34:00,434] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 0.89 total_num_tokens per device: 959022\u001b[39m\n",
      "{'loss': 0.0515, 'grad_norm': 0.53125, 'learning_rate': 0.00018763066800438636, 'epoch': 1.03}\n",
      "{'loss': 0.0415, 'grad_norm': 0.640625, 'learning_rate': 0.00018660254037844388, 'epoch': 1.06}\n",
      "{'loss': 0.0395, 'grad_norm': 0.47265625, 'learning_rate': 0.00018553642601605068, 'epoch': 1.09}\n",
      "{'loss': 0.0478, 'grad_norm': 0.5078125, 'learning_rate': 0.00018443279255020152, 'epoch': 1.12}\n",
      "{'loss': 0.0655, 'grad_norm': 0.65234375, 'learning_rate': 0.00018329212407100994, 'epoch': 1.16}\n",
      "{'loss': 0.0277, 'grad_norm': 0.369140625, 'learning_rate': 0.00018211492091337042, 'epoch': 1.19}\n",
      "{'loss': 0.0521, 'grad_norm': 0.5390625, 'learning_rate': 0.00018090169943749476, 'epoch': 1.22}\n",
      "{'loss': 0.0341, 'grad_norm': 0.359375, 'learning_rate': 0.00017965299180241963, 'epoch': 1.25}\n",
      "{'loss': 0.0385, 'grad_norm': 0.68359375, 'learning_rate': 0.000178369345732584, 'epoch': 1.28}\n",
      "{'loss': 0.0263, 'grad_norm': 0.328125, 'learning_rate': 0.00017705132427757895, 'epoch': 1.31}\n",
      "{'loss': 0.0214, 'grad_norm': 0.5078125, 'learning_rate': 0.00017569950556517566, 'epoch': 1.34}\n",
      "{'loss': 0.0323, 'grad_norm': 0.41015625, 'learning_rate': 0.00017431448254773944, 'epoch': 1.37}\n",
      "{'loss': 0.0443, 'grad_norm': 0.4453125, 'learning_rate': 0.00017289686274214118, 'epoch': 1.4}\n",
      "{'loss': 0.0573, 'grad_norm': 1.1640625, 'learning_rate': 0.00017144726796328034, 'epoch': 1.43}\n",
      "{'loss': 0.0246, 'grad_norm': 0.5078125, 'learning_rate': 0.00016996633405133655, 'epoch': 1.47}\n",
      " 30%|████████████▌                             | 48/160 [08:41<18:57, 10.16s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.92it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:05,  1.32it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.36it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.37it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:08<00:02,  1.38it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.39it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.40it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.39it/s]\u001b[A[2024-08-12 14:36:43,903] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.10108588635921478, 'eval_runtime': 11.8172, 'eval_samples_per_second': 2.708, 'eval_steps_per_second': 1.354, 'epoch': 1.47}\n",
      " 30%|████████████▌                             | 48/160 [08:53<18:57, 10.16s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:11<00:00,  1.39it/s]\u001b[A\n",
      "{'loss': 0.0385, 'grad_norm': 0.326171875, 'learning_rate': 0.00016845471059286887, 'epoch': 1.5}\n",
      "{'loss': 0.0509, 'grad_norm': 0.6015625, 'learning_rate': 0.00016691306063588583, 'epoch': 1.53}\n",
      "{'loss': 0.0351, 'grad_norm': 0.58203125, 'learning_rate': 0.00016534206039901057, 'epoch': 1.56}\n",
      "{'loss': 0.0279, 'grad_norm': 0.76171875, 'learning_rate': 0.000163742398974869, 'epoch': 1.59}\n",
      "{'loss': 0.0298, 'grad_norm': 0.427734375, 'learning_rate': 0.00016211477802783103, 'epoch': 1.62}\n",
      "{'loss': 0.0382, 'grad_norm': 0.443359375, 'learning_rate': 0.0001604599114862375, 'epoch': 1.65}\n",
      "{'loss': 0.0182, 'grad_norm': 0.32421875, 'learning_rate': 0.00015877852522924732, 'epoch': 1.68}\n",
      "{'loss': 0.0302, 'grad_norm': 0.447265625, 'learning_rate': 0.0001570713567684432, 'epoch': 1.71}\n",
      "{'loss': 0.0349, 'grad_norm': 0.48828125, 'learning_rate': 0.00015533915492433443, 'epoch': 1.74}\n",
      "{'loss': 0.0231, 'grad_norm': 0.396484375, 'learning_rate': 0.00015358267949789966, 'epoch': 1.78}\n",
      "{'loss': 0.0454, 'grad_norm': 0.53515625, 'learning_rate': 0.00015180270093731303, 'epoch': 1.81}\n",
      "{'loss': 0.054, 'grad_norm': 0.515625, 'learning_rate': 0.00015000000000000001, 'epoch': 1.84}\n",
      "{'loss': 0.0313, 'grad_norm': 0.5625, 'learning_rate': 0.00014817536741017152, 'epoch': 1.87}\n",
      "{'loss': 0.0196, 'grad_norm': 0.25, 'learning_rate': 0.00014632960351198618, 'epoch': 1.9}\n",
      "{'loss': 0.0359, 'grad_norm': 0.4609375, 'learning_rate': 0.00014446351791849276, 'epoch': 1.93}\n",
      "{'loss': 0.0277, 'grad_norm': 0.59765625, 'learning_rate': 0.00014257792915650728, 'epoch': 1.96}\n",
      " 40%|████████████████▊                         | 64/160 [11:35<16:13, 10.14s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.93it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:39:37,455] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.10450007766485214, 'eval_runtime': 11.5194, 'eval_samples_per_second': 2.778, 'eval_steps_per_second': 1.389, 'epoch': 1.96}\n",
      " 40%|████████████████▊                         | 64/160 [11:47<16:13, 10.14s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "{'loss': 0.0567, 'grad_norm': 0.8203125, 'learning_rate': 0.00014067366430758004, 'epoch': 1.99}\n",
      "{'loss': 0.0187, 'grad_norm': 0.376953125, 'learning_rate': 0.0001387515586452103, 'epoch': 2.02}\n",
      " 41%|█████████████████▎                        | 66/160 [12:08<19:55, 12.72s/it][2024-08-12 14:39:59,814] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 0.89 total_num_tokens per device: 959022\u001b[39m\n",
      "{'loss': 0.0154, 'grad_norm': 0.439453125, 'learning_rate': 0.00013681245526846783, 'epoch': 2.02}\n",
      "{'loss': 0.0156, 'grad_norm': 0.40625, 'learning_rate': 0.00013485720473218154, 'epoch': 2.05}\n",
      "{'loss': 0.017, 'grad_norm': 0.40234375, 'learning_rate': 0.00013288666467385833, 'epoch': 2.09}\n",
      "{'loss': 0.0108, 'grad_norm': 0.1376953125, 'learning_rate': 0.00013090169943749476, 'epoch': 2.12}\n",
      "{'loss': 0.0117, 'grad_norm': 0.19140625, 'learning_rate': 0.00012890317969444716, 'epoch': 2.15}\n",
      "{'loss': 0.0392, 'grad_norm': 0.75390625, 'learning_rate': 0.00012689198206152657, 'epoch': 2.18}\n",
      "{'loss': 0.0151, 'grad_norm': 1.828125, 'learning_rate': 0.0001248689887164855, 'epoch': 2.21}\n",
      "{'loss': 0.0272, 'grad_norm': 0.796875, 'learning_rate': 0.00012283508701106557, 'epoch': 2.24}\n",
      "{'loss': 0.0213, 'grad_norm': 0.2890625, 'learning_rate': 0.00012079116908177593, 'epoch': 2.27}\n",
      "{'loss': 0.0125, 'grad_norm': 0.240234375, 'learning_rate': 0.00011873813145857249, 'epoch': 2.3}\n",
      "{'loss': 0.0109, 'grad_norm': 0.28125, 'learning_rate': 0.00011667687467161024, 'epoch': 2.33}\n",
      "{'loss': 0.0188, 'grad_norm': 0.5234375, 'learning_rate': 0.00011460830285624118, 'epoch': 2.36}\n",
      "{'loss': 0.02, 'grad_norm': 0.408203125, 'learning_rate': 0.00011253332335643043, 'epoch': 2.4}\n",
      "{'loss': 0.0205, 'grad_norm': 0.28125, 'learning_rate': 0.00011045284632676536, 'epoch': 2.43}\n",
      " 50%|█████████████████████                     | 80/160 [14:28<13:31, 10.14s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.62it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.89it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.67it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.54it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.48it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.44it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.41it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.41it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:42:30,461] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1044221818447113, 'eval_runtime': 11.5683, 'eval_samples_per_second': 2.766, 'eval_steps_per_second': 1.383, 'epoch': 2.43}\n",
      " 50%|█████████████████████                     | 80/160 [14:40<13:31, 10.14s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "{'loss': 0.0292, 'grad_norm': 0.56640625, 'learning_rate': 0.00010836778433323158, 'epoch': 2.46}\n",
      "{'loss': 0.0125, 'grad_norm': 0.28125, 'learning_rate': 0.00010627905195293135, 'epoch': 2.49}\n",
      "{'loss': 0.0242, 'grad_norm': 0.431640625, 'learning_rate': 0.00010418756537291996, 'epoch': 2.52}\n",
      "{'loss': 0.0293, 'grad_norm': 0.69921875, 'learning_rate': 0.0001020942419883357, 'epoch': 2.55}\n",
      "{'loss': 0.0171, 'grad_norm': 0.369140625, 'learning_rate': 0.0001, 'epoch': 2.58}\n",
      "{'loss': 0.0107, 'grad_norm': 0.318359375, 'learning_rate': 9.790575801166432e-05, 'epoch': 2.61}\n",
      "{'loss': 0.0202, 'grad_norm': 0.279296875, 'learning_rate': 9.581243462708006e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0176, 'grad_norm': 0.5859375, 'learning_rate': 9.372094804706867e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0114, 'grad_norm': 0.2236328125, 'learning_rate': 9.163221566676847e-05, 'epoch': 2.71}\n",
      "{'loss': 0.016, 'grad_norm': 0.421875, 'learning_rate': 8.954715367323468e-05, 'epoch': 2.74}\n",
      "{'loss': 0.0129, 'grad_norm': 0.41015625, 'learning_rate': 8.746667664356956e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0083, 'grad_norm': 0.15234375, 'learning_rate': 8.539169714375885e-05, 'epoch': 2.8}\n",
      "{'loss': 0.0335, 'grad_norm': 0.79296875, 'learning_rate': 8.332312532838978e-05, 'epoch': 2.83}\n",
      "{'loss': 0.0183, 'grad_norm': 0.33984375, 'learning_rate': 8.126186854142752e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0126, 'grad_norm': 0.30859375, 'learning_rate': 7.920883091822408e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0202, 'grad_norm': 0.5234375, 'learning_rate': 7.716491298893442e-05, 'epoch': 2.92}\n",
      " 60%|█████████████████████████▏                | 96/160 [17:22<10:48, 10.14s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.74it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.93it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.54it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.49it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.41it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.41it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.40it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.39it/s]\u001b[A[2024-08-12 14:45:24,547] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.10333505272865295, 'eval_runtime': 11.5851, 'eval_samples_per_second': 2.762, 'eval_steps_per_second': 1.381, 'epoch': 2.92}\n",
      " 60%|█████████████████████████▏                | 96/160 [17:34<10:48, 10.14s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.39it/s]\u001b[A\n",
      "{'loss': 0.0366, 'grad_norm': 0.609375, 'learning_rate': 7.513101128351454e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0232, 'grad_norm': 0.431640625, 'learning_rate': 7.310801793847344e-05, 'epoch': 2.98}\n",
      "{'loss': 0.012, 'grad_norm': 0.283203125, 'learning_rate': 7.109682030555283e-05, 'epoch': 3.02}\n",
      " 62%|█████████████████████████▉                | 99/160 [18:05<12:12, 12.01s/it][2024-08-12 14:46:01,099] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 0.89 total_num_tokens per device: 959022\u001b[39m\n",
      "{'loss': 0.0082, 'grad_norm': 0.255859375, 'learning_rate': 6.909830056250527e-05, 'epoch': 3.02}\n",
      "{'loss': 0.0138, 'grad_norm': 0.39453125, 'learning_rate': 6.711333532614168e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0118, 'grad_norm': 0.2294921875, 'learning_rate': 6.51427952678185e-05, 'epoch': 3.08}\n",
      "{'loss': 0.005, 'grad_norm': 0.2734375, 'learning_rate': 6.318754473153221e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0078, 'grad_norm': 0.2314453125, 'learning_rate': 6.12484413547897e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0057, 'grad_norm': 0.119140625, 'learning_rate': 5.9326335692419995e-05, 'epoch': 3.17}\n",
      "{'loss': 0.01, 'grad_norm': 0.248046875, 'learning_rate': 5.7422070843492734e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0059, 'grad_norm': 0.16015625, 'learning_rate': 5.553648208150728e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0076, 'grad_norm': 0.1376953125, 'learning_rate': 5.3670396488013854e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0063, 'grad_norm': 0.13671875, 'learning_rate': 5.182463258982846e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0084, 'grad_norm': 0.1474609375, 'learning_rate': 5.000000000000002e-05, 'epoch': 3.33}\n",
      "{'loss': 0.009, 'grad_norm': 0.1767578125, 'learning_rate': 4.8197299062686995e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0134, 'grad_norm': 0.50390625, 'learning_rate': 4.6417320502100316e-05, 'epoch': 3.39}\n",
      " 70%|████████████████████████████▋            | 112/160 [20:17<08:07, 10.15s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.71it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.93it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:48:19,141] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1067156195640564, 'eval_runtime': 11.5256, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 1.388, 'epoch': 3.39}\n",
      " 70%|████████████████████████████▋            | 112/160 [20:28<08:07, 10.15s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "{'loss': 0.0093, 'grad_norm': 0.193359375, 'learning_rate': 4.46608450756656e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0039, 'grad_norm': 0.12353515625, 'learning_rate': 4.2928643231556844e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0026, 'grad_norm': 0.322265625, 'learning_rate': 4.12214747707527e-05, 'epoch': 3.48}\n",
      "{'loss': 0.0083, 'grad_norm': 0.1318359375, 'learning_rate': 3.954008851376252e-05, 'epoch': 3.51}\n",
      "{'loss': 0.0085, 'grad_norm': 0.451171875, 'learning_rate': 3.788522197216897e-05, 'epoch': 3.54}\n",
      "{'loss': 0.0084, 'grad_norm': 0.1328125, 'learning_rate': 3.6257601025131026e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0043, 'grad_norm': 0.15625, 'learning_rate': 3.465793960098945e-05, 'epoch': 3.6}\n",
      "{'loss': 0.0107, 'grad_norm': 0.56640625, 'learning_rate': 3.308693936411421e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0057, 'grad_norm': 0.1103515625, 'learning_rate': 3.154528940713113e-05, 'epoch': 3.67}\n",
      "{'loss': 0.0154, 'grad_norm': 0.38671875, 'learning_rate': 3.0033665948663448e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0023, 'grad_norm': 0.1591796875, 'learning_rate': 2.8552732036719687e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0061, 'grad_norm': 0.2236328125, 'learning_rate': 2.7103137257858868e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0089, 'grad_norm': 0.1376953125, 'learning_rate': 2.5685517452260567e-05, 'epoch': 3.79}\n",
      "{'loss': 0.0064, 'grad_norm': 0.23046875, 'learning_rate': 2.4300494434824373e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0041, 'grad_norm': 0.12890625, 'learning_rate': 2.2948675722421086e-05, 'epoch': 3.85}\n",
      "{'loss': 0.015, 'grad_norm': 0.4765625, 'learning_rate': 2.163065426741603e-05, 'epoch': 3.88}\n",
      " 80%|████████████████████████████████▊        | 128/160 [23:10<05:24, 10.15s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.93it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.41it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:51:12,749] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.10818994045257568, 'eval_runtime': 11.5266, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 1.388, 'epoch': 3.88}\n",
      " 80%|████████████████████████████████▊        | 128/160 [23:22<05:24, 10.15s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "{'loss': 0.0093, 'grad_norm': 0.244140625, 'learning_rate': 2.0347008197580374e-05, 'epoch': 3.91}\n",
      "{'loss': 0.0011, 'grad_norm': 0.059326171875, 'learning_rate': 1.9098300562505266e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0112, 'grad_norm': 0.2060546875, 'learning_rate': 1.78850790866296e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0072, 'grad_norm': 0.1630859375, 'learning_rate': 1.6707875928990058e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0181, 'grad_norm': 0.40625, 'learning_rate': 1.5567207449798515e-05, 'epoch': 4.04}\n",
      " 83%|██████████████████████████████████       | 133/160 [24:12<04:47, 10.65s/it][2024-08-12 14:52:02,998] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:4017307] [RANK:0] packing_efficiency_estimate: 0.89 total_num_tokens per device: 959022\u001b[39m\n",
      "{'loss': 0.01, 'grad_norm': 0.111328125, 'learning_rate': 1.4463573983949341e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0086, 'grad_norm': 0.083984375, 'learning_rate': 1.339745962155613e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0927734375, 'learning_rate': 1.2369331995613665e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0067, 'grad_norm': 0.1279296875, 'learning_rate': 1.1379642076878527e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0086, 'grad_norm': 0.1123046875, 'learning_rate': 1.042882397605871e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0037, 'grad_norm': 0.134765625, 'learning_rate': 9.517294753398064e-06, 'epoch': 4.19}\n",
      "{'loss': 0.0025, 'grad_norm': 0.09521484375, 'learning_rate': 8.645454235739903e-06, 'epoch': 4.22}\n",
      "{'loss': 0.004, 'grad_norm': 0.09375, 'learning_rate': 7.81368484114996e-06, 'epoch': 4.25}\n",
      "{'loss': 0.0034, 'grad_norm': 0.0849609375, 'learning_rate': 7.022351411174866e-06, 'epoch': 4.28}\n",
      "{'loss': 0.0076, 'grad_norm': 0.1416015625, 'learning_rate': 6.2718010508108545e-06, 'epoch': 4.31}\n",
      "{'loss': 0.0074, 'grad_norm': 0.1611328125, 'learning_rate': 5.562362976251901e-06, 'epoch': 4.34}\n",
      " 90%|████████████████████████████████████▉    | 144/160 [26:03<02:42, 10.13s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.92it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:54:05,585] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.10866738855838776, 'eval_runtime': 11.5266, 'eval_samples_per_second': 2.776, 'eval_steps_per_second': 1.388, 'epoch': 4.34}\n",
      " 90%|████████████████████████████████████▉    | 144/160 [26:15<02:42, 10.13s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "{'loss': 0.0065, 'grad_norm': 0.11328125, 'learning_rate': 4.8943483704846475e-06, 'epoch': 4.37}\n",
      "{'loss': 0.0137, 'grad_norm': 0.1484375, 'learning_rate': 4.268050246793276e-06, 'epoch': 4.4}\n",
      "{'loss': 0.0028, 'grad_norm': 0.06298828125, 'learning_rate': 3.68374332023419e-06, 'epoch': 4.43}\n",
      "{'loss': 0.0038, 'grad_norm': 0.10400390625, 'learning_rate': 3.1416838871368924e-06, 'epoch': 4.47}\n",
      "{'loss': 0.004, 'grad_norm': 0.1611328125, 'learning_rate': 2.6421097126839712e-06, 'epoch': 4.5}\n",
      "{'loss': 0.0058, 'grad_norm': 0.1337890625, 'learning_rate': 2.1852399266194314e-06, 'epoch': 4.53}\n",
      "{'loss': 0.002, 'grad_norm': 0.06103515625, 'learning_rate': 1.771274927131139e-06, 'epoch': 4.56}\n",
      "{'loss': 0.0014, 'grad_norm': 0.062255859375, 'learning_rate': 1.400396292949513e-06, 'epoch': 4.59}\n",
      "{'loss': 0.0086, 'grad_norm': 0.158203125, 'learning_rate': 1.0727667037011668e-06, 'epoch': 4.62}\n",
      "{'loss': 0.0057, 'grad_norm': 0.130859375, 'learning_rate': 7.885298685522235e-07, 'epoch': 4.65}\n",
      "{'loss': 0.0063, 'grad_norm': 0.0908203125, 'learning_rate': 5.478104631726711e-07, 'epoch': 4.68}\n",
      "{'loss': 0.0035, 'grad_norm': 0.1474609375, 'learning_rate': 3.50714075049563e-07, 'epoch': 4.71}\n",
      "{'loss': 0.0068, 'grad_norm': 0.11376953125, 'learning_rate': 1.973271571728441e-07, 'epoch': 4.74}\n",
      "{'loss': 0.0015, 'grad_norm': 0.05908203125, 'learning_rate': 8.771699011416168e-08, 'epoch': 4.78}\n",
      "{'loss': 0.0136, 'grad_norm': 0.138671875, 'learning_rate': 2.193165251545004e-08, 'epoch': 4.81}\n",
      "{'loss': 0.0032, 'grad_norm': 0.09912109375, 'learning_rate': 0.0, 'epoch': 4.84}\n",
      "100%|█████████████████████████████████████████| 160/160 [28:57<00:00, 10.10s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:05,  2.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:01<00:06,  1.93it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:02<00:07,  1.69it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:02<00:07,  1.55it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:03<00:06,  1.50it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:04<00:06,  1.45it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:05<00:05,  1.43it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:05<00:04,  1.42it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:06<00:04,  1.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:07<00:03,  1.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:07<00:02,  1.41it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:08<00:02,  1.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:09<00:01,  1.41it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:10<00:00,  1.40it/s]\u001b[A[2024-08-12 14:56:59,096] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:4017307] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.10866254568099976, 'eval_runtime': 11.5204, 'eval_samples_per_second': 2.778, 'eval_steps_per_second': 1.389, 'epoch': 4.84}\n",
      "100%|█████████████████████████████████████████| 160/160 [29:08<00:00, 10.10s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:10<00:00,  1.40it/s]\u001b[A\n",
      "{'train_runtime': 1749.5858, 'train_samples_per_second': 1.723, 'train_steps_per_second': 0.091, 'train_loss': 0.062338203515537316, 'epoch': 4.84}\n",
      "100%|█████████████████████████████████████████| 160/160 [29:09<00:00, 10.93s/it]\n",
      "[2024-08-12 14:56:59,897] [INFO] [axolotl.train.train:190] [PID:4017307] [RANK:0] Training Completed!!! Saving pre-trained model to ./out-Nous-Hermes-2-Mistral-7B-DPO\u001b[39m\n",
      "(PeftModelForCausalLM(   (base_model): LoraModel(     (model): MistralForCausalLM(       (model): MistralModel(         (embed_tokens): Embedding(32002, 4096)         (layers): ModuleList(           (0-31): 32 x MistralDecoderLayer(             (self_attn): MistralFlashAttention2(               (q_proj): lora.Linear(                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4096, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (k_proj): lora.Linear(                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=1024, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (v_proj): lora.Linear(                 (base_layer): Linear(in_features=4096, out_features=1024, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=1024, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (o_proj): lora.Linear(                 (base_layer): Linear(in_features=4096, out_features=4096, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4096, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (rotary_emb): MistralRotaryEmbedding()             )             (mlp): MistralMLP(               (gate_proj): lora.Linear(                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=14336, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (up_proj): lora.Linear(                 (base_layer): Linear(in_features=4096, out_features=14336, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4096, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=14336, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (down_proj): lora.Linear(                 (base_layer): Linear(in_features=14336, out_features=4096, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=14336, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4096, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (act_fn): SiLU()             )             (input_layernorm): MistralRMSNorm()             (post_attention_layernorm): MistralRMSNorm()           )         )         (norm): MistralRMSNorm()       )       (lm_head): Linear(in_features=4096, out_features=32002, bias=False)     )   ) ), LlamaTokenizerFast(name_or_path='NousResearch/Nous-Hermes-2-Mistral-7B-DPO', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '<|im_end|>', 'unk_token': '<unk>', 'pad_token': '</s>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={ \t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t32000: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t32001: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), })\n",
      "\u001b[0mCPU times: user 10.4 s, sys: 1.52 s, total: 11.9 s\n",
      "Wall time: 29min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/accelerate launch -m axolotl.cli.train {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [03:53<00:00, 77.95s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "qlora_model = f\"./out-{MODEL_SHORT_NAME}\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=False, padding_side='left')\n",
    "base_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME, device_map=\"auto\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").eval()\n",
    "model = PeftModel.from_pretrained(base_model, qlora_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the LoRA model (PEFT adapter) to HF Hub\n",
    "\n",
    "#hub_model_id = f\"NatLibFi/{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "#model.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the LoRA into the base model for inference\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('merged-Nous-Hermes-2-Mistral-7B-DPO/tokenizer_config.json',\n",
       " 'merged-Nous-Hermes-2-Mistral-7B-DPO/special_tokens_map.json',\n",
       " 'merged-Nous-Hermes-2-Mistral-7B-DPO/tokenizer.model',\n",
       " 'merged-Nous-Hermes-2-Mistral-7B-DPO/added_tokens.json')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the merged model to a directory (along with tokenizer)\n",
    "\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}\"\n",
    "model.save_pretrained(merged_model_dir)\n",
    "tokenizer.save_pretrained(merged_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BATCHED_LENGTH = 4096\n",
    "\n",
    "def generate(messages_batch):\n",
    "    texts = tokenizer.apply_chat_template(messages_batch, add_generation_prompt=True, tokenize=False)\n",
    "    inputs = tokenizer(texts, padding=\"longest\", return_tensors=\"pt\")\n",
    "    inputs = {key: val.cuda() for key, val in inputs.items()}\n",
    "    if len(messages_batch) > 1 and inputs['input_ids'].shape[1] > MAX_BATCHED_LENGTH:\n",
    "        # there are long documents in the batch - break it down to two smaller batches to avoid excessive padding and related problems\n",
    "        half = int(len(messages_batch) / 2)\n",
    "        return generate(messages_batch[:half]) + generate(messages_batch[half:])\n",
    "    temp_texts=tokenizer.batch_decode(inputs[\"input_ids\"], skip_special_tokens=True)\n",
    "\n",
    "    gen_tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
    "    return [i[len(temp_texts[idx]):] for idx, i in enumerate(gen_text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Ammattikielisten tekstien tutkimisesta - esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Katajam\\u00e4ki, Heli\", \"Koskela, Merja\"], \"year\": \"2012\", \"publisher\": [\"Kotimaisten kielten keskus\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Ammattikielisten tekstien tutkimisesta : esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Koskela, Merja\", \"Katajam\\u00e4ki, Heli\"], \"year\": \"2012\", \"publisher\": [\"Kotimaisten kielten keskus\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"FAQ : Taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t\", \"year\": \"2018\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"e-isbn\": [\"9789527266076\"], \"p-issn\": \"1456-002X\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t 2018 : FAQ\", \"creator\": [\"Bredenberg, Timo\", \"Suonp\\u00e4\\u00e4, Juha\"], \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"e-isbn\": [\"9789527266076\"], \"e-issn\": \"1456-002X\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Julkisen tilan taiteen tilasta. Puheenvuoroja julkisen taiteen konteksteista\", \"year\": \"2021\", \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"T\\u00e4m\\u00e4 kirja : koostuu artikkeleista ja puheenvuoroista julkisesta taiteesta, sen ajankohtaisista ilmi\\u00f6ist\\u00e4 ja tulevaisuuden suunnista\", \"year\": \"2021\", \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Karelia.fi - Karelia-ammattikorkeakoulun tutkimus- ja kehitt\\u00e4mistoimintaa EU-ohjelmakaudella 2014-2020\", \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Karelia-ammattikorkeakoulu : tutkimus- ja kehitt\\u00e4mistoimintaa EU-ohjelmakaudella 2014-2020\", \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-issn\": \"2323-8461\", \"p-issn\": \"2323-8453\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia  Kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Kulttuurituotannon ty\\u00f6papereita : kehitt\\u00e4misty\\u00f6st\\u00e4 oivallluksi\", \"creator\": [\"Halonen, Katri\"], \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : Kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Kulttuurituotannon ty\\u00f6papereita : kehitt\\u00e4misty\\u00f6st\\u00e4 oivallluksiat\", \"creator\": [\"Halonen, Katri\"], \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Monimuotoinen ansioty\\u00f6 : N\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"year\": \"2022\", \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Monimuotoinen ansioty\\u00f6 : n\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"year\": \"2022\", \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Osuma-peli \\u2013 Innostusta yhteiskehittelyyn!\", \"creator\": [\"Halonen, Katri\", \"Salmenkangas, Mai\", \"Wallin, Riikka\"], \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Osuma-peli : Innostusta yhteiskehittelyyn!\", \"creator\": [\"Halonen, Katri\", \"Salmenkangas, Mai\", \"Wallin, Riikka\"], \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Pk-yritysten liiketoiminnan muotoilun CookBook\", \"creator\": [\"Jaakola, Hanna\", \"Pietik\\u00e4inen, Minna\", \"Rinta-Jouppi, Laura\", \"Viljanen, Jenni\"], \"year\": \"2021\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Liiketoiminnan muotoilun CookBook\", \"creator\": [\"Jaakola, Hanna\", \"Pietik\\u00e4inen, Minna\", \"Rinta-Jouppi, Laura\", \"Viljanen, Jenni\"], \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Suomen Pankki 200 vuotta II: Parlamentin pankki\", \"creator\": [\"Kuuster\\u00e4, Antti\", \"Tarkka, Juha\"], \"year\": \"2012\", \"publisher\": [\"Otava\"], \"e-isbn\": [\"9789511242727\"], \"p-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Suomen Pankki 200 vuotta : parlamentin pankki\", \"creator\": [\"Kuuster\\u00e4, Antti\", \"Tarkka, Juha\"], \"year\": \"2014\", \"publisher\": [\"Suomen Pankki\"], \"e-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4rittelyt\", \"creator\": [\"Aalto, Anna\", \"Virkkunen, Heikki\", \"Turunen, Seppo\", \"Saarela, Hanna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4rittelyt\", \"creator\": [\"Aalto, Anna\", \"Virkkunen, Heikki\", \"Turunen, Seppo\", \"Saarela, Hanna-Leena\", \"R\\u00e4ty, Tarja\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"TARU-SANOMAT\", \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"e-issn\": \"2490-2055\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Taruateatteri ja taiteelliset menetelm\\u00e4t opetuksessa\", \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset\", \"creator\": [\"Haarala, P\\u00e4ivi\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"e-issn\": \"2669-8021\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset\", \"creator\": [\"Haarala, P\\u00e4ivi\"], \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"e-issn\": \"2669-8021\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Editorial\", \"creator\": [\"Illman, Ruth\", \"Lundgren, Svante\"], \"type_coar\": \"editorial\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Nordisk judaistik \\u2022 Scandinavian Jewish Studies\", \"year\": \"2020\", \"type_coar\": \"editorial\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Judiskt liv i Helsingfors\", \"creator\": [\"Lundgren, Svante\"], \"type_coar\": \"book review\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Judiskt liv i Helsingfors\", \"creator\": [\"Lundgren, Svante\"], \"year\": \"2020\", \"type_coar\": \"book review\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Mod och gl\\u00e4dje att prata svenska online\", \"creator\": [\"Linna, Mari\", \"Mets\\u00e4vainio, Marita\", \"Valtonen, Ida\", \"Kazaka, Signe\", \"Kihlbom, Liselotte\", \"Lempinen, Katja\", \"Suvila, Jari\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Mod och gl\\u00e4dje att prata svenska online\", \"creator\": [\"Linna, Mari\", \"Mets\\u00e4vainio, Marita\", \"Valtonen, Ida\", \"Kazaka, Signe\", \"Kihlbom, Liselotte\", \"Lempinen, Katja\", \"Suvila, Jari\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Torka eller ensilera? Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Yvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Torka eller ensilera? Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Yvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"V\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\", \"creator\": [\"\\u00c5kerback, Nina\", \"\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"Engblom, Sten\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"V\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\", \"creator\": [\"\\u00c5kerback, Nina\", \"\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"Engblom, Sten\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"\\u2018The wrath of God on children of disobedience\\u2019\", \"creator\": [\"\\u00d6stling, Erik\"], \"year\": \"2021\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"\\u2018The wrath of God on children of disobedience\\u2019\", \"creator\": [\"\\u00d6stling, Erik A. W.\"], \"year\": \"2021\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"\\\"Great Horizons Flooded with the Alien Light of the Sun\\\" : Le Sacre du Printemps in the Russian context\", \"creator\": [\"J\\u00e4rvinen, Hanna\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"\\u2264Great Horizons Flooded with the Alien Light of the Sun\\u2265: Le Sacre du Printemps in the Russian context\", \"creator\": [\"J\\u00e4rvinen, Timo\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A Dynamic Collusion Analysis Framework Considering Generation and Transmission Systems Maintenance Constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/EEM49802.2020.9221905\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Dynamic Collusion Analysis Framework Considering Generation and Transmission Systems Maintenance Constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/IES-SMC.2020.8939222\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A review of optical nondestructive visual and near-infrared methods for food quality and safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\", \"Mantere, Timo\"], \"year\": \"2013\", \"publisher\": [\"Hindawi\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Review of Optical Nondestructive Visual and Near-Infrared Methods for Food Quality and Safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\", \"Mantere, Timo\"], \"year\": \"2013\", \"publisher\": [\"Hindawi Publishing Corporation\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Assessing Trustworthy AI in times of COVID-19. Deep Learning for predicting a multi-regional score conveying the degree of lung compromise in COVID-19 patients\", \"creator\": [\"Allahabadi, Himanshi\", \"Amann, Julia\", \"Balot, Isabelle\", \"Beretta, Andrea\", \"Binkley, Charles\", \"Bozenhard, Jonas\", \"Bruneault, Fr\\u00e9d\\u00e9rick\", \"Brusseau, James\", \"Candemir, Sema\", \"Cappellini, Luca Alessandro\", \"Castagnet, Genevieve Fieux\", \"Chakraborty, Subrata\", \"Cherciu, Nicoleta\", \"Cociancig, Christina\", \"Coffee, Megan\", \"Ek, Irene\", \"Espinosa-Leal, Leonardo\", \"Farina, Davide\", \"Fieux-Castagnet, Genevieve\", \"Frauenfelder, Thomas\", \"Gallucci, Alessio\", \"Giuliani, Guya\", \"Golda, Adam\", \"van Halem, Irmhild\", \"Hildt, Elisabeth\", \"Holm, Sune\", \"Kararigas, Georgios\", \"Krier, Sebastien A.\", \"K\\u00fchne, Ulrich\", \"Lizzi, Francesca\", \"Madai, Vince I.\", \"Markus, Aniek F.\", \"Masis, Serg\", \"Mathez, Emilie Wiinblad\", \"Mureddu, Francesco\", \"Neri, Emanuele\", \"Osika, Walter\", \"Ozols, Matiss\", \"Panigutti, Cecilia\", \"Parent, Brendan\", \"Pratesi, Francesca\", \"Moreno-S\\u00e1nchez, Pedro A.\", \"Sartor, Giovanni\", \"Savardi, Mattia\", \"Signoroni, Alberto\", \"Sormunen, Hanna\", \"Spezzatti, Andy\", \"Srivastava, Adarsh\", \"Stephansen, Annette F.\", \"Theng, Lau Bee\", \"Tithi, Jesmin Jahan\", \"Tuominen, Jarno\", \"Umbrello, Steven\", \"Vaccher, Filippo\", \"Vetter, Dennis\", \"Westerlund, Magnus\", \"Wurth, Renee\", \"Zicari, Roberto V.\"], \"year\": \"2022\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/TTS.2022.3195114\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Assessing Trustworthy AI in times of COVID-19. Deep Learning for predicting a multi-regional score conveying the degree of lung compromise in COVID-19 patients\", \"creator\": [\"Westerlund, Magnus\", \"Wurth, Renee\", \"Zicari, Roberto V.\"], \"year\": \"2022\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/TTS.2022.3195114\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring : a qualitative study\", \"creator\": [\"Korhonen, H.\", \"Tuomikoski, A-M.\", \"Oikarainen, A.\", \"K\\u00e4\\u00e4ri\\u00e4inen, M.\", \"Elo, S.\", \"Kyng\\u00e4s, H.\", \"Liikanen, E.\", \"Mikkonen, K.\"], \"year\": \"2019\", \"doi\": \"10.1016/j.nepr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring: a qualitative study\", \"creator\": [\"Korhonen, Hannele\", \"Tuomikoski, Anu-Maija\", \"Oikarainen, Anu\", \"K\\u00e4\\u00e4ri\\u00e4inen, Matti\", \"Elo, Sari\", \"Kyng\\u00e4s, Hannele\", \"Liikanen, Eeva\", \"Mikkonen, Kaisa\"], \"year\": \"2019\", \"doi\": \"10.1016/j.nepr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Engaging audio based mobile applications\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"e-isbn\": [\"9788409147557\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Engaging audio based mobile applications\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"publisher\": [\"International Conference on Education, Research and Innovation (ICERI)\"], \"e-isbn\": [\"9788409147557\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Epistemically tuned-in?\", \"creator\": [\"St\\u00e5hl, Tore\"], \"year\": \"2020\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Epistemically Tuned-in?\", \"creator\": [\"St\\u00e5hl, Tore\"], \"year\": \"2020\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"In the shadows : Phenomenological choreographic writing\", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"doi\": \"10.1386/chor_00042_1\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"In the Shadows : Phenomenological Choreographic Writing\", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"publisher\": [\"Intellect\"], \"doi\": \"10.1386/chor_00042_1\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"MARISA Ethical, Legal and Societal Aspects\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"European Commission\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"MARISA legal, ethical and societal aspects (Final version)\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"European Commission\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Memories from the EAHIL Workshop\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Katri\", \"Mann, Mala\", \"Ferrinho, Ana Maria\", \"Ottjes, Robin\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Memories from the EAHIL Workshop \\u201cLearn, Share, Act, Bridge Borders\\u201d 17-20 June 2019, Basel, Switzerland\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Katri\", \"Mann, Mala\", \"Ferrinho, Ana Maria\", \"Ottjes, Robin\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Supporting Transformative Agency among Urban Actors in the Change Laboratory Intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"e-issn\": \"2328-4919\", \"p-issn\": \"2328-4900\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Supporting Transformative Agency among Urban Actors in the Change Laboratory Intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"The roles of temperature, nest predators and information parasites for geographical variation in egg covering behaviour of tits (Paridae)\", \"creator\": [\"Loukola, Olli J.\", \"Adamik, Peter\", \"Adriaensen, Frank\", \"Barba, Emilio\", \"Doligez, Blandine\", \"Flensted-Jensen, Einar\", \"Eeva, Tapio\", \"Kivel\\u00e4, Sami M.\", \"Laaksonen, Toni\", \"Morosinotto, Chiara\", \"M\\u00e4nd, Raivo\", \"Niemel\\u00e4, Petri T.\", \"Reme\\u0161, Vladimir\", \"Samplonius, Jelmer M.\", \"Sebastiano, Manrico\", \"Senar, Juan Carlos\", \"Slagsvold, Tore\", \"Sorace, Alberto\", \"Tschirren, Barbara\", \"T\\u00f6r\\u00f6k, J\\u00e1nos\", \"Forsman, Jukka T.\"], \"year\": \"2020\", \"publisher\": [\"John Wiley & Sons\"], \"doi\": \"10.1111/jbi.13830\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Egg covering in great and blue tits across Europe : roles of temperature, nest predation and information use\", \"creator\": [\"Loukola, Olli J.\", \"Adam, Peter\", \"Barbieri, Massimo\", \"Both, Cornel\", \"Braun, Thomas\"], \"year\": \"2020\", \"publisher\": [\"John Wiley & Sons\"], \"doi\": \"10.1111/j.1558-5646.2019.12605\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Why Is CryptoKitties (Not) Gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Why Is CryptoKitties (Not) Gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Demokrati och handel : En empirisk studie \\u00f6ver hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Demokrati och handel : En empirisk studie \\u00f6ver hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"EN L\\u00c5NG RESA En litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av br\\u00f6stcancer\", \"creator\": [\"Zvidrina, Arita\", \"Uzelac-Varda, Silvija\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"En l\\u00e5ng resa : En litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av br\\u00f6stcancer\", \"creator\": [\"Uzelac-Varda, Silvija\", \"Zvidrina, Arita\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Fr\\u00e5n \\u00c5lands Sj\\u00f6fartsl\\u00e4roverk till H\\u00f6gskolan p\\u00e5 \\u00c5land: En studie om intresset f\\u00f6r sj\\u00f6kaptensstudier \\u00f6ver tid\", \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Fr\\u00e5n \\u00c5lands Sj\\u00f6fartsl\\u00e4roverk till H\\u00f6gskolan p\\u00e5 \\u00c5land : En studie om intresset f\\u00f6r sj\\u00f6kaptensstudier \\u00f6ver tid.\", \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhantering - modell och praktik\", \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhanteringen - modell och praktik\", \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"GDPR i praktiken\", \"creator\": [\"Kahrimanovic, Arnel\", \"Mesic, Selma\"], \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"GDPR i praktiken\", \"creator\": [\"Kahrimanovic, Arnel\", \"Mesic, Selma\"], \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00e5llbara ink\\u00f6p hos tv\\u00e5 \\u00e5l\\u00e4ndska f\\u00f6retag : verksamma inom plastindustrin\", \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00e5llbara ink\\u00f6p hos tv\\u00e5 \\u00e5l\\u00e4ndska f\\u00f6retag - verksamma inom plastindustrin\", \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor \\u00f6ver tid\", \"creator\": [\"Backlund, Emma\", \"\\u00c5kerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor \\u00f6ver tid\", \"creator\": [\"Backlund, Emma\", \"Akerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rares synvinkel : En intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rarens synvinkel \\u2013 en intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av  processer i IT-f\\u00f6retag: En modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring\", \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av processer i IT-f\\u00f6retag : En modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring\", \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Monitorering av biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Holmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Monitorering av biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Holmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Musik och r\\u00f6relse som plattform f\\u00f6r kreativitet : en intervjustudie med fyra l\\u00e4rare i \\u00e5rskurserna 7-9\", \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Sibelius-Akademin, Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Musik och r\\u00f6relse som plattform f\\u00f6r kreativitet : En intervjustudie med fyra l\\u00e4rare i \\u00e5rskurserna 7-\\u00ad\\u20109\", \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Sibelius-\\u00ad\\u2010Akademin, Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Naturliga, rytmiska och holistiska individer : Diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Naturliga, rytmiska och holistiska individer : Diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Orderhantering f\\u00f6r  automationstruckssystem med  Siemens S7-1500 Logik\", \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Orderhantering f\\u00f6r automationstruckssystem med Siemens S7-1500 Logik\", \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Resultatmanipulering : En studie om f\\u00f6ruts\\u00e4ttningarna p\\u00e5 den finska marknaden\", \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Resultatmanipulation : en studie av periodiseringar av resultatet p\\u00e5 f\\u00f6retag i OMX\", \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"Akademiska f\\u00f6reningss\\u00e4tet i G\\u00f6teborg\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? : Ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? Ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Vikingakvinnan som husmor: En filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa universitet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Vikingakvinnan som husmor : En filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa universitet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A Discourse Analytic Approach to HEI Leadership in Finland : The What and How of Rectors\\u2019 Leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521241864\", \"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Discourse Analytic Approach to HEI Leadership in Finland : The What and How of Rectors' Leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521241864\"], \"p-isbn\": [\"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A Jungian Theory of Mind : Individuality, lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Jungian Theory of Mind : Individuality lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Aminophenolato complexes of Mo, W and V In catalytic alkene epoxidation and catechol oxidation\", \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Aminophenolato complexes of Mo, W, and V in catalytic alkene epoxidation and catechol oxidation\", \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : A population-based study\", \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : A population-based study\", \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"University of Helsinki\"], \"e-isbn\": [\"9789515176912\"], \"p-isbn\": [\"9789515176905\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"University of Helsinki\"], \"e-isbn\": [\"9789515176912\"], \"p-isbn\": [\"9789515176905\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Employee trust repair in the context of organizational change \\u2013 identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Employee trust repair in the context of organizational change : identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Essays on economic productivity\", \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Essays on Economic Productivity\", \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Light Field Compression Using Disparity-Based 4D Predictive Coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Light Field Compression Using Disparity-Based 4D Predictive Coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Light Manipulation in Multilayer Metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Light Manipulation in Multilayer Metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Performance Exploration and Testing of Web-based Software Systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239991\"], \"p-isbn\": [\"9789521240003\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Performance Exploration and Testing of Web-based Software Systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521240003\"], \"p-isbn\": [\"9789521239991\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Power of Myths in Energy Transition : Unveiling Timeless Mythologies in Finnish Energy Agora\", \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"University of Vaasa\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Power of Myths in Energy Transition : Unveiling Timeless Mythologies in Finnish Energy Agora\", \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"University of Vaasa\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Problem gambling in a Nordic context : Moving from social factors to a psychosocial perspective\", \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521238700\"], \"p-isbn\": [\"9789521238694\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Problem gambling in a Nordic context : Moving from social factors to a psychosocial perspective\", \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521238700\"], \"p-isbn\": [\"9789521238694\"], \"type_coar\": \"doctoral thesis\"}\n",
      "CPU times: user 3min 11s, sys: 9.07 s, total: 3min 20s\n",
      "Wall time: 3min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "from itertools import batched\n",
    "\n",
    "#BATCH_SIZE = 8  # requires ~30GB VRAM\n",
    "BATCH_SIZE = 16  # requires ~41GB VRAM\n",
    "\n",
    "def rec_to_messages(rec):\n",
    "    return [\n",
    "        {\"role\": msg[\"from\"], \"content\": msg[\"value\"]}\n",
    "        for msg in rec[\"conversations\"]\n",
    "        if msg[\"from\"] != \"gpt\"\n",
    "    ]\n",
    "\n",
    "# read the eval records from file\n",
    "test_recs = []\n",
    "with open(\"axolotl-test.jsonl\") as testfile:\n",
    "    for line in testfile:\n",
    "        test_recs.append(json.loads(line))\n",
    "\n",
    "#with open(f'test-records-{MODEL_SHORT_NAME}-slice{SLICE}.jsonl', 'w') as outfile:\n",
    "with open(f'test-records-{MODEL_SHORT_NAME}.jsonl', 'w') as outfile:\n",
    "\n",
    "    for batchno, rec_batch in enumerate(batched(test_recs[:64], BATCH_SIZE)):\n",
    "        messages_batch = [rec_to_messages(rec) for rec in rec_batch]\n",
    "        responses = generate(messages_batch)\n",
    "        gt_batch = [rec['conversations'][-1][\"value\"] for rec in rec_batch]\n",
    "\n",
    "        for ground_truth, response in zip(gt_batch, responses):\n",
    "            print(100 * \"-\")\n",
    "            print(\"Ground Truth:\")\n",
    "            print(ground_truth)\n",
    "            print(\"Prediction:\")\n",
    "            print(response)\n",
    "\n",
    "            ground_truth = json.loads(ground_truth)\n",
    "\n",
    "            try:\n",
    "                prediction = json.loads(response)\n",
    "            except json.JSONDecodeError:\n",
    "                prediction = {}\n",
    "        \n",
    "            # rowid is set to unknown as we've lost it somewhere along the way...\n",
    "            record = {\"ground_truth\": ground_truth, \"prediction\": prediction, \"rowid\": \"unknown\"}\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the statistics of the extracted metadata and save to file\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from eval import MetadataEvaluator\n",
    "\n",
    "#evaluator = MetadataEvaluator(f'test-records-{MODEL_SHORT_NAME}-slice{SLICE}.jsonl')\n",
    "evaluator = MetadataEvaluator(f'test-records-{MODEL_SHORT_NAME}.jsonl')\n",
    "results = evaluator.evaluate_records() #prediction_records[:9])\n",
    "\n",
    "#statistics_filename = f'../results-axolotl-{MODEL_SHORT_NAME}-slice{SLICE}.md'\n",
    "statistics_filename = f'../results-axolotl-{MODEL_SHORT_NAME}.md'\n",
    "evaluator.save_md(results, statistics_filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%%time\n",
    "\n",
    "# quantize/convert the merged model to exl2 using exllamav2 tools\n",
    "\n",
    "EXLLAMAV2_PATH = \"../exllamav2-tabbyapi/exllamav2\"\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}\"\n",
    "bits_per_weight = \"6.5\"\n",
    "temp_dir = f\"temp-{MODEL_SHORT_NAME}\"\n",
    "exl2_model_dir = f\"exl2-{MODEL_SHORT_NAME}-{bits_per_weight}\"\n",
    "\n",
    "!mkdir {temp_dir}\n",
    "!{EXLLAMAV2_PATH}/../venv/bin/python {EXLLAMAV2_PATH}/convert.py -i {merged_model_dir} -o {temp_dir} -cf {exl2_model_dir} -nr -b {bits_per_weight}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: merged-Nous-Hermes-2-Mistral-7B-DPO\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model weight map from 'model.safetensors.index.json'\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00001-of-00003.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,           torch.float16 --> F16, shape = {4096, 32002}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,       torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,       torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,         torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,       torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,    torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,         torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,         torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00002-of-00003.safetensors'\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model-00003-of-00003.safetensors'\n",
      "INFO:hf-to-gguf:output.weight,               torch.float16 --> F16, shape = {4096, 32002}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.24.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.24.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.24.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.24.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.25.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.25.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.25.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.25.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.26.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.26.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.26.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.26.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.27.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.27.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.27.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.27.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.28.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.28.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.28.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.28.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.29.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.29.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.29.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.29.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.30.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.30.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.30.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.30.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_norm.weight,     torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_down.weight,      torch.float16 --> F16, shape = {14336, 4096}\n",
      "INFO:hf-to-gguf:blk.31.ffn_gate.weight,      torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_up.weight,        torch.float16 --> F16, shape = {4096, 14336}\n",
      "INFO:hf-to-gguf:blk.31.ffn_norm.weight,      torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_k.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:blk.31.attn_output.weight,   torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_q.weight,        torch.float16 --> F16, shape = {4096, 4096}\n",
      "INFO:hf-to-gguf:blk.31.attn_v.weight,        torch.float16 --> F16, shape = {4096, 1024}\n",
      "INFO:hf-to-gguf:output_norm.weight,          torch.float16 --> F32, shape = {4096}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 32768\n",
      "INFO:hf-to-gguf:gguf: embedding length = 4096\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 14336\n",
      "INFO:hf-to-gguf:gguf: head count = 32\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 8\n",
      "INFO:hf-to-gguf:gguf: rope theta = 10000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-05\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Setting special token type bos to 1\n",
      "INFO:gguf.vocab:Setting special token type eos to 32000\n",
      "INFO:gguf.vocab:Setting add_bos_token to True\n",
      "INFO:gguf.vocab:Setting add_eos_token to False\n",
      "INFO:gguf.vocab:Setting chat_template to {{bos_token}}{% for message in messages %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Nous-Hermes-2-Mistral-7B-DPO-FinGreyLit-f16.gguf: n_tensors = 291, total_size = 14.5G\n",
      "Writing: 100%|██████████████████████████| 14.5G/14.5G [00:11<00:00, 1.32Gbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Nous-Hermes-2-Mistral-7B-DPO-FinGreyLit-f16.gguf\n",
      "CPU times: user 180 ms, sys: 52.7 ms, total: 232 ms\n",
      "Wall time: 17.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert the merged model to GGUF using llama.cpp tools (installed separately)\n",
    "\n",
    "LLAMA_CPP_PATH = \"../../../llama.cpp\"\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/venv/bin/python {LLAMA_CPP_PATH}/convert_hf_to_gguf.py {merged_model_dir} --outfile {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: build = 3492 (7c27a19b)\n",
      "main: built with cc (GCC) 13.3.0 for x86_64-pc-linux-gnu\n",
      "main: quantizing 'Nous-Hermes-2-Mistral-7B-DPO-FinGreyLit-f16.gguf' to 'Nous-Hermes-2-Mistral-7B-DPO-FinGreyLit-Q6_K.gguf' as Q6_K\n",
      "llama_model_loader: loaded meta data with 32 key-value pairs and 291 tensors from Nous-Hermes-2-Mistral-7B-DPO-FinGreyLit-f16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Nous Hermes 2 Mistral 7B DPO\n",
      "llama_model_loader: - kv   3:                       general.organization str              = NousResearch\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = DPO\n",
      "llama_model_loader: - kv   5:                           general.basename str              = Nous-Hermes-2-Mistral\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 7B\n",
      "llama_model_loader: - kv   7:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   8:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   9:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv  10:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv  11:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv  12:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv  13:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  14:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  15:                 llama.attention.key_length u32              = 128\n",
      "llama_model_loader: - kv  16:               llama.attention.value_length u32              = 128\n",
      "llama_model_loader: - kv  17:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  18:                           llama.vocab_size u32              = 32002\n",
      "llama_model_loader: - kv  19:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv  20:            tokenizer.ggml.add_space_prefix bool             = true\n",
      "llama_model_loader: - kv  21:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  22:                         tokenizer.ggml.pre str              = default\n",
      "llama_model_loader: - kv  23:                      tokenizer.ggml.tokens arr[str,32002]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  24:                      tokenizer.ggml.scores arr[f32,32002]   = [-1000.000000, -1000.000000, -1000.00...\n",
      "llama_model_loader: - kv  25:                  tokenizer.ggml.token_type arr[i32,32002]   = [3, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  26:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  27:                tokenizer.ggml.eos_token_id u32              = 32000\n",
      "llama_model_loader: - kv  28:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  29:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  30:                    tokenizer.chat_template str              = {{bos_token}}{% for message in messag...\n",
      "llama_model_loader: - kv  31:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type  f16:  226 tensors\n",
      "[   1/ 291]                    token_embd.weight - [ 4096, 32002,     1,     1], type =    f16, converting to q6_K .. size =   250.02 MiB ->   102.55 MiB\n",
      "[   2/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   3/ 291]                blk.0.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[   4/ 291]                blk.0.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[   5/ 291]                  blk.0.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[   6/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[   7/ 291]                  blk.0.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[   8/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[   9/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  10/ 291]                  blk.0.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  11/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  12/ 291]                blk.1.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  13/ 291]                blk.1.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  14/ 291]                  blk.1.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  15/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  16/ 291]                  blk.1.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  17/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  18/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  19/ 291]                  blk.1.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  20/ 291]               blk.10.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  21/ 291]                 blk.10.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  22/ 291]                 blk.10.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  23/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  24/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  25/ 291]                 blk.10.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  26/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  27/ 291]                blk.2.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  28/ 291]                blk.2.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  29/ 291]                  blk.2.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  30/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  31/ 291]                  blk.2.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  32/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  33/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  34/ 291]                  blk.2.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  35/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  36/ 291]                blk.3.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  37/ 291]                blk.3.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  38/ 291]                  blk.3.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  39/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  40/ 291]                  blk.3.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  41/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  42/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  43/ 291]                  blk.3.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  44/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  45/ 291]                blk.4.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  46/ 291]                blk.4.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  47/ 291]                  blk.4.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  48/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  49/ 291]                  blk.4.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  50/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  51/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  52/ 291]                  blk.4.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  53/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  54/ 291]                blk.5.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  55/ 291]                blk.5.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  56/ 291]                  blk.5.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  57/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  58/ 291]                  blk.5.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  59/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  60/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  61/ 291]                  blk.5.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  62/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  63/ 291]                blk.6.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  64/ 291]                blk.6.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  65/ 291]                  blk.6.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  66/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  67/ 291]                  blk.6.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  68/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  69/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  70/ 291]                  blk.6.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  71/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  72/ 291]                blk.7.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  73/ 291]                blk.7.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  74/ 291]                  blk.7.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  75/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  76/ 291]                  blk.7.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  77/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  78/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  79/ 291]                  blk.7.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  80/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  81/ 291]                blk.8.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  82/ 291]                blk.8.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  83/ 291]                  blk.8.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  84/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  85/ 291]                  blk.8.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  86/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  87/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  88/ 291]                  blk.8.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  89/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  90/ 291]                blk.9.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  91/ 291]                blk.9.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  92/ 291]                  blk.9.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[  93/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  94/ 291]                  blk.9.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  95/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  96/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[  97/ 291]                  blk.9.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[  98/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[  99/ 291]               blk.10.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 100/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 101/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 102/ 291]               blk.11.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 103/ 291]               blk.11.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 104/ 291]                 blk.11.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 105/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 106/ 291]                 blk.11.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 107/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 108/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 109/ 291]                 blk.11.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 110/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 111/ 291]               blk.12.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 112/ 291]               blk.12.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 113/ 291]                 blk.12.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 114/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 115/ 291]                 blk.12.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 116/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 117/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 118/ 291]                 blk.12.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 119/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 120/ 291]               blk.13.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 121/ 291]               blk.13.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 122/ 291]                 blk.13.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 123/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 124/ 291]                 blk.13.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 125/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 126/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 127/ 291]                 blk.13.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 128/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 129/ 291]               blk.14.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 130/ 291]               blk.14.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 131/ 291]                 blk.14.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 132/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 133/ 291]                 blk.14.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 134/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 135/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 136/ 291]                 blk.14.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 137/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 138/ 291]               blk.15.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 139/ 291]               blk.15.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 140/ 291]                 blk.15.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 141/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 142/ 291]                 blk.15.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 143/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 144/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 145/ 291]                 blk.15.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 146/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 147/ 291]               blk.16.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 148/ 291]               blk.16.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 149/ 291]                 blk.16.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 150/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 151/ 291]                 blk.16.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 152/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 153/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 154/ 291]                 blk.16.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 155/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 156/ 291]               blk.17.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 157/ 291]               blk.17.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 158/ 291]                 blk.17.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 159/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 160/ 291]                 blk.17.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 161/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 162/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 163/ 291]                 blk.17.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 164/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 165/ 291]               blk.18.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 166/ 291]               blk.18.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 167/ 291]                 blk.18.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 168/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 169/ 291]                 blk.18.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 170/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 171/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 172/ 291]                 blk.18.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 173/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 174/ 291]               blk.19.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 175/ 291]               blk.19.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 176/ 291]                 blk.19.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 177/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 178/ 291]                 blk.19.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 179/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 180/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 181/ 291]                 blk.19.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 182/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 183/ 291]               blk.20.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 184/ 291]               blk.20.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 185/ 291]                 blk.20.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 186/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 187/ 291]                 blk.20.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 188/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 189/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 190/ 291]                 blk.20.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 191/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 192/ 291]               blk.21.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 193/ 291]               blk.21.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 194/ 291]                 blk.21.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 195/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 196/ 291]                 blk.21.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 197/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 198/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 199/ 291]                 blk.21.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 200/ 291]                 blk.22.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 201/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 202/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 203/ 291]                 blk.22.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 204/ 291]                        output.weight - [ 4096, 32002,     1,     1], type =    f16, converting to q6_K .. size =   250.02 MiB ->   102.55 MiB\n",
      "[ 205/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 206/ 291]               blk.22.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 207/ 291]               blk.22.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 208/ 291]                 blk.22.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 209/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 210/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 211/ 291]               blk.23.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 212/ 291]               blk.23.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 213/ 291]                 blk.23.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 214/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 215/ 291]                 blk.23.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 216/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 217/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 218/ 291]                 blk.23.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 219/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 220/ 291]               blk.24.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 221/ 291]               blk.24.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 222/ 291]                 blk.24.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 223/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 224/ 291]                 blk.24.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 225/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 226/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 227/ 291]                 blk.24.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 228/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 229/ 291]               blk.25.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 230/ 291]               blk.25.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 231/ 291]                 blk.25.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 232/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 233/ 291]                 blk.25.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 234/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 235/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 236/ 291]                 blk.25.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 237/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 238/ 291]               blk.26.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 239/ 291]               blk.26.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 240/ 291]                 blk.26.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 241/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 242/ 291]                 blk.26.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 243/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 244/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 245/ 291]                 blk.26.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 246/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 247/ 291]               blk.27.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 248/ 291]               blk.27.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 249/ 291]                 blk.27.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 250/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 251/ 291]                 blk.27.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 252/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 253/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 254/ 291]                 blk.27.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 255/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 256/ 291]               blk.28.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 257/ 291]               blk.28.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 258/ 291]                 blk.28.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 259/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 260/ 291]                 blk.28.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 261/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 262/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 263/ 291]                 blk.28.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 264/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 265/ 291]               blk.29.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 266/ 291]               blk.29.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 267/ 291]                 blk.29.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 268/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 269/ 291]                 blk.29.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 270/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 271/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 272/ 291]                 blk.29.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 273/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 274/ 291]               blk.30.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 275/ 291]               blk.30.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 276/ 291]                 blk.30.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 277/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 278/ 291]                 blk.30.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 279/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 280/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 281/ 291]                 blk.30.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 282/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 283/ 291]               blk.31.ffn_down.weight - [14336,  4096,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 284/ 291]               blk.31.ffn_gate.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 285/ 291]                 blk.31.ffn_up.weight - [ 4096, 14336,     1,     1], type =    f16, converting to q6_K .. size =   112.00 MiB ->    45.94 MiB\n",
      "[ 286/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "[ 287/ 291]                 blk.31.attn_k.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 288/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 289/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, converting to q6_K .. size =    32.00 MiB ->    13.12 MiB\n",
      "[ 290/ 291]                 blk.31.attn_v.weight - [ 4096,  1024,     1,     1], type =    f16, converting to q6_K .. size =     8.00 MiB ->     3.28 MiB\n",
      "[ 291/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n",
      "llama_model_quantize_internal: model size  = 13813.05 MB\n",
      "llama_model_quantize_internal: quant size  =  5666.11 MB\n",
      "\n",
      "main: quantize time = 83812.05 ms\n",
      "main:    total time = 83812.05 ms\n",
      "CPU times: user 696 ms, sys: 141 ms, total: 836 ms\n",
      "Wall time: 1min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Quantize the F16 GGUF model to the 6+ bit Q6_K format\n",
    "QTYPE = \"Q6_K\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/llama-quantize {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf {MODEL_SHORT_NAME}-{SUFFIX}-{QTYPE}.gguf {QTYPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingreylit-axolotl",
   "language": "python",
   "name": "fingreylit-axolotl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
