{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune Qwen2.5-0.5B-Instruct model using Axolotl framework\n",
    "\n",
    "How to install dependencies (in HPC environment):\n",
    "\n",
    "- load Python and cuDNN modules\n",
    "- create a Python venv and activate it\n",
    "- install dependencies from requirements.txt (e.g. torch)\n",
    "- install Axolotl from git clone (pip won't work, see [this issue](https://github.com/OpenAccess-AI-Collective/axolotl/issues/945)):\n",
    "\n",
    "```\n",
    "git clone git@github.com:OpenAccess-AI-Collective/axolotl.git\n",
    "cd axolotl\n",
    "pip install -e '.[flash-attn,deepspeed]'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n",
      "BF16 is supported? True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print('GPU available?', torch.cuda.is_available())\n",
    "print('BF16 is supported?', torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name etc.\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "MODEL_SHORT_NAME = MODEL_NAME.split('/')[-1]\n",
    "SUFFIX = \"FinGreyLit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 640 train records\n",
      "Wrote 182 test records\n",
      "Wrote 32 eval records\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare fine-tuning dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of test set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "EVAL_SIZE = 32  # how many documents to evaluate (i.e. calculate loss) on during fine-tuning\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    output = json.dumps(sample[\"ground_truth\"])\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    # ShareGPT format\n",
    "    conversations = [\n",
    "        {'from': 'system', 'value': SYSTEM_PROMPT},\n",
    "        {'from': 'user', 'value': INSTRUCTION + \"\\n\\n\" + input_},\n",
    "        {'from': 'gpt', 'value': output}\n",
    "    ]\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "def write_jsonl(records, filename):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for record in records:\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "train_recs = dataset_to_records(train_files)\n",
    "random.shuffle(train_recs)\n",
    "write_jsonl(train_recs, \"axolotl-train.jsonl\")\n",
    "print(f\"Wrote {len(train_recs)} train records\")\n",
    "\n",
    "test_recs = dataset_to_records(test_files)\n",
    "write_jsonl(test_recs, \"axolotl-test.jsonl\")\n",
    "print(f\"Wrote {len(test_recs)} test records\")\n",
    "\n",
    "eval_recs = random.sample(test_recs, EVAL_SIZE)\n",
    "write_jsonl(eval_recs, \"axolotl-eval.jsonl\")\n",
    "print(f\"Wrote {len(eval_recs)} eval records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Axolotl configuration file\n",
    "\n",
    "CONFIG_FILE = f\"config-{MODEL_SHORT_NAME}.yml\"\n",
    "\n",
    "\n",
    "CONFIG = f\"\"\"\n",
    "base_model: {MODEL_NAME}\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: false\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: axolotl-train.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "test_datasets:\n",
    "  - path: axolotl-eval.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "output_dir: ./out-{MODEL_SHORT_NAME}\n",
    "\n",
    "#chat_template: chatml\n",
    "\n",
    "adapter: lora\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "eval_batch_size: 2\n",
    "num_epochs: 8\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: true\n",
    "fp16: false\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true  # true: saves VRAM but is slower to train\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 2\n",
    "eval_table_size:\n",
    "eval_table_max_new_tokens: 128\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "special_tokens:\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as outfile:\n",
    "    print(CONFIG, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2025-09-25 14:00:33,516] [INFO] [datasets.<module>:58] [PID:1636135] PyTorch version 2.3.1 available.\n",
      "[2025-09-25 14:01:05,685] [INFO] [axolotl.utils.config.models.input.check_eval_packing:958] [PID:1636135] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "\u001b[33m[2025-09-25 14:01:05,689] [WARNING] [axolotl.utils.config.models.input.hint_lora_8bit:1044] [PID:1636135] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "config.json: 100%|█████████████████████████████| 659/659 [00:00<00:00, 6.76MB/s]\n",
      "[2025-09-25 14:01:06,416] [INFO] [axolotl.normalize_config:183] [PID:1636135] [RANK:0] GPU memory usage baseline: 0.000GB (+0.753GB misc)\u001b[39m\n",
      "                                 dP            dP   dP \n",
      "                                 88            88   88 \n",
      "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
      "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
      "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
      "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
      "                                                       \n",
      "                                                       \n",
      "\n",
      "****************************************\n",
      "**** Axolotl Dependency Versions *****\n",
      "  accelerate: 0.32.0         \n",
      "        peft: 0.11.1         \n",
      "transformers: 4.43.0.dev0    \n",
      "         trl: 0.9.6          \n",
      "       torch: 2.3.1          \n",
      "bitsandbytes: 0.43.1         \n",
      "****************************************\n",
      "tokenizer_config.json: 7.30kB [00:00, 30.4MB/s]\n",
      "vocab.json: 2.78MB [00:00, 9.33MB/s]\n",
      "merges.txt: 1.67MB [00:00, 8.95MB/s]\n",
      "tokenizer.json: 7.03MB [00:00, 18.4MB/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2025-09-25 14:01:10,166] [DEBUG] [axolotl.load_tokenizer:280] [PID:1636135] [RANK:0] EOS: 151645 / <|im_end|>\u001b[39m\n",
      "[2025-09-25 14:01:10,166] [DEBUG] [axolotl.load_tokenizer:281] [PID:1636135] [RANK:0] BOS: None / None\u001b[39m\n",
      "[2025-09-25 14:01:10,166] [DEBUG] [axolotl.load_tokenizer:282] [PID:1636135] [RANK:0] PAD: 151643 / <|endoftext|>\u001b[39m\n",
      "[2025-09-25 14:01:10,166] [DEBUG] [axolotl.load_tokenizer:283] [PID:1636135] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2025-09-25 14:01:10,166] [INFO] [axolotl.load_tokenizer:294] [PID:1636135] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2025-09-25 14:01:10,167] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:1636135] [RANK:0] Unable to find prepared dataset in last_run_prepared/c9c2b33ade5dd94a2c68da03384cb9ad\u001b[39m\n",
      "[2025-09-25 14:01:10,167] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:1636135] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-09-25 14:01:10,167] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:1636135] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2025-09-25 14:01:10,167] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:1636135] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 640 examples [00:00, 8787.02 examples/s]\n",
      "[2025-09-25 14:01:11,175] [INFO] [axolotl.get_dataset_wrapper:540] [PID:1636135] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "Tokenizing Prompts (num_proc=64): 100%|█| 640/640 [00:08<00:00, 74.72 examples/s\n",
      "[2025-09-25 14:01:20,990] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:1636135] [RANK:0] merging datasets\u001b[39m\n",
      "Dropping Long Sequences (num_proc=128): 100%|█| 640/640 [00:01<00:00, 337.53 exa\n",
      "Add position_id column (Sample Packing) (num_proc=128): 100%|█| 577/577 [00:02<0\n",
      "[2025-09-25 14:01:29,920] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:1636135] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/c9c2b33ade5dd94a2c68da03384cb9ad\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|█| 577/577 [00:00<00:00, 3759.69 examples/\n",
      "[2025-09-25 14:01:30,118] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:1636135] [RANK:0] Unable to find prepared dataset in last_run_prepared/bbf3986b0f0a7d3f52b087fc70318d9c\u001b[39m\n",
      "[2025-09-25 14:01:30,118] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:1636135] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-09-25 14:01:30,119] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:1636135] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2025-09-25 14:01:30,119] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:1636135] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 32 examples [00:00, 754.09 examples/s]\n",
      "[2025-09-25 14:01:30,711] [INFO] [axolotl.get_dataset_wrapper:540] [PID:1636135] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2025-09-25 14:01:30,711] [WARNING] [datasets.arrow_dataset.map:3087] [PID:1636135] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Tokenizing Prompts (num_proc=32): 100%|██| 32/32 [00:03<00:00,  8.83 examples/s]\n",
      "[2025-09-25 14:01:35,191] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:1636135] [RANK:0] merging datasets\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2025-09-25 14:01:35,195] [WARNING] [datasets.arrow_dataset.map:3087] [PID:1636135] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 32/32 [00:00<00:00, 89.70 example\n",
      "num_proc must be <= 30. Reducing num_proc to 30 for dataset of size 30.\n",
      "[2025-09-25 14:01:36,020] [WARNING] [datasets.arrow_dataset.map:3087] [PID:1636135] num_proc must be <= 30. Reducing num_proc to 30 for dataset of size 30.\n",
      "Add position_id column (Sample Packing) (num_proc=30): 100%|█| 30/30 [00:00<00:0\n",
      "[2025-09-25 14:01:37,041] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:1636135] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/bbf3986b0f0a7d3f52b087fc70318d9c\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|██| 30/30 [00:00<00:00, 781.29 examples/s]\n",
      "[2025-09-25 14:01:37,112] [DEBUG] [axolotl.calculate_total_num_steps:297] [PID:1636135] [RANK:0] total_num_tokens: 1_643_670\u001b[39m\n",
      "[2025-09-25 14:01:37,129] [DEBUG] [axolotl.calculate_total_num_steps:310] [PID:1636135] [RANK:0] `total_supervised_tokens: 71_699`\u001b[39m\n",
      "[2025-09-25 14:01:44,046] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 1643670\u001b[39m\n",
      "[2025-09-25 14:01:44,048] [DEBUG] [axolotl.calculate_total_num_steps:362] [PID:1636135] [RANK:0] data_loader_len: 49\u001b[39m\n",
      "[2025-09-25 14:01:44,048] [INFO] [axolotl.calc_sample_packing_eff_est:368] [PID:1636135] [RANK:0] sample_packing_eff_est across ranks: [0.8223086497822746]\u001b[39m\n",
      "[2025-09-25 14:01:44,048] [DEBUG] [axolotl.calculate_total_num_steps:380] [PID:1636135] [RANK:0] sample_packing_eff_est: 0.83\u001b[39m\n",
      "[2025-09-25 14:01:44,048] [DEBUG] [axolotl.calculate_total_num_steps:388] [PID:1636135] [RANK:0] total_num_steps: 392\u001b[39m\n",
      "[2025-09-25 14:01:44,071] [DEBUG] [axolotl.train.train:66] [PID:1636135] [RANK:0] loading tokenizer... Qwen/Qwen2.5-0.5B-Instruct\u001b[39m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2025-09-25 14:01:44,533] [DEBUG] [axolotl.load_tokenizer:280] [PID:1636135] [RANK:0] EOS: 151645 / <|im_end|>\u001b[39m\n",
      "[2025-09-25 14:01:44,533] [DEBUG] [axolotl.load_tokenizer:281] [PID:1636135] [RANK:0] BOS: None / None\u001b[39m\n",
      "[2025-09-25 14:01:44,533] [DEBUG] [axolotl.load_tokenizer:282] [PID:1636135] [RANK:0] PAD: 151643 / <|endoftext|>\u001b[39m\n",
      "[2025-09-25 14:01:44,533] [DEBUG] [axolotl.load_tokenizer:283] [PID:1636135] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2025-09-25 14:01:44,533] [INFO] [axolotl.load_tokenizer:294] [PID:1636135] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2025-09-25 14:01:44,533] [DEBUG] [axolotl.train.train:95] [PID:1636135] [RANK:0] loading model and peft_config...\u001b[39m\n",
      "[2025-09-25 14:01:44,544] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:1636135] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "model.safetensors: 100%|██████████████████████| 988M/988M [00:09<00:00, 106MB/s]\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "generation_config.json: 100%|██████████████████| 242/242 [00:00<00:00, 2.07MB/s]\n",
      "[2025-09-25 14:01:56,844] [INFO] [axolotl.load_model:824] [PID:1636135] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2025-09-25 14:01:56,999] [INFO] [axolotl.load_lora:986] [PID:1636135] [RANK:0] found linear modules: ['k_proj', 'down_proj', 'up_proj', 'v_proj', 'o_proj', 'q_proj', 'gate_proj']\u001b[39m\n",
      "trainable params: 8,798,208 || all params: 502,830,976 || trainable%: 1.7497\n",
      "[2025-09-25 14:01:57,148] [INFO] [axolotl.load_model:869] [PID:1636135] [RANK:0] GPU memory usage after adapters: 0.000GB ()\u001b[39m\n",
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2025-09-25 14:01:57,807] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:1636135] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[2025-09-25 14:01:58,474] [INFO] [axolotl.train.train:136] [PID:1636135] [RANK:0] Pre-saving adapter config to ./out-Qwen2.5-0.5B-Instruct\u001b[39m\n",
      "[2025-09-25 14:01:58,641] [INFO] [axolotl.train.train:173] [PID:1636135] [RANK:0] Starting trainer...\u001b[39m\n",
      "[2025-09-25 14:01:58,825] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "[2025-09-25 14:01:58,825] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "  0%|                                                   | 0/472 [00:00<?, ?it/s][2025-09-25 14:01:58,884] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.2876, 'grad_norm': 4.34375, 'learning_rate': 2e-05, 'epoch': 0.02}   \n",
      "  0%|                                           | 1/472 [00:06<51:03,  6.50s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.60it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.38it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.56it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.24it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  6.02it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.92it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.70it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.76it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.74it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:01<00:00,  5.72it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.56it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.62it/s]\u001b[A[2025-09-25 14:02:08,036] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.3480581045150757, 'eval_runtime': 2.6763, 'eval_samples_per_second': 11.209, 'eval_steps_per_second': 5.605, 'epoch': 0.02}\n",
      "  0%|                                           | 1/472 [00:09<51:03,  6.50s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.75it/s]\u001b[A\n",
      "                                                                                \u001b[A[2025-09-25 14:02:10,170] [INFO] [axolotl.callbacks.on_step_end:128] [PID:1636135] [RANK:0] GPU memory usage while training: 1.165GB (+16.815GB cache, +1.265GB misc)\u001b[39m\n",
      "{'loss': 1.2385, 'grad_norm': 3.984375, 'learning_rate': 4e-05, 'epoch': 0.03}  \n",
      "{'loss': 0.9863, 'grad_norm': 3.640625, 'learning_rate': 6e-05, 'epoch': 0.05}  \n",
      "{'loss': 1.1611, 'grad_norm': 3.25, 'learning_rate': 8e-05, 'epoch': 0.07}      \n",
      "{'loss': 1.0178, 'grad_norm': 3.15625, 'learning_rate': 0.0001, 'epoch': 0.08}  \n",
      "{'loss': 0.6716, 'grad_norm': 1.7421875, 'learning_rate': 0.00012, 'epoch': 0.1}\n",
      "{'loss': 0.6824, 'grad_norm': 2.109375, 'learning_rate': 0.00014, 'epoch': 0.12}\n",
      "{'loss': 0.5825, 'grad_norm': 1.8046875, 'learning_rate': 0.00016, 'epoch': 0.13}\n",
      "{'loss': 0.4527, 'grad_norm': 1.609375, 'learning_rate': 0.00018, 'epoch': 0.15}\n",
      "{'loss': 0.5495, 'grad_norm': 1.6328125, 'learning_rate': 0.0002, 'epoch': 0.17}\n",
      "{'loss': 0.3429, 'grad_norm': 1.3203125, 'learning_rate': 0.00019999768801972172, 'epoch': 0.18}\n",
      "{'loss': 0.3116, 'grad_norm': 1.6796875, 'learning_rate': 0.00019999075218579183, 'epoch': 0.2}\n",
      "{'loss': 0.3275, 'grad_norm': 2.140625, 'learning_rate': 0.00019997919281892067, 'epoch': 0.22}\n",
      "{'loss': 0.1608, 'grad_norm': 1.1640625, 'learning_rate': 0.00019996301045360873, 'epoch': 0.24}\n",
      "{'loss': 0.4522, 'grad_norm': 1.640625, 'learning_rate': 0.00019994220583812217, 'epoch': 0.25}\n",
      "{'loss': 0.205, 'grad_norm': 1.328125, 'learning_rate': 0.0001999167799344583, 'epoch': 0.27}\n",
      "{'loss': 0.3505, 'grad_norm': 1.265625, 'learning_rate': 0.0001998867339183008, 'epoch': 0.29}\n",
      "{'loss': 0.167, 'grad_norm': 1.171875, 'learning_rate': 0.00019985206917896563, 'epoch': 0.3}\n",
      "{'loss': 0.1354, 'grad_norm': 1.1015625, 'learning_rate': 0.0001998127873193367, 'epoch': 0.32}\n",
      "{'loss': 0.1505, 'grad_norm': 1.359375, 'learning_rate': 0.00019976889015579165, 'epoch': 0.34}\n",
      "{'loss': 0.1789, 'grad_norm': 1.3828125, 'learning_rate': 0.00019972037971811802, 'epoch': 0.35}\n",
      "{'loss': 0.2739, 'grad_norm': 1.5390625, 'learning_rate': 0.00019966725824941932, 'epoch': 0.37}\n",
      "{'loss': 0.2552, 'grad_norm': 1.1484375, 'learning_rate': 0.00019960952820601135, 'epoch': 0.39}\n",
      "{'loss': 0.269, 'grad_norm': 1.0234375, 'learning_rate': 0.00019954719225730847, 'epoch': 0.4}\n",
      "{'loss': 0.1991, 'grad_norm': 1.2578125, 'learning_rate': 0.00019948025328570042, 'epoch': 0.42}\n",
      "{'loss': 0.1817, 'grad_norm': 1.1015625, 'learning_rate': 0.00019940871438641882, 'epoch': 0.44}\n",
      "{'loss': 0.1189, 'grad_norm': 0.90625, 'learning_rate': 0.00019933257886739413, 'epoch': 0.45}\n",
      "{'loss': 0.2059, 'grad_norm': 0.88671875, 'learning_rate': 0.00019925185024910277, 'epoch': 0.47}\n",
      "{'loss': 0.2559, 'grad_norm': 1.203125, 'learning_rate': 0.0001991665322644042, 'epoch': 0.49}\n",
      "{'loss': 0.1835, 'grad_norm': 0.91796875, 'learning_rate': 0.00019907662885836836, 'epoch': 0.5}\n",
      "  6%|██▋                                       | 30/472 [01:11<17:14,  2.34s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.52it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:02,  4.59it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:01<00:01,  4.85it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.05it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.22it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.24it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.40it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.48it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.51it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.40it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.50it/s]\u001b[A[2025-09-25 14:03:13,136] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.2433975636959076, 'eval_runtime': 2.9159, 'eval_samples_per_second': 10.288, 'eval_steps_per_second': 5.144, 'epoch': 0.5}\n",
      "  6%|██▋                                       | 30/472 [01:14<17:14,  2.34s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.68it/s]\u001b[A\n",
      "{'loss': 0.1465, 'grad_norm': 1.3046875, 'learning_rate': 0.0001989821441880933, 'epoch': 0.52}\n",
      "{'loss': 0.0979, 'grad_norm': 0.828125, 'learning_rate': 0.00019888308262251285, 'epoch': 0.54}\n",
      "{'loss': 0.1942, 'grad_norm': 1.453125, 'learning_rate': 0.00019877944874219483, 'epoch': 0.55}\n",
      "{'loss': 0.1601, 'grad_norm': 1.0546875, 'learning_rate': 0.0001986712473391289, 'epoch': 0.57}\n",
      "{'loss': 0.1082, 'grad_norm': 0.640625, 'learning_rate': 0.0001985584834165053, 'epoch': 0.59}\n",
      "{'loss': 0.1249, 'grad_norm': 0.7734375, 'learning_rate': 0.00019844116218848334, 'epoch': 0.61}\n",
      "{'loss': 0.144, 'grad_norm': 3.109375, 'learning_rate': 0.0001983192890799503, 'epoch': 0.62}\n",
      "{'loss': 0.2093, 'grad_norm': 0.76171875, 'learning_rate': 0.00019819286972627066, 'epoch': 0.64}\n",
      "{'loss': 0.1378, 'grad_norm': 0.76953125, 'learning_rate': 0.0001980619099730255, 'epoch': 0.66}\n",
      "{'loss': 0.1371, 'grad_norm': 0.87109375, 'learning_rate': 0.00019792641587574212, 'epoch': 0.67}\n",
      "{'loss': 0.1236, 'grad_norm': 0.921875, 'learning_rate': 0.00019778639369961415, 'epoch': 0.69}\n",
      "{'loss': 0.0915, 'grad_norm': 1.0078125, 'learning_rate': 0.00019764184991921178, 'epoch': 0.71}\n",
      "{'loss': 0.1325, 'grad_norm': 1.125, 'learning_rate': 0.00019749279121818235, 'epoch': 0.72}\n",
      "{'loss': 0.1175, 'grad_norm': 0.9140625, 'learning_rate': 0.0001973392244889415, 'epoch': 0.74}\n",
      "{'loss': 0.0817, 'grad_norm': 0.625, 'learning_rate': 0.00019718115683235417, 'epoch': 0.76}\n",
      "{'loss': 0.3445, 'grad_norm': 1.453125, 'learning_rate': 0.00019701859555740648, 'epoch': 0.77}\n",
      "{'loss': 0.218, 'grad_norm': 0.8359375, 'learning_rate': 0.00019685154818086756, 'epoch': 0.79}\n",
      "{'loss': 0.1555, 'grad_norm': 1.1328125, 'learning_rate': 0.00019668002242694238, 'epoch': 0.81}\n",
      "{'loss': 0.2293, 'grad_norm': 1.0703125, 'learning_rate': 0.000196504026226914, 'epoch': 0.82}\n",
      "{'loss': 0.1227, 'grad_norm': 0.84765625, 'learning_rate': 0.00019632356771877735, 'epoch': 0.84}\n",
      "{'loss': 0.1753, 'grad_norm': 1.0, 'learning_rate': 0.0001961386552468627, 'epoch': 0.86}\n",
      "{'loss': 0.069, 'grad_norm': 0.640625, 'learning_rate': 0.00019594929736144976, 'epoch': 0.87}\n",
      "{'loss': 0.1775, 'grad_norm': 0.78125, 'learning_rate': 0.00019575550281837248, 'epoch': 0.89}\n",
      "{'loss': 0.1728, 'grad_norm': 0.921875, 'learning_rate': 0.0001955572805786141, 'epoch': 0.91}\n",
      "{'loss': 0.1124, 'grad_norm': 0.82421875, 'learning_rate': 0.00019535463980789277, 'epoch': 0.92}\n",
      "{'loss': 0.1343, 'grad_norm': 0.74609375, 'learning_rate': 0.00019514758987623784, 'epoch': 0.94}\n",
      "{'loss': 0.1884, 'grad_norm': 0.84375, 'learning_rate': 0.00019493614035755646, 'epoch': 0.96}\n",
      "{'loss': 0.2072, 'grad_norm': 0.7578125, 'learning_rate': 0.000194720301029191, 'epoch': 0.97}\n",
      "{'loss': 0.0492, 'grad_norm': 0.55859375, 'learning_rate': 0.00019450008187146684, 'epoch': 0.99}\n",
      "{'loss': 0.1928, 'grad_norm': 0.80078125, 'learning_rate': 0.00019427549306723097, 'epoch': 1.01}\n",
      " 13%|█████▎                                    | 60/472 [02:19<18:04,  2.63s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.56it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.27it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.39it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.10it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.92it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.84it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  3.76it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:01,  4.23it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:02<00:00,  4.60it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  4.86it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  4.96it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.17it/s]\u001b[A[2025-09-25 14:04:21,611] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1821611225605011, 'eval_runtime': 3.0013, 'eval_samples_per_second': 9.996, 'eval_steps_per_second': 4.998, 'epoch': 1.01}\n",
      " 13%|█████▎                                    | 60/472 [02:22<18:04,  2.63s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.41it/s]\u001b[A\n",
      "                                                                                \u001b[A[2025-09-25 14:04:22,671] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "{'loss': 0.091, 'grad_norm': 0.80859375, 'learning_rate': 0.00019404654500138117, 'epoch': 1.01}\n",
      "{'loss': 0.1112, 'grad_norm': 0.490234375, 'learning_rate': 0.0001938132482603856, 'epoch': 1.03}\n",
      "{'loss': 0.2102, 'grad_norm': 0.65234375, 'learning_rate': 0.00019357561363179363, 'epoch': 1.04}\n",
      "{'loss': 0.0469, 'grad_norm': 0.55078125, 'learning_rate': 0.0001933336521037367, 'epoch': 1.06}\n",
      "{'loss': 0.0655, 'grad_norm': 0.37109375, 'learning_rate': 0.00019308737486442045, 'epoch': 1.08}\n",
      "{'loss': 0.0945, 'grad_norm': 0.49609375, 'learning_rate': 0.00019283679330160726, 'epoch': 1.09}\n",
      "{'loss': 0.0306, 'grad_norm': 0.515625, 'learning_rate': 0.0001925819190020898, 'epoch': 1.11}\n",
      "{'loss': 0.2948, 'grad_norm': 0.9140625, 'learning_rate': 0.00019232276375115515, 'epoch': 1.13}\n",
      "{'loss': 0.0747, 'grad_norm': 0.625, 'learning_rate': 0.00019205933953203987, 'epoch': 1.14}\n",
      "{'loss': 0.0757, 'grad_norm': 0.447265625, 'learning_rate': 0.00019179165852537596, 'epoch': 1.16}\n",
      "{'loss': 0.0486, 'grad_norm': 0.69921875, 'learning_rate': 0.00019151973310862754, 'epoch': 1.18}\n",
      "{'loss': 0.1223, 'grad_norm': 1.6640625, 'learning_rate': 0.00019124357585551872, 'epoch': 1.19}\n",
      "{'loss': 0.1361, 'grad_norm': 0.61328125, 'learning_rate': 0.00019096319953545185, 'epoch': 1.21}\n",
      "{'loss': 0.0427, 'grad_norm': 0.5390625, 'learning_rate': 0.00019067861711291744, 'epoch': 1.23}\n",
      "{'loss': 0.0316, 'grad_norm': 0.36328125, 'learning_rate': 0.00019038984174689447, 'epoch': 1.24}\n",
      "{'loss': 0.0461, 'grad_norm': 0.484375, 'learning_rate': 0.0001900968867902419, 'epoch': 1.26}\n",
      "{'loss': 0.047, 'grad_norm': 0.458984375, 'learning_rate': 0.00018979976578908144, 'epoch': 1.28}\n",
      "{'loss': 0.1091, 'grad_norm': 0.65234375, 'learning_rate': 0.000189498492482171, 'epoch': 1.29}\n",
      "{'loss': 0.0812, 'grad_norm': 0.69921875, 'learning_rate': 0.0001891930808002694, 'epoch': 1.31}\n",
      "{'loss': 0.0445, 'grad_norm': 0.4453125, 'learning_rate': 0.00018888354486549237, 'epoch': 1.33}\n",
      "{'loss': 0.1652, 'grad_norm': 0.5859375, 'learning_rate': 0.00018856989899065942, 'epoch': 1.34}\n",
      "{'loss': 0.123, 'grad_norm': 0.625, 'learning_rate': 0.00018825215767863214, 'epoch': 1.36}\n",
      "{'loss': 0.1446, 'grad_norm': 0.6015625, 'learning_rate': 0.00018793033562164343, 'epoch': 1.38}\n",
      "{'loss': 0.0556, 'grad_norm': 0.625, 'learning_rate': 0.0001876044477006183, 'epoch': 1.39}\n",
      "{'loss': 0.0545, 'grad_norm': 0.71484375, 'learning_rate': 0.00018727450898448563, 'epoch': 1.41}\n",
      "{'loss': 0.0812, 'grad_norm': 0.875, 'learning_rate': 0.00018694053472948156, 'epoch': 1.43}\n",
      "{'loss': 0.0442, 'grad_norm': 0.404296875, 'learning_rate': 0.00018660254037844388, 'epoch': 1.45}\n",
      "{'loss': 0.0544, 'grad_norm': 0.45703125, 'learning_rate': 0.00018626054156009806, 'epoch': 1.46}\n",
      "{'loss': 0.0694, 'grad_norm': 0.57421875, 'learning_rate': 0.00018591455408833462, 'epoch': 1.48}\n",
      "{'loss': 0.0907, 'grad_norm': 0.75, 'learning_rate': 0.00018556459396147775, 'epoch': 1.5}\n",
      " 19%|████████                                  | 90/472 [03:26<13:44,  2.16s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.39it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.21it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.37it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.09it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.89it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.81it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.57it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.63it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.59it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.53it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  3.91it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  4.07it/s]\u001b[A[2025-09-25 14:05:28,543] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17743875086307526, 'eval_runtime': 3.0299, 'eval_samples_per_second': 9.901, 'eval_steps_per_second': 4.951, 'epoch': 1.5}\n",
      " 19%|████████                                  | 90/472 [03:29<13:44,  2.16s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  4.55it/s]\u001b[A\n",
      "{'loss': 0.1123, 'grad_norm': 0.66015625, 'learning_rate': 0.00018521067736154568, 'epoch': 1.51}\n",
      "{'loss': 0.0939, 'grad_norm': 0.68359375, 'learning_rate': 0.00018485282065350235, 'epoch': 1.53}\n",
      "{'loss': 0.149, 'grad_norm': 0.71484375, 'learning_rate': 0.00018449104038450087, 'epoch': 1.55}\n",
      "{'loss': 0.1275, 'grad_norm': 1.0078125, 'learning_rate': 0.00018412535328311814, 'epoch': 1.56}\n",
      "{'loss': 0.1142, 'grad_norm': 0.703125, 'learning_rate': 0.00018375577625858147, 'epoch': 1.58}\n",
      "{'loss': 0.0786, 'grad_norm': 0.6171875, 'learning_rate': 0.0001833823263999867, 'epoch': 1.6}\n",
      "{'loss': 0.0451, 'grad_norm': 0.76171875, 'learning_rate': 0.00018300502097550806, 'epoch': 1.61}\n",
      "{'loss': 0.054, 'grad_norm': 0.470703125, 'learning_rate': 0.0001826238774315995, 'epoch': 1.63}\n",
      "{'loss': 0.0389, 'grad_norm': 0.486328125, 'learning_rate': 0.00018223891339218815, 'epoch': 1.65}\n",
      "{'loss': 0.0987, 'grad_norm': 0.5703125, 'learning_rate': 0.00018185014665785936, 'epoch': 1.66}\n",
      "{'loss': 0.048, 'grad_norm': 1.1171875, 'learning_rate': 0.00018145759520503358, 'epoch': 1.68}\n",
      "{'loss': 0.0776, 'grad_norm': 0.7421875, 'learning_rate': 0.00018106127718513516, 'epoch': 1.7}\n",
      "{'loss': 0.0888, 'grad_norm': 0.640625, 'learning_rate': 0.000180661210923753, 'epoch': 1.71}\n",
      "{'loss': 0.1083, 'grad_norm': 0.66796875, 'learning_rate': 0.00018025741491979326, 'epoch': 1.73}\n",
      "{'loss': 0.1082, 'grad_norm': 0.79296875, 'learning_rate': 0.0001798499078446239, 'epoch': 1.75}\n",
      "{'loss': 0.0638, 'grad_norm': 0.578125, 'learning_rate': 0.00017943870854121124, 'epoch': 1.76}\n",
      "{'loss': 0.0335, 'grad_norm': 0.419921875, 'learning_rate': 0.00017902383602324903, 'epoch': 1.78}\n",
      "{'loss': 0.1235, 'grad_norm': 0.7890625, 'learning_rate': 0.00017860530947427875, 'epoch': 1.8}\n",
      "{'loss': 0.1563, 'grad_norm': 0.78125, 'learning_rate': 0.000178183148246803, 'epoch': 1.82}\n",
      "{'loss': 0.3031, 'grad_norm': 0.85546875, 'learning_rate': 0.00017775737186139038, 'epoch': 1.83}\n",
      "{'loss': 0.0857, 'grad_norm': 0.70703125, 'learning_rate': 0.00017732800000577303, 'epoch': 1.85}\n",
      "{'loss': 0.0974, 'grad_norm': 0.5078125, 'learning_rate': 0.0001768950525339362, 'epoch': 1.87}\n",
      "{'loss': 0.0382, 'grad_norm': 0.51171875, 'learning_rate': 0.00017645854946520025, 'epoch': 1.88}\n",
      "{'loss': 0.1088, 'grad_norm': 0.3984375, 'learning_rate': 0.00017601851098329483, 'epoch': 1.9}\n",
      "{'loss': 0.0447, 'grad_norm': 0.51953125, 'learning_rate': 0.00017557495743542585, 'epoch': 1.92}\n",
      "{'loss': 0.0808, 'grad_norm': 0.53125, 'learning_rate': 0.00017512790933133437, 'epoch': 1.93}\n",
      "{'loss': 0.0814, 'grad_norm': 0.4765625, 'learning_rate': 0.0001746773873423484, 'epoch': 1.95}\n",
      "{'loss': 0.0696, 'grad_norm': 0.58203125, 'learning_rate': 0.000174223412300427, 'epoch': 1.97}\n",
      "{'loss': 0.0766, 'grad_norm': 0.447265625, 'learning_rate': 0.00017376600519719709, 'epoch': 1.98}\n",
      "{'loss': 0.0781, 'grad_norm': 0.55859375, 'learning_rate': 0.00017330518718298264, 'epoch': 2.0}\n",
      " 25%|██████████▍                              | 120/472 [04:35<13:49,  2.36s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.01it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  6.98it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.20it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  5.93it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.73it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.47it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.55it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.56it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.57it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.44it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.49it/s]\u001b[A[2025-09-25 14:06:36,649] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.15685230493545532, 'eval_runtime': 2.781, 'eval_samples_per_second': 10.788, 'eval_steps_per_second': 5.394, 'epoch': 2.0}\n",
      " 25%|██████████▍                              | 120/472 [04:37<13:49,  2.36s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.65it/s]\u001b[A\n",
      "{'loss': 0.1265, 'grad_norm': 0.51171875, 'learning_rate': 0.00017284097956582692, 'epoch': 2.02}\n",
      " 26%|██████████▌                              | 121/472 [04:39<18:18,  3.13s/it][2025-09-25 14:06:40,377] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "{'loss': 0.0493, 'grad_norm': 0.71875, 'learning_rate': 0.00017237340381050703, 'epoch': 2.0}\n",
      "{'loss': 0.0455, 'grad_norm': 0.435546875, 'learning_rate': 0.00017190248153754146, 'epoch': 2.02}\n",
      "{'loss': 0.1632, 'grad_norm': 0.98828125, 'learning_rate': 0.00017142823452219038, 'epoch': 2.04}\n",
      "{'loss': 0.0225, 'grad_norm': 0.34765625, 'learning_rate': 0.00017095068469344867, 'epoch': 2.05}\n",
      "{'loss': 0.0255, 'grad_norm': 0.357421875, 'learning_rate': 0.00017046985413303215, 'epoch': 2.07}\n",
      "{'loss': 0.0319, 'grad_norm': 0.1982421875, 'learning_rate': 0.00016998576507435618, 'epoch': 2.09}\n",
      "{'loss': 0.0431, 'grad_norm': 0.4296875, 'learning_rate': 0.00016949843990150796, 'epoch': 2.11}\n",
      "{'loss': 0.1575, 'grad_norm': 0.478515625, 'learning_rate': 0.00016900790114821122, 'epoch': 2.12}\n",
      "{'loss': 0.0581, 'grad_norm': 0.4375, 'learning_rate': 0.00016851417149678444, 'epoch': 2.14}\n",
      "{'loss': 0.277, 'grad_norm': 0.921875, 'learning_rate': 0.00016801727377709194, 'epoch': 2.16}\n",
      "{'loss': 0.0184, 'grad_norm': 0.287109375, 'learning_rate': 0.00016751723096548835, 'epoch': 2.17}\n",
      "{'loss': 0.0583, 'grad_norm': 0.42578125, 'learning_rate': 0.00016701406618375596, 'epoch': 2.19}\n",
      "{'loss': 0.0209, 'grad_norm': 0.349609375, 'learning_rate': 0.00016650780269803587, 'epoch': 2.21}\n",
      "{'loss': 0.1451, 'grad_norm': 0.62109375, 'learning_rate': 0.00016599846391775194, 'epoch': 2.22}\n",
      "{'loss': 0.0352, 'grad_norm': 0.2734375, 'learning_rate': 0.00016548607339452853, 'epoch': 2.24}\n",
      "{'loss': 0.0775, 'grad_norm': 0.53125, 'learning_rate': 0.00016497065482110125, 'epoch': 2.26}\n",
      "{'loss': 0.0985, 'grad_norm': 0.53515625, 'learning_rate': 0.00016445223203022166, 'epoch': 2.27}\n",
      "{'loss': 0.0562, 'grad_norm': 0.53125, 'learning_rate': 0.00016393082899355516, 'epoch': 2.29}\n",
      "{'loss': 0.0235, 'grad_norm': 0.265625, 'learning_rate': 0.00016340646982057247, 'epoch': 2.31}\n",
      "{'loss': 0.11, 'grad_norm': 0.51171875, 'learning_rate': 0.00016287917875743496, 'epoch': 2.32}\n",
      "{'loss': 0.0212, 'grad_norm': 0.474609375, 'learning_rate': 0.00016234898018587337, 'epoch': 2.34}\n",
      "{'loss': 0.0268, 'grad_norm': 0.330078125, 'learning_rate': 0.00016181589862206052, 'epoch': 2.36}\n",
      "{'loss': 0.0297, 'grad_norm': 0.54296875, 'learning_rate': 0.0001612799587154777, 'epoch': 2.37}\n",
      "{'loss': 0.0424, 'grad_norm': 0.52734375, 'learning_rate': 0.00016074118524777477, 'epoch': 2.39}\n",
      "{'loss': 0.0673, 'grad_norm': 0.357421875, 'learning_rate': 0.00016019960313162434, 'epoch': 2.41}\n",
      "{'loss': 0.0992, 'grad_norm': 0.63671875, 'learning_rate': 0.0001596552374095699, 'epoch': 2.42}\n",
      "{'loss': 0.0515, 'grad_norm': 0.3984375, 'learning_rate': 0.00015910811325286768, 'epoch': 2.44}\n",
      "{'loss': 0.0708, 'grad_norm': 0.5234375, 'learning_rate': 0.00015855825596032287, 'epoch': 2.46}\n",
      "{'loss': 0.0831, 'grad_norm': 0.5390625, 'learning_rate': 0.00015800569095711982, 'epoch': 2.47}\n",
      " 32%|█████████████                            | 150/472 [05:40<11:23,  2.12s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.41it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.51it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.21it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.76it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.74it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.56it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.64it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.62it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:01<00:00,  5.60it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.43it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.49it/s]\u001b[A[2025-09-25 14:07:42,559] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1526007354259491, 'eval_runtime': 2.7313, 'eval_samples_per_second': 10.984, 'eval_steps_per_second': 5.492, 'epoch': 2.47}\n",
      " 32%|█████████████                            | 150/472 [05:43<11:23,  2.12s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.63it/s]\u001b[A\n",
      "{'loss': 0.0407, 'grad_norm': 0.484375, 'learning_rate': 0.00015745044379364634, 'epoch': 2.49}\n",
      "{'loss': 0.0836, 'grad_norm': 0.5625, 'learning_rate': 0.00015689254014431225, 'epoch': 2.51}\n",
      "{'loss': 0.0496, 'grad_norm': 0.328125, 'learning_rate': 0.0001563320058063622, 'epoch': 2.53}\n",
      "{'loss': 0.0386, 'grad_norm': 0.53125, 'learning_rate': 0.00015576886669868296, 'epoch': 2.54}\n",
      "{'loss': 0.0261, 'grad_norm': 0.87890625, 'learning_rate': 0.00015520314886060467, 'epoch': 2.56}\n",
      "{'loss': 0.0554, 'grad_norm': 0.419921875, 'learning_rate': 0.00015463487845069707, 'epoch': 2.58}\n",
      "{'loss': 0.0315, 'grad_norm': 0.3359375, 'learning_rate': 0.00015406408174555976, 'epoch': 2.59}\n",
      "{'loss': 0.0645, 'grad_norm': 0.77734375, 'learning_rate': 0.00015349078513860726, 'epoch': 2.61}\n",
      "{'loss': 0.017, 'grad_norm': 0.3671875, 'learning_rate': 0.0001529150151388485, 'epoch': 2.63}\n",
      "{'loss': 0.0283, 'grad_norm': 0.37109375, 'learning_rate': 0.00015233679836966122, 'epoch': 2.64}\n",
      "{'loss': 0.0266, 'grad_norm': 0.2734375, 'learning_rate': 0.00015175616156756072, 'epoch': 2.66}\n",
      "{'loss': 0.054, 'grad_norm': 0.74609375, 'learning_rate': 0.0001511731315809637, 'epoch': 2.68}\n",
      "{'loss': 0.0608, 'grad_norm': 0.5, 'learning_rate': 0.00015058773536894685, 'epoch': 2.69}\n",
      "{'loss': 0.0894, 'grad_norm': 0.46484375, 'learning_rate': 0.00015000000000000001, 'epoch': 2.71}\n",
      "{'loss': 0.021, 'grad_norm': 0.435546875, 'learning_rate': 0.00014940995265077487, 'epoch': 2.73}\n",
      "{'loss': 0.0665, 'grad_norm': 0.6328125, 'learning_rate': 0.00014881762060482814, 'epoch': 2.74}\n",
      "{'loss': 0.0604, 'grad_norm': 0.50390625, 'learning_rate': 0.00014822303125135996, 'epoch': 2.76}\n",
      "{'loss': 0.0242, 'grad_norm': 0.3515625, 'learning_rate': 0.0001476262120839475, 'epoch': 2.78}\n",
      "{'loss': 0.0269, 'grad_norm': 0.298828125, 'learning_rate': 0.0001470271906992737, 'epoch': 2.79}\n",
      "{'loss': 0.0381, 'grad_norm': 0.54296875, 'learning_rate': 0.00014642599479585105, 'epoch': 2.81}\n",
      "{'loss': 0.0272, 'grad_norm': 0.359375, 'learning_rate': 0.00014582265217274104, 'epoch': 2.83}\n",
      "{'loss': 0.0703, 'grad_norm': 1.15625, 'learning_rate': 0.00014521719072826858, 'epoch': 2.84}\n",
      "{'loss': 0.0286, 'grad_norm': 0.373046875, 'learning_rate': 0.00014460963845873203, 'epoch': 2.86}\n",
      "{'loss': 0.0148, 'grad_norm': 0.328125, 'learning_rate': 0.0001440000234571087, 'epoch': 2.88}\n",
      "{'loss': 0.0166, 'grad_norm': 0.423828125, 'learning_rate': 0.00014338837391175582, 'epoch': 2.89}\n",
      "{'loss': 0.0631, 'grad_norm': 0.66015625, 'learning_rate': 0.0001427747181051071, 'epoch': 2.91}\n",
      "{'loss': 0.0362, 'grad_norm': 0.419921875, 'learning_rate': 0.000142159084412365, 'epoch': 2.93}\n",
      "{'loss': 0.0191, 'grad_norm': 0.484375, 'learning_rate': 0.00014154150130018866, 'epoch': 2.95}\n",
      "{'loss': 0.0291, 'grad_norm': 0.447265625, 'learning_rate': 0.00014092199732537757, 'epoch': 2.96}\n",
      "{'loss': 0.0308, 'grad_norm': 0.515625, 'learning_rate': 0.00014030060113355116, 'epoch': 2.98}\n",
      " 38%|███████████████▋                         | 180/472 [06:47<10:45,  2.21s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.38it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.25it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.48it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.16it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.96it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.88it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.64it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.71it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.69it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:01<00:00,  5.67it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.49it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.53it/s]\u001b[A[2025-09-25 14:08:48,975] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.16446195542812347, 'eval_runtime': 2.7109, 'eval_samples_per_second': 11.067, 'eval_steps_per_second': 5.533, 'epoch': 2.98}\n",
      " 38%|███████████████▋                         | 180/472 [06:50<10:45,  2.21s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.64it/s]\u001b[A\n",
      "{'loss': 0.0167, 'grad_norm': 0.35546875, 'learning_rate': 0.00013967734145782425, 'epoch': 3.0}\n",
      "{'loss': 0.0435, 'grad_norm': 0.78125, 'learning_rate': 0.00013905224711747844, 'epoch': 3.01}\n",
      "{'loss': 0.0321, 'grad_norm': 0.7578125, 'learning_rate': 0.00013842534701662945, 'epoch': 3.03}\n",
      " 39%|███████████████▉                         | 183/472 [06:56<11:54,  2.47s/it][2025-09-25 14:08:55,077] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "{'loss': 0.0464, 'grad_norm': 0.34765625, 'learning_rate': 0.00013779667014289065, 'epoch': 3.02}\n",
      "{'loss': 0.0647, 'grad_norm': 0.66015625, 'learning_rate': 0.00013716624556603274, 'epoch': 3.03}\n",
      "{'loss': 0.0343, 'grad_norm': 0.40234375, 'learning_rate': 0.00013653410243663952, 'epoch': 3.05}\n",
      "{'loss': 0.021, 'grad_norm': 0.4453125, 'learning_rate': 0.00013590026998475986, 'epoch': 3.07}\n",
      "{'loss': 0.0312, 'grad_norm': 0.330078125, 'learning_rate': 0.00013526477751855644, 'epoch': 3.08}\n",
      "{'loss': 0.0511, 'grad_norm': 0.490234375, 'learning_rate': 0.00013462765442295017, 'epoch': 3.1}\n",
      "{'loss': 0.0112, 'grad_norm': 0.357421875, 'learning_rate': 0.00013398893015826167, 'epoch': 3.12}\n",
      "{'loss': 0.0104, 'grad_norm': 0.1904296875, 'learning_rate': 0.00013334863425884907, 'epoch': 3.13}\n",
      "{'loss': 0.0301, 'grad_norm': 0.318359375, 'learning_rate': 0.00013270679633174218, 'epoch': 3.15}\n",
      "{'loss': 0.0575, 'grad_norm': 0.546875, 'learning_rate': 0.00013206344605527355, 'epoch': 3.17}\n",
      "{'loss': 0.0512, 'grad_norm': 0.31640625, 'learning_rate': 0.00013141861317770626, 'epoch': 3.18}\n",
      "{'loss': 0.0526, 'grad_norm': 0.51953125, 'learning_rate': 0.00013077232751585818, 'epoch': 3.2}\n",
      "{'loss': 0.0187, 'grad_norm': 0.41015625, 'learning_rate': 0.00013012461895372344, 'epoch': 3.22}\n",
      "{'loss': 0.0078, 'grad_norm': 0.1884765625, 'learning_rate': 0.00012947551744109043, 'epoch': 3.24}\n",
      "{'loss': 0.0353, 'grad_norm': 0.42578125, 'learning_rate': 0.0001288250529921571, 'epoch': 3.25}\n",
      "{'loss': 0.0194, 'grad_norm': 0.44921875, 'learning_rate': 0.00012817325568414297, 'epoch': 3.27}\n",
      "{'loss': 0.0081, 'grad_norm': 0.177734375, 'learning_rate': 0.00012752015565589852, 'epoch': 3.29}\n",
      "{'loss': 0.034, 'grad_norm': 0.359375, 'learning_rate': 0.0001268657831065114, 'epoch': 3.3}\n",
      "{'loss': 0.0156, 'grad_norm': 0.263671875, 'learning_rate': 0.00012621016829391022, 'epoch': 3.32}\n",
      "{'loss': 0.0152, 'grad_norm': 0.2734375, 'learning_rate': 0.0001255533415334653, 'epoch': 3.34}\n",
      "{'loss': 0.0451, 'grad_norm': 0.58984375, 'learning_rate': 0.00012489533319658702, 'epoch': 3.35}\n",
      "{'loss': 0.0602, 'grad_norm': 0.5703125, 'learning_rate': 0.00012423617370932127, 'epoch': 3.37}\n",
      "{'loss': 0.0163, 'grad_norm': 0.353515625, 'learning_rate': 0.00012357589355094275, 'epoch': 3.39}\n",
      "{'loss': 0.0151, 'grad_norm': 0.251953125, 'learning_rate': 0.00012291452325254555, 'epoch': 3.4}\n",
      "{'loss': 0.0143, 'grad_norm': 0.30859375, 'learning_rate': 0.00012225209339563145, 'epoch': 3.42}\n",
      "{'loss': 0.0488, 'grad_norm': 0.349609375, 'learning_rate': 0.00012158863461069571, 'epoch': 3.44}\n",
      "{'loss': 0.0119, 'grad_norm': 0.3984375, 'learning_rate': 0.00012092417757581085, 'epoch': 3.45}\n",
      " 44%|██████████████████▏                      | 210/472 [07:52<09:11,  2.10s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.28it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.13it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.32it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.02it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.82it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.76it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.59it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.67it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.67it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:01<00:00,  5.65it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.47it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.52it/s]\u001b[A[2025-09-25 14:09:54,397] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.16373106837272644, 'eval_runtime': 2.7345, 'eval_samples_per_second': 10.971, 'eval_steps_per_second': 5.485, 'epoch': 3.45}\n",
      " 44%|██████████████████▏                      | 210/472 [07:55<09:11,  2.10s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.60it/s]\u001b[A\n",
      "{'loss': 0.0192, 'grad_norm': 0.2490234375, 'learning_rate': 0.0001202587530152081, 'epoch': 3.47}\n",
      "{'loss': 0.0427, 'grad_norm': 0.5078125, 'learning_rate': 0.00011959239169785667, 'epoch': 3.49}\n",
      "{'loss': 0.0107, 'grad_norm': 0.208984375, 'learning_rate': 0.00011892512443604102, 'epoch': 3.5}\n",
      "{'loss': 0.02, 'grad_norm': 0.37890625, 'learning_rate': 0.00011825698208393619, 'epoch': 3.52}\n",
      "{'loss': 0.0604, 'grad_norm': 0.5, 'learning_rate': 0.00011758799553618094, 'epoch': 3.54}\n",
      "{'loss': 0.018, 'grad_norm': 0.5625, 'learning_rate': 0.00011691819572644939, 'epoch': 3.55}\n",
      "{'loss': 0.0193, 'grad_norm': 0.375, 'learning_rate': 0.00011624761362602061, 'epoch': 3.57}\n",
      "{'loss': 0.0169, 'grad_norm': 0.291015625, 'learning_rate': 0.0001155762802423463, 'epoch': 3.59}\n",
      "{'loss': 0.023, 'grad_norm': 0.263671875, 'learning_rate': 0.00011490422661761744, 'epoch': 3.61}\n",
      "{'loss': 0.0106, 'grad_norm': 0.35546875, 'learning_rate': 0.00011423148382732853, 'epoch': 3.62}\n",
      "{'loss': 0.0196, 'grad_norm': 0.283203125, 'learning_rate': 0.00011355808297884078, 'epoch': 3.64}\n",
      "{'loss': 0.0228, 'grad_norm': 0.357421875, 'learning_rate': 0.0001128840552099439, 'epoch': 3.66}\n",
      "{'loss': 0.0051, 'grad_norm': 0.2451171875, 'learning_rate': 0.000112209431687416, 'epoch': 3.67}\n",
      "{'loss': 0.0246, 'grad_norm': 0.357421875, 'learning_rate': 0.00011153424360558267, 'epoch': 3.69}\n",
      "{'loss': 0.032, 'grad_norm': 0.2060546875, 'learning_rate': 0.00011085852218487454, 'epoch': 3.71}\n",
      "{'loss': 0.0921, 'grad_norm': 0.70703125, 'learning_rate': 0.00011018229867038356, 'epoch': 3.72}\n",
      "{'loss': 0.0259, 'grad_norm': 0.34375, 'learning_rate': 0.00010950560433041826, 'epoch': 3.74}\n",
      "{'loss': 0.033, 'grad_norm': 0.365234375, 'learning_rate': 0.00010882847045505808, 'epoch': 3.76}\n",
      "{'loss': 0.0296, 'grad_norm': 0.53125, 'learning_rate': 0.00010815092835470633, 'epoch': 3.77}\n",
      "{'loss': 0.0289, 'grad_norm': 0.6875, 'learning_rate': 0.00010747300935864243, 'epoch': 3.79}\n",
      "{'loss': 0.0503, 'grad_norm': 0.439453125, 'learning_rate': 0.00010679474481357341, 'epoch': 3.81}\n",
      "{'loss': 0.025, 'grad_norm': 0.306640625, 'learning_rate': 0.00010611616608218429, 'epoch': 3.82}\n",
      "{'loss': 0.1355, 'grad_norm': 0.67578125, 'learning_rate': 0.00010543730454168794, 'epoch': 3.84}\n",
      "{'loss': 0.0155, 'grad_norm': 0.3046875, 'learning_rate': 0.00010475819158237425, 'epoch': 3.86}\n",
      "{'loss': 0.0221, 'grad_norm': 0.1728515625, 'learning_rate': 0.00010407885860615859, 'epoch': 3.87}\n",
      "{'loss': 0.0421, 'grad_norm': 0.451171875, 'learning_rate': 0.00010339933702512979, 'epoch': 3.89}\n",
      "{'loss': 0.0169, 'grad_norm': 1.2109375, 'learning_rate': 0.00010271965826009777, 'epoch': 3.91}\n",
      "{'loss': 0.025, 'grad_norm': 0.42578125, 'learning_rate': 0.00010203985373914056, 'epoch': 3.92}\n",
      "{'loss': 0.0095, 'grad_norm': 0.1591796875, 'learning_rate': 0.000101359954896151, 'epoch': 3.94}\n",
      "{'loss': 0.013, 'grad_norm': 0.2890625, 'learning_rate': 0.00010067999316938347, 'epoch': 3.96}\n",
      " 51%|████████████████████▊                    | 240/472 [08:59<08:36,  2.22s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.11it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.00it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.19it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  5.92it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.74it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.69it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.52it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.61it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.61it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.61it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  3.64it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  4.12it/s]\u001b[A[2025-09-25 14:11:01,674] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.16346503794193268, 'eval_runtime': 3.0642, 'eval_samples_per_second': 9.791, 'eval_steps_per_second': 4.895, 'epoch': 3.96}\n",
      " 51%|████████████████████▊                    | 240/472 [09:02<08:36,  2.22s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  4.58it/s]\u001b[A\n",
      "{'loss': 0.0129, 'grad_norm': 0.275390625, 'learning_rate': 0.0001, 'epoch': 3.97}A\n",
      "{'loss': 0.0164, 'grad_norm': 0.416015625, 'learning_rate': 9.932000683061653e-05, 'epoch': 3.99}\n",
      "{'loss': 0.0321, 'grad_norm': 0.80078125, 'learning_rate': 9.864004510384903e-05, 'epoch': 4.01}\n",
      " 51%|█████████████████████                    | 243/472 [09:09<09:54,  2.59s/it][2025-09-25 14:11:08,503] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "{'loss': 0.0534, 'grad_norm': 0.439453125, 'learning_rate': 9.79601462608595e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0146, 'grad_norm': 0.50390625, 'learning_rate': 9.728034173990224e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0204, 'grad_norm': 0.296875, 'learning_rate': 9.660066297487022e-05, 'epoch': 4.05}\n",
      "{'loss': 0.012, 'grad_norm': 0.224609375, 'learning_rate': 9.592114139384145e-05, 'epoch': 4.06}\n",
      "{'loss': 0.012, 'grad_norm': 0.1806640625, 'learning_rate': 9.524180841762577e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0085, 'grad_norm': 0.203125, 'learning_rate': 9.45626954583121e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0069, 'grad_norm': 0.4453125, 'learning_rate': 9.388383391781575e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0427, 'grad_norm': 0.4609375, 'learning_rate': 9.320525518642661e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0284, 'grad_norm': 0.6796875, 'learning_rate': 9.252699064135758e-05, 'epoch': 4.15}\n",
      "{'loss': 0.0221, 'grad_norm': 0.53125, 'learning_rate': 9.184907164529368e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0248, 'grad_norm': 0.2470703125, 'learning_rate': 9.117152954494194e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0051, 'grad_norm': 0.263671875, 'learning_rate': 9.049439566958175e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0033, 'grad_norm': 0.158203125, 'learning_rate': 8.981770132961649e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0386, 'grad_norm': 0.4609375, 'learning_rate': 8.914147781512546e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0188, 'grad_norm': 0.263671875, 'learning_rate': 8.846575639441732e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0099, 'grad_norm': 0.478515625, 'learning_rate': 8.779056831258402e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0179, 'grad_norm': 0.28125, 'learning_rate': 8.711594479005614e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0363, 'grad_norm': 0.68359375, 'learning_rate': 8.644191702115924e-05, 'epoch': 4.3}\n",
      "{'loss': 0.013, 'grad_norm': 0.28125, 'learning_rate': 8.57685161726715e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0031, 'grad_norm': 0.09814453125, 'learning_rate': 8.509577338238255e-05, 'epoch': 4.33}\n",
      "{'loss': 0.0057, 'grad_norm': 0.119140625, 'learning_rate': 8.442371975765368e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0251, 'grad_norm': 0.26953125, 'learning_rate': 8.375238637397942e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0063, 'grad_norm': 0.19140625, 'learning_rate': 8.308180427355062e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0152, 'grad_norm': 0.365234375, 'learning_rate': 8.24120044638191e-05, 'epoch': 4.4}\n",
      "{'loss': 0.016, 'grad_norm': 0.5234375, 'learning_rate': 8.174301791606385e-05, 'epoch': 4.42}\n",
      "{'loss': 0.0619, 'grad_norm': 0.4921875, 'learning_rate': 8.107487556395901e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0121, 'grad_norm': 0.384765625, 'learning_rate': 8.040760830214333e-05, 'epoch': 4.45}\n",
      " 57%|███████████████████████▍                 | 270/472 [10:05<07:03,  2.10s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.66it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.04it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  5.65it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  5.63it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.62it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.66it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.52it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.64it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.67it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.69it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.53it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.59it/s]\u001b[A[2025-09-25 14:12:07,355] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1705552488565445, 'eval_runtime': 2.7548, 'eval_samples_per_second': 10.89, 'eval_steps_per_second': 5.445, 'epoch': 4.45}\n",
      " 57%|███████████████████████▍                 | 270/472 [10:08<07:03,  2.10s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.74it/s]\u001b[A\n",
      "{'loss': 0.0158, 'grad_norm': 0.330078125, 'learning_rate': 7.974124698479192e-05, 'epoch': 4.47}\n",
      "{'loss': 0.009, 'grad_norm': 0.2412109375, 'learning_rate': 7.907582242418916e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0189, 'grad_norm': 0.51171875, 'learning_rate': 7.841136538930431e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0237, 'grad_norm': 0.4296875, 'learning_rate': 7.774790660436858e-05, 'epoch': 4.52}\n",
      "{'loss': 0.0128, 'grad_norm': 0.189453125, 'learning_rate': 7.708547674745447e-05, 'epoch': 4.53}\n",
      "{'loss': 0.016, 'grad_norm': 0.3203125, 'learning_rate': 7.642410644905726e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0063, 'grad_norm': 0.2470703125, 'learning_rate': 7.576382629067877e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0123, 'grad_norm': 0.51953125, 'learning_rate': 7.510466680341301e-05, 'epoch': 4.58}\n",
      "{'loss': 0.0296, 'grad_norm': 0.400390625, 'learning_rate': 7.44466584665347e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0141, 'grad_norm': 0.2890625, 'learning_rate': 7.378983170608982e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0537, 'grad_norm': 0.6171875, 'learning_rate': 7.313421689348862e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0295, 'grad_norm': 0.291015625, 'learning_rate': 7.24798443441015e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0042, 'grad_norm': 0.10302734375, 'learning_rate': 7.182674431585704e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0217, 'grad_norm': 0.56640625, 'learning_rate': 7.117494700784292e-05, 'epoch': 4.68}\n",
      "{'loss': 0.0139, 'grad_norm': 0.259765625, 'learning_rate': 7.052448255890957e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0252, 'grad_norm': 0.291015625, 'learning_rate': 6.98753810462766e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0056, 'grad_norm': 0.154296875, 'learning_rate': 6.922767248414184e-05, 'epoch': 4.74}\n",
      "{'loss': 0.0239, 'grad_norm': 0.43359375, 'learning_rate': 6.858138682229376e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0112, 'grad_norm': 0.322265625, 'learning_rate': 6.793655394472644e-05, 'epoch': 4.77}\n",
      "{'loss': 0.0194, 'grad_norm': 0.4765625, 'learning_rate': 6.729320366825784e-05, 'epoch': 4.79}\n",
      "{'loss': 0.0376, 'grad_norm': 0.6015625, 'learning_rate': 6.665136574115096e-05, 'epoch': 4.8}\n",
      "{'loss': 0.0422, 'grad_norm': 0.318359375, 'learning_rate': 6.601106984173835e-05, 'epoch': 4.82}\n",
      "{'loss': 0.0215, 'grad_norm': 0.32421875, 'learning_rate': 6.537234557704987e-05, 'epoch': 4.84}\n",
      "{'loss': 0.0086, 'grad_norm': 0.2236328125, 'learning_rate': 6.47352224814436e-05, 'epoch': 4.85}\n",
      "{'loss': 0.0039, 'grad_norm': 0.197265625, 'learning_rate': 6.409973001524012e-05, 'epoch': 4.87}\n",
      "{'loss': 0.0172, 'grad_norm': 0.271484375, 'learning_rate': 6.34658975633605e-05, 'epoch': 4.89}\n",
      "{'loss': 0.0086, 'grad_norm': 0.703125, 'learning_rate': 6.283375443396726e-05, 'epoch': 4.9}\n",
      "{'loss': 0.0221, 'grad_norm': 0.734375, 'learning_rate': 6.220332985710936e-05, 'epoch': 4.92}\n",
      "{'loss': 0.0068, 'grad_norm': 0.19140625, 'learning_rate': 6.157465298337057e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0293, 'grad_norm': 0.34375, 'learning_rate': 6.094775288252157e-05, 'epoch': 4.95}\n",
      " 64%|██████████████████████████               | 300/472 [11:11<06:07,  2.14s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.56it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.32it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.54it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.25it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  6.04it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.95it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.68it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.74it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.73it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:01<00:00,  5.72it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.55it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.62it/s]\u001b[A[2025-09-25 14:13:13,048] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.16635656356811523, 'eval_runtime': 2.672, 'eval_samples_per_second': 11.228, 'eval_steps_per_second': 5.614, 'epoch': 4.95}\n",
      " 64%|██████████████████████████               | 300/472 [11:14<06:07,  2.14s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.76it/s]\u001b[A\n",
      "{'loss': 0.027, 'grad_norm': 0.37109375, 'learning_rate': 6.0322658542175736e-05, 'epoch': 4.97}\n",
      "{'loss': 0.0154, 'grad_norm': 0.189453125, 'learning_rate': 5.969939886644884e-05, 'epoch': 4.99}\n",
      "{'loss': 0.0256, 'grad_norm': 0.39453125, 'learning_rate': 5.9078002674622465e-05, 'epoch': 5.0}\n",
      " 64%|██████████████████████████▎              | 303/472 [11:20<07:03,  2.51s/it][2025-09-25 14:13:19,886] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "{'loss': 0.0158, 'grad_norm': 0.1982421875, 'learning_rate': 5.845849869981137e-05, 'epoch': 5.01}\n",
      "{'loss': 0.0085, 'grad_norm': 0.37109375, 'learning_rate': 5.7840915587635014e-05, 'epoch': 5.03}\n",
      "{'loss': 0.0072, 'grad_norm': 0.185546875, 'learning_rate': 5.7225281894892935e-05, 'epoch': 5.05}\n",
      "{'loss': 0.0241, 'grad_norm': 0.251953125, 'learning_rate': 5.6611626088244194e-05, 'epoch': 5.06}\n",
      "{'loss': 0.0031, 'grad_norm': 0.0859375, 'learning_rate': 5.599997654289129e-05, 'epoch': 5.08}\n",
      "{'loss': 0.005, 'grad_norm': 0.1630859375, 'learning_rate': 5.539036154126799e-05, 'epoch': 5.1}\n",
      "{'loss': 0.0312, 'grad_norm': 0.46484375, 'learning_rate': 5.478280927173145e-05, 'epoch': 5.11}\n",
      "{'loss': 0.0026, 'grad_norm': 0.10693359375, 'learning_rate': 5.417734782725896e-05, 'epoch': 5.13}\n",
      "{'loss': 0.0032, 'grad_norm': 0.0986328125, 'learning_rate': 5.357400520414898e-05, 'epoch': 5.15}\n",
      "{'loss': 0.0028, 'grad_norm': 0.111328125, 'learning_rate': 5.297280930072632e-05, 'epoch': 5.16}\n",
      "{'loss': 0.0031, 'grad_norm': 0.1201171875, 'learning_rate': 5.2373787916052486e-05, 'epoch': 5.18}\n",
      "{'loss': 0.0072, 'grad_norm': 0.1396484375, 'learning_rate': 5.1776968748640063e-05, 'epoch': 5.2}\n",
      "{'loss': 0.004, 'grad_norm': 0.1513671875, 'learning_rate': 5.11823793951719e-05, 'epoch': 5.21}\n",
      "{'loss': 0.019, 'grad_norm': 0.25390625, 'learning_rate': 5.0590047349225135e-05, 'epoch': 5.23}\n",
      "{'loss': 0.0231, 'grad_norm': 0.365234375, 'learning_rate': 5.000000000000002e-05, 'epoch': 5.25}\n",
      "{'loss': 0.007, 'grad_norm': 0.13671875, 'learning_rate': 4.9412264631053216e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0057, 'grad_norm': 0.2216796875, 'learning_rate': 4.882686841903628e-05, 'epoch': 5.28}\n",
      "{'loss': 0.0135, 'grad_norm': 0.19140625, 'learning_rate': 4.824383843243929e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0126, 'grad_norm': 0.2109375, 'learning_rate': 4.7663201630338816e-05, 'epoch': 5.32}\n",
      "{'loss': 0.0137, 'grad_norm': 0.2578125, 'learning_rate': 4.7084984861151506e-05, 'epoch': 5.33}\n",
      "{'loss': 0.0214, 'grad_norm': 0.392578125, 'learning_rate': 4.650921486139278e-05, 'epoch': 5.35}\n",
      "{'loss': 0.0065, 'grad_norm': 0.1337890625, 'learning_rate': 4.593591825444028e-05, 'epoch': 5.37}\n",
      "{'loss': 0.0183, 'grad_norm': 0.28125, 'learning_rate': 4.5365121549302914e-05, 'epoch': 5.38}\n",
      "{'loss': 0.0014, 'grad_norm': 0.036376953125, 'learning_rate': 4.4796851139395335e-05, 'epoch': 5.4}\n",
      "{'loss': 0.0086, 'grad_norm': 0.150390625, 'learning_rate': 4.423113330131707e-05, 'epoch': 5.42}\n",
      "{'loss': 0.0051, 'grad_norm': 0.15625, 'learning_rate': 4.3667994193637796e-05, 'epoch': 5.43}\n",
      "{'loss': 0.0072, 'grad_norm': 0.208984375, 'learning_rate': 4.310745985568778e-05, 'epoch': 5.45}\n",
      " 70%|████████████████████████████▋            | 330/472 [12:17<04:57,  2.09s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.45it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.10it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  6.31it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:00<00:01,  6.01it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.81it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.72it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.49it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.58it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.57it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.57it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.45it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.53it/s]\u001b[A[2025-09-25 14:14:18,763] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17741312086582184, 'eval_runtime': 2.7398, 'eval_samples_per_second': 10.95, 'eval_steps_per_second': 5.475, 'epoch': 5.45}\n",
      " 70%|████████████████████████████▋            | 330/472 [12:19<04:57,  2.09s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.69it/s]\u001b[A\n",
      "{'loss': 0.0037, 'grad_norm': 0.1630859375, 'learning_rate': 4.25495562063537e-05, 'epoch': 5.47}\n",
      "{'loss': 0.0096, 'grad_norm': 0.263671875, 'learning_rate': 4.19943090428802e-05, 'epoch': 5.48}\n",
      "{'loss': 0.0043, 'grad_norm': 0.1376953125, 'learning_rate': 4.144174403967713e-05, 'epoch': 5.5}\n",
      "{'loss': 0.0051, 'grad_norm': 0.1318359375, 'learning_rate': 4.089188674713236e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0039, 'grad_norm': 0.1318359375, 'learning_rate': 4.034476259043012e-05, 'epoch': 5.53}\n",
      "{'loss': 0.0042, 'grad_norm': 0.1552734375, 'learning_rate': 3.980039686837568e-05, 'epoch': 5.55}\n",
      "{'loss': 0.0033, 'grad_norm': 0.080078125, 'learning_rate': 3.9258814752225284e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0122, 'grad_norm': 0.1748046875, 'learning_rate': 3.872004128452231e-05, 'epoch': 5.58}\n",
      "{'loss': 0.0029, 'grad_norm': 0.2392578125, 'learning_rate': 3.8184101377939476e-05, 'epoch': 5.6}\n",
      "{'loss': 0.0049, 'grad_norm': 0.12109375, 'learning_rate': 3.7651019814126654e-05, 'epoch': 5.62}\n",
      "{'loss': 0.0324, 'grad_norm': 0.81640625, 'learning_rate': 3.7120821242565086e-05, 'epoch': 5.63}\n",
      "{'loss': 0.0014, 'grad_norm': 0.042236328125, 'learning_rate': 3.6593530179427535e-05, 'epoch': 5.65}\n",
      "{'loss': 0.0043, 'grad_norm': 0.205078125, 'learning_rate': 3.606917100644488e-05, 'epoch': 5.67}\n",
      "{'loss': 0.0184, 'grad_norm': 1.1015625, 'learning_rate': 3.554776796977836e-05, 'epoch': 5.68}\n",
      "{'loss': 0.0059, 'grad_norm': 0.2490234375, 'learning_rate': 3.5029345178898756e-05, 'epoch': 5.7}\n",
      "{'loss': 0.0223, 'grad_norm': 0.2216796875, 'learning_rate': 3.45139266054715e-05, 'epoch': 5.72}\n",
      "{'loss': 0.0086, 'grad_norm': 0.259765625, 'learning_rate': 3.400153608224807e-05, 'epoch': 5.74}\n",
      "{'loss': 0.0093, 'grad_norm': 0.1884765625, 'learning_rate': 3.3492197301964145e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0486, 'grad_norm': 0.396484375, 'learning_rate': 3.298593381624406e-05, 'epoch': 5.77}\n",
      "{'loss': 0.0017, 'grad_norm': 0.06494140625, 'learning_rate': 3.248276903451171e-05, 'epoch': 5.79}\n",
      "{'loss': 0.0068, 'grad_norm': 0.11474609375, 'learning_rate': 3.198272622290804e-05, 'epoch': 5.8}\n",
      "{'loss': 0.0115, 'grad_norm': 0.1748046875, 'learning_rate': 3.1485828503215585e-05, 'epoch': 5.82}\n",
      "{'loss': 0.0029, 'grad_norm': 0.0791015625, 'learning_rate': 3.099209885178882e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0125, 'grad_norm': 0.1572265625, 'learning_rate': 3.0501560098492056e-05, 'epoch': 5.85}\n",
      "{'loss': 0.0028, 'grad_norm': 0.13671875, 'learning_rate': 3.0014234925643837e-05, 'epoch': 5.87}\n",
      "{'loss': 0.0064, 'grad_norm': 0.1904296875, 'learning_rate': 2.9530145866967895e-05, 'epoch': 5.89}\n",
      "{'loss': 0.0036, 'grad_norm': 0.1337890625, 'learning_rate': 2.9049315306551304e-05, 'epoch': 5.9}\n",
      "{'loss': 0.0483, 'grad_norm': 0.46484375, 'learning_rate': 2.8571765477809643e-05, 'epoch': 5.92}\n",
      "{'loss': 0.0052, 'grad_norm': 0.2099609375, 'learning_rate': 2.8097518462458562e-05, 'epoch': 5.94}\n",
      "{'loss': 0.0058, 'grad_norm': 0.1591796875, 'learning_rate': 2.7626596189492983e-05, 'epoch': 5.95}\n",
      " 76%|███████████████████████████████▎         | 360/472 [13:23<03:58,  2.13s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 11.69it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  7.38it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:02,  4.74it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:01<00:01,  4.98it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.14it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.30it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.28it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.41it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:01<00:00,  5.46it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.50it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  5.36it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  5.44it/s]\u001b[A[2025-09-25 14:15:25,118] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17853529751300812, 'eval_runtime': 2.8899, 'eval_samples_per_second': 10.381, 'eval_steps_per_second': 5.19, 'epoch': 5.95}\n",
      " 76%|███████████████████████████████▎         | 360/472 [13:26<03:58,  2.13s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.59it/s]\u001b[A\n",
      "{'loss': 0.0026, 'grad_norm': 0.12890625, 'learning_rate': 2.71590204341731e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0288, 'grad_norm': 0.416015625, 'learning_rate': 2.669481281701739e-05, 'epoch': 5.99}\n",
      "{'loss': 0.0116, 'grad_norm': 0.275390625, 'learning_rate': 2.623399480280292e-05, 'epoch': 6.0}\n",
      " 77%|███████████████████████████████▌         | 363/472 [13:32<04:35,  2.53s/it][2025-09-25 14:15:32,422] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "{'loss': 0.0035, 'grad_norm': 0.10986328125, 'learning_rate': 2.5776587699573006e-05, 'epoch': 6.01}\n",
      "{'loss': 0.0083, 'grad_norm': 0.162109375, 'learning_rate': 2.5322612657651634e-05, 'epoch': 6.03}\n",
      "{'loss': 0.0046, 'grad_norm': 0.1513671875, 'learning_rate': 2.487209066866565e-05, 'epoch': 6.04}\n",
      "{'loss': 0.0222, 'grad_norm': 0.302734375, 'learning_rate': 2.4425042564574184e-05, 'epoch': 6.06}\n",
      "{'loss': 0.0155, 'grad_norm': 0.185546875, 'learning_rate': 2.3981489016705205e-05, 'epoch': 6.08}\n",
      "{'loss': 0.0047, 'grad_norm': 0.111328125, 'learning_rate': 2.354145053479978e-05, 'epoch': 6.09}\n",
      "{'loss': 0.002, 'grad_norm': 0.064453125, 'learning_rate': 2.3104947466063787e-05, 'epoch': 6.11}\n",
      "{'loss': 0.0116, 'grad_norm': 0.12890625, 'learning_rate': 2.2671999994226978e-05, 'epoch': 6.13}\n",
      "{'loss': 0.0029, 'grad_norm': 0.09765625, 'learning_rate': 2.2242628138609623e-05, 'epoch': 6.14}\n",
      "{'loss': 0.0064, 'grad_norm': 0.1513671875, 'learning_rate': 2.181685175319702e-05, 'epoch': 6.16}\n",
      "{'loss': 0.0147, 'grad_norm': 0.22265625, 'learning_rate': 2.139469052572127e-05, 'epoch': 6.18}\n",
      "{'loss': 0.0021, 'grad_norm': 0.07666015625, 'learning_rate': 2.0976163976750984e-05, 'epoch': 6.19}\n",
      "{'loss': 0.0082, 'grad_norm': 0.15625, 'learning_rate': 2.0561291458788733e-05, 'epoch': 6.21}\n",
      "{'loss': 0.0127, 'grad_norm': 0.1455078125, 'learning_rate': 2.0150092155376133e-05, 'epoch': 6.23}\n",
      "{'loss': 0.0033, 'grad_norm': 0.10888671875, 'learning_rate': 1.9742585080206755e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0045, 'grad_norm': 0.12109375, 'learning_rate': 1.9338789076247e-05, 'epoch': 6.26}\n",
      "{'loss': 0.0044, 'grad_norm': 0.099609375, 'learning_rate': 1.893872281486486e-05, 'epoch': 6.28}\n",
      "{'loss': 0.02, 'grad_norm': 0.25, 'learning_rate': 1.854240479496643e-05, 'epoch': 6.29}\n",
      "{'loss': 0.0017, 'grad_norm': 0.06103515625, 'learning_rate': 1.8149853342140645e-05, 'epoch': 6.31}\n",
      "{'loss': 0.0127, 'grad_norm': 0.1708984375, 'learning_rate': 1.776108660781186e-05, 'epoch': 6.33}\n",
      "{'loss': 0.0023, 'grad_norm': 0.11767578125, 'learning_rate': 1.7376122568400532e-05, 'epoch': 6.34}\n",
      "{'loss': 0.0023, 'grad_norm': 0.12060546875, 'learning_rate': 1.6994979024491942e-05, 'epoch': 6.36}\n",
      "{'loss': 0.0059, 'grad_norm': 0.11865234375, 'learning_rate': 1.6617673600013296e-05, 'epoch': 6.38}\n",
      "{'loss': 0.0127, 'grad_norm': 0.1669921875, 'learning_rate': 1.6244223741418573e-05, 'epoch': 6.39}\n",
      "{'loss': 0.0017, 'grad_norm': 0.062255859375, 'learning_rate': 1.587464671688187e-05, 'epoch': 6.41}\n",
      "{'loss': 0.0068, 'grad_norm': 0.125, 'learning_rate': 1.5508959615499142e-05, 'epoch': 6.43}\n",
      "{'loss': 0.0019, 'grad_norm': 0.0654296875, 'learning_rate': 1.5147179346497664e-05, 'epoch': 6.45}\n",
      " 83%|█████████████████████████████████▉       | 390/472 [14:30<03:06,  2.27s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01,  9.95it/s]\u001b[A\n",
      " 20%|████████▊                                   | 3/15 [00:00<00:01,  7.13it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  6.24it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  5.56it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:01<00:01,  5.33it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.18it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.13it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  4.99it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.04it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:02<00:00,  5.03it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.03it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  4.88it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  4.94it/s]\u001b[A[2025-09-25 14:16:32,389] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17974495887756348, 'eval_runtime': 3.0527, 'eval_samples_per_second': 9.827, 'eval_steps_per_second': 4.914, 'epoch': 6.45}\n",
      " 83%|█████████████████████████████████▉       | 390/472 [14:33<03:06,  2.27s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  4.96it/s]\u001b[A\n",
      "{'loss': 0.0114, 'grad_norm': 0.1552734375, 'learning_rate': 1.4789322638454351e-05, 'epoch': 6.46}\n",
      "{'loss': 0.0105, 'grad_norm': 0.2021484375, 'learning_rate': 1.443540603852227e-05, 'epoch': 6.48}\n",
      "{'loss': 0.0244, 'grad_norm': 0.25, 'learning_rate': 1.4085445911665407e-05, 'epoch': 6.5}\n",
      "{'loss': 0.0066, 'grad_norm': 0.1513671875, 'learning_rate': 1.373945843990192e-05, 'epoch': 6.51}\n",
      "{'loss': 0.004, 'grad_norm': 0.275390625, 'learning_rate': 1.339745962155613e-05, 'epoch': 6.53}\n",
      "{'loss': 0.003, 'grad_norm': 0.2021484375, 'learning_rate': 1.3059465270518468e-05, 'epoch': 6.55}\n",
      "{'loss': 0.0134, 'grad_norm': 0.15234375, 'learning_rate': 1.272549101551438e-05, 'epoch': 6.56}\n",
      "{'loss': 0.0074, 'grad_norm': 0.1298828125, 'learning_rate': 1.2395552299381741e-05, 'epoch': 6.58}\n",
      "{'loss': 0.0062, 'grad_norm': 0.1708984375, 'learning_rate': 1.2069664378356604e-05, 'epoch': 6.6}\n",
      "{'loss': 0.0123, 'grad_norm': 0.21484375, 'learning_rate': 1.1747842321367886e-05, 'epoch': 6.61}\n",
      "{'loss': 0.0018, 'grad_norm': 0.05517578125, 'learning_rate': 1.1430101009340576e-05, 'epoch': 6.63}\n",
      "{'loss': 0.0032, 'grad_norm': 0.1396484375, 'learning_rate': 1.1116455134507664e-05, 'epoch': 6.65}\n",
      "{'loss': 0.0028, 'grad_norm': 0.07470703125, 'learning_rate': 1.0806919199730615e-05, 'epoch': 6.66}\n",
      "{'loss': 0.0113, 'grad_norm': 0.21484375, 'learning_rate': 1.0501507517829012e-05, 'epoch': 6.68}\n",
      "{'loss': 0.0123, 'grad_norm': 0.1904296875, 'learning_rate': 1.0200234210918559e-05, 'epoch': 6.7}\n",
      "{'loss': 0.0028, 'grad_norm': 0.1064453125, 'learning_rate': 9.903113209758096e-06, 'epoch': 6.71}\n",
      "{'loss': 0.007, 'grad_norm': 0.3984375, 'learning_rate': 9.610158253105539e-06, 'epoch': 6.73}\n",
      "{'loss': 0.0034, 'grad_norm': 0.11572265625, 'learning_rate': 9.321382887082563e-06, 'epoch': 6.75}\n",
      "{'loss': 0.0114, 'grad_norm': 0.228515625, 'learning_rate': 9.036800464548157e-06, 'epoch': 6.76}\n",
      "{'loss': 0.0059, 'grad_norm': 0.162109375, 'learning_rate': 8.756424144481312e-06, 'epoch': 6.78}\n",
      "{'loss': 0.0064, 'grad_norm': 0.166015625, 'learning_rate': 8.480266891372469e-06, 'epoch': 6.8}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0693359375, 'learning_rate': 8.208341474624071e-06, 'epoch': 6.82}\n",
      "{'loss': 0.0133, 'grad_norm': 0.21875, 'learning_rate': 7.940660467960137e-06, 'epoch': 6.83}\n",
      "{'loss': 0.0022, 'grad_norm': 0.09228515625, 'learning_rate': 7.677236248844855e-06, 'epoch': 6.85}\n",
      "{'loss': 0.0105, 'grad_norm': 0.20703125, 'learning_rate': 7.4180809979102036e-06, 'epoch': 6.87}\n",
      "{'loss': 0.0129, 'grad_norm': 0.169921875, 'learning_rate': 7.163206698392744e-06, 'epoch': 6.88}\n",
      "{'loss': 0.0054, 'grad_norm': 0.1376953125, 'learning_rate': 6.9126251355795864e-06, 'epoch': 6.9}\n",
      "{'loss': 0.0107, 'grad_norm': 0.212890625, 'learning_rate': 6.666347896263325e-06, 'epoch': 6.92}\n",
      "{'loss': 0.0135, 'grad_norm': 0.189453125, 'learning_rate': 6.424386368206392e-06, 'epoch': 6.93}\n",
      "{'loss': 0.002, 'grad_norm': 0.07177734375, 'learning_rate': 6.186751739614405e-06, 'epoch': 6.95}\n",
      " 89%|████████████████████████████████████▍    | 420/472 [15:42<01:59,  2.30s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01,  9.68it/s]\u001b[A\n",
      " 20%|████████▊                                   | 3/15 [00:00<00:01,  7.10it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  6.19it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  5.53it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:01<00:01,  5.30it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.17it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.11it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  4.93it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:01,  4.98it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:02<00:00,  4.99it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  4.99it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  4.86it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  4.91it/s]\u001b[A[2025-09-25 14:17:44,486] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18098019063472748, 'eval_runtime': 3.079, 'eval_samples_per_second': 9.743, 'eval_steps_per_second': 4.872, 'epoch': 6.95}\n",
      " 89%|████████████████████████████████████▍    | 420/472 [15:45<01:59,  2.30s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.02it/s]\u001b[A\n",
      "{'loss': 0.0107, 'grad_norm': 0.2255859375, 'learning_rate': 5.953454998618857e-06, 'epoch': 6.97}\n",
      "{'loss': 0.0016, 'grad_norm': 0.0439453125, 'learning_rate': 5.724506932769014e-06, 'epoch': 6.98}\n",
      "{'loss': 0.0158, 'grad_norm': 0.25390625, 'learning_rate': 5.499918128533155e-06, 'epoch': 7.0}\n",
      "{'loss': 0.0023, 'grad_norm': 0.0791015625, 'learning_rate': 5.27969897080901e-06, 'epoch': 7.02}\n",
      " 90%|████████████████████████████████████▊    | 424/472 [15:54<02:04,  2.60s/it][2025-09-25 14:17:54,192] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:1636135] [RANK:0] packing_efficiency_estimate: 0.83 total_num_tokens per device: 1643670\u001b[39m\n",
      "{'loss': 0.004, 'grad_norm': 0.15625, 'learning_rate': 5.063859642443536e-06, 'epoch': 7.01}\n",
      "{'loss': 0.0091, 'grad_norm': 0.1796875, 'learning_rate': 4.8524101237621635e-06, 'epoch': 7.03}\n",
      "{'loss': 0.0035, 'grad_norm': 0.08740234375, 'learning_rate': 4.6453601921072395e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0024, 'grad_norm': 0.09326171875, 'learning_rate': 4.442719421385922e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0098, 'grad_norm': 0.1611328125, 'learning_rate': 4.244497181627549e-06, 'epoch': 7.08}\n",
      "{'loss': 0.0041, 'grad_norm': 0.099609375, 'learning_rate': 4.050702638550275e-06, 'epoch': 7.1}\n",
      "{'loss': 0.0024, 'grad_norm': 0.09619140625, 'learning_rate': 3.861344753137319e-06, 'epoch': 7.11}\n",
      "{'loss': 0.0021, 'grad_norm': 0.0927734375, 'learning_rate': 3.6764322812226415e-06, 'epoch': 7.13}\n",
      "{'loss': 0.0282, 'grad_norm': 0.2421875, 'learning_rate': 3.495973773086014e-06, 'epoch': 7.15}\n",
      "{'loss': 0.0017, 'grad_norm': 0.08642578125, 'learning_rate': 3.319977573057642e-06, 'epoch': 7.16}\n",
      "{'loss': 0.0111, 'grad_norm': 0.2236328125, 'learning_rate': 3.1484518191324254e-06, 'epoch': 7.18}\n",
      "{'loss': 0.0192, 'grad_norm': 0.3046875, 'learning_rate': 2.9814044425935606e-06, 'epoch': 7.2}\n",
      "{'loss': 0.0025, 'grad_norm': 0.11083984375, 'learning_rate': 2.818843167645835e-06, 'epoch': 7.21}\n",
      "{'loss': 0.0079, 'grad_norm': 0.171875, 'learning_rate': 2.6607755110584887e-06, 'epoch': 7.23}\n",
      "{'loss': 0.0199, 'grad_norm': 0.244140625, 'learning_rate': 2.5072087818176382e-06, 'epoch': 7.25}\n",
      "{'loss': 0.011, 'grad_norm': 0.1484375, 'learning_rate': 2.3581500807882462e-06, 'epoch': 7.26}\n",
      "{'loss': 0.0131, 'grad_norm': 0.1875, 'learning_rate': 2.2136063003858733e-06, 'epoch': 7.28}\n",
      "{'loss': 0.0052, 'grad_norm': 0.134765625, 'learning_rate': 2.073584124257899e-06, 'epoch': 7.3}\n",
      "{'loss': 0.0144, 'grad_norm': 0.251953125, 'learning_rate': 1.938090026974504e-06, 'epoch': 7.32}\n",
      "{'loss': 0.0085, 'grad_norm': 0.1640625, 'learning_rate': 1.8071302737293295e-06, 'epoch': 7.33}\n",
      "{'loss': 0.0031, 'grad_norm': 0.10498046875, 'learning_rate': 1.6807109200496995e-06, 'epoch': 7.35}\n",
      "{'loss': 0.0324, 'grad_norm': 0.36328125, 'learning_rate': 1.5588378115166669e-06, 'epoch': 7.37}\n",
      "{'loss': 0.0021, 'grad_norm': 0.080078125, 'learning_rate': 1.4415165834947064e-06, 'epoch': 7.38}\n",
      "{'loss': 0.0039, 'grad_norm': 0.111328125, 'learning_rate': 1.3287526608711131e-06, 'epoch': 7.4}\n",
      "{'loss': 0.0062, 'grad_norm': 0.1328125, 'learning_rate': 1.2205512578051913e-06, 'epoch': 7.42}\n",
      "{'loss': 0.0094, 'grad_norm': 0.140625, 'learning_rate': 1.1169173774871478e-06, 'epoch': 7.43}\n",
      " 95%|███████████████████████████████████████  | 450/472 [16:53<00:50,  2.27s/it]\n",
      "  0%|                                                    | 0/15 [00:00<?, ?it/s]\u001b[A\n",
      " 13%|█████▊                                      | 2/15 [00:00<00:01, 10.11it/s]\u001b[A\n",
      " 27%|███████████▋                                | 4/15 [00:00<00:01,  6.42it/s]\u001b[A\n",
      " 33%|██████████████▋                             | 5/15 [00:00<00:01,  5.75it/s]\u001b[A\n",
      " 40%|█████████████████▌                          | 6/15 [00:01<00:01,  5.49it/s]\u001b[A\n",
      " 47%|████████████████████▌                       | 7/15 [00:01<00:01,  5.30it/s]\u001b[A\n",
      " 53%|███████████████████████▍                    | 8/15 [00:01<00:01,  5.23it/s]\u001b[A\n",
      " 60%|██████████████████████████▍                 | 9/15 [00:01<00:01,  5.01it/s]\u001b[A\n",
      " 67%|████████████████████████████▋              | 10/15 [00:01<00:00,  5.07it/s]\u001b[A\n",
      " 73%|███████████████████████████████▌           | 11/15 [00:02<00:00,  5.05it/s]\u001b[A\n",
      " 80%|██████████████████████████████████▍        | 12/15 [00:02<00:00,  5.05it/s]\u001b[A\n",
      " 87%|█████████████████████████████████████▎     | 13/15 [00:02<00:00,  4.91it/s]\u001b[A\n",
      " 93%|████████████████████████████████████████▏  | 14/15 [00:02<00:00,  4.95it/s]\u001b[A[2025-09-25 14:18:55,551] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:1636135] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.180302694439888, 'eval_runtime': 3.0323, 'eval_samples_per_second': 9.893, 'eval_steps_per_second': 4.947, 'epoch': 7.43}\n",
      " 95%|███████████████████████████████████████  | 450/472 [16:56<00:50,  2.27s/it]\n",
      "100%|███████████████████████████████████████████| 15/15 [00:02<00:00,  5.06it/s]\u001b[A\n",
      "{'loss': 0.0116, 'grad_norm': 0.1796875, 'learning_rate': 1.0178558119067315e-06, 'epoch': 7.45}\n",
      "{'loss': 0.0141, 'grad_norm': 0.216796875, 'learning_rate': 9.233711416316571e-07, 'epoch': 7.47}\n",
      "{'loss': 0.0035, 'grad_norm': 0.1240234375, 'learning_rate': 8.334677355958054e-07, 'epoch': 7.48}\n",
      "{'loss': 0.0027, 'grad_norm': 0.09375, 'learning_rate': 7.481497508972312e-07, 'epoch': 7.5}\n",
      "{'loss': 0.0132, 'grad_norm': 0.2255859375, 'learning_rate': 6.674211326058721e-07, 'epoch': 7.52}\n",
      "{'loss': 0.0017, 'grad_norm': 0.05859375, 'learning_rate': 5.912856135812051e-07, 'epoch': 7.53}\n",
      "{'loss': 0.0216, 'grad_norm': 0.1748046875, 'learning_rate': 5.19746714299596e-07, 'epoch': 7.55}\n",
      "{'loss': 0.0048, 'grad_norm': 0.1025390625, 'learning_rate': 4.5280774269154115e-07, 'epoch': 7.57}\n",
      "{'loss': 0.0042, 'grad_norm': 0.083984375, 'learning_rate': 3.9047179398866704e-07, 'epoch': 7.58}\n",
      "{'loss': 0.0071, 'grad_norm': 0.162109375, 'learning_rate': 3.3274175058067846e-07, 'epoch': 7.6}\n",
      "{'loss': 0.0022, 'grad_norm': 0.08154296875, 'learning_rate': 2.7962028188198706e-07, 'epoch': 7.62}\n",
      "{'loss': 0.0036, 'grad_norm': 0.09033203125, 'learning_rate': 2.311098442083659e-07, 'epoch': 7.63}\n",
      "{'loss': 0.0021, 'grad_norm': 0.08056640625, 'learning_rate': 1.8721268066330676e-07, 'epoch': 7.65}\n",
      "{'loss': 0.0118, 'grad_norm': 0.11962890625, 'learning_rate': 1.4793082103435885e-07, 'epoch': 7.67}\n",
      "{'loss': 0.0018, 'grad_norm': 0.06494140625, 'learning_rate': 1.1326608169920372e-07, 'epoch': 7.68}\n",
      "{'loss': 0.0052, 'grad_norm': 0.11767578125, 'learning_rate': 8.322006554171146e-08, 'epoch': 7.7}\n",
      "{'loss': 0.0019, 'grad_norm': 0.061767578125, 'learning_rate': 5.7794161877833265e-08, 'epoch': 7.72}\n",
      "{'loss': 0.0018, 'grad_norm': 0.055419921875, 'learning_rate': 3.6989546391297256e-08, 'epoch': 7.74}\n",
      "{'loss': 0.0102, 'grad_norm': 0.2099609375, 'learning_rate': 2.080718107935198e-08, 'epoch': 7.75}\n",
      "{'loss': 0.0025, 'grad_norm': 0.1123046875, 'learning_rate': 9.24781420816867e-09, 'epoch': 7.77}\n",
      "{'loss': 0.0068, 'grad_norm': 0.25, 'learning_rate': 2.3119802783022615e-09, 'epoch': 7.79}\n",
      "{'loss': 0.0058, 'grad_norm': 0.1572265625, 'learning_rate': 0.0, 'epoch': 7.8} \n",
      "{'train_runtime': 1067.856, 'train_samples_per_second': 4.323, 'train_steps_per_second': 0.442, 'train_loss': 0.06631014162257227, 'epoch': 7.8}\n",
      "100%|█████████████████████████████████████████| 472/472 [17:47<00:00,  2.26s/it]\n",
      "[2025-09-25 14:19:46,784] [INFO] [axolotl.train.train:190] [PID:1636135] [RANK:0] Training Completed!!! Saving pre-trained model to ./out-Qwen2.5-0.5B-Instruct\u001b[39m\n",
      "(PeftModelForCausalLM(   (base_model): LoraModel(     (model): Qwen2ForCausalLM(       (model): Qwen2Model(         (embed_tokens): Embedding(151936, 896)         (layers): ModuleList(           (0-23): 24 x Qwen2DecoderLayer(             (self_attn): Qwen2FlashAttention2(               (q_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=896, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (k_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=128, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=128, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (v_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=128, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=128, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (o_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=896, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (rotary_emb): Qwen2RotaryEmbedding()             )             (mlp): Qwen2MLP(               (gate_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=4864, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4864, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (up_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=4864, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4864, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (down_proj): lora.Linear(                 (base_layer): Linear(in_features=4864, out_features=896, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4864, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (act_fn): SiLU()             )             (input_layernorm): Qwen2RMSNorm()             (post_attention_layernorm): Qwen2RMSNorm()           )         )         (norm): Qwen2RMSNorm()       )       (lm_head): Linear(in_features=896, out_features=151936, bias=False)     )   ) ), Qwen2TokenizerFast(name_or_path='Qwen/Qwen2.5-0.5B-Instruct', vocab_size=151643, model_max_length=131072, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={ \t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151657: AddedToken(\"<tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), \t151658: AddedToken(\"</tool_call>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), \t151659: AddedToken(\"<|fim_prefix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), \t151660: AddedToken(\"<|fim_middle|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), \t151661: AddedToken(\"<|fim_suffix|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), \t151662: AddedToken(\"<|fim_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), \t151663: AddedToken(\"<|repo_name|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), \t151664: AddedToken(\"<|file_sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=False), })\n",
      "\u001b[0mCPU times: user 7.7 s, sys: 2.2 s, total: 9.9 s\n",
      "Wall time: 19min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/accelerate launch -m axolotl.cli.train {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "qlora_model = f\"./out-{MODEL_SHORT_NAME}\"\n",
    "base_model = MODEL_NAME\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=False, padding_side='left')\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"auto\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").eval()\n",
    "model = PeftModel.from_pretrained(base_model, qlora_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the LoRA model (PEFT adapter) to HF Hub\n",
    "\n",
    "#hub_model_id = f\"NatLibFi/{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "#model.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the LoRA into the base model for inference\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BATCHED_LENGTH = 4096\n",
    "\n",
    "def generate(messages_batch):\n",
    "    texts = tokenizer.apply_chat_template(messages_batch, add_generation_prompt=True, tokenize=False)\n",
    "    inputs = tokenizer(texts, padding=\"longest\", return_tensors=\"pt\", return_token_type_ids=False)\n",
    "    inputs = {key: val.cuda() for key, val in inputs.items()}\n",
    "    if len(messages_batch) > 1 and inputs['input_ids'].shape[1] > MAX_BATCHED_LENGTH:\n",
    "        # there are long documents in the batch - break it down to two smaller batches to avoid excessive padding and related problems\n",
    "        half = int(len(messages_batch) / 2)\n",
    "        return generate(messages_batch[:half]) + generate(messages_batch[half:])\n",
    "    temp_texts=tokenizer.batch_decode(inputs[\"input_ids\"], skip_special_tokens=True)\n",
    "\n",
    "    gen_tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
    "    return [i[len(temp_texts[idx]):] for idx, i in enumerate(gen_text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A light enterprise information security architecture model for creating and improving security architecture\", \"alt_title\": [\"Kevyt yritystietoturva-arkkitehtuurimalli tietoturva-arkkitehtuurin luomiseksi ja kehitt\\u00e4miseksi {fi}\"], \"creator\": [\"Kossila, Johannes\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Improving security architecture\", \"creator\": [\"Kossila, Johannes\"], \"year\": \"2019\", \"publisher\": [\"Turun kauppakorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"An analysis of Facebook posts\", \"creator\": [\"To, My\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"An analysis of Facebook posts\", \"creator\": [\"To Ngoc My\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Analysis of user exploration patterns during scene cuts in omnidirectional videos\", \"creator\": [\"Monakhov, Dmitrii\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Analysis of user exploration patterns during scene cuts in omnidirectional videos\", \"creator\": [\"Monakhov, Dmitrii\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Benefits of kinetics and proxemics for a conceptual virtual reality Obeya : exploratory research on virtual reality as a medium for interpersonal interaction\", \"alt_title\": [\"Kinetiikan ja proksemiikan luomat edut konsptuaaliselle virtuaalitodellisuus Obeyalle {fi}\"], \"creator\": [\"Mattila, Jaakko\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \" realities obeya\", \"creator\": [\"Mattila, Jaakko\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Black African entrepreneurs in Finland: structural barriers\", \"creator\": [\"Vorobeva, Ekaterina\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Black African entrepreneurs in Finland : structural barriers\", \"creator\": [\"Vorobeva, Ekaterina\"], \"year\": \"2019\", \"publisher\": [\"University of Turkul\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Creating and implementing a business process model\", \"creator\": [\"Skog, Patrik\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Creating and implementing a business process model\", \"creator\": [\"Skog, Patrik\"], \"year\": \"2020\", \"publisher\": [\"University of Vaasa\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Developing a football game for Android\", \"alt_title\": [\"Jalkapallopelin kehitt\\u00e4minen Androidille {fi}\"], \"creator\": [\"Huhtam\\u00e4ki, Markus\"], \"year\": \"2021\", \"publisher\": [\"Tampere University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Developing a football game for Android\", \"alt_title\": [\"Jalkapallopelin kehitt\\u00e4minen Androidille {fi}\"], \"creator\": [\"Huhtam\\u00e4ki, Markus\"], \"year\": \"2021\", \"publisher\": [\"Tampere University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Gender differences in the Finnish labour market : decomposing the gender wage gap in Finland\", \"alt_title\": [\"K\\u00f6nsskillnader p\\u00e5 den finska arbetsmarknaden : en dekomponering av l\\u00f6negapet mellan k\\u00f6nen i Finland {sv}\"], \"creator\": [\"Kortelainen, Julia\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Gender differences in the Finnish labour market : decomposing the gender wage gap in Finland\", \"creator\": [\"Kortelainen, Julia\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"On the history and future of clarinet systems\", \"creator\": [\"Agababa Shaked, Gil\"], \"year\": \"2018\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"On the history and future of clarinet systems\", \"creator\": [\"Shaked, Gil\"], \"year\": \"2018\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Resource piroductivity as the EU\\u00b4s lead resource efficiency indicator : a quantitative macro-comparative study on indicator drivers\", \"alt_title\": [\"Resursproduktivitet som EU:s huvudindikator f\\u00f6r resurseffektivitet : en QMCR-studie p\\u00e5 faktorer som driver resursproduktivitet {sv}\"], \"creator\": [\"J\\u00e4rnefelt, Elisabeth\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Resource productivity as the EU\\u00b4s lead resource efficiency indicator : a quantitative macro-comparative study on indicator drivers\", \"creator\": [\"J\\u00e4rnefelt, Elisabeth\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Slippage between : a common void\", \"creator\": [\"Oliva, Maya\"], \"year\": \"2022\", \"publisher\": [\"Theatre Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Slippage between, a common void\", \"creator\": [\"Oliva, Maya\"], \"year\": \"2022\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The cultural history of politics in Swedish contemporary art.\", \"creator\": [\"Kozma, Madeleine\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"The cultural history of politics in Swedish contemporary art\", \"creator\": [\"Kozma, Madeleine\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The English-Finnish-Nepali-Arabic dictionary for nursing students\", \"creator\": [\"Olundegun, Ololade\", \"Pokharel, Jyoti\", \"Al-Rammahi, Mohammed\"], \"year\": \"2021\", \"publisher\": [\"Laurea University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": [\"en\"], \"title\": \"The English-Finnish-Nepali-Arabic dictionary for nursing students\", \"creator\": [\"Pokharel, Jyoti\", \"AL-Rammahi, Mohammed\", \"Oladugun, Ololade\"], \"year\": \"2021\", \"publisher\": [\"Laurea University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Utopian reconfiguration of the nature/culture dualism in Ursula Le Guin\\u2019s Always Coming Home\", \"creator\": [\"Veistola, Atte\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Utopian reconfiguration of the nature/culture dualism in Ursula Le Guin's Always Coming Home\", \"creator\": [\"Veistola, Atte\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"\\u2018The wrath of God on children of disobedience\\u2019\", \"alt_title\": [\"COVID-19 in the theology and ideology of the Westboro Baptist Church {en}\"], \"creator\": [\"\\u00d6stling, Erik\"], \"year\": \"2021\", \"doi\": \"10.30664/ar.107883\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"\\u00d6stling, Erik A. w.\", \"alt_title\": [\"\\u2018The wrath of God on children of disobedience\\u2019 : COVID-19 in the theology and ideology of the Westboro Baptist Church {en}\"], \"creator\": [\"W\\u00e4stling, Erik A. w.\"], \"year\": \"2021\", \"doi\": \"10.30664/ar.107883\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"\\\"Great horizons flooded with the alien light of the Sun\\\" : Le Sacre du Printemps in the Russian context\", \"creator\": [\"J\\u00e4rvinen, Hanna\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Great Horizons flooded with the alien light of the sun : Le Sacre du Printemps in the Russian context\", \"creator\": [\"J\\u00e4rvinen, Anitta\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A dynamic collusion analysis framework considering generation and transmission systems maintenance constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/EEM49802.2020.9221905\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"A dynamic collusion analysis framework considering generation and transmission systems maintenance constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/EEM49802.2020.9221905\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A review of optical nondestructive visual and near-infrared methods for food quality and safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\", \"Mantere, Timo\"], \"year\": \"2013\", \"publisher\": [\"Hindawi\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Review article : a review of optical nondestructive visual and near-infrared methods for food quality and safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir V.\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\", \"Mantere, Timo\"], \"year\": \"2013\", \"publisher\": [\"Hindawi\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"review article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Assessing trustworthy AI in times of COVID-19 : deep learning for predicting a multi-regional score conveying the degree of lung compromise in COVID-19 patients\", \"creator\": [\"Allahabadi, Himanshi\", \"Amann, Julia\", \"Balot, Isabelle\", \"Beretta, Andrea\", \"Binkley, Charles\", \"Bozenhard, Jonas\", \"Bruneault, Fr\\u00e9d\\u00e9rick\", \"Brusseau, James\", \"Candemir, Sema\", \"Cappellini, Luca Alessandro\", \"Castagnet, Genevieve Fieux\", \"Chakraborty, Subrata\", \"Cherciu, Nicoleta\", \"Cociancig, Christina\", \"Coffee, Megan\", \"Ek, Irene\", \"Espinosa-Leal, Leonardo\", \"Farina, Davide\", \"Fieux-Castagnet, Genevieve\", \"Frauenfelder, Thomas\", \"Gallucci, Alessio\", \"Giuliani, Guya\", \"Golda, Adam\", \"van Halem, Irmhild\", \"Hildt, Elisabeth\", \"Holm, Sune\", \"Kararigas, Georgios\", \"Krier, Sebastien A.\", \"K\\u00fchne, Ulrich\", \"Lizzi, Francesca\", \"Madai, Vince I.\", \"Markus, Aniek F.\", \"Masis, Serg\", \"Mathez, Emilie Wiinblad\", \"Mureddu, Francesco\", \"Neri, Emanuele\", \"Osika, Walter\", \"Ozols, Matiss\", \"Panigutti, Cecilia\", \"Parent, Brendan\", \"Pratesi, Francesca\", \"Moreno-S\\u00e1nchez, Pedro A.\", \"Sartor, Giovanni\", \"Savardi, Mattia\", \"Signoroni, Alberto\", \"Sormunen, Hanna\", \"Spezzatti, Andy\", \"Srivastava, Adarsh\", \"Stephansen, Annette F.\", \"Theng, Lau Bee\", \"Tithi, Jesmin Jahan\", \"Tuominen, Jarno\", \"Umbrello, Steven\", \"Vaccher, Filippo\", \"Vetter, Dennis\", \"Westerlund, Magnus\", \"Wurth, Renee\", \"Zicari, Roberto V.\"], \"year\": \"2022\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/TTS.2022.3195114\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Assessing trustworthy AI in times of COVID-19 : deep learning for predicting a multi-regional score conveying the degree of lung compromise in COVID-19 patients\", \"creator\": [\"Allahabadi, Himanshi\", \"Amann, Julia\", \"Balot, Isabelle\", \"Beretta, Andrea\", \"Binkley, Charles\", \"Bozenhard, Jonas\", \"Brusseau, James\", \"Candemir, Sema\", \"Alessandro Cappellini\", \"Genevieve Fieux Castagnet\", \"Subrata Chakraborty\", \"Nicoleta Cherciu\", \"Christina Cociancig\", \"Megan Coffee\", \"Irene Ek\", \"Leonardo Espinosa-Leal\", \"Davide Farina\", \"Genevi\\u00e8re Fieux-Castagnet\", \"Thomas Frauenfelder\", \"Alessio Gallucci\", \"Guya Giuliani\", \"Adam Golda\", \"Irmhild van Halem\", \"Esi Maas\", \"Matthew Osika\", \"Alberto Signoroni\", \"Hanna Sormunen\", \"Andy Spezzatti\", \"Adarsh Srivastava\", \"Annette F.\", \"Luisa Theng\", \"Jesmin Tithi\", \"Jarno Tuominen\", \"Steven Umbrello\", \"Filippo Vaccher\", \"Dennis Vetter\", \"Magnus Westerlund\", \"Renée Wurth\", \"Roberto V. Zicari\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring : a qualitative study\", \"creator\": [\"Korhonen, H.\", \"Tuomikoski, A-M.\", \"Oikarainen, A.\", \"K\\u00e4\\u00e4ri\\u00e4inen, M.\", \"Elo, S.\", \"Kyng\\u00e4s, H.\", \"Liikanen, E.\", \"Mikkonen, K.\"], \"year\": \"2019\", \"doi\": \"10.1016/j.nepr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring : a qualitative study\", \"creator\": [\"Korhonen, Heleena\", \"Tuomikoski, Anitta-Maija\", \"Oikarainen, Annika\", \"K\\u00e4\\u00e4ri\\u00e4inen, Martina\", \"Elo, S\\u00f6leyva\", \"Kyng\\u00e4s, Hans\", \"Liikanen, Eeva\"], \"year\": \"2019\", \"doi\": \"10.1016/j.nepr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Engaging audio based mobile applications\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"e-isbn\": [\"9788409147557\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Engaging audio-based mobile applications\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"publisher\": [\"Metropolia University of Applied Sciences\"], \"e-isbn\": [\"9788409147557\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Epistemically tuned-in?\", \"creator\": [\"St\\u00e5hl, Tore\"], \"year\": \"2020\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"EAPRIL 2019 conference proceedings\", \"creator\": [\"St\\u00e5hl, Tore\"], \"year\": \"2020\", \"publisher\": [\"EAPRIL\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"In the shadows : phenomenological choreographic writing\", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"doi\": \"10.1386/chor_00042_1\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"In the shadows : phenomenological choreographic writing\", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"doi\": \"10.1386/chor_00042_1_\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"MARISA ethical, legal and societal aspects\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"European Commission\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"MARISA : ethical, legal and societal aspects\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"European Commission\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Memories from the EAHIL Workshop\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Katri\", \"Mann, Mala\", \"Ferrinho, Ana Maria\", \"Ottjes, Robin\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Memories from the EAHIL workshop \\\"learn, share, act, bridge borders\\\" : welcome reception, gala dinner, visit to the botanical garden at the University of Basel and historical walk black death in Basel\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Katri\", \"Mann, Ma\\u00f3lia\", \"Ferrinho, Ami\", \"Ottjes, Rainer\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Supporting transformative agency among urban actors in the Change Laboratory intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"e-issn\": \"2328-4919\", \"p-issn\": \"2328-4900\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Supporting transformative agency among urban actors in the change laboratory intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The roles of temperature, nest predators and information parasites for geographical variation in egg covering behaviour of tits (Paridae)\", \"creator\": [\"Loukola, Olli J.\", \"Adamik, Peter\", \"Adriaensen, Frank\", \"Barba, Emilio\", \"Doligez, Blandine\", \"Flensted-Jensen, Einar\", \"Eeva, Tapio\", \"Kivel\\u00e4, Sami M.\", \"Laaksonen, Toni\", \"Morosinotto, Chiara\", \"M\\u00e4nd, Raivo\", \"Niemel\\u00e4, Petri T.\", \"Reme\\u0161, Vladimir\", \"Samplonius, Jelmer M.\", \"Sebastiano, Manrico\", \"Senar, Juan Carlos\", \"Slagsvold, Tore\", \"Sorace, Alberto\", \"Tschirren, Barbara\", \"T\\u00f6r\\u00f6k, J\\u00e1nos\", \"Forsman, Jukka T.\"], \"year\": \"2020\", \"publisher\": [\"John Wiley & Sons\"], \"doi\": \"10.1111/jbi.13830\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"The roles of temperature, nest predators and information parasites for geographical variation in egg covering behaviour of tits (Paridae)\", \"creator\": [\"Loukola, Olli J.\", \"Adamik, Peter\", \"Adriaensen, Frank\", \"Barba, Emilio\", \"Eeva, Tapio\", \"Eva, Sami\", \"M\\u00e4nd, Raivo\", \"Niemel\\u00e4, Petri\", \"Reme\\u0161, Vladimir\", \"Samplonius, Jelmer\", \"Sarn\", \"Slagsvold, Tore\", \"Sorace, Alberto\", \"Tschirren, Barbara\"], \"year\": \"2020\", \"publisher\": [\"John Wiley & Sons\"], \"doi\": \"10.1111/jbi.13830\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Why is CryptoKitties (not) gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Why is CryptoKitties (not) gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"se\", \"title\": \"T\\u0113 lijen s\\u014dmes p\\u0101len ai aktan saijesne s\\u0101mi\\u2019 : giella\\u010d\\u00e1j\\u00e1nasat boarr\\u00e1samos \\u010d\\u00e1llon s\\u00e1mi muitalusain\", \"creator\": [\"Ylikoski, Jussi\"], \"year\": \"2017\", \"publisher\": [\"S\\u00e1mis\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"se\", \"title\": \"T\\u0113 lijen s\\u014dmes p\\u0101len ai aktan saijesne s\\u0101mi\\u2019: Giella\\u010d\\u00e1j\\u00e1nasat boarr\\u00e1samos \\u010d\\u00e1llon s\\u00e1mi muitalusain\", \"creator\": [\"Ylikoski, Jussi\"], \"year\": \"2017\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Bothnian Bay hydrogen valley :  research report\", \"year\": \"2021\", \"publisher\": [\"LUT University\"], \"e-isbn\": [\"9789523357631\"], \"p-issn\": \"2243-3376\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Bothnian Bay Hydrogen Valley : research report\", \"creator\": [\"Karjunen, Hannu\", \"Lassila, Jukka\", \"Tynj\\u00e4l\\u00e4, Tero\", \"Laaksonen, Petri\", \"Tuomaala, Mari\", \"Vilppo, Julius\", \"Taulasto, Kimmo\", \"Karppanen, Janne\", \"Laari, Arto\", \"Kosonen, Antti\", \"Ahola, Jero\"], \"year\": \"2021\", \"publisher\": [\"Lappeenrannan-Lahden Teknillinen Yliopisto\"], \"e-isbn\": [\"9789523357631\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Channels of dialogue between international businesses and national governments : the implications for domestic reforms and international relations in the case of Russia\", \"creator\": [\"Yakovlev, Andrei\", \"Freinkman, Lev\", \"Ershova, Nina\"], \"year\": \"2018\", \"publisher\": [\"Bank of Finland\"], \"e-issn\": \"2342-205X\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Channels of dialogue between international businesses and national governments : the implications for domestic reforms and international relations in the case of Russia\", \"creator\": [\"Yakovlev, Andrei\", \"Freinkman, Lev\", \"Ershova, Nina\"], \"year\": \"2018\", \"publisher\": [\"Bank of Finland\"], \"e-issn\": \"2342-205X\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Finland in Figures 2015\", \"publisher\": [\"Statistics Finland\"], \"e-isbn\": [\"9789522445896\"], \"p-isbn\": [\"9789522445223\"], \"e-issn\": \"2242-8496\", \"p-issn\": \"0357-0371\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Finland in figures 2015\", \"publisher\": [\"Statistics Finland\"], \"e-isbn\": [\"9789522444595\"], \"p-isbn\": [\"9789522444602\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Housing market and current account imbalances in the international economy\", \"creator\": [\"Punzi, Maria Teresa\"], \"year\": \"2012\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789524627849\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Housing market and current account imbalances in the international economy\", \"creator\": [\"Punzi, Maria Teresa\"], \"year\": \"2012\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789524627849\"], \"p-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"How to explain errors in budget balance forecasts in euro area countries? : empirical evidence based on real-time data\", \"alt_title\": [\"Miten euromaiden budjettivajeita koskevia ennustevirheit\\u00e4 voidaan selitt\\u00e4\\u00e4 reaaliaikaisen aineiston avulla? {fi}\"], \"creator\": [\"Paloviita, Maritta\", \"Ikonen, Pasi\"], \"year\": \"2016\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789523231146\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"How to explain errors in budget balance forecasts in euro area countries? : empirical evidence based on real-time data\", \"creator\": [\"Paloviita, Maritta\", \"Ikonen, Pasi\"], \"year\": \"2016\", \"publisher\": [\"Bank of Finland\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A discourse analytic approach to HEI leadership in Finland : the what and how of rectors\\u2019 leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521241864\", \"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"A discourse analytic approach to HEI leadership in Finland : the what and how of rectors' leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521241864\"], \"p-isbn\": [\"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A Jungian theory of mind : individuality, lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"A Jungian theory of mind : individuality lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Aminophenolato complexes of Mo, W and V in catalytic alkene epoxidation and catechol oxidation\", \"alt_title\": [\"Mo, W ja V aminofenolaattokompleksit katalyyttisess\\u00e4 alkeenien epoksidaatiossa ja katekolien hapetuksessa {fi}\"], \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Aminophenolato complexes of mo, w and v in catalytic alkene epoxidation and catechol oxidation\", \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"alt_title\": [\"Sinitiaisten pes\\u00e4nrakennusk\\u00e4ytt\\u00e4ytymisen vaihtelun syyt ja seuraukset {fi}\"], \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : a population-based study\", \"alt_title\": [\"Muutokset mielenterveyden ongelmissa, kiusaamisessa, yksin\\u00e4isyydess\\u00e4 ja palveluiden k\\u00e4yt\\u00f6ss\\u00e4 suomenkielisten 8-9- vuotiaiden lasten joukossa 24 vuoden aikana : v\\u00e4est\\u00f6pohjainen tutkimus {fi}\"], \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : a population-based study\", \"alt_title\": [\"Gangkanyaan laitos voimansiirtoketjun j\\u00e4rjestelm\\u00f6mistalla k\\u00e4upungeikkoiden hoitamin\\u00f6kulmia ja k\\u00e4upungeiksi t\\u00e4iden 24 m\\u00f6nisteri {fi}\"], \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"University of Helsinki\"], \"e-isbn\": [\"9789515176912\"], \"p-isbn\": [\"9789515176905\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"University of Helsinki\"], \"e-isbn\": [\"9789515176912\"], \"p-isbn\": [\"9789515176905\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Employee trust repair in the context of organizational change : identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Employee trust repair in the context of organizational change : identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Essays on economic productivity\", \"alt_title\": [\"Esseit\\u00e4 taloudellisesta tuottavuudesta {fi}\"], \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Essays on economic productivity\", \"alt_title\": [\"Esseit\\u00e4 taloudellisesta tuottavuudesta {fi}\"], \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Light field compression using disparity-based 4D predictive coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Light field compression using disparity-based 4D predictive coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Light manipulation in multilayer metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Light manipulation in multilayer metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Performance exploration and testing of web-based software systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239991\"], \"p-isbn\": [\"9789521240003\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Performance exploration and testing of web-based software systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"\\u02daAbo Akademi University\"], \"e-isbn\": [\"9789521240003\"], \"p-isbn\": [\"9789521239991\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Power of myths in energy transition : unveiling timeless mythologies in Finnish energy agora\", \"alt_title\": [\"Myytit energiamurroksessa : ajattomien mytologioiden voima suomalaisessa energia-agorassa {fi}\"], \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"University of Vaasa\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Power of myths in energy transition : unveiling timeless mythologies in Finnish energy agora\", \"alt_title\": [\"Myths in energy transition : unveiling timeless mythologies in Finnish energy agorassa {en}\"], \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Problem gambling in a Nordic context : moving from social factors to a psychosocial perspective\", \"alt_title\": [\"Spelproblem i en nordisk kontext : fr\\u00e5n sociala faktorer till ett psykosocialt perspektiv {sv}\"], \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521238700\"], \"p-isbn\": [\"9789521238694\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Problem gambling in a Nordic context : moving from social factors to a psychosocial perspective\", \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239700\"], \"p-isbn\": [\"9789521238700\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Rescheduling sudden absences of nursing staff in hospital settings\", \"alt_title\": [\"Hoitohenkil\\u00f6kunnan \\u00e4killisten poissaolojen hallinta sairaaloissa {fi}\"], \"creator\": [\"Tuominen, Outi\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512979615\"], \"p-isbn\": [\"9789512979608\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Rescheduling sudden absences of nursing staff in hospital settings\", \"creator\": [\"Tuominen, Outi\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512979615\"], \"p-isbn\": [\"9789512979608\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Role of urinary findings and adipokines in Puumala virus-induced acute kidney injury\", \"creator\": [\"Mantula, Paula\"], \"year\": \"2021\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520318802\"], \"p-isbn\": [\"978\\u00ad952\\u00ad03\\u00ad1879\\u00ad6\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Role of urinary findings and adipokines in puumala virus-induced acute kidney injury\", \"creator\": [\"Mantula, Paula\"], \"year\": \"2021\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520318796\"], \"p-isbn\": [\"9789520318802\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Surgical, oncological and reconstructive outcomes after complex oncological pelvic resections : the development of an algorithm based on a multidisciplinary approach\", \"creator\": [\"Kiiski, Juha\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520316549\"], \"p-isbn\": [\"9789520316532\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Surgical, oncological and reconstructive outcomes after complex oncological pelvic resections : the development of an algorithm based on a multidisciplinary approach\", \"creator\": [\"Kiiski, Juhani\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520316549\"], \"p-isbn\": [\"9789520316532\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Constellations\", \"creator\": [\"Feehily, Fergus\", \"Suutari, Inkeri\", \"Demozay, Annie May\", \"Winters, Terry\", \"Long, Declan\", \"Paavilainen, Kukka\", \"Hutchinson, John\"], \"year\": \"2018\", \"publisher\": [\"Academy of Fine Arts of the University of the Arts Helsinki\"], \"e-isbn\": [\"9789527131510\"], \"p-isbn\": [\"9789527131503\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Ključne vrednosti za izraz sastavnike\", \"creator\": [\"Rosenberg, Peter\"], \"year\": \"2015\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Creating opportunity spaces for co-production : professional co-producers in inter-organizational collaborations\", \"creator\": [\"Brix, Jacob\", \"Tuurnas, Sanna\", \"Mortensen, Nanna M\\u00f8ller\"], \"year\": \"2021\", \"publisher\": [\"IGI Global\"], \"doi\": \"10.4018/978-1-7998-4975-9.ch009\", \"p-isbn\": [\"9781799849759\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Creating opportunity spaces for co-production : professional co-producers in inter-organizational collaborations\", \"creator\": [\"Brix, Jacob\", \"Tuurnas, Sanna\", \"Mortensen, Nanna M\\u00f8ller\"], \"year\": \"2021\", \"publisher\": [\"IGI Global\"], \"doi\": \"10.4018/978-1-7998-4975-9.ch009\", \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Full-body interaction in a remote context : adapting a dance piece to a browser-based installation\", \"creator\": [\"Masu, Raul\", \"Pajala-Assefa, Hanna\", \"Correia, Nuno N.\", \"Rom\\u00e3o, Teresa\"], \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3483529.3483747\", \"p-isbn\": [\"9781450384209\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Full-body interaction in a remote context : adapting a dance piece to a browser-based installation\", \"creator\": [\"Masu, Raul\", \"Pajala-Assefa, Hanna\", \"Correia, Nuno N.\", \"Rom\\u00e3o, Teresa\"], \"year\": \"2021\", \"publisher\": [\"Association for Computing Machinery\"], \"doi\": \"10.1145/3483529.3483747\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Gender inequalities in family leaves, employment and pensions in Finland\", \"creator\": [\"Kuitto, Kati\", \"Kuivalainen, Susan\"], \"year\": \"2021\", \"publisher\": [\"Edward Elgar\"], \"p-isbn\": [\"9781839106101\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Gender inequalities in family leaves, employment and pensions in Finland\", \"creator\": [\"Kuitto, Kati\", \"Kuivalainen, Susan\"], \"year\": \"2021\", \"publisher\": [\"Finnish Centre for Pensions\"], \"e-isbn\": [\"9781839106101\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Germany as a cultural paragon : transferring modern musical life from Central Europe to Finland\", \"creator\": [\"Kurkela, Vesa\", \"Rantanen, Saijaleena\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Germany as a cultural paragon transferring modern musical life from central Europe to Finland\", \"creator\": [\"Kurkela, Vesa\", \"Rantanen, Saijaleena\"], \"year\": \"2015\", \"publisher\": [\"Sukupohjan yliopisto\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Introduction\", \"creator\": [\"Anttila, Eeva\", \"Suominen, Anniina\"], \"year\": \"2018\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9781351111195\", \"e-isbn\": [\"9781351111195\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Art as a political, cultural, and social force : arts education for sustaining hope\", \"creator\": [\"Anttila, Eeva\", \"Suominen, Anniina\"], \"year\": \"2018\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9781351111195\", \"p-isbn\": [\"9781351111195\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Musical engagement in one-to-one contexts\", \"creator\": [\"Gaunt, Helena\", \"L\\u00f3pez-\\u00cd\\u00f1iguez, Guadalupe\", \"Creech, Andrea\"], \"year\": \"2021\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9780429295362-29\", \"e-isbn\": [\"9780429295362\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Musical engagement in one-to-one contexts\", \"creator\": [\"Gaunt, Helena\", \"L\\u00f3pez-\\u00cd\\u00f1iguez, Guadalupe\", \"Creech, Andrea\"], \"year\": \"2021\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9780429295362-29\", \"p-isbn\": [\"9780429295362\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The Dalcroze approach : experiencing and knowing music through embodied exploration\", \"creator\": [\"Juntunen, Marja-Leena\"], \"year\": \"2016\", \"publisher\": [\"Oxford University Press\"], \"doi\": \"10.1093/acprof:oso/9780199328093.001.0001\", \"p-isbn\": [\"9780199328093\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"The Dalcroze approach : experiencing and knowing music through embodied exploration\", \"creator\": [\"Juntunen, Marja-Leena\"], \"year\": \"2016\", \"publisher\": [\"Oxford University Press\"], \"doi\": \"10.1093/acprof:oso/9780199328093.001.0001\", \"e-isbn\": [\"9780199328093\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Traces of performance : opera, music theatre, and theatre music in the long 19th century\", \"year\": \"2013\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Traces' of performance : opera, music theatre and theatre music in the long 19th century!\", \"creator\": [\"Sivuoja, Anne\"], \"year\": \"2013\", \"publisher\": [\"Sibelius Academy\"], \"type_coar\": \"programme\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Vitality in later years : food recommendation for older adults\", \"year\": \"2020\", \"publisher\": [\"Finnish Institute for Health and Welfare\"], \"e-isbn\": [\"9789523435179\"], \"p-issn\": \"2323-4172\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Vitality in later years : food recommendation for older adults\", \"year\": \"2020\", \"publisher\": [\"Finnish Institute for Health and Welfare\"], \"e-isbn\": [\"9789523435179\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"BOFIT Ven\\u00e4j\\u00e4-ennuste 2019-2021\", \"year\": \"2019\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"BOFIT Ven\\u00e4j\\u00e4-ennuste 2019-2021\", \"publisher\": [\"Bofen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Eduskunnan pankkivaltuuston kertomus 2013\", \"year\": \"2014\", \"publisher\": [\"Edita Prima Oy\"], \"p-issn\": \"1237-4334\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Eduskunnan pankkivaltuuston kertomus 2013 : Helsinki 2014\", \"year\": \"2014\", \"publisher\": [\"Eduskunta\"], \"e-isbn\": [\"9789522445885\"], \"p-isbn\": [\"9789522445878\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Fyysisen toimintakyvyn mittaaminen ja arviointi v\\u00e4est\\u00f6tutkimuksissa\", \"creator\": [\"Sainio, P\\u00e4ivi\", \"Valkeinen, Heli\", \"Stenholm, Sari\", \"Vaara, Mariitta\", \"Rinne, Marjo\"], \"year\": \"2020\", \"publisher\": [\"TOIMIA\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Fyysisen toimintakyvyn mittaaminen ja arviointi v\\u00e4est\\u00f6tutkimuksissa\", \"creator\": [\"Sainio, P\\u00e4ivi\", \"Valkeinen, Heli\", \"Stenholm, Sari\", \"Vaara, Marietta\", \"Rinne, Marjo\"], \"year\": \"2020\", \"publisher\": [\"Toimitus- ja ajoneuvoton instituutionsaika\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hepolammen (Enon pit\\u00e4j\\u00e4/Joensuu) kalastorakenne loppukes\\u00e4ll\\u00e4 2022 ja kalastonhoidon suositukset\", \"creator\": [\"Tossavainen, Tarmo\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753809\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hepolammen (Enon pit\\u00e4j\\u00e4/Joensuu) kalastorakenne loppukes\\u00e4ll\\u00e4 2022 ja kalastonhoidon suositukset\", \"creator\": [\"Tossavainen, Tarmo\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753809\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hoidon tarpeen arviointi : nykytilan selvitys\", \"creator\": [\"Saukkonen, Sanna-Mari\", \"\\u00c5lander, Anne\"], \"year\": \"2021\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hoidon tarpeen arviointi : nykytilan selvitys\", \"creator\": [\"Saukkonen, Sanna-Mari\", \"Alander, Anne\"], \"year\": \"2021\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Huomioi toimintarajoitteiset lapset ja nuoret hyvinvointikertomuksessa\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Huomioi toimintarajoitteiset lapset ja nuoret hyvinvointikertomuksessa\", \"creator\": [\"Ratfioimat, Suomen\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Johtokunnan kertomus pankkivaltuustolle Finanssivalvonnan toiminnasta 2022\", \"year\": \"2023\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Johtokunnan kertomus pankkivaltuustolle Finanssivalvonnan toiminnasta 2022\", \"year\": \"2023\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Koronaepidemian vaikutukset hyvinvointiin, palveluihin ja talouteen : THL:n seurantaraportti, viikot 49-50/2020, 16.12.2020\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Coronaepidemian vaikutukset hyvinvointiin, palveluihin ja talouteen\", \"creator\": [\"Honkatukia, Juha\", \"H\\u00e4rm\\u00e4, Vuokko\", \"Jormanainen, Vesa\", \"Kestil\\u00e4, Laura\", \"Rissanen, Pekka\"], \"year\": \"2020\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Koulufysioterapialla hyvinvointia Pohjois-Karjalaan : Otsakorpi-hankkeen loppuraportti\", \"creator\": [\"Issakainen, Maiju\", \"Mustonen, Hilppa\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753410\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Koulufysioterapialla hyvin-vointia Pohjois-Karjalaan : Otsakorpi-hankkeen loppuraportti\", \"creator\": [\"Mustonen, Hilppa\", \"Issakainen, Maiju\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753410\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Lohkoketjuteknologian massa-adoption mahdollisuutta tutkimassa\", \"creator\": [\"Honkanen, Petri\"], \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"e-isbn\": [\"9789527365090\"], \"e-issn\": \"2342-3064\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Lohkoketjuteknologian massa-adoption mahdollisuutta tutkimassa\", \"creator\": [\"Honkanen, Petri\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"e-isbn\": [\"9789527365090\"], \"p-issn\": \"2342-3064\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Loppuraportti : koliikkivauvojen hoito vy\\u00f6hyketerapialla -pilottitutkimus 2017-2019\", \"creator\": [\"Hannula, Leena\", \"M\\u00e4kij\\u00e4rvi, Markku\"], \"publisher\": [\"Luonnonl\\u00e4\\u00e4ketieteen Keskusliitto LKL ry\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Loppuraportti Koliikkivauvojen hoito vy\\u00f6hyketerapialla : pilottitutkimus 2017-2019\", \"creator\": [\"Hannula, Leena\", \"M\\u00e4kij\\u00e4rvi, Markku\"], \"year\": \"2020\", \"publisher\": [\"Kerava: Luonnonl\\u00e4\\u00e4ketieteen keskusliitto\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"L\\u00e4\\u00e4kehoidon tiedonhallinnan konsepti\", \"creator\": [\"Virkkunen, Heikki\", \"Relander, Toni\", \"Malmivaara, Antti\", \"Hiltunen, Piritta\", \"Jalonen, Marko\", \"N\\u00e4rv\\u00e4nen, Jarkko\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"L\\u00e4\\u00e4kehoidon tiedonhallinnan konsepti\", \"creator\": [\"Virkkunen, Heikki\", \"Relander, Toni\", \"Malmivaara, Antti\", \"Hiltunen, Piritta\", \"Jalonen, Marko\", \"N\\u00e4rv\\u00e4nen, Jarkko\"], \"year\": \"2020\", \"publisher\": [\"Institutet f\\u00f6r h\\u00e4lsa och v\\u00e4lf\\u00e4rd\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Mist\\u00e4 kohtuusperiaatteessa ja yhti\\u00f6iden lis\\u00e4etujen jakamisessa on kysymys?\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Mist\\u00e4 kohtuusperiaatteessa ja yhti\\u00f6iden lis\\u00e4etujen jakamisessa on kysymys?\", \"creator\": [\"Riikko, Hannu\"], \"year\": \"2015\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Poliisikoulutuksen vaikuttavuusarviointi 2021 : vuosina 2018-2019 valmistuneiden poliisien ty\\u00f6llisyys ja arviot koulutuksen ty\\u00f6el\\u00e4m\\u00e4vastaavuudesta\", \"alt_title\": [\"Utv\\u00e4rdering av polisutbildningsens effektivitetet 2021 : syssels\\u00e4ttningen bland poliser som utexaminerats \\u00e5ren 2018\\u20132019 och bed\\u00f6mningar av utbildningens arbetslivsmotsvarighet {sv}\", \"Evaluation of the effectiveness of police education 2021 : employment and occupational validity of the education as assessed by police officers who graduated during 2018\\u20132019 {en}\"], \"creator\": [\"Vuorensyrj\\u00e4, Matti\"], \"publisher\": [\"Poliisiammattikorkeakoulu\"], \"e-isbn\": [\"9789518153866\"], \"p-issn\": \"1797-5743\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Poliisikoulutuksen vaikuttavuusarviointi 2021 : poliisikorkeakoulun raportteja 138\", \"year\": \"2021\", \"publisher\": [\"Poliisiammattikorkeakoulu\"], \"e-isbn\": [\"9789518153866\"], \"p-issn\": \"1797-5743\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta Etel\\u00e4-Savon kunnissa 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta ETEL\\u00c4-SAVON KUNNISSA 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta Pohjois-Karjalan kunnissa 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta : pohipportajien ryhm\\u00e4kulmia 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ymp\\u00e4rist\\u00f6vaikutusten arviointi 80-luvun liikerakennuksen kiinteist\\u00f6kehitt\\u00e4misess\\u00e4 : elinkaariarvioinnin (LCA), elinkaarikustannusten (LCC) ja energiasimuloinnin arviointiraportti\", \"creator\": [\"Keskisalo, Mika\", \"Kuusisto, Jari\", \"Matveinen, Mikko\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753656\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ymp\\u00e4rist\\u00f6vaikutusten arviointi : 80-luvun liikerakennuksen kiinteist\\u00f6kehitt\\u00e4misess\\u00e4\", \"creator\": [\"Keskisalo, Mika\", \"Kuusisto, Jari\", \"Matveinen, Mikko\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753656\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Dynaamisten kyvykkyyksien syntyminen ja kehittyminen hyvinvointialuevalmistelun yhteydess\\u00e4 : kyvykkyysperusteinen n\\u00e4k\\u00f6kulma julkishallinnon organisaation muutosprosessiin\", \"creator\": [\"Post, Juha\"], \"year\": \"2023\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950740\"], \"p-isbn\": [\"9789523950733\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Dynaamisten kyvykkyyksien syntyminen ja kehittyminen hyvinvointialuevalmistelun yhteydess\\u00e4 : kyvykkyysperusteinen n\\u00e4k\\u00f6kulma julkishallinnon organisaation muutosprosessiin\", \"creator\": [\"Post, Juha\"], \"year\": \"2023\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950740\"], \"p-isbn\": [\"9789523950733\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Edess\\u00e4 ja edell\\u00e4: Suomen ete-vartaloisten tilagrammien merkitykset ja metaforisuus\", \"alt_title\": [\"\\u2018In front\\u2019 and \\u2018ahead\\u2019 : semantics and metaphoricity of Finnish FRONT grams {en}\"], \"creator\": [\"Teeri-Niknammoghadam, Krista\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512984374\"], \"p-isbn\": [\"9789512984367\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Edess\\u00e4 ja edell\\u00e4 : Suomen ete -vartaloisten tilagrammien merkitykset ja metaforisuus\", \"alt_title\": [\"Front grams in front and ahead : semantics and metaphoricity of Finnish FRONT grams {en}\"], \"creator\": [\"Teeri-Niknammoghadam, Krista\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512984374\"], \"p-isbn\": [\"9789512984367\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kielellisesti tuettu opetus : yl\\u00e4kouluik\\u00e4iset maahanmuuttajaoppilaat opetuskielt\\u00e4 ja oppiainesis\\u00e4lt\\u00f6j\\u00e4 oppimassa\", \"creator\": [\"Harju-Autti, Raisa\"], \"year\": \"2022\", \"publisher\": [\"Tampereen yliopisto\"], \"e-isbn\": [\"9789520326661\"], \"p-isbn\": [\"9789520326654\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kielellisesti tuettu opetus : yl\\u00e4kouluik\\u00e4iset maahanmuuttajaoppilaat opetuskielt\\u00e4 ja oppiainesis\\u00e4lt\\u00f6j\\u00e4 oppimassa\", \"creator\": [\"Harju-Autti, Raissa\"], \"year\": \"2022\", \"publisher\": [\"Tampereen yliopisto\"], \"e-isbn\": [\"9789520326661\"], \"p-isbn\": [\"9789520326654\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"K\\u00e4tketty maisema : arkitieto l\\u00e4hiymp\\u00e4rist\\u00f6n kohtaamisessa\", \"alt_title\": [\"Hidden landscape : local knowledge in encounters with everyday environment {en}\"], \"creator\": [\"Puolam\\u00e4ki, Laura\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512979301\"], \"p-isbn\": [\"9789512979523\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"HIDDEN LANDSCAPE\", \"alt_title\": [\"Arkitieto l\\u00e4hiymp\\u00e4rist\\u00f6n kohtaamisessa : k\\u00e4tketty maisema {fi}\"], \"creator\": [\"Puolam\\u00e4ki, Laura\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512979301\"], \"p-isbn\": [\"9789512979523\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"P\\u00e4ivitt\\u00e4inen johtaminen l\\u00e4hiesimiehen ty\\u00f6ss\\u00e4 leikkaus- ja anestesiaosastolla\", \"alt_title\": [\"Nurse managers\\u2019 daily unit operation in perioperative settings {en}\"], \"creator\": [\"Siirala, Eriikka\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512982967\"], \"p-isbn\": [\"9789512982950\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"P\\u00e4ivitt\\u00e4inen johtaminen l\\u00e4hiesimiehen ty\\u00f6ss\\u00e4 leikkaus- ja anesthesiaosastolla\", \"alt_title\": [\"Nurse managers\\u2019 daily unit operation in perioperative settings {en}\"], \"creator\": [\"Siirala, Eriikka\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512982967\"], \"p-isbn\": [\"9789512982950\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Toimijat, taistelijat, tipahtaneet : koulutus- ja ty\\u00f6toimijuus mielenterveyskuntoutujien el\\u00e4m\\u00e4nkerronnoissa\", \"creator\": [\"Vilppola, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512983025\"], \"p-isbn\": [\"9789512983018\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Toimijat, taistelijat, tipahtaneet : koulutus- ja ty\\u00f6toimijuus mielenterveyskuntoutujien el\\u00e4m\\u00e4nkerronnoissa\", \"creator\": [\"Vilppola, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512983025\"], \"p-isbn\": [\"9789512983018\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Vastuullinen julkinen johtaminen : hallinto-oppien kommunikatiivinen arviointi\", \"alt_title\": [\"Responsible public management : communicative assessment of administrative doctrine {en}\"], \"creator\": [\"Autioniemi, Jari\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769655\"], \"p-isbn\": [\"9789524769648\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Vastuullinen julkinen johtaminen : hallinto-oppien kommunikatiivinen arviointi\", \"alt_title\": [\"Responsible public management : communicative assessment of administrative doctrines {en}\"], \"creator\": [\"Autioniemi, Jari\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769655\"], \"p-isbn\": [\"9789524769648\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Veron kiert\\u00e4misen tunnistaminen : oikeuden v\\u00e4\\u00e4rink\\u00e4yt\\u00f6n kielto VML 28 \\u00a7:n tulkinnassa\", \"creator\": [\"Kaunisto, Siru\"], \"year\": \"2022\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950276\"], \"p-isbn\": [\"9789523950269\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Veron kiert\\u00e4misen tunnistaminen : oikeuden v\\u00e4\\u00e4rink\\u00e4yt\\u00f6n kielto VML 28 \\u00a7:n tulkinnassa\", \"creator\": [\"Kaunisto, Siru\"], \"year\": \"2022\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950276\"], \"p-isbn\": [\"9789523950269\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"V\\u00e4litt\\u00e4v\\u00e4 kasvatus ja opetus peruskoulun yhdeks\\u00e4sluokkalaisten kokemana\", \"alt_title\": [\"Personal caring and caring teaching in basic education experienced by 9th grade students {en}\"], \"creator\": [\"Hosio, Maarit\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512986835\"], \"p-isbn\": [\"9789512986828\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"V\\u00e4litt\\u00e4v\\u00e4 kasvatus ja opetus peruskoulun yhdeks\\u00e4sluokkalaisten kokemana\", \"creator\": [\"Hosio, Maarit\"], \"year\": \"2021\", \"publisher\": [\"Turun Yliopisto\"], \"e-isbn\": [\"9789512986835\"], \"p-isbn\": [\"9789512986828\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ammattikielisten tekstien tutkimisesta : esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Katajam\\u00e4ki, Heli\", \"Koskela, Merja\"], \"year\": \"2012\", \"publisher\": [\"Kotimaisten kielten keskus\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ammattikielisten tekstien tutkimisesta : esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Koskela, Merja\", \"Katajam\\u00e4ki, Heli\"], \"year\": \"2012\", \"publisher\": [\"Kotimaisten kielten keskus\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"FAQ : taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t\", \"year\": \"2018\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"e-isbn\": [\"9789527266076\"], \"p-issn\": \"1456-002X\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t\", \"year\": \"2018\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"e-isbn\": [\"9789527266076\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Julkisen tilan taiteen tilasta : puheenvuoroja julkisen taiteen konteksteista\", \"year\": \"2021\", \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"V\\u00e4liaikainen julkinen taide ja uudet teknologiat : ymp\\u00e4rist\\u00f6taide ja pienet paikkakunnat, hallinto, kuratointi ja kaupunkisuunnittelu, kokemuksellisuus ja pedagogiikka\", \"year\": \"2021\", \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Karelia.fi : Karelia-ammattikorkeakoulun tutkimus- ja kehitt\\u00e4mistoimintaa EU-ohjelmakaudella 2014-2020\", \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Karelia.fi : usia n\\u00e4k\\u00f6kulmia ja kyvykkyytt\\u00e4\", \"creator\": [\"Raivo, Petri\"], \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-issn\": \"2323-8461\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : kulttuurituotannon yliopettaja isku Halonen\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : kulttuurituotannon ty\\u00f6papereita\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Monimuotoinen ansioty\\u00f6 : n\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"year\": \"2022\", \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Monimuotoinen ansioty\\u00f6 : n\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"year\": \"2022\", \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Osuma-peli : innostusta yhteiskehittelyyn!\", \"creator\": [\"Halonen, Katri\", \"Salmenkangas, Mai\", \"Wallin, Riikka\"], \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Osuma-peli : innostusta yhteiskehittelyyn!\", \"creator\": [\"Halonen, Katri\", \"Salmenkangas, Mai\", \"Wallin, Riikka\"], \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Pk-yritysten liiketoiminnan muotoilun CookBook\", \"creator\": [\"Jaakola, Hanna\", \"Pietik\\u00e4inen, Minna\", \"Rinta-Jouppi, Laura\", \"Viljanen, Jenni\"], \"year\": \"2021\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Liiketoiminnan muotoilun CookBook\", \"year\": \"2021\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Suomen Pankki 200 vuotta II : parlamentin pankki\", \"creator\": [\"Kuuster\\u00e4, Antti\", \"Tarkka, Juha\"], \"year\": \"2012\", \"publisher\": [\"Otava\"], \"e-isbn\": [\"9789511242727\"], \"p-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Suomen Pankki 200 vuotta : parlamentin pankki\", \"year\": \"2014\", \"publisher\": [\"Otavan Kirjapaino Oy\"], \"e-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4rittelyt\", \"creator\": [\"Aalto, Anna\", \"Virkkunen, Heikki\", \"Turunen, Seppo\", \"Saarela, Hanna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4ritykset\", \"creator\": [\"Kuronen, Kirstimaria\", \"Virkkunen, Heikki\", \"Turunen, Seppo\", \"Saarela\", \"Hanna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Taru-sanomat\", \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"e-issn\": \"2490-2055\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Tarinateatteri ja taiteelliset menetelm\\u00e4t opetuksessa : toimittajan palsta\", \"creator\": [\"Rahmel, P\\u00e4ivi\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"e-issn\": \"2490-2055\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset\", \"creator\": [\"Haarala, P\\u00e4ivi\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"e-issn\": \"2669-8021\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset\", \"creator\": [\"Haarala, P\\u00e4ivi\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"D\\u00e4r kunskapen t\\u00e4tnar som moln : ess\\u00e4er om litteraturen som kunskapsf\\u00e4lt och kunskapsform\", \"year\": \"2021\", \"publisher\": [\"Litteraturvetenskap och filosofi vid \\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240201\"], \"p-isbn\": [\"9789521240195\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Poesi och ess\\u00e4istik som kunskapsform\", \"year\": \"2021\", \"publisher\": [\"Svenska litteraturs\\u00e4llskapet i Finland\"], \"e-isbn\": [\"9789521240201\"], \"p-isbn\": [\"9789521240195\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finsk straffr\\u00e4tt : grundkurs i straffr\\u00e4ttens allm\\u00e4nna l\\u00e4ror\", \"creator\": [\"Boucht, Johan\", \"Fr\\u00e4nde, Dan\"], \"year\": \"2020\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518153767\"], \"p-isbn\": [\"9789518153750\"], \"e-issn\": \"1455-8270\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finsk straffr\\u00e4tt grundkurs i straffr\\u00e4ttens allm\\u00e4nna l\\u00e4ror\", \"creator\": [\"Boucht, Johan\", \"Fr\\u00e4nde, Dan\"], \"year\": \"2020\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518153767\"], \"p-isbn\": [\"9789518153750\"], \"p-issn\": \"1455-8270\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"N\\u00e4r man g\\u00e5r i stora skor l\\u00e4mnar man stora sp\\u00e5r efter sig : aderton perspektiv p\\u00e5 polisarbetet\", \"alt_title\": [\"Studiematerial f\\u00f6r Polisyrkesh\\u00f6gskolans intr\\u00e4desprov 2014 {sv}\"], \"year\": \"2014\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518152630\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Studiematerial f\\u00f6r Polisyrkesh\\u00f6gskolans intr\\u00e4desprov 2014\", \"year\": \"2014\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518152630\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Kartering av fisksamh\\u00e4llen och f\\u00f6rekomst av plattfiskar och n\\u00e4bbg\\u00e4dda (Belone belone) p\\u00e5 exponerade str\\u00e4nder p\\u00e5 \\u00c5land\", \"alt_title\": [\"Mapping of fish communities and the occurrence of flatfish and garpike (Belone belone) on exposed  beaches in the \\u00c5land Islands {en}\"], \"creator\": [\"Finnb\\u00e4ck, Lars\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521240249\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Forskningsrapporter fr\\u00e5n Hus\\u00f6 biologiska station : no 157 (2021)\", \"creator\": [\"Finnb\\u00e4ck, Lars\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521240249\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Uppf\\u00f6ljningsstudie av g\\u00f6sens (Sander lucioperca (L.)) och de allm\\u00e4nna fiskbest\\u00e5ndens f\\u00f6rekomst i \\u00c5lands inre sk\\u00e4rg\\u00e5rd\", \"alt_title\": [\"Follow up study on the occurrence of pikeperch (Sander lucioperca (L.)) and the common fish stocks in the inner archipelago of \\u00c5land {en}\"], \"creator\": [\"\\u00d6sterlund, Jonas\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521242496\"], \"p-isbn\": [\"9789521242489\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Uppf\\u00f6ljningsstudie av g\\u00f6sens (Sander lucioperca (L.)) och de allm\\u00e4nna fiskbest\\u00e5ndens f\\u00f6rekomst i \\u00c5lands inre sk\\u00e4rg\\u00e5rd\", \"alt_title\": [\"Follow up study on the occurrence of pikeperch (Sander lucioperca (L.)) and the common fish stocks in the inner archipelago of \\u00c5land {en}\"], \"creator\": [\"\\u00d6sterlund, Jonas\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521242489\"], \"p-isbn\": [\"9789521242496\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Svenskfinland i pandemitider : resultat fr\\u00e5n den finlandssvenska medborgarpanelen Barometern 2020\\u20132022\", \"creator\": [\"Backstr\\u00f6m, Jenny\", \"Backstr\\u00f6m, Kim\", \"Karv, Thomas\", \"Lindell, Marina\", \"Malmberg, Fredrik\", \"Schauman, Jonas\", \"Sir\\u00e9n, Rasmus\", \"Weckman, Albert\"], \"year\": \"2022\", \"publisher\": [\"Institutet f\\u00f6r samh\\u00e4llsforskning (Samforsk), \\u00c5bo Akademi, Vasa\"], \"e-isbn\": [\"9789521242106\"], \"p-isbn\": [\"9789521242090\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Svanskfinland i pandemitider : resultat fr\\u00e5n den finlandssvenska medborgarpanelen Barometern 2020-2022\", \"year\": \"2022\", \"publisher\": [\"Institutet f\\u00f6r samh\\u00e4llsforskning (Samforsk), \\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242106\"], \"p-isbn\": [\"9789521242090\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Elevers matematiska utmaningar i sl\\u00f6jd : \\u00e4mnes\\u00f6verskridande l\\u00e4rande via handens arbete\", \"creator\": [\"Hjelm, \\u00c5sa\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789523890435\"], \"p-isbn\": [\"9789523890428\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Elevers matematiska utmaningar i sl\\u00f6jd : \\u00e4mnes\\u00f6verskridande l\\u00e4rande via handens arbete\", \"creator\": [\"Hjelm, \\u00c5sa\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789523890435\"], \"p-isbn\": [\"9789523890428\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Hantera frihet och ansvar : om unga personers liv, h\\u00e4lsa och behov av st\\u00f6d\", \"creator\": [\"\\u00d6stman, Lillemor\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240874\"], \"p-isbn\": [\"9789521240867\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Hantera frihet och ansvar : om unga personers liv, h\\u00e4lsa och behov av st\\u00f6d.\", \"creator\": [\"\\u00d6stman, Lillemor\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240874\"], \"p-isbn\": [\"9789521240867\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00e4lsans tomrum : en hermeneutisk studie om f\\u00f6rsakelsens betydelse f\\u00f6r h\\u00e4lsan\", \"alt_title\": [\"A void for health : a hermeneutic study of the significance of renunciation for health {en}\"], \"creator\": [\"Koskinen, Monika\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789517659932\"], \"p-isbn\": [\"9789517659925\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00e4lsans tomrum : en hermeneutisk studie om f\\u00f6rsakelsens betydelse f\\u00f6r h\\u00e4lsan\", \"creator\": [\"Koskinen, Monika\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789517659932\"], \"p-isbn\": [\"9789517659925\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e4rmilj\\u00f6ns betydelse f\\u00f6r barns ut\\u00f6vande och l\\u00e4rande av grundl\\u00e4ggande motoriska f\\u00e4rdigheter i sm\\u00e5barnspedagogik\", \"creator\": [\"Svanb\\u00e4ck-Laaksonen, Mikaela\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242236\"], \"p-isbn\": [\"9789521242229\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e4rmilj\\u00f6ns betydelse f\\u00f6r barns ut\\u00f6vande och l\\u00e4rande av grundl\\u00e4ggande motoriska f\\u00e4rdigheter i sm\\u00e5barnspedagogik\", \"creator\": [\"Svanb\\u00e4ck-Laaksonen, Mikaela\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242236\"], \"p-isbn\": [\"9789521242229\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Musikerr\\u00f6ster i Betsy Jolas musik : dialoger och spelerfarenheter i analys\", \"creator\": [\"Korhonen-Bj\\u00f6rkman, Heidi\"], \"year\": \"2016\", \"publisher\": [\"Sibelius-Akademin, Konstuniversitetet\", \"Musikvetenskapliga s\\u00e4llskapet i Finland\"], \"e-isbn\": [\"9789526834726\"], \"p-isbn\": [\"9789526834719\"], \"p-issn\": \"0587-2448\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Tammerfors : tammerfors 2016\", \"year\": \"2016\", \"publisher\": [\"Sibelius-Akademin\"], \"e-isbn\": [\"9789526834726\"], \"p-isbn\": [\"9789526834719\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Att v\\u00e5rda vattendrag tillsammans : kommunikation och anpassning till klimatf\\u00f6r\\u00e4ndringens utmaningar i Herts\\u00e5nger\\u00e4lven och Toby \\u00e5 (Laihianjoki)\", \"creator\": [\"Nordberg, Kenneth\", \"Ghorbanzadeh, Sakineh\"], \"publisher\": [\"Regionalvetenskap, \\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242328\"], \"p-isbn\": [\"9789521242328\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Att v\\u00e5rda vattendrag tillsammans : komunikation och anpassning till klimatf\\u00f6r\\u00e4ndringens utmaningar i Herts\\u00e5nger\\u00e4lven och Toby \\u00e5 (Laihianjoki)\", \"creator\": [\"Nordberg, Kenneth\", \"Ghorbanzadeh, Sakineh\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242328\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Direktionens ber\\u00e4ttelse till bankfullm\\u00e4ktige om Finansinspektionens verksamhet 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Direktionens ber\\u00e4ttelse till bankfullm\\u00e4ktige 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Egentliga Finland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Egentliga Finland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2014\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522444943\"], \"p-isbn\": [\"9789522444745\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2014\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522449879\"], \"p-isbn\": [\"9789522449862\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2020\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446534\"], \"p-isbn\": [\"9789522446527\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2020\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522444444\"], \"p-isbn\": [\"9789522444437\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2022\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446961\"], \"p-isbn\": [\"9789522446954\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2022\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522449909\"], \"p-isbn\": [\"9789522449992\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Kompetens i palliativ v\\u00e5rd och v\\u00e5rd i livets slutskede i sjuksk\\u00f6tarexamen : rekommendation f\\u00f6r l\\u00e4roplan i palliativ v\\u00e5rd och v\\u00e5rd i livets slutskede\", \"creator\": [\"H\\u00f6kk\\u00e4, Minna\", \"Lehto, Juho\", \"Joutsia, Karoliina\", \"Kallio, Suvi\", \"Kiiski, Katri\", \"Kurunsaari, Merja\", \"Lifl\\u00e4nder, Birgit\", \"L\\u00e4hdetniemi, Marika\", \"Matilainen, Irmeli\", \"Mikkonen, Heli\", \"Muurinen, Katja\", \"Pyk\\u00e4l\\u00e4inen, Tarja\", \"P\\u00e4\\u00e4llysaho, Annikki\", \"Sunikka, Tuulia\", \"Tohmola, Anniina\", \"Turunen, Elina\", \"V\\u00e4is\\u00e4nen, Irja\", \"Ylinen, Eeva-Riitta\", \"\\u00d6hberg, Isa\"], \"publisher\": [\"Kajaanin Ammattikorkeakoulu Oy\"], \"e-isbn\": [\"9789527219607\"], \"p-isbn\": [\"9789527219560\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Kompetens i palliativ v\\u00e5rd och v\\u00e5rd i livets slutskede i sjuk- sk\\u00f6tarexamen\", \"creator\": [\"H\\u00f6kk\\u00e4, Minna\", \"Lehto, Juho\", \"Joutsia, Karoliina\", \"Kallio, Suvi\", \"Kiiski, Katri\", \"Kurunsaari, Merja\", \"Lifl\\u00e4nder, Birgit\", \"L\\u00e4hdetniemi, Marika\", \"Matilainen, Irmeli\", \"Mikkonen, Heli\", \"Muurinen, Katja\", \"Pyk\\u00e4l\\u00e4inen, Tarja\", \"P\\u00e4\\u00e4lysaho, Annikki\", \"Sunikka, Tuulia\", \"Tohmola, Anniina\", \"Turunen, Elina\", \"V\\u00e4is\\u00e4nen, Irja\", \"Ylinen, Studerandemedlemmarginaliserade\"], \"publisher\": [\"Kajaanin Ammattikorkeakoulu\"], \"e-isbn\": [\"9789527219607\"], \"p-isbn\": [\"9789527219560\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Norra Karelen och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Norra Karelen och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Norra \\u00d6sterbotten och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Norra \\u00d6sterbotten och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"P\\u00e4ij\\u00e4nne-Tavastland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"P\\u00e4ij\\u00e4nne-Tavastland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Unders\\u00f6kning av l\\u00f6nsamheten inom lagstadgad olycksfallsf\\u00f6rs\\u00e4kring 2004-2013 : analys\", \"year\": \"2014\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Unders\\u00f6kning av l\\u00f6nsamheten inom lagstadgad olycksfallsf\\u00f6rs\\u00e4kring 2004-2013 : analys\", \"year\": \"2014\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse : 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse 2018\", \"creator\": [\"Lahnalammi-Vesivalo, Milka\", \"Alhonsuo, Sampo\", \"Armila-Paalasmaa, Miia\", \"Heikkinen, Raakel\", \"Heiskanen, Hanna\", \"Juutinen, Anne-Mari\", \"Korpiaho, Teija\", \"Rantama, Jaana\", \"Rautanen, Erja\", \"Tulonen, Tommi\", \"Tuomikoski, Kristiina\"], \"year\": \"2019\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse 2018\", \"year\": \"2019\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"\\\"Pit\\u00e4is varmaan sanoa, ett\\u00e4 Jumala se kutsuu\\\" : n\\u00e4k\\u00f6kulmia kanttorin kutsumukseen\", \"alt_title\": [\"\\u201dI probably should say it\\u00b4s God calling me\\u201d : wiewpoints to the calling of a cantor {en}\"], \"creator\": [\"Alasaarela, Laura\"], \"year\": \"2019\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"\\u201cPit\\u00e4is varmaan sanoa, ett\\u00e4 Jumala se kutsuu\\u201d : n\\u00e4k\\u00f6kulmia kanttorin kutsumukseen\", \"alt_title\": [\"\\u201cI probably should say it\\u00b4s God calling me\\u201d : Wiewpoints to the calling of a cantor {en}\"], \"creator\": [\"Alasaarela, Laura\"], \"year\": \"2019\", \"publisher\": [\"University of Art and Design\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"13\\u201317-vuotiaiden poikien plyometrinen harjoittelu jalkapallossa : opas valmentajille\", \"alt_title\": [\"13-17-year-old young male\\u2019s plyometric training in soccer : Information guide for coaches {en}\"], \"creator\": [\"Qvickstr\\u00f6m, Henri\", \"Silfverberg, Ville\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"13-17-year-old young male\\u2019s plyometric training in soccer : information guide for coaches\", \"alt_title\": [\"13-17-year-old young male\\u2019s plyometric training in soccer {en}\"], \"creator\": [\"Qvickstr\\u00f6m, Henri\", \"Sifverberg, Ville\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Einojuhani Rautavaaran Lapsimessu (op. 71) : n\\u00e4k\\u00f6kulmia harjoittamiseen\", \"creator\": [\"Norjanen, Anna-Elina\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Einojuhani Rautavaaran Lapsimessu (Op.71)\", \"creator\": [\"Norjanen, Anna-Elina\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopisto Sibelius-Akatemia\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Esimiehen\\u00e4 muuttuvan organisaation aallokoissa : organisaatio tuen merkitys muutoksen johtamisessa\", \"creator\": [\"Hihnala, Heidi\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Esimiehen\\u00e4 muuttuvan organisaation aallokoissa : organisaatio tuen merkitys muutoksen johtamisessa\", \"creator\": [\"Hihnala, Heidi\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitajien ergonomiaosaaminen potilaan siirto- ja nostotilanteissa\", \"alt_title\": [\"Nurses ergonomic know-how in patient moving and handling situations {en}\"], \"creator\": [\"Helander, Anna-Kaisa\", \"Koivisto, Tuomas-Heikki\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitajien ergonomiaosaaminen potilaan siirto- ja nostotilanteissa\", \"alt_title\": [\"Nurses ergonomic know-how in patient moving and handling situations {en}\"], \"creator\": [\"Helander, Anna-Kaisa\", \"Koivisto, Tuomas-Heikki\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitoty\\u00f6n vertaisarviointiprosessin testaaminen osana lasten spirometriatutkimuksen laadun kehitt\\u00e4mist\\u00e4\", \"alt_title\": [\"Testing of peer review process of nursing as a part of quality development of spirometry test for child patient {en}\"], \"creator\": [\"Kinnunen, Karoliina\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitoty\\u00f6n vertaisarviointiprosessin testaaminen osana lasten spirometriatutki-munkfen laadun kehitt\\u00e4mist\\u00e4\", \"alt_title\": [\"Testing of peer review process of nursing as a part of quality development of spirometry test for child patient {en}\"], \"creator\": [\"Kinnunen, Karoliina\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Itsem\\u00e4\\u00e4r\\u00e4\\u00e4misoikeus lain n\\u00e4k\\u00f6kulmasta kehitysvammahuollon laitospalveluissa : auditointisuunnitelma\", \"alt_title\": [\"Self-determination from the perspective of law in institutional services for people with intellectual disabilities : an audit plan {en}\"], \"creator\": [\"Rahkj\\u00e4rvi, P\\u00e4ivi\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Itsem\\u00e4\\u00e4r\\u00e4\\u00e4misoikeus lain n\\u00e4k\\u00f6kulmasta : kehitysvammahuollon laitospalveluissa - auditointisuunnitelma\", \"alt_title\": [\"Self-determination from the perspective of law in institutional services for people with intellectual disabilities : an audit plan {en}\"], \"creator\": [\"Rakahjirovich, P\\u00e4vi\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kaisa Juhantytt\\u00e4ren (1782\\u20131856) el\\u00e4m\\u00e4nhistoria ja muistivihkoon k\\u00e4tketty minuus\", \"creator\": [\"Kautto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kaisa Juhantytt\\u00e4ren : el\\u00e4m\\u00e4nhistoria ja muistivihkoon k\\u00e4tketty minuus\", \"alt_title\": [\"Kaisa Juhantyt\\u00e4r and the history of ideas and the nature of things {en}\"], \"creator\": [\"Kautto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Laadunhallintaj\\u00e4rjestelm\\u00e4 Bluet Oy:lle\", \"alt_title\": [\"Quality management system for a specific engineering company {en}\"], \"creator\": [\"Ivanov, Slava\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Laadunhallintaj\\u00e4rjestelm\\u00e4 : Bluet Oy ltd\", \"alt_title\": [\"Quality management system for a specific engineering company {en}\"], \"creator\": [\"Ivanov, Slava\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Lahjakkaan lapsen erityisopetus : n\\u00e4k\\u00f6kulmana tasa-arvo\", \"alt_title\": [\"Special education of a gifted child : from the perspective of equality {en}\"], \"creator\": [\"Niitamo, Katri\"], \"year\": \"2019\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Lahjakkaan lapsen erityisopetus : n\\u00e4k\\u00f6kulmana tasa-arvo\", \"alt_title\": [\"Special education of a gifted child : from the perspective of equality {en}\"], \"creator\": [\"Niitamo, Katri\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Mannerheimin Lastensuojeluliiton Tampereen osaston Eron ensiapupisteen ohjaus- ja neuvontaty\\u00f6 : perheiden ja ty\\u00f6ntekij\\u00f6iden kokemuksia palveluista\", \"alt_title\": [\"Guidance and counseling work at Tampere department\\u2019s divorce services of Mannerheim League for Child Welfare {en}\"], \"creator\": [\"Annala, Riina\", \"Ryh\\u00e4nen, Juulia\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Mannerheimin Lastensuojeluliiton Tampereen osaston Eron ensiapupisteen ohjaus- ja neuvontaty\\u00f6n vaikutuksia palveluista\", \"alt_title\": [\"Guidance and counseling work at Tampere departments divorce services of Matterheim League for child welfare families and employees\\u2019 experiences of services {en}\"], \"creator\": [\"Annala, Riina\", \"Ryh\\u00e4nen, Juulia\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Musiikinopettajan pedagogisten l\\u00e4hestymistapojen vaikutus murrosik\\u00e4isen oppilaan motivaatioon\", \"creator\": [\"Kauppinen, Sakari\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Musiikinopettajan pedagogisten l\\u00e4hestymistapojen vaikutus murrosik\\u00e4isen oppilaan motivaatioon\", \"creator\": [\"Kauppinen, Sakari\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ohjelmistorobotiikan k\\u00e4ytt\\u00f6\\u00f6notosta aiheutuneen muutoksen kokeminen : Tampereen kaupungin ty\\u00f6llisyys- ja kasvupalvelut\", \"alt_title\": [\"Experience of the change affected by software robotics deployment : City of Tampere Employment and Growth Services {en}\"], \"creator\": [\"Toukola, Lilli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ohjelmistorobotiikan k\\u00e4ytt\\u00f6\\u00f6notosta aiheutuneen muutoksen kokeminen\", \"alt_title\": [\"Experience of the change affected by software robotics deployment {en}\"], \"creator\": [\"Toukola, Lilli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen kaupungin ty\\u00f6llisyys- ja kasvupalvelut\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Osakkeen hinnassa tapahtuva muutos ennen tulosjulkistusta : markkinoiden ennustuskyky\", \"creator\": [\"Viitala, Kalle\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Osakkeen hinnassa tapahtuva muutos ennen tulosjulkistusta : markkinoiden ennustuskyky\", \"alt_title\": [\"Osakkeen hintaa tapahtumista ennen tulosjulkistuksista : tutkimusaineisto {fi}\"], \"creator\": [\"Viitala, Kalle\"], \"year\": \"2020\", \"publisher\": [\"Taideyliopiston proGradu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Postresuskitaatiohoito ensihoidossa : tarkistuslista ensihoitajille\", \"alt_title\": [\"Post-resuscitation care in emergency care : a checklist for paramedics {en}\"], \"creator\": [\"Jaakkola, Amanda\", \"Mattila, Janina\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Postresuskitaationhoito ensihoidossa : tarkistuslista ensihoitajille\", \"alt_title\": [\"Postresuskitaatiohoito perustuu elvytyksen j\\u00e4lkeiseen potilaan elintoimintojen va {fi}\"], \"creator\": [\"Jaakkola, Amanda\", \"Mattila, Janina\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ravitsemusprofilointi osana SOK:n Omat Ostot -palvelua\", \"alt_title\": [\"Nutritional profiling as a part of SOK\\u2019s Omat Ostot service {en}\"], \"creator\": [\"Valli, Nelli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ravitsemusprofilointi osana SOK:n Omat Ostot -palvelua\", \"alt_title\": [\"Nutritional Profiling as a Part of SOK\\u2019s Omat Ostot Service {en}\"], \"creator\": [\"Vallis, Nelli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Suomalaisuuden reunaehdot sotien v\\u00e4lisen\\u00e4 aikana : rajank\\u00e4ynti\\u00e4 menneisyyskuvilla Lauri Haarlan historiallisessa romaanissa Kurkien taru (1938\\u20131940)\", \"creator\": [\"Lepist\\u00f6, Vilma\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Suomalaisuuden reunaehdot sotien v\\u00e4lisen\\u00e4 aikana : Rajank\\u00e4ynti\\u00e4 menneisyyskuvilla Lauri Haarlan historiallisessa romaanissa Kurkien taru (1938\\u20131940)\", \"creator\": [\"Lepist\\u00f6, Vilma\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun : tarkastusvaliokunnat suomalaisissa ja ruotsalaisissa p\\u00f6rssiyhti\\u00f6iss\\u00e4\", \"creator\": [\"Salminen, Heini\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun\", \"creator\": [\"Salminen, Heini\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveys ja lihavuus Olet mit\\u00e4 sy\\u00f6t -ohjelmassa : \\u201dEt s\\u00e4 oo mik\\u00e4\\u00e4n l\\u00e4\\u00e4ketieteellinen ihme, vaikka s\\u00e4 oot luullu niin\\u201d\", \"creator\": [\"Nevalainen, Emmi\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveyys ja liHAVUUS : otet mit\\u00e4 sy\\u00f6t - ohjelmaassa\", \"creator\": [\"Nevalainen, Emmi\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ty\\u00f6hyvinvoinnin vaikutus sairauspoissaoloihin\", \"alt_title\": [\"Influence of work well-being on sickness absence {en}\"], \"creator\": [\"Katajisto, Riikka\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ty\\u00f6hyvinvoinnin vaikutus sairauspoissaoloihin\", \"alt_title\": [\"Influence of work well-being on sickness absence {en}\"], \"creator\": [\"Katajisto, Riikka\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Villikasveista jalosteiksi\", \"alt_title\": [\"From a wild plant to a processed product {en}\"], \"creator\": [\"Kuusela, Sofia\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Villikasveista jalosteiksi\", \"alt_title\": [\"From a wild plant to a processed product {en}\"], \"creator\": [\"Kuusela, Sofia\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Bystr\\u00f6min Ohjaamon toimintaa kehitettiin asiakasl\\u00e4ht\\u00f6isesti\", \"creator\": [\"Visuri, Anna\", \"Koivisto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Bystr\\u00f6min Ohjaamon toimintaa kehitettiin asiakasl\\u00e4ht\\u00f6isesti\", \"creator\": [\"Visuri, Anna\", \"Koivisto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hahmottamisen laaja-alaisuus ja tiedon luonne\", \"creator\": [\"Sepp\\u00e4l\\u00e4, Mikael\"], \"year\": \"2022\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hahmottamisen laaja-alaisuus ja tiedon luonne\", \"creator\": [\"Sepp\\u00e4l\\u00e4, Mika\"], \"year\": \"2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"IMF ennustaa talouskasvua euroalueelle ja Suomelle\", \"creator\": [\"Toivanen, Mervi\"], \"year\": \"2015\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"blog post\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Banki : IMF ennustaa talouskasvua euro-alueelle ja Suomelle\", \"creator\": [\"Toivanen, Mervi\"], \"year\": \"2015\", \"publisher\": [\"Banksyngresses\"], \"type_coar\": \"blog post\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kansalliset keskuspankit tuntevat oman maansa markkinapaikat\", \"creator\": [\"Hievanen, Laura\"], \"year\": \"2015\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"blog post\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kansalliset keskuspankit tuntevat oman maansa markkinapaikat\", \"creator\": [\"Hievanen, Laura\"], \"year\": \"2015\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"blog post\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kest\\u00e4v\\u00e4n j\\u00e4tehuollon koulutusosaamista vahvistamassa Ven\\u00e4j\\u00e4ll\\u00e4 ja Kazakstanissa\", \"alt_title\": [\"Enhancing Competences of Sustainable Waste Management in Russian and Kazakh HEIs (EduEnvi) {en}\"], \"creator\": [\"Asikainen, Eveliina\", \"Kallio, Ella\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kest\\u00e4v\\u00e4n j\\u00e4tehuollon koulutusosaamista vahvistamassa : Ven\\u00e4j\\u00e4ll\\u00e4 ja Kazakstanissa\", \"creator\": [\"Asikainen, Eveliina\", \"Kallio, Ella\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Maamassojen tilavuuksien mittaamiseen uusia menetelmi\\u00e4 : maan pinnalta ilmaan\", \"creator\": [\"Pesonen, Joonas\", \"J\\u00e4rvel\\u00e4inen, Titta\", \"K\\u00e4yhk\\u00f6, Virpi\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Maamassojen tilavuuksien mittaamiseen uusia menetelmi\\u00e4 : maan pinnalta ilmaan\", \"creator\": [\"Pesonen, Joonas\", \"Jarvelainen, Titta\", \"Virpi, Kayhko\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Medianomit ehk\\u00e4isev\\u00e4t ennalta ty\\u00f6tt\\u00f6myytt\\u00e4\", \"creator\": [\"Karppinen, Anneli\", \"Ketonen, Emma\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Medianomit ehk\\u00e4isev\\u00e4t ennalta ty\\u00f6tt\\u00f6myytt\\u00e4\", \"creator\": [\"Ketonen, Emma\", \"Karppinen, Anneli\"], \"year\": \"2019\", \"publisher\": [\"Tampereen kaupungin ty\\u00f6llisyyspalvelujen\"], \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Mik\\u00e4 saa myllypurolaisen voimaan hyvin?\", \"creator\": [\"Ruotsalainen, Taru\", \"Vuorij\\u00e4rvi, Aino\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Mik\\u00e4 saa myllypurolaisen voimaan hyvin\", \"creator\": [\"Ruotsalainen, Taru\", \"Vuorij\\u00e4rvi, Aino\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Moodlen oppimisanalytiikkaa pedagogiikan tueksi\", \"creator\": [\"Kurttila, Jukka\", \"Aalto, Markus\"], \"year\": \"2021\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Moodlen oppimisanalytiikkaa pedagogiikan tueksi\", \"creator\": [\"Kurttila, Jukka\", \"Aalto, Markus\"], \"year\": \"2021\", \"publisher\": [\"Oulun ammattakoulu\"], \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Oluenarviointisovellukset : olutskenen siunaus vai kirous\", \"creator\": [\"Lehtinen, Aniko\"], \"year\": \"2020\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Oluenarviointisovellukset : oltskenen siunaus vai kirous\", \"creator\": [\"Lehtinen, Anna\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Opiskelija keikkaty\\u00f6n kiemuroissa\", \"creator\": [\"Pajula, Carolina\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Opiskelija keikkaty\\u00f6n kiemuroissa\", \"creator\": [\"Pajula, Cäsia\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Pitk\\u00e4aikaissairauksien ja suun limakalvomuutosten yhteys\", \"creator\": [\"Tapio, Anni\", \"Sepp\\u00e4l\\u00e4, Anne-Mari\", \"Luoto, Annika\", \"Holappa-Girginkaya, Jaana\", \"Kuure, Marja-Helena\", \"Kein\\u00e4nen, Anna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Pitk\\u00e4aikaissairauksien ja suun limakalvomuutosten yhteys\", \"creator\": [\"Anni, Tapio\", \"Anne-Mari, Sepp\\u00e4l\\u00e4\", \"Annika, Luoto\", \"Jaana, Holappa-Girginkaya\", \"Kuure, Marja-Helena\", \"Kein\\u00e4nen\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Siivouskemikaalien ja \\u2013menetelmien vaikutukset koulu- ja p\\u00e4iv\\u00e4kotiymp\\u00e4rist\\u00f6n mikrobistoon ja sis\\u00e4ilman laatuun\", \"creator\": [\"Kakko, Leila\", \"Reunanen, Eija\", \"Kylm\\u00e4korpi, Paula\", \"Alapieti, Tuomas\", \"T\\u00e4ubel, Martin\", \"Mikkola, Raimo\", \"Salonen, Heidi\"], \"year\": \"2019\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Siivouskemikaalien ja \\\"menetelmien vaikutukset koulu- ja p\\u00e4iv\\u00e4kotiymp\\u00e4rist\\u00f6n mikrobistoon ja sis\\u00e4ilman laatuun\", \"creator\": [\"Kakko, Leela\", \"Reunanen, Eija\", \"Kylm\\u00e4korpi, Pentti\", \"Alapieti, Tiia\", \"T\\u00e4ubel, Minna\", \"Mikkola, Riitta\", \"Salonen, Hannu\"], \"year\": \"2019\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"se\", \"title\": \"Deanuleagi eanadatdik\\u0161un- ja geavahanpl\\u00e1na : Biesjohka \\u2013 Nuvvos\", \"creator\": [\"Kokko, Marjut\", \"Koskiniemi, Marika\"], \"publisher\": [\"Lappi eal\\u00e1hus-, johtalus- ja birasguovdd\\u00e1\\u0161\"], \"e-isbn\": [\"9789521150647\"], \"p-isbn\": [\"9789521150630\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"se\", \"title\": \"Deanuleagi eanadatdik\\u0161un- ja geavahanpl\\u00e1na : biesjohka \\u2013 Nuvvos Marjut Kokko ja Marika Koskiniemi\", \"year\": \"2019\", \"publisher\": [\"Ruuttako Roavvenj\\u00e1rga Musta Oy\"], \"e-isbn\": [\"9789521150647\"], \"p-isbn\": [\"9789521150630\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Editorial\", \"creator\": [\"Illman, Ruth\", \"Lundgren, Svante\"], \"doi\": \"10.30752/nj.100124\", \"type_coar\": \"editorial\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Editorial\", \"creator\": [\"Nykvort�Drawing, Lars\"], \"year\": \"2020\", \"doi\": \"10.30752/nj.100124\", \"type_coar\": \"editorial\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Judiskt liv i Helsingfors\", \"creator\": [\"Lundgren, Svante\"], \"doi\": \"10.30752/nj.91511\", \"type_coar\": \"book review\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Judiskt liv i Helsingfors\", \"creator\": [\"Lundgren, Svante\"], \"year\": \"2020\", \"doi\": \"10.30752/nj.91511\", \"type_coar\": \"book review\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen : Vasabladet\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Torka eller ensilera? : Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Yvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Torka eller ensilera? Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Yvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"V\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\", \"creator\": [\"\\u00c5kerback, Nina\", \"\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"Engblom, Sten\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"\\u00c5kerback, Viveka \\u00d6ling-W\\u00e4rn\\u00e5, Engblom, Sten : v\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\", \"creator\": [\"\\u00c5kerback, Nina\", \"V\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"Engblom, Sten\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Demokrati och handel : en empirisk studie \\u00f6ver hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Demokrati och handel : en empirisk studie p\\u00e5verkar hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"En l\\u00e5ng resa : en litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av br\\u00f6stcancer\", \"alt_title\": [\"A long journey : a literature review of women's experiences with breast reconstruction after mastectomy due to breast cancer {en}\"], \"creator\": [\"Zvidrina, Arita\", \"Uzelac-Varda, Silvija\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"En l\\u00e5ng resa : en litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av br\\u00f6stcancer\", \"alt_title\": [\"A long journey : a literature review of women's experiences with breast reconstruction after mastectomy due to breast cancer {en}\"], \"creator\": [\"Zvidrina, Arita\", \"Uzelac-Varda, Silvija\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Fr\\u00e5n \\u00c5lands Sj\\u00f6fartsl\\u00e4roverk till H\\u00f6gskolan p\\u00e5 \\u00c5land : en studie om intresset f\\u00f6r sj\\u00f6kaptensstudier \\u00f6ver tid\", \"alt_title\": [\"From Maritime Institute to the \\u00c5land University of Applied Sciences : a study of the interest in master mariner studies over time {en}\"], \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"From maritime institute to \\u00c5land University of Applied Sciences :  en studie om intresset f\\u00f6r sj\\u00f6kaptensstudier over timmerycka\", \"alt_title\": [\"Sj\\u00f6kaptensutbildning, s\\u00f6kande, studerande, utbildningskrav, variationer, \\u00c5land {sv}\"], \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhantering : modell och praktik\", \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhanteringen modell och praktik : model och praktik\", \"alt_title\": [\"F\\u00f6retags\\u00f6vergripande riskhantering modell och praktik {sv}\"], \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"GDPR i praktiken\", \"alt_title\": [\"GDPR in practice {en}\"], \"creator\": [\"Kahrimanovic, Arnel\", \"Mesic, Selma\"], \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"GDPR i praktiken\", \"alt_title\": [\" GDPR in practice {en}\"], \"creator\": [\"Kahrimanovic, Arnel\", \"Mesic, Selma\"], \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00e5llbara ink\\u00f6p hos tv\\u00e5 \\u00e5l\\u00e4ndska f\\u00f6retag : verksamma inom plastindustrin\", \"alt_title\": [\"Sustainable purchases at two \\u00c5land companies : active in the plastics industry {en}\"], \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00e5llbara ink\\u00f6p hos tv\\u00e5 \\u00e5l\\u00e4ndska f\\u00f6retag : verksamma inom plastindustrin\", \"alt_title\": [\"Sustainable purchases at two \\u00c5land companies : active in the plastics industry {en}\"], \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00e5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor \\u00f6ver tid\", \"creator\": [\"Backlund, Emma\", \"\\u00c5kerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor : vermedanta tid\", \"alt_title\": [\"The role of play and toys in children's cognitive development {en}\"], \"creator\": [\"Backlund, Emma\", \"\\u00c5kerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rares synvinkel : en intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"\\u00c5rtal : inskolningen och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rarens 20 synvinkel : en intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Fakulteten f\\u00f6r pedagogik och v\\u00e4lf\\u00e4rdsstudier\"], type_coar: \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av  processer i IT-f\\u00f6retag : en modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring\", \"alt_title\": [\"Prosessien kartoitus ja kehitys IT-yrityksess\\u00e4 {fi}\", \"Mapping and improving of processes in an IT-company {en}\"], \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av processer i IT-f\\u00f6retag\", \"alt_title\": [\"Prosessien kartoitus ja kehitys IT-yrityksess\\u00e4 {fi}\", \"Mapping and improving of processes in an IT company {en}\"], \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Monitorering av biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Holmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Monitorering av biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Holmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"Januari 2023\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Musik och r\\u00f6relse som plattform f\\u00f6r kreativitet : en intervjustudie med fyra l\\u00e4rare i \\u00e5rskurserna 7-9\", \"alt_title\": [\"Music and movement as a platform for creativity: an interview study involving four teachers in grades 7-9 {en}\"], \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Sibelius-Akademin, Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Musik \\r och \\r r\\u00f6relse : 76+4 en \\u00e5rskurserna 7-9\", \"alt_title\": [\"Music and movement as a platform for creativity: 76+4 for grades 7-\\u00ad\\u20109 {en}\"], \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Sibelius-\\\\u00ad\\u2010Akademin Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Naturliga, rytmiska och holistiska individer : diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Naturliga, rytmiska och holistiska individer : diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"Marcus Moberg\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Orderhantering f\\u00f6r automationstruckssystem med Siemens S7-1500 Logik\", \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Orderhantering f\\u00f6r automationstruckssystem med Siemens S7-1500 Logik\", \"alt_title\": [\"Ordering of components for an automated production line with Siemens S7-1500 Logic {en}\"], \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Resultatmanipulering : en studie om f\\u00f6ruts\\u00e4ttningarna p\\u00e5 den finska marknaden\", \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Resultatmanipulering : en studie om f\\u00f6ruts\\u00e4ttningarna p\\u00e5 den finska marknaden\", \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? : ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? : ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bos Animsarkitym森茂学院医学理工学部人文科学 Faculty of Humaniora, Psykologi och Teologia\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Vikingakvinnan som husmor : en filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa universitet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Vikingakvinnan som husmor : en filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"alt_title\": [\"Vikingakvinnan som husmor : en filologisk n\\u00e4rl\\u00e4sning av _Njals saga_ {en}\"], \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa universitet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"se\", \"title\": \"Davvis\\u00e1megiela goalloss\\u00e1tnegerunddat : \\u201dmun ohppen suoidnec\\u00e1medettiin, duddjodettiin, s\\u00e1lmmaid l\\u00e1vllodettiin, nuohti geasedettiin ja heargevuojedettiin.\\u201d\", \"creator\": [\"Rauhala, Mira\"], \"year\": \"2017\", \"publisher\": [\"Oulu universitehta Giellagas-instituhtta\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"se\", \"title\": \"Davvis\\u00e1megiela goalloss\\u00e1ntegerundnadana : \\u201cMun ohppen suoidnec\\u00e1medettiin, duddjodettiin, s\\u00e1lmmaid_ l\\u00e1vllodettiin, nuohti geasedettiin ja heargevuojedettiin .\\u201d_\", \"creator\": [\"Rauhala, Mira\"], \"year\": \"2017\", \"publisher\": [\"Oulu universitehta\"], \"type_coar\": \"master thesis\"}\n",
      "CPU times: user 7min 7s, sys: 56 s, total: 8min 2s\n",
      "Wall time: 8min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "from itertools import batched\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def rec_to_messages(rec):\n",
    "    return [\n",
    "        {\"role\": msg[\"from\"], \"content\": msg[\"value\"]}\n",
    "        for msg in rec[\"conversations\"]\n",
    "        if msg[\"from\"] != \"gpt\"\n",
    "    ]\n",
    "\n",
    "# read the eval records from file\n",
    "test_recs = []\n",
    "with open(\"axolotl-test.jsonl\") as testfile:\n",
    "    for line in testfile:\n",
    "        test_recs.append(json.loads(line))\n",
    "\n",
    "with open(f'test-records-{MODEL_SHORT_NAME}-{SUFFIX}.jsonl', 'w') as outfile:\n",
    "\n",
    "    for batchno, rec_batch in enumerate(batched(test_recs, BATCH_SIZE)):\n",
    "        messages_batch = [rec_to_messages(rec) for rec in rec_batch]\n",
    "        responses = generate(messages_batch)\n",
    "        gt_batch = [rec['conversations'][-1][\"value\"] for rec in rec_batch]\n",
    "\n",
    "        for ground_truth, response in zip(gt_batch, responses):\n",
    "            print(100 * \"-\")\n",
    "            print(\"Ground Truth:\")\n",
    "            print(ground_truth)\n",
    "            print(\"Prediction:\")\n",
    "            print(response)\n",
    "\n",
    "            ground_truth = json.loads(ground_truth)\n",
    "\n",
    "            try:\n",
    "                prediction = json.loads(response)\n",
    "            except json.JSONDecodeError:\n",
    "                prediction = {}\n",
    "        \n",
    "            # rowid is set to unknown as we've lost it somewhere along the way...\n",
    "            record = {\"ground_truth\": ground_truth, \"prediction\": prediction, \"rowid\": \"unknown\"}\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the statistics of the extracted metadata and save to file\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from eval import MetadataEvaluator\n",
    "\n",
    "evaluator = MetadataEvaluator(f'test-records-{MODEL_SHORT_NAME}-{SUFFIX}.jsonl')\n",
    "results = evaluator.evaluate_records() #prediction_records[:9])\n",
    "\n",
    "model_name = MODEL_SHORT_NAME.replace('.', '_')  # avoid . as it causes problems when merging result files\n",
    "\n",
    "statistics_filename = f'../results-axolotl-{model_name}-{SUFFIX}.md'\n",
    "evaluator.save_md(results, statistics_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('merged-Qwen2.5-0.5B-Instruct-FinGreyLit/tokenizer_config.json',\n",
       " 'merged-Qwen2.5-0.5B-Instruct-FinGreyLit/special_tokens_map.json',\n",
       " 'merged-Qwen2.5-0.5B-Instruct-FinGreyLit/vocab.json',\n",
       " 'merged-Qwen2.5-0.5B-Instruct-FinGreyLit/merges.txt',\n",
       " 'merged-Qwen2.5-0.5B-Instruct-FinGreyLit/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the merged model to a directory (along with tokenizer)\n",
    "\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "model.save_pretrained(merged_model_dir)\n",
    "tokenizer.save_pretrained(merged_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: merged-Qwen2-0.5B-Instruct\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> F16, shape = {896, 151936}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 32768\n",
      "INFO:hf-to-gguf:gguf: embedding length = 896\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 4864\n",
      "INFO:hf-to-gguf:gguf: head count = 14\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 2\n",
      "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 151387 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 151643\n",
      "INFO:gguf.vocab:Setting special token type eos to 151645\n",
      "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf: n_tensors = 290, total_size = 988.2M\n",
      "Writing: 100%|████████████████████████████| 988M/988M [00:00<00:00, 1.17Gbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf\n",
      "CPU times: user 146 ms, sys: 50.4 ms, total: 196 ms\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert the merged model to GGUF using llama.cpp tools (installed separately)\n",
    "\n",
    "LLAMA_CPP_PATH = \"../../../llama.cpp\"\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/venv/bin/python {LLAMA_CPP_PATH}/convert_hf_to_gguf.py {merged_model_dir} --outfile {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: build = 3492 (7c27a19b)\n",
      "main: built with cc (GCC) 13.3.0 for x86_64-pc-linux-gnu\n",
      "main: quantizing 'Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf' to 'Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf' as Q4_K_M\n",
      "llama_model_loader: loaded meta data with 25 key-value pairs and 290 tensors from Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2 0.5B Instruct\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Qwen\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   5:                           general.basename str              = Qwen2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 0.5B\n",
      "llama_model_loader: - kv   7:                          qwen2.block_count u32              = 24\n",
      "llama_model_loader: - kv   8:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv   9:                     qwen2.embedding_length u32              = 896\n",
      "llama_model_loader: - kv  10:                  qwen2.feed_forward_length u32              = 4864\n",
      "llama_model_loader: - kv  11:                 qwen2.attention.head_count u32              = 14\n",
      "llama_model_loader: - kv  12:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  13:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  14:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  121 tensors\n",
      "llama_model_loader: - type  f16:  169 tensors\n",
      "[   1/ 290]                    token_embd.weight - [  896, 151936,     1,     1], type =    f16, converting to q8_0 .. size =   259.66 MiB ->   137.94 MiB\n",
      "[   2/ 290]               blk.0.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[   3/ 290]                blk.0.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[   4/ 290]                blk.0.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[   5/ 290]                  blk.0.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[   6/ 290]                blk.0.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[   7/ 290]                    blk.0.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   8/ 290]                  blk.0.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[   9/ 290]             blk.0.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  10/ 290]                    blk.0.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  11/ 290]                  blk.0.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  12/ 290]                    blk.0.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  13/ 290]                  blk.0.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  14/ 290]               blk.1.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  15/ 290]                blk.1.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  16/ 290]                blk.1.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  17/ 290]                  blk.1.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  18/ 290]                blk.1.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  19/ 290]                    blk.1.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  20/ 290]                  blk.1.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  21/ 290]             blk.1.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  22/ 290]                    blk.1.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  23/ 290]                  blk.1.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  24/ 290]                    blk.1.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  25/ 290]                  blk.1.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  26/ 290]              blk.10.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  27/ 290]               blk.10.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  28/ 290]               blk.10.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  29/ 290]                 blk.10.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  30/ 290]               blk.10.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  31/ 290]                   blk.10.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  32/ 290]                 blk.10.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  33/ 290]            blk.10.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  34/ 290]                   blk.10.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  35/ 290]                 blk.10.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  36/ 290]                   blk.10.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  37/ 290]                 blk.10.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  38/ 290]              blk.11.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  39/ 290]               blk.11.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  40/ 290]               blk.11.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  41/ 290]                 blk.11.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  42/ 290]               blk.11.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  43/ 290]                   blk.11.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  44/ 290]                 blk.11.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  45/ 290]            blk.11.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  46/ 290]                   blk.11.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  47/ 290]                 blk.11.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  48/ 290]                   blk.11.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  49/ 290]                 blk.11.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  50/ 290]              blk.12.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  51/ 290]               blk.12.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  52/ 290]               blk.12.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  53/ 290]                 blk.12.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  54/ 290]               blk.12.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  55/ 290]                   blk.12.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  56/ 290]                 blk.12.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  57/ 290]            blk.12.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  58/ 290]                   blk.12.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  59/ 290]                 blk.12.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  60/ 290]                   blk.12.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  61/ 290]                 blk.12.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  62/ 290]              blk.13.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  63/ 290]               blk.13.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  64/ 290]               blk.13.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  65/ 290]                 blk.13.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  66/ 290]               blk.13.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  67/ 290]                   blk.13.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  68/ 290]                 blk.13.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  69/ 290]            blk.13.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  70/ 290]                   blk.13.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  71/ 290]                 blk.13.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  72/ 290]                   blk.13.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  73/ 290]                 blk.13.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  74/ 290]              blk.14.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  75/ 290]               blk.14.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  76/ 290]               blk.14.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  77/ 290]                 blk.14.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  78/ 290]               blk.14.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  79/ 290]                   blk.14.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  80/ 290]                 blk.14.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  81/ 290]            blk.14.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  82/ 290]                   blk.14.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  83/ 290]                 blk.14.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  84/ 290]                   blk.14.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  85/ 290]                 blk.14.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  86/ 290]              blk.15.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  87/ 290]               blk.15.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  88/ 290]               blk.15.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  89/ 290]                 blk.15.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  90/ 290]               blk.15.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  91/ 290]                   blk.15.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  92/ 290]                 blk.15.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  93/ 290]            blk.15.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  94/ 290]                   blk.15.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  95/ 290]                 blk.15.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  96/ 290]                   blk.15.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  97/ 290]                 blk.15.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  98/ 290]              blk.16.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  99/ 290]               blk.16.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 100/ 290]               blk.16.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 101/ 290]                 blk.16.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 102/ 290]               blk.16.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 103/ 290]                   blk.16.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 104/ 290]                 blk.16.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 105/ 290]            blk.16.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 106/ 290]                   blk.16.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 107/ 290]                 blk.16.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 108/ 290]                   blk.16.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 109/ 290]                 blk.16.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 110/ 290]              blk.17.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 111/ 290]               blk.17.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 112/ 290]               blk.17.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 113/ 290]                 blk.17.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 114/ 290]               blk.17.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 115/ 290]                   blk.17.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 116/ 290]                 blk.17.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 117/ 290]            blk.17.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 118/ 290]                   blk.17.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 119/ 290]                 blk.17.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 120/ 290]                   blk.17.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 121/ 290]                 blk.17.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 122/ 290]              blk.18.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 123/ 290]               blk.18.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 124/ 290]               blk.18.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 125/ 290]                 blk.18.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 126/ 290]               blk.18.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 127/ 290]                   blk.18.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 128/ 290]                 blk.18.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 129/ 290]            blk.18.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 130/ 290]                   blk.18.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 131/ 290]                 blk.18.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 132/ 290]                   blk.18.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 133/ 290]                 blk.18.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 134/ 290]              blk.19.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 135/ 290]               blk.19.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 136/ 290]               blk.19.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 137/ 290]                 blk.19.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 138/ 290]               blk.19.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 139/ 290]                   blk.19.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 140/ 290]                 blk.19.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 141/ 290]            blk.19.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 142/ 290]                   blk.19.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 143/ 290]                 blk.19.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 144/ 290]                   blk.19.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 145/ 290]                 blk.19.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 146/ 290]               blk.2.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 147/ 290]                blk.2.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 148/ 290]                blk.2.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 149/ 290]                  blk.2.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 150/ 290]                blk.2.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 151/ 290]                    blk.2.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 152/ 290]                  blk.2.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 153/ 290]             blk.2.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 154/ 290]                    blk.2.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 155/ 290]                  blk.2.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 156/ 290]                    blk.2.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 157/ 290]                  blk.2.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 158/ 290]              blk.20.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 159/ 290]               blk.20.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 160/ 290]               blk.20.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 161/ 290]                 blk.20.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 162/ 290]               blk.20.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 163/ 290]                   blk.20.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 164/ 290]                 blk.20.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 165/ 290]            blk.20.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 166/ 290]                   blk.20.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 167/ 290]                 blk.20.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 168/ 290]                   blk.20.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 169/ 290]                 blk.20.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 170/ 290]              blk.21.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 171/ 290]               blk.21.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 172/ 290]               blk.21.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 173/ 290]                 blk.21.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 174/ 290]               blk.21.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 175/ 290]                   blk.21.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 176/ 290]                 blk.21.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 177/ 290]            blk.21.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 178/ 290]                   blk.21.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 179/ 290]                 blk.21.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 180/ 290]                   blk.21.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 181/ 290]                 blk.21.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 182/ 290]              blk.22.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 183/ 290]               blk.22.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 184/ 290]               blk.22.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 185/ 290]                 blk.22.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 186/ 290]               blk.22.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 187/ 290]                   blk.22.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 188/ 290]                 blk.22.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 189/ 290]            blk.22.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 190/ 290]                   blk.22.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 191/ 290]                 blk.22.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 192/ 290]                   blk.22.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 193/ 290]                 blk.22.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 194/ 290]              blk.23.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 195/ 290]               blk.23.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 196/ 290]               blk.23.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 197/ 290]                 blk.23.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 198/ 290]               blk.23.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 199/ 290]                   blk.23.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 200/ 290]                 blk.23.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 201/ 290]            blk.23.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 202/ 290]                   blk.23.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 203/ 290]                 blk.23.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 204/ 290]                   blk.23.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 205/ 290]                 blk.23.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 206/ 290]               blk.3.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 207/ 290]                blk.3.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 208/ 290]                blk.3.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 209/ 290]                  blk.3.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 210/ 290]                blk.3.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 211/ 290]                    blk.3.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 212/ 290]                  blk.3.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 213/ 290]             blk.3.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 214/ 290]                    blk.3.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 215/ 290]                  blk.3.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 216/ 290]                    blk.3.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 217/ 290]                  blk.3.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 218/ 290]               blk.4.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 219/ 290]                blk.4.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 220/ 290]                blk.4.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 221/ 290]                  blk.4.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 222/ 290]                blk.4.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 223/ 290]                    blk.4.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 224/ 290]                  blk.4.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 225/ 290]             blk.4.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 226/ 290]                    blk.4.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 227/ 290]                  blk.4.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 228/ 290]                    blk.4.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 229/ 290]                  blk.4.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 230/ 290]               blk.5.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 231/ 290]                blk.5.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 232/ 290]                blk.5.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 233/ 290]                  blk.5.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 234/ 290]                blk.5.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 235/ 290]                    blk.5.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 236/ 290]                  blk.5.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 237/ 290]             blk.5.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 238/ 290]                    blk.5.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 239/ 290]                  blk.5.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 240/ 290]                    blk.5.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 241/ 290]                  blk.5.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 242/ 290]               blk.6.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 243/ 290]                blk.6.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 244/ 290]                blk.6.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 245/ 290]                  blk.6.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 246/ 290]                blk.6.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 247/ 290]                    blk.6.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 248/ 290]                  blk.6.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 249/ 290]             blk.6.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 250/ 290]                    blk.6.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 251/ 290]                  blk.6.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 252/ 290]                    blk.6.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 253/ 290]                  blk.6.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 254/ 290]               blk.7.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 255/ 290]                blk.7.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 256/ 290]                blk.7.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 257/ 290]                  blk.7.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 258/ 290]                blk.7.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 259/ 290]                    blk.7.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 260/ 290]                  blk.7.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 261/ 290]             blk.7.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 262/ 290]                    blk.7.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 263/ 290]                  blk.7.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 264/ 290]                    blk.7.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 265/ 290]                  blk.7.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 266/ 290]               blk.8.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 267/ 290]                blk.8.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 268/ 290]                blk.8.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 269/ 290]                  blk.8.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 270/ 290]                blk.8.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 271/ 290]                    blk.8.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 272/ 290]                  blk.8.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 273/ 290]             blk.8.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 274/ 290]                    blk.8.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 275/ 290]                  blk.8.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 276/ 290]                    blk.8.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 277/ 290]                  blk.8.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 278/ 290]               blk.9.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 279/ 290]                blk.9.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 280/ 290]                blk.9.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 281/ 290]                  blk.9.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 282/ 290]                blk.9.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 283/ 290]                    blk.9.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 284/ 290]                  blk.9.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 285/ 290]             blk.9.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 286/ 290]                    blk.9.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 287/ 290]                  blk.9.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 288/ 290]                    blk.9.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 289/ 290]                  blk.9.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 290/ 290]                   output_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "llama_model_quantize_internal: model size  =   942.43 MB\n",
      "llama_model_quantize_internal: quant size  =   373.71 MB\n",
      "llama_model_quantize_internal: WARNING: 144 of 168 tensor(s) required fallback quantization\n",
      "\n",
      "main: quantize time =  3876.16 ms\n",
      "main:    total time =  3876.16 ms\n",
      "CPU times: user 65.2 ms, sys: 45.4 ms, total: 111 ms\n",
      "Wall time: 4.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Quantize the F16 GGUF model to the 4+ bit Q4_K_M format\n",
    "QTYPE = \"Q4_K_M\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/llama-quantize {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf {MODEL_SHORT_NAME}-{SUFFIX}-{QTYPE}.gguf {QTYPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using `hf_transfer` for faster uploads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
      "Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf: 100%|█| 398M/398M [00:13<00:00, 28.5\n",
      "https://huggingface.co/NatLibFi/Qwen2-0.5B-Instruct-FinGreyLit-GGUF/blob/main/Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "# Upload the quantized GGUF file to HF Hub\n",
    "\n",
    "FINAL_MODEL_NAME = f\"NatLibFi/{MODEL_SHORT_NAME}-{SUFFIX}-GGUF\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/venv/bin/huggingface-cli upload {FINAL_MODEL_NAME} {MODEL_SHORT_NAME}-{SUFFIX}-{QTYPE}.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingreylit-axolotl",
   "language": "python",
   "name": "fingreylit-axolotl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
