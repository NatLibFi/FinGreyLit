{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune Qwen2-0.5B-Instruct model using Axolotl framework\n",
    "\n",
    "How to install dependencies (in HPC environment):\n",
    "\n",
    "- load Python and cuDNN modules\n",
    "- create a Python venv and activate it\n",
    "- install dependencies from requirements.txt (e.g. torch)\n",
    "- install Axolotl from git clone (pip won't work, see [this issue](https://github.com/OpenAccess-AI-Collective/axolotl/issues/945)):\n",
    "\n",
    "```\n",
    "git clone git@github.com:OpenAccess-AI-Collective/axolotl.git\n",
    "cd axolotl\n",
    "pip install -e '.[flash-attn,deepspeed]'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n",
      "BF16 is supported? True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print('GPU available?', torch.cuda.is_available())\n",
    "print('BF16 is supported?', torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name etc.\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "MODEL_SHORT_NAME = MODEL_NAME.split('/')[-1]\n",
    "SUFFIX = \"FinGreyLit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 640 train records\n",
      "Wrote 182 test records\n",
      "Wrote 32 eval records\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare fine-tuning dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of test set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "EVAL_SIZE = 32  # how many documents to evaluate (i.e. calculate loss) on during fine-tuning\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    output = json.dumps(sample[\"ground_truth\"])\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    # ShareGPT format\n",
    "    conversations = [\n",
    "        {'from': 'system', 'value': SYSTEM_PROMPT},\n",
    "        {'from': 'user', 'value': INSTRUCTION + \"\\n\\n\" + input_},\n",
    "        {'from': 'gpt', 'value': output}\n",
    "    ]\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "def write_jsonl(records, filename):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for record in records:\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "train_recs = dataset_to_records(train_files)\n",
    "random.shuffle(train_recs)\n",
    "write_jsonl(train_recs, \"axolotl-train.jsonl\")\n",
    "print(f\"Wrote {len(train_recs)} train records\")\n",
    "\n",
    "test_recs = dataset_to_records(test_files)\n",
    "write_jsonl(test_recs, \"axolotl-test.jsonl\")\n",
    "print(f\"Wrote {len(test_recs)} test records\")\n",
    "\n",
    "eval_recs = random.sample(test_recs, EVAL_SIZE)\n",
    "write_jsonl(eval_recs, \"axolotl-eval.jsonl\")\n",
    "print(f\"Wrote {len(eval_recs)} eval records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Axolotl configuration file\n",
    "\n",
    "CONFIG_FILE = f\"config-{MODEL_SHORT_NAME}.yml\"\n",
    "\n",
    "\n",
    "CONFIG = f\"\"\"\n",
    "base_model: {MODEL_NAME}\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: false\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: axolotl-train.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "test_datasets:\n",
    "  - path: axolotl-eval.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "output_dir: ./out-{MODEL_SHORT_NAME}\n",
    "\n",
    "#chat_template: chatml\n",
    "\n",
    "adapter: lora\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "eval_batch_size: 2\n",
    "num_epochs: 8\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: true\n",
    "fp16: false\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true  # true: saves VRAM but is slower to train\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 2\n",
    "eval_table_size:\n",
    "eval_table_max_new_tokens: 128\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "special_tokens:\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as outfile:\n",
    "    print(CONFIG, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-11-28 12:27:29,976] [INFO] [datasets.<module>:58] [PID:2795718] PyTorch version 2.3.1 available.\n",
      "[2024-11-28 12:27:37,607] [INFO] [axolotl.utils.config.models.input.check_eval_packing:958] [PID:2795718] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "\u001b[33m[2024-11-28 12:27:37,607] [WARNING] [axolotl.utils.config.models.input.hint_lora_8bit:1044] [PID:2795718] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2024-11-28 12:27:37,765] [INFO] [axolotl.normalize_config:183] [PID:2795718] [RANK:0] GPU memory usage baseline: 0.000GB (+0.818GB misc)\u001b[39m\n",
      "                                 dP            dP   dP \n",
      "                                 88            88   88 \n",
      "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
      "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
      "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
      "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
      "                                                       \n",
      "                                                       \n",
      "\n",
      "****************************************\n",
      "**** Axolotl Dependency Versions *****\n",
      "  accelerate: 0.32.0         \n",
      "        peft: 0.11.1         \n",
      "transformers: 4.43.0.dev0    \n",
      "         trl: 0.9.6          \n",
      "       torch: 2.3.1          \n",
      "bitsandbytes: 0.43.1         \n",
      "****************************************\n",
      "\u001b[33m[2024-11-28 12:27:37,785] [WARNING] [axolotl.scripts.check_accelerate_default_config:468] [PID:2795718] [RANK:0] accelerate config file found at /home/oisuomin/.cache/huggingface/accelerate/default_config.yaml. This can lead to unexpected errors\u001b[39m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-11-28 12:27:38,387] [DEBUG] [axolotl.load_tokenizer:280] [PID:2795718] [RANK:0] EOS: 151645 / <|im_end|>\u001b[39m\n",
      "[2024-11-28 12:27:38,387] [DEBUG] [axolotl.load_tokenizer:281] [PID:2795718] [RANK:0] BOS: None / None\u001b[39m\n",
      "[2024-11-28 12:27:38,387] [DEBUG] [axolotl.load_tokenizer:282] [PID:2795718] [RANK:0] PAD: 151643 / <|endoftext|>\u001b[39m\n",
      "[2024-11-28 12:27:38,387] [DEBUG] [axolotl.load_tokenizer:283] [PID:2795718] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-11-28 12:27:38,387] [INFO] [axolotl.load_tokenizer:294] [PID:2795718] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2024-11-28 12:27:38,387] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:2795718] [RANK:0] Unable to find prepared dataset in last_run_prepared/a483be133f8a1d68761ef634ff3e062f\u001b[39m\n",
      "[2024-11-28 12:27:38,387] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:2795718] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2024-11-28 12:27:38,387] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:2795718] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2024-11-28 12:27:38,387] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:2795718] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 640 examples [00:00, 21524.43 examples/s]\n",
      "[2024-11-28 12:27:39,081] [INFO] [axolotl.get_dataset_wrapper:540] [PID:2795718] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "Tokenizing Prompts (num_proc=64): 100%|█| 640/640 [00:07<00:00, 90.51 examples/s\n",
      "[2024-11-28 12:27:46,658] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:2795718] [RANK:0] merging datasets\u001b[39m\n",
      "Dropping Long Sequences (num_proc=128): 100%|█| 640/640 [00:01<00:00, 539.67 exa\n",
      "Add position_id column (Sample Packing) (num_proc=128): 100%|█| 628/628 [00:02<0\n",
      "[2024-11-28 12:27:52,004] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:2795718] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/a483be133f8a1d68761ef634ff3e062f\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|█| 628/628 [00:00<00:00, 15125.63 examples\n",
      "[2024-11-28 12:27:52,070] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:2795718] [RANK:0] Unable to find prepared dataset in last_run_prepared/216b4dd617b95176c0bbcb3df0e1bccc\u001b[39m\n",
      "[2024-11-28 12:27:52,071] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:2795718] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2024-11-28 12:27:52,071] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:2795718] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2024-11-28 12:27:52,071] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:2795718] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 32 examples [00:00, 8488.88 examples/s]\n",
      "[2024-11-28 12:27:52,709] [INFO] [axolotl.get_dataset_wrapper:540] [PID:2795718] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-11-28 12:27:52,710] [WARNING] [datasets.arrow_dataset.map:3087] [PID:2795718] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Tokenizing Prompts (num_proc=32): 100%|██| 32/32 [00:03<00:00,  9.70 examples/s]\n",
      "[2024-11-28 12:27:56,300] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:2795718] [RANK:0] merging datasets\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-11-28 12:27:56,304] [WARNING] [datasets.arrow_dataset.map:3087] [PID:2795718] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 32/32 [00:00<00:00, 114.39 exampl\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-11-28 12:27:56,808] [WARNING] [datasets.arrow_dataset.map:3087] [PID:2795718] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "[2024-11-28 12:27:57,465] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:2795718] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/216b4dd617b95176c0bbcb3df0e1bccc\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|█| 32/32 [00:00<00:00, 2620.67 examples/s]\n",
      "[2024-11-28 12:27:57,495] [DEBUG] [axolotl.calculate_total_num_steps:297] [PID:2795718] [RANK:0] total_num_tokens: 918_922\u001b[39m\n",
      "[2024-11-28 12:27:57,504] [DEBUG] [axolotl.calculate_total_num_steps:310] [PID:2795718] [RANK:0] `total_supervised_tokens: 78_855`\u001b[39m\n",
      "[2024-11-28 12:28:03,096] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 918922\u001b[39m\n",
      "[2024-11-28 12:28:03,096] [DEBUG] [axolotl.calculate_total_num_steps:362] [PID:2795718] [RANK:0] data_loader_len: 27\u001b[39m\n",
      "[2024-11-28 12:28:03,096] [INFO] [axolotl.calc_sample_packing_eff_est:368] [PID:2795718] [RANK:0] sample_packing_eff_est across ranks: [0.8763523101806641]\u001b[39m\n",
      "[2024-11-28 12:28:03,097] [DEBUG] [axolotl.calculate_total_num_steps:380] [PID:2795718] [RANK:0] sample_packing_eff_est: 0.88\u001b[39m\n",
      "[2024-11-28 12:28:03,097] [DEBUG] [axolotl.calculate_total_num_steps:388] [PID:2795718] [RANK:0] total_num_steps: 216\u001b[39m\n",
      "[2024-11-28 12:28:03,116] [DEBUG] [axolotl.train.train:66] [PID:2795718] [RANK:0] loading tokenizer... Qwen/Qwen2-0.5B-Instruct\u001b[39m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-11-28 12:28:03,516] [DEBUG] [axolotl.load_tokenizer:280] [PID:2795718] [RANK:0] EOS: 151645 / <|im_end|>\u001b[39m\n",
      "[2024-11-28 12:28:03,516] [DEBUG] [axolotl.load_tokenizer:281] [PID:2795718] [RANK:0] BOS: None / None\u001b[39m\n",
      "[2024-11-28 12:28:03,516] [DEBUG] [axolotl.load_tokenizer:282] [PID:2795718] [RANK:0] PAD: 151643 / <|endoftext|>\u001b[39m\n",
      "[2024-11-28 12:28:03,516] [DEBUG] [axolotl.load_tokenizer:283] [PID:2795718] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-11-28 12:28:03,516] [INFO] [axolotl.load_tokenizer:294] [PID:2795718] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2024-11-28 12:28:03,516] [DEBUG] [axolotl.train.train:95] [PID:2795718] [RANK:0] loading model and peft_config...\u001b[39m\n",
      "[2024-11-28 12:28:03,520] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:2795718] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[2024-11-28 12:28:05,083] [INFO] [axolotl.load_model:824] [PID:2795718] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-11-28 12:28:05,130] [INFO] [axolotl.load_lora:986] [PID:2795718] [RANK:0] found linear modules: ['q_proj', 'v_proj', 'gate_proj', 'k_proj', 'up_proj', 'down_proj', 'o_proj']\u001b[39m\n",
      "trainable params: 8,798,208 || all params: 502,830,976 || trainable%: 1.7497\n",
      "[2024-11-28 12:28:05,271] [INFO] [axolotl.load_model:869] [PID:2795718] [RANK:0] GPU memory usage after adapters: 0.000GB ()\u001b[39m\n",
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-11-28 12:28:05,787] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:2795718] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[2024-11-28 12:28:07,219] [INFO] [axolotl.train.train:136] [PID:2795718] [RANK:0] Pre-saving adapter config to ./out-Qwen2-0.5B-Instruct\u001b[39m\n",
      "[2024-11-28 12:28:07,327] [INFO] [axolotl.train.train:173] [PID:2795718] [RANK:0] Starting trainer...\u001b[39m\n",
      "[2024-11-28 12:28:07,512] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "[2024-11-28 12:28:07,513] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "  0%|                                                   | 0/248 [00:00<?, ?it/s][2024-11-28 12:28:07,564] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.0888, 'grad_norm': 4.28125, 'learning_rate': 2e-05, 'epoch': 0.03}   \n",
      "  0%|▏                                          | 1/248 [00:02<11:44,  2.85s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.48it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.94it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.98it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.56it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.49it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.05it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.16it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.05it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:28:13,030] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.3680918216705322, 'eval_runtime': 2.6587, 'eval_samples_per_second': 12.036, 'eval_steps_per_second': 6.018, 'epoch': 0.03}\n",
      "  0%|▏                                          | 1/248 [00:05<11:44,  2.85s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.23it/s]\u001b[A\n",
      "                                                                                \u001b[A[2024-11-28 12:28:15,087] [INFO] [axolotl.callbacks.on_step_end:128] [PID:2795718] [RANK:0] GPU memory usage while training: 1.165GB (+17.114GB cache, +1.326GB misc)\u001b[39m\n",
      "{'loss': 1.288, 'grad_norm': 4.375, 'learning_rate': 4e-05, 'epoch': 0.06}      \n",
      "{'loss': 1.253, 'grad_norm': 3.796875, 'learning_rate': 6e-05, 'epoch': 0.1}    \n",
      "{'loss': 1.1684, 'grad_norm': 2.5625, 'learning_rate': 8e-05, 'epoch': 0.13}    \n",
      "{'loss': 1.2039, 'grad_norm': 2.03125, 'learning_rate': 0.0001, 'epoch': 0.16}  \n",
      "{'loss': 1.004, 'grad_norm': 1.765625, 'learning_rate': 0.00012, 'epoch': 0.19} \n",
      "{'loss': 0.9143, 'grad_norm': 1.5703125, 'learning_rate': 0.00014, 'epoch': 0.22}\n",
      "{'loss': 0.7012, 'grad_norm': 1.4296875, 'learning_rate': 0.00016, 'epoch': 0.26}\n",
      "{'loss': 0.4855, 'grad_norm': 1.6875, 'learning_rate': 0.00018, 'epoch': 0.29}  \n",
      "{'loss': 0.4953, 'grad_norm': 1.3671875, 'learning_rate': 0.0002, 'epoch': 0.32}\n",
      "{'loss': 0.4035, 'grad_norm': 1.2578125, 'learning_rate': 0.00019999128816724108, 'epoch': 0.35}\n",
      "{'loss': 0.4146, 'grad_norm': 1.1640625, 'learning_rate': 0.0001999651541868849, 'epoch': 0.38}\n",
      "{'loss': 0.5346, 'grad_norm': 1.4140625, 'learning_rate': 0.00019992160261242877, 'epoch': 0.42}\n",
      "{'loss': 0.3098, 'grad_norm': 1.21875, 'learning_rate': 0.00019986064103215339, 'epoch': 0.45}\n",
      "{'loss': 0.5016, 'grad_norm': 0.9921875, 'learning_rate': 0.00019978228006780054, 'epoch': 0.48}\n",
      "{'loss': 0.2736, 'grad_norm': 1.09375, 'learning_rate': 0.00019968653337272261, 'epoch': 0.51}\n",
      "  6%|██▋                                       | 16/248 [00:35<07:46,  2.01s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.42it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.88it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.05it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:28:45,758] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.3433626890182495, 'eval_runtime': 2.6559, 'eval_samples_per_second': 12.049, 'eval_steps_per_second': 6.024, 'epoch': 0.51}\n",
      "  6%|██▋                                       | 16/248 [00:38<07:46,  2.01s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.24it/s]\u001b[A\n",
      "{'loss': 0.2885, 'grad_norm': 0.96875, 'learning_rate': 0.00019957341762950344, 'epoch': 0.54}\n",
      "{'loss': 0.1771, 'grad_norm': 0.8671875, 'learning_rate': 0.00019944295254705185, 'epoch': 0.58}\n",
      "{'loss': 0.3343, 'grad_norm': 1.0234375, 'learning_rate': 0.00019929516085716734, 'epoch': 0.61}\n",
      "{'loss': 0.2868, 'grad_norm': 0.99609375, 'learning_rate': 0.00019913006831057969, 'epoch': 0.64}\n",
      "{'loss': 0.2461, 'grad_norm': 0.84765625, 'learning_rate': 0.00019894770367246195, 'epoch': 0.67}\n",
      "{'loss': 0.2317, 'grad_norm': 0.7890625, 'learning_rate': 0.00019874809871741876, 'epoch': 0.7}\n",
      "{'loss': 0.1378, 'grad_norm': 0.78125, 'learning_rate': 0.00019853128822394975, 'epoch': 0.74}\n",
      "{'loss': 0.2517, 'grad_norm': 0.828125, 'learning_rate': 0.0001982973099683902, 'epoch': 0.77}\n",
      "{'loss': 0.1942, 'grad_norm': 0.86328125, 'learning_rate': 0.0001980462047183287, 'epoch': 0.8}\n",
      "{'loss': 0.4142, 'grad_norm': 1.03125, 'learning_rate': 0.00019777801622550408, 'epoch': 0.83}\n",
      "{'loss': 0.2391, 'grad_norm': 0.68359375, 'learning_rate': 0.00019749279121818235, 'epoch': 0.86}\n",
      "{'loss': 0.2879, 'grad_norm': 0.80859375, 'learning_rate': 0.00019719057939301477, 'epoch': 0.9}\n",
      "{'loss': 0.198, 'grad_norm': 0.796875, 'learning_rate': 0.00019687143340637887, 'epoch': 0.93}\n",
      "{'loss': 0.1971, 'grad_norm': 0.6484375, 'learning_rate': 0.00019653540886520386, 'epoch': 0.96}\n",
      "{'loss': 0.3041, 'grad_norm': 1.015625, 'learning_rate': 0.00019618256431728194, 'epoch': 0.99}\n",
      " 12%|█████▎                                    | 31/248 [01:08<07:15,  2.01s/it][2024-11-28 12:29:17,374] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "{'loss': 0.1266, 'grad_norm': 0.53515625, 'learning_rate': 0.0001958129612410668, 'epoch': 1.02}\n",
      " 13%|█████▍                                    | 32/248 [01:10<07:47,  2.17s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.46it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.16it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.05it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:29:21,013] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.23637062311172485, 'eval_runtime': 2.656, 'eval_samples_per_second': 12.048, 'eval_steps_per_second': 6.024, 'epoch': 1.02}\n",
      " 13%|█████▍                                    | 32/248 [01:13<07:47,  2.17s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.24it/s]\u001b[A\n",
      "{'loss': 0.1587, 'grad_norm': 0.56640625, 'learning_rate': 0.00019542666403496233, 'epoch': 1.05}\n",
      "{'loss': 0.1886, 'grad_norm': 0.640625, 'learning_rate': 0.00019502374000610151, 'epoch': 1.08}\n",
      "{'loss': 0.221, 'grad_norm': 0.61328125, 'learning_rate': 0.00019460425935861948, 'epoch': 1.11}\n",
      "{'loss': 0.1975, 'grad_norm': 0.65625, 'learning_rate': 0.00019416829518142118, 'epoch': 1.14}\n",
      "{'loss': 0.0939, 'grad_norm': 0.53125, 'learning_rate': 0.00019371592343544656, 'epoch': 1.18}\n",
      "{'loss': 0.1263, 'grad_norm': 0.6796875, 'learning_rate': 0.00019324722294043558, 'epoch': 1.21}\n",
      "{'loss': 0.1455, 'grad_norm': 0.56640625, 'learning_rate': 0.0001927622753611948, 'epoch': 1.24}\n",
      "{'loss': 0.2263, 'grad_norm': 0.443359375, 'learning_rate': 0.0001922611651933683, 'epoch': 1.27}\n",
      "{'loss': 0.1343, 'grad_norm': 0.52734375, 'learning_rate': 0.00019174397974871564, 'epoch': 1.3}\n",
      "{'loss': 0.1869, 'grad_norm': 0.75390625, 'learning_rate': 0.0001912108091398988, 'epoch': 1.34}\n",
      "{'loss': 0.1341, 'grad_norm': 0.5234375, 'learning_rate': 0.0001906617462647813, 'epoch': 1.37}\n",
      "{'loss': 0.2121, 'grad_norm': 1.3671875, 'learning_rate': 0.0001900968867902419, 'epoch': 1.4}\n",
      "{'loss': 0.133, 'grad_norm': 0.52734375, 'learning_rate': 0.00018951632913550626, 'epoch': 1.43}\n",
      "{'loss': 0.1748, 'grad_norm': 0.65234375, 'learning_rate': 0.0001889201744549981, 'epoch': 1.46}\n",
      "{'loss': 0.1534, 'grad_norm': 0.65234375, 'learning_rate': 0.00018830852662071507, 'epoch': 1.5}\n",
      "{'loss': 0.1361, 'grad_norm': 0.546875, 'learning_rate': 0.0001876814922041299, 'epoch': 1.53}\n",
      " 19%|████████▏                                 | 48/248 [01:45<06:41,  2.01s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.46it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.95it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.47it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  5.71it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  5.94it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  5.98it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.05it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.79it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  5.99it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.03it/s]\u001b[A[2024-11-28 12:29:55,773] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19787918031215668, 'eval_runtime': 2.6885, 'eval_samples_per_second': 11.903, 'eval_steps_per_second': 5.951, 'epoch': 1.53}\n",
      " 19%|████████▏                                 | 48/248 [01:48<06:41,  2.01s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.21it/s]\u001b[A\n",
      "{'loss': 0.2276, 'grad_norm': 0.6640625, 'learning_rate': 0.00018703918045762197, 'epoch': 1.56}\n",
      "{'loss': 0.1182, 'grad_norm': 0.53515625, 'learning_rate': 0.00018638170329544164, 'epoch': 1.59}\n",
      "{'loss': 0.2435, 'grad_norm': 0.625, 'learning_rate': 0.00018570917527421048, 'epoch': 1.62}\n",
      "{'loss': 0.2145, 'grad_norm': 0.73828125, 'learning_rate': 0.00018502171357296144, 'epoch': 1.66}\n",
      "{'loss': 0.1659, 'grad_norm': 0.5703125, 'learning_rate': 0.00018431943797272187, 'epoch': 1.69}\n",
      "{'loss': 0.1507, 'grad_norm': 0.62109375, 'learning_rate': 0.00018360247083564342, 'epoch': 1.72}\n",
      "{'loss': 0.1184, 'grad_norm': 0.54296875, 'learning_rate': 0.00018287093708368188, 'epoch': 1.75}\n",
      "{'loss': 0.1418, 'grad_norm': 0.53515625, 'learning_rate': 0.00018212496417683137, 'epoch': 1.78}\n",
      "{'loss': 0.1925, 'grad_norm': 0.796875, 'learning_rate': 0.00018136468209091602, 'epoch': 1.82}\n",
      "{'loss': 0.1265, 'grad_norm': 0.5859375, 'learning_rate': 0.0001805902232949435, 'epoch': 1.85}\n",
      "{'loss': 0.16, 'grad_norm': 0.458984375, 'learning_rate': 0.000179801722728024, 'epoch': 1.88}\n",
      "{'loss': 0.1555, 'grad_norm': 0.6484375, 'learning_rate': 0.00017899931777585882, 'epoch': 1.91}\n",
      "{'loss': 0.1399, 'grad_norm': 0.5078125, 'learning_rate': 0.000178183148246803, 'epoch': 1.94}\n",
      "{'loss': 0.1241, 'grad_norm': 0.56640625, 'learning_rate': 0.00017735335634750532, 'epoch': 1.98}\n",
      "{'loss': 0.1295, 'grad_norm': 0.46875, 'learning_rate': 0.00017651008665813081, 'epoch': 2.01}\n",
      " 25%|██████████▋                               | 63/248 [02:19<06:48,  2.21s/it][2024-11-28 12:30:26,894] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "{'loss': 0.1807, 'grad_norm': 0.52734375, 'learning_rate': 0.0001756534861071696, 'epoch': 2.02}\n",
      " 26%|██████████▊                               | 64/248 [02:20<06:24,  2.09s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.47it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.07it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  5.92it/s]\u001b[A[2024-11-28 12:30:31,037] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18234089016914368, 'eval_runtime': 2.6682, 'eval_samples_per_second': 11.993, 'eval_steps_per_second': 5.997, 'epoch': 2.02}\n",
      " 26%|██████████▊                               | 64/248 [02:23<06:24,  2.09s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.13it/s]\u001b[A\n",
      "{'loss': 0.1327, 'grad_norm': 0.470703125, 'learning_rate': 0.00017478370394583646, 'epoch': 2.06}\n",
      "{'loss': 0.1161, 'grad_norm': 0.43359375, 'learning_rate': 0.00017390089172206592, 'epoch': 2.09}\n",
      "{'loss': 0.148, 'grad_norm': 0.52734375, 'learning_rate': 0.00017300520325410701, 'epoch': 2.12}\n",
      "{'loss': 0.141, 'grad_norm': 0.50390625, 'learning_rate': 0.0001720967946037225, 'epoch': 2.15}\n",
      "{'loss': 0.0977, 'grad_norm': 0.4296875, 'learning_rate': 0.00017117582404899712, 'epoch': 2.18}\n",
      "{'loss': 0.0893, 'grad_norm': 0.365234375, 'learning_rate': 0.00017024245205675986, 'epoch': 2.22}\n",
      "{'loss': 0.0596, 'grad_norm': 0.3984375, 'learning_rate': 0.0001692968412546247, 'epoch': 2.25}\n",
      "{'loss': 0.0793, 'grad_norm': 0.39453125, 'learning_rate': 0.00016833915640265484, 'epoch': 2.28}\n",
      "{'loss': 0.1892, 'grad_norm': 0.5390625, 'learning_rate': 0.00016736956436465573, 'epoch': 2.31}\n",
      "{'loss': 0.1118, 'grad_norm': 0.58984375, 'learning_rate': 0.00016638823407910084, 'epoch': 2.34}\n",
      "{'loss': 0.0952, 'grad_norm': 0.625, 'learning_rate': 0.00016539533652969683, 'epoch': 2.38}\n",
      "{'loss': 0.1778, 'grad_norm': 0.5703125, 'learning_rate': 0.00016439104471559156, 'epoch': 2.41}\n",
      "{'loss': 0.1297, 'grad_norm': 0.59375, 'learning_rate': 0.00016337553362123165, 'epoch': 2.44}\n",
      "{'loss': 0.0428, 'grad_norm': 0.53125, 'learning_rate': 0.00016234898018587337, 'epoch': 2.47}\n",
      "{'loss': 0.0591, 'grad_norm': 0.3671875, 'learning_rate': 0.00016131156327275372, 'epoch': 2.5}\n",
      "{'loss': 0.1176, 'grad_norm': 0.462890625, 'learning_rate': 0.00016026346363792567, 'epoch': 2.54}\n",
      " 32%|█████████████▌                            | 80/248 [02:55<05:37,  2.01s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.44it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.08it/s]\u001b[A[2024-11-28 12:31:05,840] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A                                                                             {'eval_loss': 0.1774550974369049, 'eval_runtime': 2.6547, 'eval_samples_per_second': 12.054, 'eval_steps_per_second': 6.027, 'epoch': 2.54}\n",
      " 32%|█████████████▌                            | 80/248 [02:58<05:37,  2.01s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.24it/s]\u001b[A\n",
      "{'loss': 0.0824, 'grad_norm': 0.470703125, 'learning_rate': 0.00015920486389876383, 'epoch': 2.57}\n",
      "{'loss': 0.0834, 'grad_norm': 0.400390625, 'learning_rate': 0.000158135948502146, 'epoch': 2.6}\n",
      "{'loss': 0.0662, 'grad_norm': 0.376953125, 'learning_rate': 0.00015705690369231551, 'epoch': 2.63}\n",
      "{'loss': 0.1026, 'grad_norm': 0.42578125, 'learning_rate': 0.0001559679174784308, 'epoch': 2.66}\n",
      "{'loss': 0.052, 'grad_norm': 0.314453125, 'learning_rate': 0.0001548691796018074, 'epoch': 2.7}\n",
      "{'loss': 0.0841, 'grad_norm': 0.384765625, 'learning_rate': 0.00015376088150285773, 'epoch': 2.73}\n",
      "{'loss': 0.1003, 'grad_norm': 0.42578125, 'learning_rate': 0.0001526432162877356, 'epoch': 2.76}\n",
      "{'loss': 0.1461, 'grad_norm': 0.478515625, 'learning_rate': 0.0001515163786946896, 'epoch': 2.79}\n",
      "{'loss': 0.1579, 'grad_norm': 0.482421875, 'learning_rate': 0.00015038056506013297, 'epoch': 2.82}\n",
      "{'loss': 0.1191, 'grad_norm': 0.62890625, 'learning_rate': 0.00014923597328443422, 'epoch': 2.86}\n",
      "{'loss': 0.1104, 'grad_norm': 0.478515625, 'learning_rate': 0.00014808280279743593, 'epoch': 2.89}\n",
      "{'loss': 0.0531, 'grad_norm': 0.314453125, 'learning_rate': 0.00014692125452370663, 'epoch': 2.92}\n",
      "{'loss': 0.0832, 'grad_norm': 0.5390625, 'learning_rate': 0.00014575153084753233, 'epoch': 2.95}\n",
      "{'loss': 0.0894, 'grad_norm': 0.47265625, 'learning_rate': 0.00014457383557765386, 'epoch': 2.98}\n",
      " 38%|███████████████▉                          | 94/248 [03:27<05:43,  2.23s/it][2024-11-28 12:31:35,690] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "{'loss': 0.0851, 'grad_norm': 0.35546875, 'learning_rate': 0.00014338837391175582, 'epoch': 3.02}\n",
      "{'loss': 0.0428, 'grad_norm': 0.396484375, 'learning_rate': 0.00014219535240071377, 'epoch': 3.05}\n",
      " 39%|████████████████▎                         | 96/248 [03:31<05:20,  2.11s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.46it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.54it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:31:41,317] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17458337545394897, 'eval_runtime': 2.6557, 'eval_samples_per_second': 12.049, 'eval_steps_per_second': 6.025, 'epoch': 3.05}\n",
      " 39%|████████████████▎                         | 96/248 [03:33<05:20,  2.11s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.23it/s]\u001b[A\n",
      "{'loss': 0.0508, 'grad_norm': 0.337890625, 'learning_rate': 0.00014099497891260538, 'epoch': 3.08}\n",
      "{'loss': 0.066, 'grad_norm': 0.396484375, 'learning_rate': 0.00013978746259649209, 'epoch': 3.11}\n",
      "{'loss': 0.0898, 'grad_norm': 0.375, 'learning_rate': 0.00013857301384597796, 'epoch': 3.14}\n",
      "{'loss': 0.0632, 'grad_norm': 0.44140625, 'learning_rate': 0.00013735184426255117, 'epoch': 3.18}\n",
      "{'loss': 0.0637, 'grad_norm': 0.306640625, 'learning_rate': 0.00013612416661871533, 'epoch': 3.21}\n",
      "{'loss': 0.0921, 'grad_norm': 0.396484375, 'learning_rate': 0.0001348901948209167, 'epoch': 3.24}\n",
      "{'loss': 0.0796, 'grad_norm': 0.34765625, 'learning_rate': 0.00013365014387227393, 'epoch': 3.27}\n",
      "{'loss': 0.0673, 'grad_norm': 0.435546875, 'learning_rate': 0.0001324042298351166, 'epoch': 3.3}\n",
      "{'loss': 0.0899, 'grad_norm': 0.380859375, 'learning_rate': 0.00013115266979333917, 'epoch': 3.34}\n",
      "{'loss': 0.0213, 'grad_norm': 0.212890625, 'learning_rate': 0.00012989568181457704, 'epoch': 3.37}\n",
      "{'loss': 0.0971, 'grad_norm': 0.4375, 'learning_rate': 0.00012863348491221128, 'epoch': 3.4}\n",
      "{'loss': 0.073, 'grad_norm': 0.43359375, 'learning_rate': 0.0001273662990072083, 'epoch': 3.43}\n",
      "{'loss': 0.0987, 'grad_norm': 0.427734375, 'learning_rate': 0.00012609434488980168, 'epoch': 3.46}\n",
      "{'loss': 0.0257, 'grad_norm': 0.322265625, 'learning_rate': 0.00012481784418102242, 'epoch': 3.5}\n",
      "{'loss': 0.0533, 'grad_norm': 0.412109375, 'learning_rate': 0.00012353701929408427, 'epoch': 3.53}\n",
      "{'loss': 0.0767, 'grad_norm': 0.5703125, 'learning_rate': 0.00012225209339563145, 'epoch': 3.56}\n",
      " 45%|██████████████████▌                      | 112/248 [04:05<04:32,  2.00s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.48it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  5.03it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  5.40it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  5.60it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  5.77it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.62it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  5.86it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  5.95it/s]\u001b[A[2024-11-28 12:32:16,149] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17851926386356354, 'eval_runtime': 2.7645, 'eval_samples_per_second': 11.575, 'eval_steps_per_second': 5.788, 'epoch': 3.56}\n",
      " 45%|██████████████████▌                      | 112/248 [04:08<04:32,  2.00s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.15it/s]\u001b[A\n",
      "{'loss': 0.0946, 'grad_norm': 0.5234375, 'learning_rate': 0.00012096329036685468, 'epoch': 3.59}\n",
      "{'loss': 0.0672, 'grad_norm': 0.357421875, 'learning_rate': 0.00011967083476448282, 'epoch': 3.62}\n",
      "{'loss': 0.0597, 'grad_norm': 0.3984375, 'learning_rate': 0.00011837495178165706, 'epoch': 3.66}\n",
      "{'loss': 0.1166, 'grad_norm': 0.64453125, 'learning_rate': 0.00011707586720869374, 'epoch': 3.69}\n",
      "{'loss': 0.0636, 'grad_norm': 0.51171875, 'learning_rate': 0.00011577380739374375, 'epoch': 3.72}\n",
      "{'loss': 0.0377, 'grad_norm': 0.3828125, 'learning_rate': 0.00011446899920335405, 'epoch': 3.75}\n",
      "{'loss': 0.059, 'grad_norm': 0.51171875, 'learning_rate': 0.00011316166998293935, 'epoch': 3.78}\n",
      "{'loss': 0.0603, 'grad_norm': 0.3515625, 'learning_rate': 0.00011185204751717029, 'epoch': 3.82}\n",
      "{'loss': 0.1084, 'grad_norm': 0.51171875, 'learning_rate': 0.00011054035999028478, 'epoch': 3.85}\n",
      "{'loss': 0.0984, 'grad_norm': 0.609375, 'learning_rate': 0.00010922683594633021, 'epoch': 3.88}\n",
      "{'loss': 0.0426, 'grad_norm': 0.353515625, 'learning_rate': 0.00010791170424934247, 'epoch': 3.91}\n",
      "{'loss': 0.0553, 'grad_norm': 0.56640625, 'learning_rate': 0.00010659519404346954, 'epoch': 3.94}\n",
      "{'loss': 0.1045, 'grad_norm': 0.546875, 'learning_rate': 0.00010527753471304625, 'epoch': 3.98}\n",
      "{'loss': 0.0356, 'grad_norm': 0.376953125, 'learning_rate': 0.00010395895584262696, 'epoch': 4.01}\n",
      " 51%|████████████████████▊                    | 126/248 [04:37<04:21,  2.14s/it][2024-11-28 12:32:45,158] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "{'loss': 0.0457, 'grad_norm': 0.3046875, 'learning_rate': 0.00010263968717698364, 'epoch': 4.02}\n",
      "{'loss': 0.0403, 'grad_norm': 0.24609375, 'learning_rate': 0.00010131995858107591, 'epoch': 4.06}\n",
      " 52%|█████████████████████▏                   | 128/248 [04:41<04:03,  2.03s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.46it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.95it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.07it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.08it/s]\u001b[A[2024-11-28 12:32:51,283] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17244917154312134, 'eval_runtime': 2.7335, 'eval_samples_per_second': 11.706, 'eval_steps_per_second': 5.853, 'epoch': 4.06}\n",
      " 52%|█████████████████████▏                   | 128/248 [04:43<04:03,  2.03s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.24it/s]\u001b[A\n",
      "{'loss': 0.0538, 'grad_norm': 0.365234375, 'learning_rate': 0.0001, 'epoch': 4.09}A\n",
      "{'loss': 0.0497, 'grad_norm': 0.36328125, 'learning_rate': 9.868004141892411e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0479, 'grad_norm': 0.3671875, 'learning_rate': 9.73603128230164e-05, 'epoch': 4.15}\n",
      "{'loss': 0.1137, 'grad_norm': 0.482421875, 'learning_rate': 9.604104415737308e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0333, 'grad_norm': 0.341796875, 'learning_rate': 9.472246528695376e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0448, 'grad_norm': 0.3203125, 'learning_rate': 9.340480595653047e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0529, 'grad_norm': 0.40234375, 'learning_rate': 9.208829575065754e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0697, 'grad_norm': 0.353515625, 'learning_rate': 9.077316405366981e-05, 'epoch': 4.31}\n",
      "{'loss': 0.0197, 'grad_norm': 0.3203125, 'learning_rate': 8.945964000971524e-05, 'epoch': 4.34}\n",
      "{'loss': 0.0559, 'grad_norm': 0.40234375, 'learning_rate': 8.814795248282974e-05, 'epoch': 4.38}\n",
      "{'loss': 0.0404, 'grad_norm': 0.326171875, 'learning_rate': 8.683833001706067e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0514, 'grad_norm': 0.44921875, 'learning_rate': 8.553100079664598e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0412, 'grad_norm': 0.388671875, 'learning_rate': 8.422619260625625e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0223, 'grad_norm': 0.25390625, 'learning_rate': 8.292413279130624e-05, 'epoch': 4.5}\n",
      "{'loss': 0.0547, 'grad_norm': 0.4375, 'learning_rate': 8.162504821834295e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0407, 'grad_norm': 0.44140625, 'learning_rate': 8.03291652355172e-05, 'epoch': 4.57}\n",
      " 58%|███████████████████████▊                 | 144/248 [05:15<03:28,  2.01s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.46it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.95it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.16it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.05it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.09it/s]\u001b[A[2024-11-28 12:33:26,117] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19070746004581451, 'eval_runtime': 2.6545, 'eval_samples_per_second': 12.055, 'eval_steps_per_second': 6.028, 'epoch': 4.57}\n",
      " 58%|███████████████████████▊                 | 144/248 [05:18<03:28,  2.01s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.25it/s]\u001b[A\n",
      "{'loss': 0.0678, 'grad_norm': 0.60546875, 'learning_rate': 7.903670963314536e-05, 'epoch': 4.6}\n",
      "{'loss': 0.0323, 'grad_norm': 0.369140625, 'learning_rate': 7.774790660436858e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0319, 'grad_norm': 0.345703125, 'learning_rate': 7.646298070591578e-05, 'epoch': 4.66}\n",
      "{'loss': 0.0353, 'grad_norm': 0.396484375, 'learning_rate': 7.518215581897763e-05, 'epoch': 4.7}\n",
      "{'loss': 0.0575, 'grad_norm': 0.314453125, 'learning_rate': 7.390565511019834e-05, 'epoch': 4.73}\n",
      "{'loss': 0.044, 'grad_norm': 0.52734375, 'learning_rate': 7.263370099279172e-05, 'epoch': 4.76}\n",
      "{'loss': 0.0494, 'grad_norm': 0.3828125, 'learning_rate': 7.136651508778875e-05, 'epoch': 4.79}\n",
      "{'loss': 0.0292, 'grad_norm': 0.310546875, 'learning_rate': 7.010431818542297e-05, 'epoch': 4.82}\n",
      "{'loss': 0.0398, 'grad_norm': 0.3515625, 'learning_rate': 6.884733020666086e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0328, 'grad_norm': 0.44921875, 'learning_rate': 6.759577016488343e-05, 'epoch': 4.89}\n",
      "{'loss': 0.0436, 'grad_norm': 0.365234375, 'learning_rate': 6.634985612772611e-05, 'epoch': 4.92}\n",
      "{'loss': 0.0661, 'grad_norm': 0.357421875, 'learning_rate': 6.510980517908334e-05, 'epoch': 4.95}\n",
      "{'loss': 0.0484, 'grad_norm': 0.3515625, 'learning_rate': 6.387583338128471e-05, 'epoch': 4.98}\n",
      " 63%|█████████████████████████▉               | 157/248 [05:45<03:20,  2.20s/it][2024-11-28 12:33:54,376] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "{'loss': 0.0462, 'grad_norm': 0.375, 'learning_rate': 6.264815573744884e-05, 'epoch': 5.01}\n",
      "{'loss': 0.028, 'grad_norm': 0.26171875, 'learning_rate': 6.142698615402205e-05, 'epoch': 5.04}\n",
      "{'loss': 0.0402, 'grad_norm': 0.345703125, 'learning_rate': 6.021253740350793e-05, 'epoch': 5.07}\n",
      " 65%|██████████████████████████▍              | 160/248 [05:51<02:59,  2.04s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.45it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.88it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.16it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.05it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.08it/s]\u001b[A[2024-11-28 12:34:01,524] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1812368482351303, 'eval_runtime': 2.6561, 'eval_samples_per_second': 12.048, 'eval_steps_per_second': 6.024, 'epoch': 5.07}\n",
      " 65%|██████████████████████████▍              | 160/248 [05:54<02:59,  2.04s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.24it/s]\u001b[A\n",
      "{'loss': 0.0535, 'grad_norm': 0.298828125, 'learning_rate': 5.900502108739465e-05, 'epoch': 5.1}\n",
      "{'loss': 0.0384, 'grad_norm': 0.2373046875, 'learning_rate': 5.780464759928623e-05, 'epoch': 5.14}\n",
      "{'loss': 0.0639, 'grad_norm': 0.29296875, 'learning_rate': 5.6611626088244194e-05, 'epoch': 5.17}\n",
      "{'loss': 0.0423, 'grad_norm': 0.341796875, 'learning_rate': 5.542616442234618e-05, 'epoch': 5.2}\n",
      "{'loss': 0.0161, 'grad_norm': 0.185546875, 'learning_rate': 5.4248469152467695e-05, 'epoch': 5.23}\n",
      "{'loss': 0.0175, 'grad_norm': 0.296875, 'learning_rate': 5.307874547629339e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0234, 'grad_norm': 0.21484375, 'learning_rate': 5.191719720256407e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0372, 'grad_norm': 0.279296875, 'learning_rate': 5.0764026715565785e-05, 'epoch': 5.33}\n",
      "{'loss': 0.0433, 'grad_norm': 0.3125, 'learning_rate': 4.961943493986708e-05, 'epoch': 5.36}\n",
      "{'loss': 0.0362, 'grad_norm': 0.376953125, 'learning_rate': 4.848362130531039e-05, 'epoch': 5.39}\n",
      "{'loss': 0.0136, 'grad_norm': 0.1640625, 'learning_rate': 4.735678371226441e-05, 'epoch': 5.42}\n",
      "{'loss': 0.0519, 'grad_norm': 0.33984375, 'learning_rate': 4.6239118497142256e-05, 'epoch': 5.46}\n",
      "{'loss': 0.0377, 'grad_norm': 0.34375, 'learning_rate': 4.513082039819264e-05, 'epoch': 5.49}\n",
      "{'loss': 0.0561, 'grad_norm': 0.37109375, 'learning_rate': 4.403208252156921e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0144, 'grad_norm': 0.201171875, 'learning_rate': 4.2943096307684516e-05, 'epoch': 5.55}\n",
      "{'loss': 0.0302, 'grad_norm': 0.32421875, 'learning_rate': 4.186405149785403e-05, 'epoch': 5.58}\n",
      " 71%|█████████████████████████████            | 176/248 [06:26<02:24,  2.01s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.44it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.05it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.15it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.16it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.86it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.05it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.08it/s]\u001b[A[2024-11-28 12:34:36,326] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19149330258369446, 'eval_runtime': 2.6574, 'eval_samples_per_second': 12.042, 'eval_steps_per_second': 6.021, 'epoch': 5.58}\n",
      " 71%|█████████████████████████████            | 176/248 [06:28<02:24,  2.01s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.24it/s]\u001b[A\n",
      "{'loss': 0.0279, 'grad_norm': 0.44140625, 'learning_rate': 4.079513610123619e-05, 'epoch': 5.62}\n",
      "{'loss': 0.0254, 'grad_norm': 0.361328125, 'learning_rate': 3.973653636207437e-05, 'epoch': 5.65}\n",
      "{'loss': 0.0155, 'grad_norm': 0.2890625, 'learning_rate': 3.86884367272463e-05, 'epoch': 5.68}\n",
      "{'loss': 0.0138, 'grad_norm': 0.21875, 'learning_rate': 3.7651019814126654e-05, 'epoch': 5.71}\n",
      "{'loss': 0.0096, 'grad_norm': 0.22265625, 'learning_rate': 3.662446637876838e-05, 'epoch': 5.74}\n",
      "{'loss': 0.0224, 'grad_norm': 0.265625, 'learning_rate': 3.5608955284408443e-05, 'epoch': 5.78}\n",
      "{'loss': 0.0257, 'grad_norm': 0.3828125, 'learning_rate': 3.460466347030319e-05, 'epoch': 5.81}\n",
      "{'loss': 0.0521, 'grad_norm': 0.326171875, 'learning_rate': 3.361176592089919e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0182, 'grad_norm': 0.2138671875, 'learning_rate': 3.263043563534428e-05, 'epoch': 5.87}\n",
      "{'loss': 0.0125, 'grad_norm': 0.232421875, 'learning_rate': 3.1660843597345135e-05, 'epoch': 5.9}\n",
      "{'loss': 0.0567, 'grad_norm': 0.39453125, 'learning_rate': 3.070315874537532e-05, 'epoch': 5.94}\n",
      "{'loss': 0.0168, 'grad_norm': 0.2138671875, 'learning_rate': 2.975754794324015e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0403, 'grad_norm': 0.31640625, 'learning_rate': 2.8824175951002917e-05, 'epoch': 6.0}\n",
      " 76%|███████████████████████████████▏         | 189/248 [06:55<02:05,  2.12s/it][2024-11-28 12:35:03,177] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "{'loss': 0.0223, 'grad_norm': 0.259765625, 'learning_rate': 2.7903205396277542e-05, 'epoch': 6.03}\n",
      "{'loss': 0.0411, 'grad_norm': 0.314453125, 'learning_rate': 2.6994796745893002e-05, 'epoch': 6.06}\n",
      "{'loss': 0.0121, 'grad_norm': 0.1962890625, 'learning_rate': 2.6099108277934103e-05, 'epoch': 6.1}\n",
      " 77%|███████████████████████████████▋         | 192/248 [07:01<01:54,  2.05s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.47it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.95it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.54it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.16it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:35:11,839] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19757115840911865, 'eval_runtime': 2.7214, 'eval_samples_per_second': 11.759, 'eval_steps_per_second': 5.879, 'epoch': 6.1}\n",
      " 77%|███████████████████████████████▋         | 192/248 [07:04<01:54,  2.05s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.15it/s]\u001b[A\n",
      "{'loss': 0.03, 'grad_norm': 0.263671875, 'learning_rate': 2.5216296054163546e-05, 'epoch': 6.13}\n",
      "{'loss': 0.0334, 'grad_norm': 0.279296875, 'learning_rate': 2.4346513892830423e-05, 'epoch': 6.16}\n",
      "{'loss': 0.0261, 'grad_norm': 0.259765625, 'learning_rate': 2.3489913341869195e-05, 'epoch': 6.19}\n",
      "{'loss': 0.0199, 'grad_norm': 0.1875, 'learning_rate': 2.2646643652494692e-05, 'epoch': 6.22}\n",
      "{'loss': 0.0949, 'grad_norm': 0.435546875, 'learning_rate': 2.181685175319702e-05, 'epoch': 6.26}\n",
      "{'loss': 0.0226, 'grad_norm': 0.224609375, 'learning_rate': 2.100068222414121e-05, 'epoch': 6.29}\n",
      "{'loss': 0.0065, 'grad_norm': 0.2021484375, 'learning_rate': 2.0198277271976052e-05, 'epoch': 6.32}\n",
      "{'loss': 0.0538, 'grad_norm': 0.369140625, 'learning_rate': 1.9409776705056516e-05, 'epoch': 6.35}\n",
      "{'loss': 0.0274, 'grad_norm': 0.248046875, 'learning_rate': 1.8635317909083983e-05, 'epoch': 6.38}\n",
      "{'loss': 0.0132, 'grad_norm': 0.1884765625, 'learning_rate': 1.787503582316864e-05, 'epoch': 6.42}\n",
      "{'loss': 0.0153, 'grad_norm': 0.1943359375, 'learning_rate': 1.712906291631814e-05, 'epoch': 6.45}\n",
      "{'loss': 0.0188, 'grad_norm': 0.2216796875, 'learning_rate': 1.6397529164356606e-05, 'epoch': 6.48}\n",
      "{'loss': 0.0279, 'grad_norm': 0.2578125, 'learning_rate': 1.5680562027278157e-05, 'epoch': 6.51}\n",
      "{'loss': 0.0106, 'grad_norm': 0.353515625, 'learning_rate': 1.4978286427038601e-05, 'epoch': 6.54}\n",
      "{'loss': 0.0383, 'grad_norm': 0.30859375, 'learning_rate': 1.4290824725789542e-05, 'epoch': 6.58}\n",
      "{'loss': 0.0333, 'grad_norm': 0.25, 'learning_rate': 1.3618296704558364e-05, 'epoch': 6.61}\n",
      " 84%|██████████████████████████████████▍      | 208/248 [07:36<01:20,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.45it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.95it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.05it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.15it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:35:46,717] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19907647371292114, 'eval_runtime': 2.6576, 'eval_samples_per_second': 12.041, 'eval_steps_per_second': 6.02, 'epoch': 6.61}\n",
      " 84%|██████████████████████████████████▍      | 208/248 [07:39<01:20,  2.02s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.23it/s]\u001b[A\n",
      "{'loss': 0.0138, 'grad_norm': 0.1787109375, 'learning_rate': 1.2960819542378056e-05, 'epoch': 6.64}\n",
      "{'loss': 0.0359, 'grad_norm': 0.275390625, 'learning_rate': 1.2318507795870138e-05, 'epoch': 6.67}\n",
      "{'loss': 0.015, 'grad_norm': 0.1728515625, 'learning_rate': 1.1691473379284944e-05, 'epoch': 6.7}\n",
      "{'loss': 0.0112, 'grad_norm': 0.23046875, 'learning_rate': 1.1079825545001888e-05, 'epoch': 6.74}\n",
      "{'loss': 0.016, 'grad_norm': 0.2158203125, 'learning_rate': 1.0483670864493778e-05, 'epoch': 6.77}\n",
      "{'loss': 0.0249, 'grad_norm': 0.2236328125, 'learning_rate': 9.903113209758096e-06, 'epoch': 6.8}\n",
      "{'loss': 0.0137, 'grad_norm': 0.234375, 'learning_rate': 9.33825373521875e-06, 'epoch': 6.83}\n",
      "{'loss': 0.0137, 'grad_norm': 0.255859375, 'learning_rate': 8.789190860101225e-06, 'epoch': 6.86}\n",
      "{'loss': 0.0265, 'grad_norm': 0.2294921875, 'learning_rate': 8.25602025128438e-06, 'epoch': 6.9}\n",
      "{'loss': 0.0309, 'grad_norm': 0.25390625, 'learning_rate': 7.738834806631711e-06, 'epoch': 6.93}\n",
      "{'loss': 0.021, 'grad_norm': 0.228515625, 'learning_rate': 7.237724638805221e-06, 'epoch': 6.96}\n",
      "{'loss': 0.0156, 'grad_norm': 0.349609375, 'learning_rate': 6.75277705956443e-06, 'epoch': 6.99}\n",
      " 89%|████████████████████████████████████▎    | 220/248 [08:04<00:58,  2.10s/it][2024-11-28 12:36:11,592] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2795718] [RANK:0] packing_efficiency_estimate: 0.88 total_num_tokens per device: 918922\u001b[39m\n",
      "{'loss': 0.01, 'grad_norm': 0.1669921875, 'learning_rate': 6.284076564553465e-06, 'epoch': 7.03}\n",
      "{'loss': 0.0186, 'grad_norm': 0.3046875, 'learning_rate': 5.831704818578843e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0247, 'grad_norm': 0.3203125, 'learning_rate': 5.3957406413805315e-06, 'epoch': 7.1}\n",
      "{'loss': 0.0492, 'grad_norm': 0.330078125, 'learning_rate': 4.976259993898502e-06, 'epoch': 7.13}\n",
      " 90%|█████████████████████████████████████    | 224/248 [08:12<00:48,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.46it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.80it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.87it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:36:22,202] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19952048361301422, 'eval_runtime': 2.6561, 'eval_samples_per_second': 12.048, 'eval_steps_per_second': 6.024, 'epoch': 7.13}\n",
      " 90%|█████████████████████████████████████    | 224/248 [08:14<00:48,  2.02s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.23it/s]\u001b[A\n",
      "{'loss': 0.0165, 'grad_norm': 0.1865234375, 'learning_rate': 4.573335965037706e-06, 'epoch': 7.16}\n",
      "{'loss': 0.0181, 'grad_norm': 0.2255859375, 'learning_rate': 4.187038758933204e-06, 'epoch': 7.19}\n",
      "{'loss': 0.0173, 'grad_norm': 0.22265625, 'learning_rate': 3.817435682718096e-06, 'epoch': 7.22}\n",
      "{'loss': 0.0145, 'grad_norm': 0.16796875, 'learning_rate': 3.4645911347961357e-06, 'epoch': 7.26}\n",
      "{'loss': 0.0163, 'grad_norm': 0.1826171875, 'learning_rate': 3.1285665936211515e-06, 'epoch': 7.29}\n",
      "{'loss': 0.0165, 'grad_norm': 0.23046875, 'learning_rate': 2.809420606985236e-06, 'epoch': 7.32}\n",
      "{'loss': 0.0088, 'grad_norm': 0.2041015625, 'learning_rate': 2.5072087818176382e-06, 'epoch': 7.35}\n",
      "{'loss': 0.0323, 'grad_norm': 0.26953125, 'learning_rate': 2.2219837744959283e-06, 'epoch': 7.38}\n",
      "{'loss': 0.0197, 'grad_norm': 0.2021484375, 'learning_rate': 1.9537952816713333e-06, 'epoch': 7.42}\n",
      "{'loss': 0.0347, 'grad_norm': 0.28125, 'learning_rate': 1.7026900316098215e-06, 'epoch': 7.45}\n",
      "{'loss': 0.0372, 'grad_norm': 0.275390625, 'learning_rate': 1.4687117760502578e-06, 'epoch': 7.48}\n",
      "{'loss': 0.0277, 'grad_norm': 0.240234375, 'learning_rate': 1.2519012825812804e-06, 'epoch': 7.51}\n",
      "{'loss': 0.0198, 'grad_norm': 0.271484375, 'learning_rate': 1.0522963275380493e-06, 'epoch': 7.54}\n",
      "{'loss': 0.0083, 'grad_norm': 0.1552734375, 'learning_rate': 8.699316894203224e-07, 'epoch': 7.58}\n",
      "{'loss': 0.0163, 'grad_norm': 0.1650390625, 'learning_rate': 7.048391428326584e-07, 'epoch': 7.61}\n",
      "{'loss': 0.0115, 'grad_norm': 0.240234375, 'learning_rate': 5.570474529481562e-07, 'epoch': 7.64}\n",
      " 97%|███████████████████████████████████████▋ | 240/248 [08:46<00:16,  2.01s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 12.42it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.05it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.15it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.16it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  5.86it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-11-28 12:36:56,952] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2795718] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19981276988983154, 'eval_runtime': 2.6583, 'eval_samples_per_second': 12.038, 'eval_steps_per_second': 6.019, 'epoch': 7.64}\n",
      " 97%|███████████████████████████████████████▋ | 240/248 [08:49<00:16,  2.01s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.23it/s]\u001b[A\n",
      "{'loss': 0.0345, 'grad_norm': 0.283203125, 'learning_rate': 4.2658237049655323e-07, 'epoch': 7.67}\n",
      "{'loss': 0.033, 'grad_norm': 0.21875, 'learning_rate': 3.134666272774034e-07, 'epoch': 7.7}\n",
      "{'loss': 0.0088, 'grad_norm': 0.1962890625, 'learning_rate': 2.177199321994672e-07, 'epoch': 7.74}\n",
      "{'loss': 0.0285, 'grad_norm': 0.28125, 'learning_rate': 1.393589678466367e-07, 'epoch': 7.77}\n",
      "{'loss': 0.0375, 'grad_norm': 0.20703125, 'learning_rate': 7.839738757123849e-08, 'epoch': 7.8}\n",
      "{'loss': 0.0225, 'grad_norm': 0.255859375, 'learning_rate': 3.484581311511414e-08, 'epoch': 7.83}\n",
      "{'loss': 0.0227, 'grad_norm': 0.236328125, 'learning_rate': 8.711832758934169e-09, 'epoch': 7.86}\n",
      "{'loss': 0.0089, 'grad_norm': 0.1796875, 'learning_rate': 0.0, 'epoch': 7.9}    \n",
      "{'train_runtime': 546.1814, 'train_samples_per_second': 9.198, 'train_steps_per_second': 0.454, 'train_loss': 0.12260984371213483, 'epoch': 7.9}\n",
      "100%|█████████████████████████████████████████| 248/248 [09:06<00:00,  2.20s/it]\n",
      "[2024-11-28 12:37:13,771] [INFO] [axolotl.train.train:190] [PID:2795718] [RANK:0] Training Completed!!! Saving pre-trained model to ./out-Qwen2-0.5B-Instruct\u001b[39m\n",
      "(PeftModelForCausalLM(   (base_model): LoraModel(     (model): Qwen2ForCausalLM(       (model): Qwen2Model(         (embed_tokens): Embedding(151936, 896)         (layers): ModuleList(           (0-23): 24 x Qwen2DecoderLayer(             (self_attn): Qwen2FlashAttention2(               (q_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=896, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (k_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=128, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=128, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (v_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=128, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=128, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (o_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=896, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (rotary_emb): Qwen2RotaryEmbedding()             )             (mlp): Qwen2MLP(               (gate_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=4864, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4864, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (up_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=4864, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4864, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (down_proj): lora.Linear(                 (base_layer): Linear(in_features=4864, out_features=896, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4864, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (act_fn): SiLU()             )             (input_layernorm): Qwen2RMSNorm()             (post_attention_layernorm): Qwen2RMSNorm()           )         )         (norm): Qwen2RMSNorm()       )       (lm_head): Linear(in_features=896, out_features=151936, bias=False)     )   ) ), Qwen2TokenizerFast(name_or_path='Qwen/Qwen2-0.5B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={ \t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), })\n",
      "\u001b[0mCPU times: user 3.87 s, sys: 559 ms, total: 4.43 s\n",
      "Wall time: 9min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/accelerate launch -m axolotl.cli.train {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "qlora_model = f\"./out-{MODEL_SHORT_NAME}\"\n",
    "base_model = MODEL_NAME\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=False, padding_side='left')\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"auto\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").eval()\n",
    "model = PeftModel.from_pretrained(base_model, qlora_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the LoRA model (PEFT adapter) to HF Hub\n",
    "\n",
    "#hub_model_id = f\"NatLibFi/{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "#model.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the LoRA into the base model for inference\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_BATCHED_LENGTH = 4096\n",
    "\n",
    "def generate(messages_batch):\n",
    "    texts = tokenizer.apply_chat_template(messages_batch, add_generation_prompt=True, tokenize=False)\n",
    "    inputs = tokenizer(texts, padding=\"longest\", return_tensors=\"pt\", return_token_type_ids=False)\n",
    "    inputs = {key: val.cuda() for key, val in inputs.items()}\n",
    "    if len(messages_batch) > 1 and inputs['input_ids'].shape[1] > MAX_BATCHED_LENGTH:\n",
    "        # there are long documents in the batch - break it down to two smaller batches to avoid excessive padding and related problems\n",
    "        half = int(len(messages_batch) / 2)\n",
    "        return generate(messages_batch[:half]) + generate(messages_batch[half:])\n",
    "    temp_texts=tokenizer.batch_decode(inputs[\"input_ids\"], skip_special_tokens=True)\n",
    "\n",
    "    gen_tokens = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "\n",
    "    gen_text = tokenizer.batch_decode(gen_tokens, skip_special_tokens=True)\n",
    "    return [i[len(temp_texts[idx]):] for idx, i in enumerate(gen_text)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A light enterprise information security architecture model for creating and improving security architecture\", \"alt_title\": [\"Kevyt yritystietoturva-arkkitehtuurimalli tietoturva-arkkitehtuurin luomiseksi ja kehitt\\u00e4miseksi {fi}\"], \"creator\": [\"Kossila, Johannes\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"A light enterprise information security architecture model for creating and improving security architecture\", \"alt_title\": [\"Keskused entissuksen laitoslaskenta yhteisvildestuneesta : luet素ysty\\u00f6ykuntioihin ja yhteisviimeis\\u00f6ihin olevat rinkotutkimuksissa {fi}\"], \"creator\": [\"Kossila, Johannes\"], \"year\": \"2020\", \"publisher\": [\"Turun kauppakorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"An analysis of Facebook posts\", \"creator\": [\"To, My\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"An analysis of Facebook posts\", \"creator\": [\"Ngoc My Arcada\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Analysis of user exploration patterns during scene cuts in omnidirectional videos\", \"creator\": [\"Monakhov, Dmitrii\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Analysis of user exploration patterns during scene cuts in omnidirectional videos\", \"creator\": [\"Monakhov, Dmitrii\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Benefits of kinetics and proxemics for a conceptual virtual reality Obeya : exploratory research on virtual reality as a medium for interpersonal interaction\", \"alt_title\": [\"Kinetiikan ja proksemiikan luomat edut konsptuaaliselle virtuaalitodellisuus Obeyalle {fi}\"], \"creator\": [\"Mattila, Jaakko\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Benefits of kinematics and proxemics for a conceptual virtual reality oeyiba\", \"creator\": [\"Mattila, Jaakko\"], \"year\": \"2019\", \"publisher\": [\"Technion - Israel Institute of Technology\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Black African entrepreneurs in Finland: structural barriers\", \"creator\": [\"Vorobeva, Ekaterina\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Black African entrepreneurs in Finland : structural barriers\", \"creator\": [\"Vorobeva, Ekaterina\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Creating and implementing a business process model\", \"creator\": [\"Skog, Patrik\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Creating and implementing a business process model\", \"alt_title\": [\"Ny kunnan m\\u00e4lsa johtajan talteenotto P\\u00e4rvieh\\u00e4ratkoimuksen j\\u00e4rjestelym\\u00e4t {fi}\"], \"creator\": [\"Skog, Patrik\"], \"year\": \"2020\", \"publisher\": [\"University of Vaasa\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Developing a football game for Android\", \"alt_title\": [\"Jalkapallopelin kehitt\\u00e4minen Androidille {fi}\"], \"creator\": [\"Huhtam\\u00e4ki, Markus\"], \"year\": \"2021\", \"publisher\": [\"Tampere University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Developing a football game for Android\", \"creator\": [\"Huttam\\u00e4ki, Markus\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Gender differences in the Finnish labour market : decomposing the gender wage gap in Finland\", \"alt_title\": [\"K\\u00f6nsskillnader p\\u00e5 den finska arbetsmarknaden : en dekomponering av l\\u00f6negapet mellan k\\u00f6nen i Finland {sv}\"], \"creator\": [\"Kortelainen, Julia\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Gender differences in the Finnish labour market : decomposing the gender wage gap in Finland\", \"creator\": [\"Kortelainen, Julia\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"On the history and future of clarinet systems\", \"creator\": [\"Agababa Shaked, Gil\"], \"year\": \"2018\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"On the history and future of clarinet systems\", \"creator\": [\"Agababa-Shaked, Gil\"], \"year\": \"2018\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Resource piroductivity as the EU\\u00b4s lead resource efficiency indicator : a quantitative macro-comparative study on indicator drivers\", \"alt_title\": [\"Resursproduktivitet som EU:s huvudindikator f\\u00f6r resurseffektivitet : en QMCR-studie p\\u00e5 faktorer som driver resursproduktivitet {sv}\"], \"creator\": [\"J\\u00e4rnefelt, Elisabeth\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Resource productivity as the EU\\u00b4s lead : resource efficiency indicator a quantitative macro-comparative study on indicator drivers\", \"creator\": [\"J\\u00e4rnefelt, Elisabeth\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Slippage between : a common void\", \"creator\": [\"Oliva, Maya\"], \"year\": \"2022\", \"publisher\": [\"Theatre Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Slipping between a common void : a subjective experience of presence in a public performance\", \"alt_title\": [\"I wish I were on planet Earth : a subjective experience of presence in a public performance {en}\"], \"creator\": [\"Oliva, Maya\"], \"year\": \"2022\", \"publisher\": [\"Theatre Academy, University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The cultural history of politics in Swedish contemporary art.\", \"creator\": [\"Kozma, Madeleine\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"The cultural history of politics in Swedish contemporary art.\", \"creator\": [\"Kozma, Madeleine\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The English-Finnish-Nepali-Arabic dictionary for nursing students\", \"creator\": [\"Olundegun, Ololade\", \"Pokharel, Jyoti\", \"Al-Rammahi, Mohammed\"], \"year\": \"2021\", \"publisher\": [\"Laurea University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Laurea university of applied sciences degree program in nursing : bachelor thesis\", \"creator\": [\"Pokharel, Jyoti\", \"AL-Rammahi, Mohammed\", \"Olundegun, Ololade\"], \"year\": \"2021\", \"publisher\": [\"Laurea University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Utopian reconfiguration of the nature/culture dualism in Ursula Le Guin\\u2019s Always Coming Home\", \"creator\": [\"Veistola, Atte\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Utopian reconfiguration of the nature/culture dualism in Ursula Le Guin's Always Coming Home\", \"creator\": [\"Veistola, Atte\"], \"year\": \"2020\", \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"\\u2018The wrath of God on children of disobedience\\u2019\", \"alt_title\": [\"COVID-19 in the theology and ideology of the Westboro Baptist Church {en}\"], \"creator\": [\"\\u00d6stling, Erik\"], \"year\": \"2021\", \"doi\": \"10.30664/ar.107883\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"\\u00d6stling \\u2018The wrath of God on children of disobedience : COVID-19 in the theology and ideology of the Westboro Baptist Church\", \"creator\": [\"Wu, Erik Ahn\\u2019stling\"], \"year\": \"2021\", \"doi\": \"10.30664/ar.107883\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"\\\"Great horizons flooded with the alien light of the Sun\\\" : Le Sacre du Printemps in the Russian context\", \"creator\": [\"J\\u00e4rvinen, Hanna\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Great Horizons flooded with the alien light of the sun : le sacre du printemps in the russian context\", \"creator\": [\"Stansky, Peter\"], \"year\": \"1999\", \"publisher\": [\"Yale University Press\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A dynamic collusion analysis framework considering generation and transmission systems maintenance constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/EEM49802.2020.9221905\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"A dynamic collusion analysis framework considering generation and transmission systems maintenance constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/IEE电。org.78.123926\", \"p-issn\": \"1941-704y\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A review of optical nondestructive visual and near-infrared methods for food quality and safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\", \"Mantere, Timo\"], \"year\": \"2013\", \"publisher\": [\"Hindawi\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Review of optical nondestructive visual and near-infrared methods for food quality and safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\"], \"year\": \"2013\", \"publisher\": [\"Hindawi\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"review article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Assessing trustworthy AI in times of COVID-19 : deep learning for predicting a multi-regional score conveying the degree of lung compromise in COVID-19 patients\", \"creator\": [\"Allahabadi, Himanshi\", \"Amann, Julia\", \"Balot, Isabelle\", \"Beretta, Andrea\", \"Binkley, Charles\", \"Bozenhard, Jonas\", \"Bruneault, Fr\\u00e9d\\u00e9rick\", \"Brusseau, James\", \"Candemir, Sema\", \"Cappellini, Luca Alessandro\", \"Castagnet, Genevieve Fieux\", \"Chakraborty, Subrata\", \"Cherciu, Nicoleta\", \"Cociancig, Christina\", \"Coffee, Megan\", \"Ek, Irene\", \"Espinosa-Leal, Leonardo\", \"Farina, Davide\", \"Fieux-Castagnet, Genevieve\", \"Frauenfelder, Thomas\", \"Gallucci, Alessio\", \"Giuliani, Guya\", \"Golda, Adam\", \"van Halem, Irmhild\", \"Hildt, Elisabeth\", \"Holm, Sune\", \"Kararigas, Georgios\", \"Krier, Sebastien A.\", \"K\\u00fchne, Ulrich\", \"Lizzi, Francesca\", \"Madai, Vince I.\", \"Markus, Aniek F.\", \"Masis, Serg\", \"Mathez, Emilie Wiinblad\", \"Mureddu, Francesco\", \"Neri, Emanuele\", \"Osika, Walter\", \"Ozols, Matiss\", \"Panigutti, Cecilia\", \"Parent, Brendan\", \"Pratesi, Francesca\", \"Moreno-S\\u00e1nchez, Pedro A.\", \"Sartor, Giovanni\", \"Savardi, Mattia\", \"Signoroni, Alberto\", \"Sormunen, Hanna\", \"Spezzatti, Andy\", \"Srivastava, Adarsh\", \"Stephansen, Annette F.\", \"Theng, Lau Bee\", \"Tithi, Jesmin Jahan\", \"Tuominen, Jarno\", \"Umbrello, Steven\", \"Vaccher, Filippo\", \"Vetter, Dennis\", \"Westerlund, Magnus\", \"Wurth, Renee\", \"Zicari, Roberto V.\"], \"year\": \"2022\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/TTS.2022.3195114\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Assessing trustworthy AI in times of COVID-19\", \"creator\": [\"Westerlund, Magnus\", \"Wurth, Renee\", \"Zicari, Roberto V.\"], \"year\": \"2022\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/TTS.2022.3195114\", \"p-issn\": \"1877-3598\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring : a qualitative study\", \"creator\": [\"Korhonen, H.\", \"Tuomikoski, A-M.\", \"Oikarainen, A.\", \"K\\u00e4\\u00e4ri\\u00e4inen, M.\", \"Elo, S.\", \"Kyng\\u00e4s, H.\", \"Liikanen, E.\", \"Mikkonen, K.\"], \"year\": \"2019\", \"doi\": \"10.1016/j.nepr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring : a qualitative study\", \"alt_title\": [\"Caldbi h\\u00e4r\\u00e4lisma i\\u00e4hk\\u00f6nlishman\\u00f6sika kokonaisliitosilla ja m\\u00e4yt\\u00e4t\\u00e4illisesta kerran {fi}\"], \"creator\": [\"Korhonen, Hannele\", \"Tuomikoski, Anu-Matti\", \"Oikarainen, Arianna\", \"K\\u00e4\\u00e4ri\\u00e4inen, Matti\", \"Elo, Suoma\", \"Kyng\\u00e4s, Harriett\", \"Liikanen, Ella\" \"Mikkonen, Kaisa\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"doi\": \"10.1016/j.npr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Engaging audio based mobile applications\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"e-isbn\": [\"9788409147557\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Engaging audio based mobile applications : supporting extracurricular activities for cultural institutions\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"publisher\": [\"Metropolia University of Applied Sciences\"], \"e-isbn\": [\"9788409147557\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Epistemically tuned-in?\", \"creator\": [\"St\\u00e5hl, Tore\"], \"year\": \"2020\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Epistemologically tuned-in : eparadigmally responsive learning communities at the conference of the International Association for Computational Linguistics (IACL 2019)\", \"creator\": [\"St\\u00e5hl, Tore\"], \"year\": \"2020\", \"publisher\": [\"International Association for Computational Linguistics\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"In the shadows : phenomenological choreographic writing\", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"doi\": \"10.1386/chor_00042_1\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"In the shadows : phenonologische choreografische Writtung \", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"doi\": \"10.1386/chor00042_1\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"MARISA ethical, legal and societal aspects\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"European Commission\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"MARISA ethical, legal and societal aspects\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"Marine Technical Research Laboratory (UK government)\", \"European Commission\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Memories from the EAHIL Workshop\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Katri\", \"Mann, Mala\", \"Ferrinho, Ana Maria\", \"Ottjes, Robin\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Memories from the EAHIL Workshop : learn, share, act, bridge borders\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Katri\", \"Mann, Maja\", \"Ferrinho, Ana Maria\", \"Ottjes, Robin\"], \"year\": \"2019\", \"publisher\": [\"Eighth European Academy for Health Information Leadership (EAHIL)\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Supporting transformative agency among urban actors in the Change Laboratory intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"e-issn\": \"2328-4919\", \"p-issn\": \"2328-4900\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Supporting transformative agency among urban actors in the change laboratory intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The roles of temperature, nest predators and information parasites for geographical variation in egg covering behaviour of tits (Paridae)\", \"creator\": [\"Loukola, Olli J.\", \"Adamik, Peter\", \"Adriaensen, Frank\", \"Barba, Emilio\", \"Doligez, Blandine\", \"Flensted-Jensen, Einar\", \"Eeva, Tapio\", \"Kivel\\u00e4, Sami M.\", \"Laaksonen, Toni\", \"Morosinotto, Chiara\", \"M\\u00e4nd, Raivo\", \"Niemel\\u00e4, Petri T.\", \"Reme\\u0161, Vladimir\", \"Samplonius, Jelmer M.\", \"Sebastiano, Manrico\", \"Senar, Juan Carlos\", \"Slagsvold, Tore\", \"Sorace, Alberto\", \"Tschirren, Barbara\", \"T\\u00f6r\\u00f6k, J\\u00e1nos\", \"Forsman, Jukka T.\"], \"year\": \"2020\", \"publisher\": [\"John Wiley & Sons\"], \"doi\": \"10.1111/jbi.13830\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"The roles of temperature, nest predators and information parasites for geographical variation in egg covering behaviour of tits (Paridae)\", \"creator\": [\"Loukola, Olli\"], \"year\": \"2020\", \"doi\": \"10.1111/jbi.13830\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Why is CryptoKitties (not) gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Why is cryptokitties (not) gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"Association for Computer Graphics and Web Design\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"se\", \"title\": \"T\\u0113 lijen s\\u014dmes p\\u0101len ai aktan saijesne s\\u0101mi\\u2019 : giella\\u010d\\u00e1j\\u00e1nasat boarr\\u00e1samos \\u010d\\u00e1llon s\\u00e1mi muitalusain\", \"creator\": [\"Ylikoski, Jussi\"], \"year\": \"2017\", \"publisher\": [\"S\\u00e1mis\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"se\", \"title\": \"S\\u00e1mis 25/2017\", \"year\": \"2017\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Bothnian Bay hydrogen valley :  research report\", \"year\": \"2021\", \"publisher\": [\"LUT University\"], \"e-isbn\": [\"9789523357631\"], \"p-issn\": \"2243-3376\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Bothnian bay hydrogen valley : research report\", \"creator\": [\"Karjunen, Hannu\", \"Lassila, Jukka\", \"Tynj\\u00e4l\\u00e4, Tero\", \"Laaksonen, Petteri\", \"Tuomaala, Mari\", \"Vilppo, Julius\", \"Taulasto, Kimmo\", \"Karppanen, Janne\", \"Laari, Arto\", \"Kosonen, Antti\", \"Ahuola, Jero\"], \"publisher\": [\"LUT\"], \"e-isbn\": [\"9789523357631\"], \"e-issn\": \"2243-3376\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Channels of dialogue between international businesses and national governments : the implications for domestic reforms and international relations in the case of Russia\", \"creator\": [\"Yakovlev, Andrei\", \"Freinkman, Lev\", \"Ershova, Nina\"], \"year\": \"2018\", \"publisher\": [\"Bank of Finland\"], \"e-issn\": \"2342-205X\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Channels of dialogue between international businesses and national governments : the implications for domestic reforms and international relations in the case of Russia\", \"creator\": [\"Yakovlev, Andrei\", \"Freinkman, Lev\", \"Ershova, Nina\"], \"year\": \"2018\", \"publisher\": [\"Bank of Finland\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Finland in Figures 2015\", \"publisher\": [\"Statistics Finland\"], \"e-isbn\": [\"9789522445896\"], \"p-isbn\": [\"9789522445223\"], \"e-issn\": \"2242-8496\", \"p-issn\": \"0357-0371\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Finland in figures 2015\", \"year\": \"2016\", \"publisher\": [\"Statistics Finland\"], \"e-isbn\": [\"9789522445896\"], \"p-isbn\": [\"9789522445793\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Housing market and current account imbalances in the international economy\", \"creator\": [\"Punzi, Maria Teresa\"], \"year\": \"2012\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789524627849\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Housing market and current account imbalances in the international economy\", \"creator\": [\"Punzi, Maria Teresa\"], \"year\": \"2012\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789524627849\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"How to explain errors in budget balance forecasts in euro area countries? : empirical evidence based on real-time data\", \"alt_title\": [\"Miten euromaiden budjettivajeita koskevia ennustevirheit\\u00e4 voidaan selitt\\u00e4\\u00e4 reaaliaikaisen aineiston avulla? {fi}\"], \"creator\": [\"Paloviita, Maritta\", \"Ikonen, Pasi\"], \"year\": \"2016\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789523231146\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"How to explain errors in budget balance forecasts in euro area countries? : empirical evidence based on real-time data\", \"creator\": [\"Paloviita, Maritta\", \"Ikonen, Pasi\"], \"year\": \"2016\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789523231146\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A discourse analytic approach to HEI leadership in Finland : the what and how of rectors\\u2019 leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521241864\", \"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"A discourse analytic approach to HEI leadership in Finland : the what and how of rectors\\u2019 leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521241864\"], \"p-isbn\": [\"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"A Jungian theory of mind : individuality, lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"A jungian theory of mind : individuality lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Aminophenolato complexes of Mo, W and V in catalytic alkene epoxidation and catechol oxidation\", \"alt_title\": [\"Mo, W ja V aminofenolaattokompleksit katalyyttisess\\u00e4 alkeenien epoksidaatiossa ja katekolien hapetuksessa {fi}\"], \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Aminophenolato complexes of Mo, W, and V : in catalytic alkene epoxidation and catechol oxidation\", \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"alt_title\": [\"Sinitiaisten pes\\u00e4nrakennusk\\u00e4ytt\\u00e4ytymisen vaihtelun syyt ja seuraukset {fi}\"], \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : a population-based study\", \"alt_title\": [\"Muutokset mielenterveyden ongelmissa, kiusaamisessa, yksin\\u00e4isyydess\\u00e4 ja palveluiden k\\u00e4yt\\u00f6ss\\u00e4 suomenkielisten 8-9- vuotiaiden lasten joukossa 24 vuoden aikana : v\\u00e4est\\u00f6pohjainen tutkimus {fi}\"], \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : a population-based study\", \"alt_title\": [\"Pohjois-Antaiset taloudellisia vaikutteita, joilla ei hyvin ole n\\u00e4ista asiakassia:\", \"N\\u00e4ista ihmisest\\u00e4 yrityksess\\u00f7i m\\u00e4lemaan ajoneuvot {fi}\"], \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"University of Helsinki\"], \"e-isbn\": [\"9789515176912\"], \"p-isbn\": [\"9789515176905\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"Finnish Institute for Health and Welfare\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Employee trust repair in the context of organizational change : identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Employee trust repair in the context of organizational change : identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Essays on economic productivity\", \"alt_title\": [\"Esseit\\u00e4 taloudellisesta tuottavuudesta {fi}\"], \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Essays on economic productivity\", \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Light field compression using disparity-based 4D predictive coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Light field compression using disparity-based 4d predictive coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Light manipulation in multilayer metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Light manipulation in multilayer metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Performance exploration and testing of web-based software systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239991\"], \"p-isbn\": [\"9789521240003\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Performance exploration and testing of web-based software systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"Abo Akademi University\"], \"e-isbn\": [\"9789521240003\"], \"p-isbn\": [\"9789521239991\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Power of myths in energy transition : unveiling timeless mythologies in Finnish energy agora\", \"alt_title\": [\"Myytit energiamurroksessa : ajattomien mytologioiden voima suomalaisessa energia-agorassa {fi}\"], \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"University of Vaasa\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Power of myths in energy transition : uncovering timeless mythologies in Finnish energy agora\", \"alt_title\": [\"Power of myths in energy transition : unveiling timeless mythologies in Finnish energy agora {en}\"], \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Problem gambling in a Nordic context : moving from social factors to a psychosocial perspective\", \"alt_title\": [\"Spelproblem i en nordisk kontext : fr\\u00e5n sociala faktorer till ett psykosocialt perspektiv {sv}\"], \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521238700\"], \"p-isbn\": [\"9789521238694\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Problem gambling in a Nordic context : moving from social factors to a psychosocial perspective\", \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239700\"], \"p-isbn\": [\"9789521238700\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Rescheduling sudden absences of nursing staff in hospital settings\", \"alt_title\": [\"Hoitohenkil\\u00f6kunnan \\u00e4killisten poissaolojen hallinta sairaaloissa {fi}\"], \"creator\": [\"Tuominen, Outi\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512979615\"], \"p-isbn\": [\"9789512979608\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Rescheduling sudden absences of nursing staff in hospital settings\", \"alt_title\": [\"Hoitohenkil\\u00f6kunnan \\u00e4killisten poissaolojen hallinta sairaaloissa {fi}\"], \"creator\": [\"Tuominen, Outi\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512979615\"], \"p-isbn\": [\"9789512979608\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Role of urinary findings and adipokines in Puumala virus-induced acute kidney injury\", \"creator\": [\"Mantula, Paula\"], \"year\": \"2021\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520318802\"], \"p-isbn\": [\"978\\u00ad952\\u00ad03\\u00ad1879\\u00ad6\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Role of urinary findings and adipokines in puumala virus-induced acute kidney injury\", \"creator\": [\"Mantula, Paula\"], \"year\": \"2021\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789523582228\"], \"p-isbn\": [\"9789523582215\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Surgical, oncological and reconstructive outcomes after complex oncological pelvic resections : the development of an algorithm based on a multidisciplinary approach\", \"creator\": [\"Kiiski, Juha\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520316549\"], \"p-isbn\": [\"9789520316532\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Surgical, oncological and reconstructive outcomes after complex pelvic resections : the development of an algorithm based on a multidisciplinary approach\", \"creator\": [\"Kiiski, Juha\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520316549\"], \"p-isbn\": [\"9789520316532\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Constellations\", \"creator\": [\"Feehily, Fergus\", \"Suutari, Inkeri\", \"Demozay, Annie May\", \"Winters, Terry\", \"Long, Declan\", \"Paavilainen, Kukka\", \"Hutchinson, John\"], \"year\": \"2018\", \"publisher\": [\"Academy of Fine Arts of the University of the Arts Helsinki\"], \"e-isbn\": [\"9789527131510\"], \"p-isbn\": [\"9789527131503\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"The impact of the internet on education : survey research report\", \"creator\": [\"Mancuso, John\"], \"year\": \"2018\", \"publisher\": [\"Academy of被授予荣誉科学和工程学奖章的机构\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Creating opportunity spaces for co-production : professional co-producers in inter-organizational collaborations\", \"creator\": [\"Brix, Jacob\", \"Tuurnas, Sanna\", \"Mortensen, Nanna M\\u00f8ller\"], \"year\": \"2021\", \"publisher\": [\"IGI Global\"], \"doi\": \"10.4018/978-1-7998-4975-9.ch009\", \"p-isbn\": [\"9781799849759\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Creating opportunity spaces for co-production : professional co-producers in inter-organizational collaborations\", \"creator\": [\"Brix, Jacob\", \"Tuurnas, Sanna\", \"Mortensen, Nanna M\\u00f8ller\"], \"year\": \"2021\", \"publisher\": [\"University of Vaasa\"], \"e-isbn\": [\"9789523569821\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Full-body interaction in a remote context : adapting a dance piece to a browser-based installation\", \"creator\": [\"Masu, Raul\", \"Pajala-Assefa, Hanna\", \"Correia, Nuno N.\", \"Rom\\u00e3o, Teresa\"], \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3483529.3483747\", \"p-isbn\": [\"9781450384209\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Full-body interaction in a remote context : adapting a dance piece to a browser-based installation\", \"creator\": [\"Masu, Raul\", \"Pajala-Assefa, Hanna\", \"Ncorreia, Nuno, and Rom\\u00e3o, Teresa\"], \"year\": \"2021\", \"publisher\": [\"New York\"], \"doi\": \"10.1145/3483529.3483747\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Gender inequalities in family leaves, employment and pensions in Finland\", \"creator\": [\"Kuitto, Kati\", \"Kuivalainen, Susan\"], \"year\": \"2021\", \"publisher\": [\"Edward Elgar\"], \"p-isbn\": [\"9781839106101\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Gender inequalities in family leaves, employment and pensions in Finland\", \"creator\": [\"Kuitto, Kati\", \"Kuivalainen, Susan\"], \"year\": \"2021\", \"publisher\": [\"Edward Elgar Publishing\"], \"e-isbn\": [\"9781839106101\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Germany as a cultural paragon : transferring modern musical life from Central Europe to Finland\", \"creator\": [\"Kurkela, Vesa\", \"Rantanen, Saijaleena\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Germany as a cultural paragon : transferring modern musical life from central Europe to Finland\", \"creator\": [\"Kurkela, Vesa\", \"Rantanen, Saijaleena\"], \"year\": \"2019\", \"publisher\": [\"Otava\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Introduction\", \"creator\": [\"Anttila, Eeva\", \"Suominen, Anniina\"], \"year\": \"2018\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9781351111195\", \"e-isbn\": [\"9781351111195\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Critical articulations of hope from the margins of arts education\", \"creator\": [\"Anttila, Eeva\", \"Suominen, Anniina\"], \"year\": \"2018\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9781351111195\", \"p-isbn\": [\"9781351111195\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Musical engagement in one-to-one contexts\", \"creator\": [\"Gaunt, Helena\", \"L\\u00f3pez-\\u00cd\\u00f1iguez, Guadalupe\", \"Creech, Andrea\"], \"year\": \"2021\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9780429295362-29\", \"e-isbn\": [\"9780429295362\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Musical engagement in one-to-one contexts\", \"creator\": [\"Gaunt, Helena\", \"L\\u00f3pez-\\u00cd\\u00f1iguez, Guadalupe\", \"Creech, Andrea\"], \"year\": \"2021\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9780429295362-29\", \"p-isbn\": [\"9780429295362\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"The Dalcroze approach : experiencing and knowing music through embodied exploration\", \"creator\": [\"Juntunen, Marja-Leena\"], \"year\": \"2016\", \"publisher\": [\"Oxford University Press\"], \"doi\": \"10.1093/acprof:oso/9780199328093.001.0001\", \"p-isbn\": [\"9780199328093\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"The dalcroze approach : experiencing and knowing music through embodied exploration\", \"creator\": [\"Juntunen, Marja-Leena\"], \"year\": \"2016\", \"publisher\": [\"Oxford University Press\"], \"doi\": \"10.1093/ acprof:oso/9780199328093.001.0001\", \"p-isbn\": [\"9780199328093\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Traces of performance : opera, music theatre, and theatre music in the long 19th century\", \"year\": \"2013\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Traces' of performance:' opera, music', theatre and$ theatre$music$in the Long$ 19th$ century!\", \"year\": \"2013\", \"publisher\": [\"Sibelius Academy\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"en\", \"title\": \"Vitality in later years : food recommendation for older adults\", \"year\": \"2020\", \"publisher\": [\"Finnish Institute for Health and Welfare\"], \"e-isbn\": [\"9789523435179\"], \"p-issn\": \"2323-4172\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"en\", \"title\": \"Vitality in later years : food recommendation for older adults\", \"creator\": [\"Nucleartioprosessointipohjaiselle n\\u00f6rdiscardmisen laitosmahdollisuuksien tulevaisuuden ty\\u00f6yty\\u00f6ihin NLP\"], \"publisher\": [\"Finnish Institute for Health and Welfare (THL)\"], \"e-isbn\": [\"9789523435179\"], \"p-issn\": \"2323-4172\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"BOFIT Ven\\u00e4j\\u00e4-ennuste 2019-2021\", \"year\": \"2019\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"BOFIT Ven\\u00e4j\\u00e4-ennuste 2019-2021\", \"year\": \"2019\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Eduskunnan pankkivaltuuston kertomus 2013\", \"year\": \"2014\", \"publisher\": [\"Edita Prima Oy\"], \"p-issn\": \"1237-4334\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Eduskunnan pankkivaltuuston kertomus 2013 : ehd u d suurto positiivise ortetta\", \"year\": \"2014\", \"publisher\": [\"Finantiopisto\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Fyysisen toimintakyvyn mittaaminen ja arviointi v\\u00e4est\\u00f6tutkimuksissa\", \"creator\": [\"Sainio, P\\u00e4ivi\", \"Valkeinen, Heli\", \"Stenholm, Sari\", \"Vaara, Mariitta\", \"Rinne, Marjo\"], \"year\": \"2020\", \"publisher\": [\"TOIMIA\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Fyysisen toimintakyvyn mittaaminen ja arviointi v\\u00e4est\\u00f6tutkimuksissa\", \"creator\": [\"Sainio, Sanna\", \"Valkeinen, Heli\", \"Stenholm, Sari\", \"Vaara, Mariitta\", \"Rinne, Marjo\"], \"year\": \"2020\", \"publisher\": [\"Toимя\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hepolammen (Enon pit\\u00e4j\\u00e4/Joensuu) kalastorakenne loppukes\\u00e4ll\\u00e4 2022 ja kalastonhoidon suositukset\", \"creator\": [\"Tossavainen, Tarmo\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753809\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hepolammen (Enon pit\\u00e4j\\u00e4/Joensuu) kalastorakenne loppukes\\u00e4ll\\u00e4 2022 ja kalastonhoidon suositukset\", \"creator\": [\"Tossavainen, Tarmo\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753809\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hoidon tarpeen arviointi : nykytilan selvitys\", \"creator\": [\"Saukkonen, Sanna-Mari\", \"\\u00c5lander, Anne\"], \"year\": \"2021\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hoidontarpeen arviointi : nykytilan selvitys\", \"creator\": [\"Saukkonen, Sanna-Mari\", \"Alander, Anne\"], \"year\": \"2021\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Huomioi toimintarajoitteiset lapset ja nuoret hyvinvointikertomuksessa\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Huomioi toimintarajoitteiset lapset ja nuoret hyvinvointikertomuksessa\", \"publisher\": [\"Vammaisfoorumi\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Johtokunnan kertomus pankkivaltuustolle Finanssivalvonnan toiminnasta 2022\", \"year\": \"2023\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Johtokunnan kertomus pankkivaltuustolle Finanssivalvonnan toiminnasta 2022\", \"year\": \"2022\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Koronaepidemian vaikutukset hyvinvointiin, palveluihin ja talouteen : THL:n seurantaraportti, viikot 49-50/2020, 16.12.2020\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Koronaepidemian vaikutukset hyvinvointiin, palveluihin ja talouteen : thl.seura tapahtumiseen \", \"creator\": [\"Honkatukia, Juha\", \"H\\u00e4rm\\u00e4, Vuokko\", \"Jormanainen, Vesa\", \"Rissanen, Pekka\", \"Kestil\\u00e4, Laura\"], \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Koulufysioterapialla hyvinvointia Pohjois-Karjalaan : Otsakorpi-hankkeen loppuraportti\", \"creator\": [\"Issakainen, Maiju\", \"Mustonen, Hilppa\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753410\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Koulufysioterapialla hyvin-vointia Pohjois-Karjalaan : otsakorpi-hankkeen loppuraportti\", \"creator\": [\"Issakainen, Maiju\", \"Mustonen, Hilppa\"], \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753410\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Lohkoketjuteknologian massa-adoption mahdollisuutta tutkimassa\", \"creator\": [\"Honkanen, Petri\"], \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"e-isbn\": [\"9789527365090\"], \"e-issn\": \"2342-3064\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Lohkoketjuteknologian massa-adoption mahdollisuutta tutkimassa : petri Honkanen\", \"creator\": [\"Honkanen, Petri\"], \"year\": \"2020\", \"publisher\": [\"Arcada\"], \"e-isbn\": [\"9789527365090\"], \"p-isbn\": [\"9789527365087\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Loppuraportti : koliikkivauvojen hoito vy\\u00f6hyketerapialla -pilottitutkimus 2017-2019\", \"creator\": [\"Hannula, Leena\", \"M\\u00e4kij\\u00e4rvi, Markku\"], \"publisher\": [\"Luonnonl\\u00e4\\u00e4ketieteen Keskusliitto LKL ry\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Loppuraportti Koliikkivauvojen hoito vy\\u00f6hyketerapialla : pilottitutkimus 2017-2019\", \"creator\": [\"Hannula, Leena\", \"M\\u00e4kij\\u00e4rvi, Markku\"], \"year\": \"2020\", \"publisher\": [\"Luonnonl\\u00e4\\u00e4ketieteen keskusliitto LKL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"L\\u00e4\\u00e4kehoidon tiedonhallinnan konsepti\", \"creator\": [\"Virkkunen, Heikki\", \"Relander, Toni\", \"Malmivaara, Antti\", \"Hiltunen, Piritta\", \"Jalonen, Marko\", \"N\\u00e4rv\\u00e4nen, Jarkko\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"L\\u00e4\\u00e4kehoidon tiedonhallinnan konsepti : versio 1.0\", \"year\": \"2020\", \"publisher\": [\"Institutet f\\u00f6r h\\u00e4lsa och v\\u00e4lf\\u00e4rd\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Mist\\u00e4 kohtuusperiaatteessa ja yhti\\u00f6iden lis\\u00e4etujen jakamisessa on kysymys?\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Mist\\u00e4 kohtuusperiaatteessa ja yhti\\u00f6iden lis\\u00e4etujen jakamisessa : on kysymys?\", \"creator\": [\"Raitila, Matti\"], \"year\": \"2014\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Poliisikoulutuksen vaikuttavuusarviointi 2021 : vuosina 2018-2019 valmistuneiden poliisien ty\\u00f6llisyys ja arviot koulutuksen ty\\u00f6el\\u00e4m\\u00e4vastaavuudesta\", \"alt_title\": [\"Utv\\u00e4rdering av polisutbildningsens effektivitetet 2021 : syssels\\u00e4ttningen bland poliser som utexaminerats \\u00e5ren 2018\\u20132019 och bed\\u00f6mningar av utbildningens arbetslivsmotsvarighet {sv}\", \"Evaluation of the effectiveness of police education 2021 : employment and occupational validity of the education as assessed by police officers who graduated during 2018\\u20132019 {en}\"], \"creator\": [\"Vuorensyrj\\u00e4, Matti\"], \"publisher\": [\"Poliisiammattikorkeakoulu\"], \"e-isbn\": [\"9789518153866\"], \"p-issn\": \"1797-5743\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Poliisikoulutuksen vaikuttavuusarviointi 2021 : poliisikorkeakouluvaltaisoa rapport\", \"year\": \"2021\", \"publisher\": [\"Poliisiammattikorkeakoulu\"], \"e-isbn\": [\"9789518153866\"], \"p-isn\": \"9789518153866\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta Etel\\u00e4-Savon kunnissa 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta : ETEL\\u00c4-SAVON KUNNISSA 2020\", \"creator\": [\"N\\u00e4inen, Matti\"], \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta Pohjois-Karjalan kunnissa 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta POHJOIS-\\nKarjalanan kunnissa : liikunnan edist\\u00e4misaktiivisuus Suomen kunnissa\", \"creator\": [\"Pohjaniari, Jari\"], \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ymp\\u00e4rist\\u00f6vaikutusten arviointi 80-luvun liikerakennuksen kiinteist\\u00f6kehitt\\u00e4misess\\u00e4 : elinkaariarvioinnin (LCA), elinkaarikustannusten (LCC) ja energiasimuloinnin arviointiraportti\", \"creator\": [\"Keskisalo, Mika\", \"Kuusisto, Jari\", \"Matveinen, Mikko\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753656\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ymp\\u00e4rist\\u00f6vaikutusten arviointi 80-luvun liikerakennuksen kiinteist\\u00f6kehitt\\u00e4misess\\u00e4 : Elinkaariarvioinnin (LCA), elinkaarikustannusten (LCC) ja energiasimuloinnin arviointiraportti\", \"creator\": [\"Keskisalo, Mika\", \"Kuusisto, Jari\", \"Matveinen, Mikko\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753656\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Dynaamisten kyvykkyyksien syntyminen ja kehittyminen hyvinvointialuevalmistelun yhteydess\\u00e4 : kyvykkyysperusteinen n\\u00e4k\\u00f6kulma julkishallinnon organisaation muutosprosessiin\", \"creator\": [\"Post, Juha\"], \"year\": \"2023\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950740\"], \"p-isbn\": [\"9789523950733\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Dynaamisten kyvykkyyksien syntyminen ja kehittyminen hyvinvointialuevalmistelun yhteydess\\u00e4 : kyvykkyysperusteinen n\\u00e4k\\u00f6kulma julkishallinnon organisaation muutosprosessiin\", \"creator\": [\"Post, Juha\"], \"year\": \"2023\", \"publisher\": [\"Taideyliopiston Kyvykkyyliopisto\"], \"e-isbn\": [\"9789523950740\"], \"p-isbn\": [\"9789523950733\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Edess\\u00e4 ja edell\\u00e4: Suomen ete-vartaloisten tilagrammien merkitykset ja metaforisuus\", \"alt_title\": [\"\\u2018In front\\u2019 and \\u2018ahead\\u2019 : semantics and metaphoricity of Finnish FRONT grams {en}\"], \"creator\": [\"Teeri-Niknammoghadam, Krista\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512984374\"], \"p-isbn\": [\"9789512984367\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Edess\\u00e4 ja edell\\u00e4 : suomen ete-vartaloisten tilagrammien merkitykset ja metaforisuus\", \"alt_title\": [\"\\u2018Front\\u2019 and \\u2018ahead\\u2019 : semantics and metaphoricity of Finnish FRONT grammes {en}\"], \"creator\": [\"Teeri-Niknammoghadam, Krista\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512984374\"], \"p-isbn\": [\"9789512984367\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kielellisesti tuettu opetus : yl\\u00e4kouluik\\u00e4iset maahanmuuttajaoppilaat opetuskielt\\u00e4 ja oppiainesis\\u00e4lt\\u00f6j\\u00e4 oppimassa\", \"creator\": [\"Harju-Autti, Raisa\"], \"year\": \"2022\", \"publisher\": [\"Tampereen yliopisto\"], \"e-isbn\": [\"9789520326661\"], \"p-isbn\": [\"9789520326654\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kielellisesti tuettu opetus : yl\\u00e4kouluik\\u00e4iset maahanmuuttajaoppilaat opetuskielt\\u00e4 ja oppiainesis\\u00e4lt\\u00f6j\\u00e4 oppimassa\", \"creator\": [\"Harju-Autti, Raissa\"], \"year\": \"2022\", \"publisher\": [\"Tampereen yliopisto\"], \"e-isbn\": [\"9789520326661\"], \"p-isbn\": [\"9789520326654\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"K\\u00e4tketty maisema : arkitieto l\\u00e4hiymp\\u00e4rist\\u00f6n kohtaamisessa\", \"alt_title\": [\"Hidden landscape : local knowledge in encounters with everyday environment {en}\"], \"creator\": [\"Puolam\\u00e4ki, Laura\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512979301\"], \"p-isbn\": [\"9789512979523\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"K\\u00e4tketty maisema : arkitieto l\\u00e4hiymp\\u00e4rist\\u00f6n kohtaamisessa\", \"alt_title\": [\"Hidden landscape : local knowledge in encounters with everyday environment {en}\"], \"creator\": [\"Puolam\\u00e4ki, Laura\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512979301\"], \"p-isbn\": [\"9789512979523\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"P\\u00e4ivitt\\u00e4inen johtaminen l\\u00e4hiesimiehen ty\\u00f6ss\\u00e4 leikkaus- ja anestesiaosastolla\", \"alt_title\": [\"Nurse managers\\u2019 daily unit operation in perioperative settings {en}\"], \"creator\": [\"Siirala, Eriikka\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512982967\"], \"p-isbn\": [\"9789512982950\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"P\\u00e4ivitt\\u00e4inen johtaminen l\\u00e4hiesimiehen ty\\u00f6ss\\u00e4 leikkaus- ja anestesiaosastolla\", \"alt_title\": [\"Nurse managers\\u2019 daily unit operation in perioperative settings {en}\"], \"creator\": [\"Siirala, Eriikka\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512982967\"], \"p-isbn\": [\"9789512982950\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Toimijat, taistelijat, tipahtaneet : koulutus- ja ty\\u00f6toimijuus mielenterveyskuntoutujien el\\u00e4m\\u00e4nkerronnoissa\", \"creator\": [\"Vilppola, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512983025\"], \"p-isbn\": [\"9789512983018\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Toimijat, taistelijat, tipahtaneet : koulutus- ja ty\\u00f6toimijuus mielenterveyskuntoutujien el\\u00e4m\\u00e4nkerronnoissa\", \"alt_title\": [\"Agentic actors, Warriors, dropouts : education and work agency in life stories of mental health rehabilitees {en}\"], \"creator\": [\"Vilppola, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512983025\"], \"p-isbn\": [\"9789512983018\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Vastuullinen julkinen johtaminen : hallinto-oppien kommunikatiivinen arviointi\", \"alt_title\": [\"Responsible public management : communicative assessment of administrative doctrine {en}\"], \"creator\": [\"Autioniemi, Jari\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769655\"], \"p-isbn\": [\"9789524769648\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Vastuullinen julkinen johtaminen : hallinto-oppien kommunikatiivinen arviointi\", \"alt_title\": [\"Responsible public management : communicative assessment of administrative doctrines {en}\"], \"creator\": [\"Autioniemi, Jari\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950189\"], \"p-isbn\": [\"9789523950172\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Veron kiert\\u00e4misen tunnistaminen : oikeuden v\\u00e4\\u00e4rink\\u00e4yt\\u00f6n kielto VML 28 \\u00a7:n tulkinnassa\", \"creator\": [\"Kaunisto, Siru\"], \"year\": \"2022\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950276\"], \"p-isbn\": [\"9789523950269\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Veron kiert\\u00e4misen tunnistaminen : oikeuden v\\u00e4\\u00e4rink\\u00e4yt\\u00f6n kielto VML 28 \\u00a7:n tulkinnassa\", \"creator\": [\"Kaunisto, Siru\"], \"year\": \"2022\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950276\"], \"v-isbn\": [\"9789523950269\"], \"e-issn\": \"2323-9123\", \"v-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"V\\u00e4litt\\u00e4v\\u00e4 kasvatus ja opetus peruskoulun yhdeks\\u00e4sluokkalaisten kokemana\", \"alt_title\": [\"Personal caring and caring teaching in basic education experienced by 9th grade students {en}\"], \"creator\": [\"Hosio, Maarit\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512986835\"], \"p-isbn\": [\"9789512986828\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"V\\u00e4litt\\u00e4v\\u00e4 kasvatus ja opetus peruskoulun yhdeks\\u00e4sluokkaisten kokemana\", \"creator\": [\"Hosio, Mararit\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512986835\"], \"p-isbn\": [\"9789512986828\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ammattikielisten tekstien tutkimisesta : esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Katajam\\u00e4ki, Heli\", \"Koskela, Merja\"], \"year\": \"2012\", \"publisher\": [\"Kotimaisten kielten keskus\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ammattikielisten tekstien tutkimisesta : esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Koskela, Merja\", \"Katajam\\u00e4ki, Heli\"], \"year\": \"2012\", \"publisher\": [\"Finla\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"FAQ : taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t\", \"year\": \"2018\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"e-isbn\": [\"9789527266076\"], \"p-issn\": \"1456-002X\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t : FAQ\", \"creator\": [\"Suonp\\u00e4\\u00e4, Juha\"], \"publisher\": [\"Taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t\"], \"e-isbn\": [\"9789527266076\"], \"p-issn\": \"1456-002X\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Julkisen tilan taiteen tilasta : puheenvuoroja julkisen taiteen konteksteista\", \"year\": \"2021\", \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Taideyliopiston s\\u00e4hk\\u00f6isess\\u00e4 julkaisuarkistossa : puheenvuoroja julkisen taiteen konteksteista\", \"year\": \"2021\", \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Karelia.fi : Karelia-ammattikorkeakoulun tutkimus- ja kehitt\\u00e4mistoimintaa EU-ohjelmakaudella 2014-2020\", \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Karelia-ammattikorkeakoulu : tutkimus- ja kehitt\\u00e4mis- ja innovaatiotoiminnan vaikutuksessa eu-ojahdentelmaa 2014-2020\", \"creator\": [\"Matveevi\\u00e5, Sanna\", \"Pakarin, Timo\", \"Mertanen, Ville\"], \"publisher\": [\"Kansainv\\u00e4list\\u00e4\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : kulttuurituotannon ty\\u00f6papereita\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kulttuurituotannon ty\\u00f6papereita : kehitt\\u00e4misty\\u00f6si oivallukset\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Monimuotoinen ansioty\\u00f6 : n\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"year\": \"2022\", \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Monimuotoinen ansioty\\u00f6 : n\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"creator\": [\"J\\u00e4rvensivu, Anu\", \"Haapakorpi, Arja\"], \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Osuma-peli : innostusta yhteiskehittelyyn!\", \"creator\": [\"Halonen, Katri\", \"Salmenkangas, Mai\", \"Wallin, Riikka\"], \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Osuma-peli : innostusta yhteiskehittelyyn!\", \"creator\": [\"Halonen, Katri\", \"Salmenkangas, Mai\", \"Wallin, Riikka\"], \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Pk-yritysten liiketoiminnan muotoilun CookBook\", \"creator\": [\"Jaakola, Hanna\", \"Pietik\\u00e4inen, Minna\", \"Rinta-Jouppi, Laura\", \"Viljanen, Jenni\"], \"year\": \"2021\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Liiketoiminnan muotoilun CookBook : cookbook perustuu kokemuksiin joku yritt\\u00e4j\\u00e4ty\\u00f6pajoilla\", \"creator\": [\"Jaakola, Hanna\", \"Pietik\\u00e4inen, Minna\", \"Rinta-Jouppi, Laura\", \"Viljanen, Jenni\"], \"year\": \"2021\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Suomen Pankki 200 vuotta II : parlamentin pankki\", \"creator\": [\"Kuuster\\u00e4, Antti\", \"Tarkka, Juha\"], \"year\": \"2012\", \"publisher\": [\"Otava\"], \"e-isbn\": [\"9789511242727\"], \"p-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Suomen Pankki 200 vuotta parlamentin pankki : II\", \"year\": \"2014\", \"publisher\": [\"Suomen Pankki\"], \"e-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4rittelyt\", \"creator\": [\"Aalto, Anna\", \"Virkkunen, Heikki\", \"Turunen, Seppo\", \"Saarela, Hanna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4rittelyt\", \"creator\": [\"Anna, Thelma\", \"Heikki, Virkki\", \"Seppo, Turunen\", \"Hanna-Leena, Saarela Tarja\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Taru-sanomat\", \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"e-issn\": \"2490-2055\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Taru-sanomat : toimittaja P\\u00e4ivi Rahmel\", \"creator\": [\"Rahmel, P\\u00e4ivi\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"p-issn\": \"2490-2055\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset\", \"creator\": [\"Haarala, P\\u00e4ivi\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"e-issn\": \"2669-8021\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset : metropolia Ammattikorkeakoulu\", \"creator\": [\"Haarala, P\\u00e4ivi\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"p-isbn\": [\"9789523283406\"], \"p-issn\": \"2669-8021\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"D\\u00e4r kunskapen t\\u00e4tnar som moln : ess\\u00e4er om litteraturen som kunskapsf\\u00e4lt och kunskapsform\", \"year\": \"2021\", \"publisher\": [\"Litteraturvetenskap och filosofi vid \\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240201\"], \"p-isbn\": [\"9789521240195\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"D\\u00e4r kunskapen t\\u00e4tnar som moln : ess\\u00e4er om litteraturen som kunskapsf\\u00e4lt och kunskapsform\", \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6r konst\"], \"e-isbn\": [\"9789521240201\"], \"p-isbn\": [\"9789521240195\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finsk straffr\\u00e4tt : grundkurs i straffr\\u00e4ttens allm\\u00e4nna l\\u00e4ror\", \"creator\": [\"Boucht, Johan\", \"Fr\\u00e4nde, Dan\"], \"year\": \"2020\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518153767\"], \"p-isbn\": [\"9789518153750\"], \"e-issn\": \"1455-8270\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finsk strafffr\\u00e4tt : grundkurs i straffr\\u00e4ttens allm\\u00e4nna l\\u00e4ror\", \"creator\": [\"Boucht, Johan\", \"Fr\\u00e4nde, Dan\"], \"year\": \"2020\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518153767\"], \"p-isbn\": [\"9789518153750\"], \"p-issn\": \"1455-8270\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"N\\u00e4r man g\\u00e5r i stora skor l\\u00e4mnar man stora sp\\u00e5r efter sig : aderton perspektiv p\\u00e5 polisarbetet\", \"alt_title\": [\"Studiematerial f\\u00f6r Polisyrkesh\\u00f6gskolans intr\\u00e4desprov 2014 {sv}\"], \"year\": \"2014\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518152630\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Aderton perspektiv p\\u00e5 polisarbetet : n\\u00e4r man g\\u00e5r i stora skor l\\u00e4mnar man stora sp\\u00e5r efter sig\", \"year\": \"2014\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Kartering av fisksamh\\u00e4llen och f\\u00f6rekomst av plattfiskar och n\\u00e4bbg\\u00e4dda (Belone belone) p\\u00e5 exponerade str\\u00e4nder p\\u00e5 \\u00c5land\", \"alt_title\": [\"Mapping of fish communities and the occurrence of flatfish and garpike (Belone belone) on exposed  beaches in the \\u00c5land Islands {en}\"], \"creator\": [\"Finnb\\u00e4ck, Lars\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521240249\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Kartering av fisksamh\\u00e4llen och f\\u00f6rekomst av plattfiskar och n\\u00e4bbg\\u00e4dda : belone belone p\\u00e5 exponerade str\\u00e4nder p\\u00e5 \\u00c5land\", \"creator\": [\"Finnb\\u00e4ck, Lars\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi, \\u00c5land\"], \"e-isbn\": [\"9789521240249\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Uppf\\u00f6ljningsstudie av g\\u00f6sens (Sander lucioperca (L.)) och de allm\\u00e4nna fiskbest\\u00e5ndens f\\u00f6rekomst i \\u00c5lands inre sk\\u00e4rg\\u00e5rd\", \"alt_title\": [\"Follow up study on the occurrence of pikeperch (Sander lucioperca (L.)) and the common fish stocks in the inner archipelago of \\u00c5land {en}\"], \"creator\": [\"\\u00d6sterlund, Jonas\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521242496\"], \"p-isbn\": [\"9789521242489\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Uppf\\u00f6ljningsstudie av g\\u00f6sens (Sander lucioperca (L.) ) och de allm\\u00e4nna fiskbest\\u00e5ndens f\\u00f6rekomst i \\u00c5lands inre sk\\u00e4rg\\u00e5rd\", \"creator\": [\"\\u00d6sterlund, Jonas\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242489\"], \"p-isbn\": [\"9789521242496\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Svenskfinland i pandemitider : resultat fr\\u00e5n den finlandssvenska medborgarpanelen Barometern 2020\\u20132022\", \"creator\": [\"Backstr\\u00f6m, Jenny\", \"Backstr\\u00f6m, Kim\", \"Karv, Thomas\", \"Lindell, Marina\", \"Malmberg, Fredrik\", \"Schauman, Jonas\", \"Sir\\u00e9n, Rasmus\", \"Weckman, Albert\"], \"year\": \"2022\", \"publisher\": [\"Institutet f\\u00f6r samh\\u00e4llsforskning (Samforsk), \\u00c5bo Akademi, Vasa\"], \"e-isbn\": [\"9789521242106\"], \"p-isbn\": [\"9789521242090\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Svenskf\\u00f6rlands pandemitider : resultat fr\\u00e5n den finlandssvenska medborgarpanelen Barometern 2020-2022\", \"year\": \"2022\", \"publisher\": [\"Institutet f\\u00f6r samh\\u00e4llsforskning\"], \"e-isbn\": [\"9789521242106\"], \"p-isbn\": [\"9789521242090\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Elevers matematiska utmaningar i sl\\u00f6jd : \\u00e4mnes\\u00f6verskridande l\\u00e4rande via handens arbete\", \"creator\": [\"Hjelm, \\u00c5sa\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789523890435\"], \"p-isbn\": [\"9789523890428\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Elevers matematiska utmaningar i sl\\u00f6jd : \\u00e4mnes\\u00f6verskridande l\\u00e4rande via handens arbete\", \"creator\": [\"Hjelm, \\u00c5sa\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789523890435\"], \"p-isbn\": [\"9789523890428\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Hantera frihet och ansvar : om unga personers liv, h\\u00e4lsa och behov av st\\u00f6d\", \"creator\": [\"\\u00d6stman, Lillemor\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240874\"], \"p-isbn\": [\"9789521240867\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Hantera frihet och ansvar : om unga personers liv, h\\u00e4lsa och behov av st\\u00f6d\", \"alt_title\": [\"Managing well-being and responsibility : about unwell people, relationships and the responsibilities of society {en}\"], \"creator\": [\"\\u00d6stman, Lillemor\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240874\"], \"p-isbn\": [\"9789521240867\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00e4lsans tomrum : en hermeneutisk studie om f\\u00f6rsakelsens betydelse f\\u00f6r h\\u00e4lsan\", \"alt_title\": [\"A void for health : a hermeneutic study of the significance of renunciation for health {en}\"], \"creator\": [\"Koskinen, Monika\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789517659932\"], \"p-isbn\": [\"9789517659925\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00e4lsans tomrum : en hermeneutisk studie om f\\u00f6rsakelsens betydelse f\\u00f6r h\\u00e4lsan\", \"creator\": [\"Koskinen, Monika\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789517659932\"], \"p-isbn\": [\"9789517659925\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e4rmilj\\u00f6ns betydelse f\\u00f6r barns ut\\u00f6vande och l\\u00e4rande av grundl\\u00e4ggande motoriska f\\u00e4rdigheter i sm\\u00e5barnspedagogik\", \"creator\": [\"Svanb\\u00e4ck-Laaksonen, Mikaela\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242236\"], \"p-isbn\": [\"9789521242229\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e4rmilj\\u00f6ns betydelse f\\u00f6r barns ut\\u00f6vande och l\\u00e4rande av grundl\\u00e4ggande motoriska f\\u00e4rdigheter i sm\\u00e5barnspedagogik\", \"creator\": [\"Svanb\\u00e4ck-Laaksonen, Mikaela\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242236\"], \"p-isbn\": [\"9789521242229\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Musikerr\\u00f6ster i Betsy Jolas musik : dialoger och spelerfarenheter i analys\", \"creator\": [\"Korhonen-Bj\\u00f6rkman, Heidi\"], \"year\": \"2016\", \"publisher\": [\"Sibelius-Akademin, Konstuniversitetet\", \"Musikvetenskapliga s\\u00e4llskapet i Finland\"], \"e-isbn\": [\"9789526834726\"], \"p-isbn\": [\"9789526834719\"], \"p-issn\": \"0587-2448\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Musikerr\\u00d6ster i betsy jolas musik : dialoger och spelerfarenheter i analys\", \"creator\": [\"Korhonen-Bj\\u00f6rkman, Heidi\"], \"year\": \"2016\", \"publisher\": [\"Tammerfors, Fysiksola\"], \"e-isbn\": [\"9789526834726\"], \"p-isbn\": [\"9789526834719\"], \"p-issn\": \"0587-2448\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Att v\\u00e5rda vattendrag tillsammans : kommunikation och anpassning till klimatf\\u00f6r\\u00e4ndringens utmaningar i Herts\\u00e5nger\\u00e4lven och Toby \\u00e5 (Laihianjoki)\", \"creator\": [\"Nordberg, Kenneth\", \"Ghorbanzadeh, Sakineh\"], \"publisher\": [\"Regionalvetenskap, \\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242328\"], \"p-isbn\": [\"9789521242328\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Att v\\u00e5rda vattendrag tillsammans : Kommunikation och anpassning till klimatf\\u00f6r\\u00e4ndringens utmaningar i Herts\\u00e5nger\\u00e4lven och Toby \\u00e5 (Laihianjoki)\", \"creator\": [\"Nordberg, Kenneth\", \"Ghorbanzadeh, Sakineh\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242328\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Direktionens ber\\u00e4ttelse till bankfullm\\u00e4ktige om Finansinspektionens verksamhet 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Direktionens ber\\u00e4ttelse till bankfullm\\u00e4ktige om Finansinspektionens verksamhet 2012 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Egentliga Finland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Egentliga Finland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2014\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522444943\"], \"p-isbn\": [\"9789522444745\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2014\", \"year\": \"2015\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522449433\"], \"p-isbn\": [\"9789522447457\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2020\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446534\"], \"p-isbn\": [\"9789522446527\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2020\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446534\"], \"p-isbn\": [\"9789522446527\"], \"e-issn\": \"0357-4962\", \"p-issn\": \"2242-8488\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2022\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446961\"], \"p-isbn\": [\"9789522446954\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Finland i siffror 2022\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446961\"], \"p-isbn\": [\"9789522446954\"], \"e-issn\": \"0357-4962\", \"p-issn\": \"2242-8488\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Kompetens i palliativ v\\u00e5rd och v\\u00e5rd i livets slutskede i sjuksk\\u00f6tarexamen : rekommendation f\\u00f6r l\\u00e4roplan i palliativ v\\u00e5rd och v\\u00e5rd i livets slutskede\", \"creator\": [\"H\\u00f6kk\\u00e4, Minna\", \"Lehto, Juho\", \"Joutsia, Karoliina\", \"Kallio, Suvi\", \"Kiiski, Katri\", \"Kurunsaari, Merja\", \"Lifl\\u00e4nder, Birgit\", \"L\\u00e4hdetniemi, Marika\", \"Matilainen, Irmeli\", \"Mikkonen, Heli\", \"Muurinen, Katja\", \"Pyk\\u00e4l\\u00e4inen, Tarja\", \"P\\u00e4\\u00e4llysaho, Annikki\", \"Sunikka, Tuulia\", \"Tohmola, Anniina\", \"Turunen, Elina\", \"V\\u00e4is\\u00e4nen, Irja\", \"Ylinen, Eeva-Riitta\", \"\\u00d6hberg, Isa\"], \"publisher\": [\"Kajaanin Ammattikorkeakoulu Oy\"], \"e-isbn\": [\"9789527219607\"], \"p-isbn\": [\"9789527219560\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Tv\\u00e4rsektoriellt och arbetslivsorienterat utvecklande av palliativt v\\u00e5rdarbete och medicinsk utbildning : EduPal 2018-2021\", \"year\": \"2021\", \"publisher\": [\"Spetsprojekt finansierat av undervisnings- och kulturministeriet\"], \"e-isbn\": [\"9789527219607\"], \"p-isbn\": [\"9789527219560\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Norra Karelen och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Norra Karelen och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Norra \\u00d6sterbotten och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Norra \\\"sterbotten\\\" och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"P\\u00e4ij\\u00e4nne-Tavastland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"P\\u00e4ij\\u00e4nne-Tavastland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Unders\\u00f6kning av l\\u00f6nsamheten inom lagstadgad olycksfallsf\\u00f6rs\\u00e4kring 2004-2013 : analys\", \"year\": \"2014\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Unders\\u00f6kning av l\\u00f6nsamheten inom lagstadgad olycksfallsf\\u00f6rs\\u00e4kring 2004-2013 : analys\", \"year\": \"2014\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse 2018\", \"creator\": [\"Lahnalammi-Vesivalo, Milka\", \"Alhonsuo, Sampo\", \"Armila-Paalasmaa, Miia\", \"Heikkinen, Raakel\", \"Heiskanen, Hanna\", \"Juutinen, Anne-Mari\", \"Korpiaho, Teija\", \"Rantama, Jaana\", \"Rautanen, Erja\", \"Tulonen, Tommi\", \"Tuomikoski, Kristiina\"], \"year\": \"2019\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Verksamhetsber\\u00e4ttelse 2018\", \"year\": \"2018\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"\\\"Pit\\u00e4is varmaan sanoa, ett\\u00e4 Jumala se kutsuu\\\" : n\\u00e4k\\u00f6kulmia kanttorin kutsumukseen\", \"alt_title\": [\"\\u201dI probably should say it\\u00b4s God calling me\\u201d : wiewpoints to the calling of a cantor {en}\"], \"creator\": [\"Alasaarela, Laura\"], \"year\": \"2019\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Pit\\u00e4is varmaan sanoa, ett\\u00e4 Jumala se kutsuu\\u201d : n\\u00e4k\\u00f6kulmia kanttorin kutsumukseen\", \"alt_title\": [\"The sound of singing children's voices is pleasant, the wind blowing gently {en}\"], \"creator\": [\"Alasaarela\", \"Laura\"], \"year\": \"2019\", \"publisher\": [\"Taideylioty\\u00f6pin Sibelius-Akatemia\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"13\\u201317-vuotiaiden poikien plyometrinen harjoittelu jalkapallossa : opas valmentajille\", \"alt_title\": [\"13-17-year-old young male\\u2019s plyometric training in soccer : Information guide for coaches {en}\"], \"creator\": [\"Qvickstr\\u00f6m, Henri\", \"Silfverberg, Ville\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Laurea-ammattikorkeakoulu : fysioterapian koulutusohjelma : vuosikym\\u00e4 2020\", \"alt_title\": [\"Bachelor thesis : physiotherapy bachelor programme : 2020/2021 {en}\"], \"creator\": [\"Qvickstr\\u00f6m, Henri\", \"Silfverberg, Ville\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Einojuhani Rautavaaran Lapsimessu (op. 71) : n\\u00e4k\\u00f6kulmia harjoittamiseen\", \"creator\": [\"Norjanen, Anna-Elina\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"N\\u00e4k\\u00f6kulmia harjoittamiseen : Anna-\\u00ad\\u2010Elina Norjanen S-\\u00ad\\u2010km25 Kirjallinen ty\\u00f6 Kirkkomusiikin ja urkujen aineryhm\\u00e4\", \"creator\": [\"Norjanen, S\\u00ad\\u2010Kimta\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Esimiehen\\u00e4 muuttuvan organisaation aallokoissa : organisaatio tuen merkitys muutoksen johtamisessa\", \"creator\": [\"Hihnala, Heidi\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Esimiehen\\u00e4 muuttuvan organisaation aallokoissa : organisaatio tuen merkitys muutoksen johtamisessa\", \"creator\": [\"Hihnala, Heidi\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitajien ergonomiaosaaminen potilaan siirto- ja nostotilanteissa\", \"alt_title\": [\"Nurses ergonomic know-how in patient moving and handling situations {en}\"], \"creator\": [\"Helander, Anna-Kaisa\", \"Koivisto, Tuomas-Heikki\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitajien ergonomiaosaaminen potilaan siirto- ja nostotilanteissa\", \"alt_title\": [\"Nurses ergonomic know-how in patient moving and handling situations {en}\"], \"creator\": [\"Helander, Anna-Kaisa\", \"Koivisto, Tuomas-Heikki\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitoty\\u00f6n vertaisarviointiprosessin testaaminen osana lasten spirometriatutkimuksen laadun kehitt\\u00e4mist\\u00e4\", \"alt_title\": [\"Testing of peer review process of nursing as a part of quality development of spirometry test for child patient {en}\"], \"creator\": [\"Kinnunen, Karoliina\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hoitoty\\u00f6n vertaisarviointiprosessin tes- taaminen osana lasten spirometrytutkimuksen laadun kehitt\\u00e4mist\\u00e4\", \"alt_title\": [\"Number of Pages : 1\", \"Metropolia Ammattikorkeakoulu\", \"Phd thesis en es\", \"Medical research design : qualitative research method in health services management {fr}\"], \"creator\": [\"Kinnunen, Karoliina\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Itsem\\u00e4\\u00e4r\\u00e4\\u00e4misoikeus lain n\\u00e4k\\u00f6kulmasta kehitysvammahuollon laitospalveluissa : auditointisuunnitelma\", \"alt_title\": [\"Self-determination from the perspective of law in institutional services for people with intellectual disabilities : an audit plan {en}\"], \"creator\": [\"Rahkj\\u00e4rvi, P\\u00e4ivi\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Auditointisuunnitelma : auditointisuunnitelman prosessikaavio 1 (1) vaikheit\\u00e4konval                tulevaisuudessa\", \"alt_title\": [\"Itsem\\u00e4\\u00e4r\\u00e4\\u00e4misoikeus lain n\\u00e4k\\u00f6kulmasta kehitysvammahuollon laitospalveluissa : auditointisuunnitelma {fi}\"], \"creator\": [\"Rahkj\\u00e4rvi, P\\u00e4ivi\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kaisa Juhantytt\\u00e4ren (1782\\u20131856) el\\u00e4m\\u00e4nhistoria ja muistivihkoon k\\u00e4tketty minuus\", \"creator\": [\"Kautto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kaisa Juhantytt\\u00e4ren : el\\u00e4m\\u00e4nhistoria ja muistivihkoon k\\u00e4tketty minuus\", \"creator\": [\"Kautto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Laadunhallintaj\\u00e4rjestelm\\u00e4 Bluet Oy:lle\", \"alt_title\": [\"Quality management system for a specific engineering company {en}\"], \"creator\": [\"Ivanov, Slava\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Laadunhallintaj\\u00e4rjestelm\\u00e4 : bluet\", \"alt_title\": [\"Project manager for Bluet Oil Company {en}\"], \"creator\": [\"Ivanov, Slava\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Lahjakkaan lapsen erityisopetus : n\\u00e4k\\u00f6kulmana tasa-arvo\", \"alt_title\": [\"Special education of a gifted child : from the perspective of equality {en}\"], \"creator\": [\"Niitamo, Katri\"], \"year\": \"2019\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Lahjakkaan lapsen erityisopetus : N\\u00e4k\\u00f6kulmana tasa-arvo\", \"alt_title\": [\"Special education of a gifted child : from the perspective of equality {en}\"], \"creator\": [\"Nittimai, Katri\"], \"year\": \"2019\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Mannerheimin Lastensuojeluliiton Tampereen osaston Eron ensiapupisteen ohjaus- ja neuvontaty\\u00f6 : perheiden ja ty\\u00f6ntekij\\u00f6iden kokemuksia palveluista\", \"alt_title\": [\"Guidance and counseling work at Tampere department\\u2019s divorce services of Mannerheim League for Child Welfare {en}\"], \"creator\": [\"Annala, Riina\", \"Ryh\\u00e4nen, Juulia\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Mannerheimin lastensuojeluliiton : tampereen osaston Eron ensiapu-pysteen ohjamaa perheiden ja ty\\u00f6ntekij\\u00f6iden kokemuksia palveluista\", \"alt_title\": [\"Guidance and counseling work at the Division of Divorce Services of the Mannerheim League for Children's Rights {en}\"], \"creator\": [\"Annala, Riina\", \"Ryh\\u00e4nen, Juilla\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Musiikinopettajan pedagogisten l\\u00e4hestymistapojen vaikutus murrosik\\u00e4isen oppilaan motivaatioon\", \"creator\": [\"Kauppinen, Sakari\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Musiikinopettajan pedagogisten l\\u00e4hestymistapojen vaikutus murrosik\\u00e4isen oppilaan motivaatioon\", \"creator\": [\"Kauppinen, Sakari\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ohjelmistorobotiikan k\\u00e4ytt\\u00f6\\u00f6notosta aiheutuneen muutoksen kokeminen : Tampereen kaupungin ty\\u00f6llisyys- ja kasvupalvelut\", \"alt_title\": [\"Experience of the change affected by software robotics deployment : City of Tampere Employment and Growth Services {en}\"], \"creator\": [\"Toukola, Lilli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ohjelmistorobotiikan k\\u00e4ytt\\u00f6\\u00f6notosta aiheutuneen muutoksen kokeminen\", \"creator\": [\"Toukola, Lilli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Osakkeen hinnassa tapahtuva muutos ennen tulosjulkistusta : markkinoiden ennustuskyky\", \"creator\": [\"Viitala, Kalle\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Osakkeen hinnassa tapahtuva muutos ennen tulosjulkistusta : markkinoiden ennustuskyky\", \"creator\": [\"Viitala, Kalle\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Postresuskitaatiohoito ensihoidossa : tarkistuslista ensihoitajille\", \"alt_title\": [\"Post-resuscitation care in emergency care : a checklist for paramedics {en}\"], \"creator\": [\"Jaakkola, Amanda\", \"Mattila, Janina\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Postresuskitaatiohoito ensihoidossa : tarkistuslista ensihoitajille\", \"alt_title\": [\"Post-resuscitation care in emergency care : checklist for paramedics {en}\"], \"creator\": [\"Jaakkola, Amanda\", \"Mattila, Janina\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ravitsemusprofilointi osana SOK:n Omat Ostot -palvelua\", \"alt_title\": [\"Nutritional profiling as a part of SOK\\u2019s Omat Ostot service {en}\"], \"creator\": [\"Valli, Nelli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ravitsemusprofilointi osana : sok:n omat ostot -palvelua\", \"alt_title\": [\"Nutritional profiling as a part of SOK's omat ostot service {en}\"], \"creator\": [\"Valli, Neli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Suomalaisuuden reunaehdot sotien v\\u00e4lisen\\u00e4 aikana : rajank\\u00e4ynti\\u00e4 menneisyyskuvilla Lauri Haarlan historiallisessa romaanissa Kurkien taru (1938\\u20131940)\", \"creator\": [\"Lepist\\u00f6, Vilma\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Suomalaisuuden reunaehdot sotien v\\u00e4lisen\\u00e4 aikana : Rajank\\u00e4ynti\\u00e4 menneisyyskuvilla Lauri Haarlan historiallisessa romaanissa\", \"creator\": [\"Lepist\\u00f6, Vilma\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun : tarkastusvaliokunnat suomalaisissa ja ruotsalaisissa p\\u00f6rssiyhti\\u00f6iss\\u00e4\", \"creator\": [\"Salminen, Heini\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun : tarkastusvaliokunnat suomalaisissa ja ruotsalaisissa p\\u00f6rssiyhti\\u00f6iss\\u00e4\", \"alt_title\": [\"Taloudellisen raportointi taloudelliselle ty\\u00f6yhyntien p\\u00f6rjestelyss\\u00e4t {fi}\"], \"creator\": [\"Salminen, Heini\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Terveys ja lihavuus Olet mit\\u00e4 sy\\u00f6t -ohjelmassa : \\u201dEt s\\u00e4 oo mik\\u00e4\\u00e4n l\\u00e4\\u00e4ketieteellinen ihme, vaikka s\\u00e4 oot luullu niin\\u201d\", \"creator\": [\"Nevalainen, Emmi\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Terveys ja lihuvuus olet mit\\u00e4 sy\\u00f6t : ohjelmassa \\u201dEt s\\u00e4 oo mik\\u00e4\\u00e4n l\\u00e4\\u00e4ketieteellinen ihme, vaikka s\\u00e4 oot luullu niin\\u201d\", \"creator\": [\"Nevalainen, Emmi\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Ty\\u00f6hyvinvoinnin vaikutus sairauspoissaoloihin\", \"alt_title\": [\"Influence of work well-being on sickness absence {en}\"], \"creator\": [\"Katajisto, Riikka\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Ty\\u00f6hyvinvoinnin vaikutus sairauspoissaoloihin\", \"alt_title\": [\"Influence of work well-being on sickness absence {en}\"], \"creator\": [\"Katajisto, Riikka\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Villikasveista jalosteiksi\", \"alt_title\": [\"From a wild plant to a processed product {en}\"], \"creator\": [\"Kuusela, Sofia\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Villikasveista jalosteiksi : metropolia ammattikorkeakoulu\", \"alt_title\": [\"From a wild plant to a processed product {en}\"], \"creator\": [\"Kuusela, Sofia\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Bystr\\u00f6min Ohjaamon toimintaa kehitettiin asiakasl\\u00e4ht\\u00f6isesti\", \"creator\": [\"Visuri, Anna\", \"Koivisto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Bystr\\u00f6min Ohjaamon toimintaa kehitettiin asiakasl\\u00e4ht\\u00f6isesti\", \"creator\": [\"Visuri, Anna\", \"Koivisto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Hahmottamisen laaja-alaisuus ja tiedon luonne\", \"creator\": [\"Sepp\\u00e4l\\u00e4, Mikael\"], \"year\": \"2022\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Hahmottamisen laaja-alaisuus ja tiedon luonne\", \"creator\": [\"Sepp\\u00e4l\\u00e4, Mikael\"], \"year\": \"2022\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"IMF ennustaa talouskasvua euroalueelle ja Suomelle\", \"creator\": [\"Toivanen, Mervi\"], \"year\": \"2015\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"blog post\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Blogi IMF ennustaa talouskasvvas euro-alueelle ja Suomelle\", \"creator\": [\"Toivanen, Vemir\"], \"year\": \"2015\", \"publisher\": [\"International Monetary Fund (IMF)\"], \"type_coar\": \"blog post\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kansalliset keskuspankit tuntevat oman maansa markkinapaikat\", \"creator\": [\"Hievanen, Laura\"], \"year\": \"2015\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"blog post\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"First North Bond Market Finland on pienille ja keskisuurille yrityksille suunnattu niin sanottu vaihtoehtoinen markkinapaikka\", \"creator\": [\"Hievanen, Laura\"], \"year\": \"2015\", \"type_coar\": \"blog post\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Kest\\u00e4v\\u00e4n j\\u00e4tehuollon koulutusosaamista vahvistamassa Ven\\u00e4j\\u00e4ll\\u00e4 ja Kazakstanissa\", \"alt_title\": [\"Enhancing Competences of Sustainable Waste Management in Russian and Kazakh HEIs (EduEnvi) {en}\"], \"creator\": [\"Asikainen, Eveliina\", \"Kallio, Ella\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Kest\\u00e4v\\u00e4n j\\u00e4tehuollon koulutusosaamista vahvistamassa Ven\\u00e4j\\u00e4ll\\u00e4 ja Kazakstanissa\", \"creator\": [\"Asikainen, Eveliina\", \"Kallio, Ella\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Maamassojen tilavuuksien mittaamiseen uusia menetelmi\\u00e4 : maan pinnalta ilmaan\", \"creator\": [\"Pesonen, Joonas\", \"J\\u00e4rvel\\u00e4inen, Titta\", \"K\\u00e4yhk\\u00f6, Virpi\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Maamassojen tilavuuksien mittaamiseen uusia menetelmi\\u00e4 \\u2013 maan pinnalta ilmaan\", \"creator\": [\"Pesonen, Joonas\", \"J\\u00e4rvel\\u00e4inen, Titta\", \"K\\u00e4yhk\\u00f6, Virpi\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Medianomit ehk\\u00e4isev\\u00e4t ennalta ty\\u00f6tt\\u00f6myytt\\u00e4\", \"creator\": [\"Karppinen, Anneli\", \"Ketonen, Emma\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Medianomit ehk\\u00e4isev\\u00e4t ennalta ty\\u00f6tt\\u00f6myytt\\u00e4\", \"creator\": [\"Karppinen, Anneli\", \"Ketonen, Emma\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Mik\\u00e4 saa myllypurolaisen voimaan hyvin?\", \"creator\": [\"Ruotsalainen, Taru\", \"Vuorij\\u00e4rvi, Aino\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Mik\\u00e4 saa myllypurolaisen voimaan hyvin\", \"creator\": [\"Ruotsalainen, Taru\", \"Vuorij\\u00e4rvi, Aino\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Moodlen oppimisanalytiikkaa pedagogiikan tueksi\", \"creator\": [\"Kurttila, Jukka\", \"Aalto, Markus\"], \"year\": \"2021\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"T\\u00e4m\\u00e4 on alkuper\\u00e4isen artikkelin rinnakkaistallenne\", \"creator\": [\"Kurttila, Jukka\"], \"author\": [\"Aalto, Mark\"], \"year\": \"2021\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Oluenarviointisovellukset : olutskenen siunaus vai kirous\", \"creator\": [\"Lehtinen, Aniko\"], \"year\": \"2020\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Oluenarviointisovellukset : olutskenen siunaus vai kirous\", \"creator\": [\"Lehtinen, Sanat Aniko\"], \"year\": \"2020\", \"publisher\": [\"Olutposti\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Opiskelija keikkaty\\u00f6n kiemuroissa\", \"creator\": [\"Pajula, Carolina\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Opiskelija keikkaty\\u00f6n kiemuroissa\", \"creator\": [\"Pajula, Ilona\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Pitk\\u00e4aikaissairauksien ja suun limakalvomuutosten yhteys\", \"creator\": [\"Tapio, Anni\", \"Sepp\\u00e4l\\u00e4, Anne-Mari\", \"Luoto, Annika\", \"Holappa-Girginkaya, Jaana\", \"Kuure, Marja-Helena\", \"Kein\\u00e4nen, Anna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Pitk\\u00e4aikaissairauksien ja suun limakalvomuutosten yhteys\", \"creator\": [\"Kein\\u00e4nen, Tapio\", \"Sepp\\u00e4l\\u00e4, Sepp\\u00e4l\\u00e4Anne-Mari\", \"Luoto, Annika\", \"Haluapa-Girginkaya, Jaana\", \"Marja-Helena Kein\\u00e4nen, Anna-Leena\", \"Kuure, Marja-Helena\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fi\", \"title\": \"Siivouskemikaalien ja \\u2013menetelmien vaikutukset koulu- ja p\\u00e4iv\\u00e4kotiymp\\u00e4rist\\u00f6n mikrobistoon ja sis\\u00e4ilman laatuun\", \"creator\": [\"Kakko, Leila\", \"Reunanen, Eija\", \"Kylm\\u00e4korpi, Paula\", \"Alapieti, Tuomas\", \"T\\u00e4ubel, Martin\", \"Mikkola, Raimo\", \"Salonen, Heidi\"], \"year\": \"2019\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"fi\", \"title\": \"Siivouskemikaalien ja \\u2013menetelmien vaikutukset koulu- ja p\\u00e4iv\\u00e4kotiymp\\u00e4rist\\u00f6n mikrobistoon ja sis\\u00e4mman laatuun : tuncatokatu 28.\", \"creator\": [\"Kakko, Leena\", \"Reunanen, Eija\", \"Kylm\\u00e4korpi, Pirkka\", \"Alapieti, Tori\", \"T\\u00e4ubel, Matti\", \"Mikkola, Riitta\", \"Salonen, Harjo\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"se\", \"title\": \"Deanuleagi eanadatdik\\u0161un- ja geavahanpl\\u00e1na : Biesjohka \\u2013 Nuvvos\", \"creator\": [\"Kokko, Marjut\", \"Koskiniemi, Marika\"], \"publisher\": [\"Lappi eal\\u00e1hus-, johtalus- ja birasguovdd\\u00e1\\u0161\"], \"e-isbn\": [\"9789521150647\"], \"p-isbn\": [\"9789521150630\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"se\", \"title\": \"Deanuleagi eanadatdik\\u0161un- ja geavahanpl\\u00e1na : biesjohka - nuvvos Marjut Kokko ja Marika Koskiniemi\", \"publisher\": [\"Suomen ymp\\u00e4rist\\u00f6\"], \"e-isbn\": [\"9789521150647\"], \"p-isbn\": [\"9789521150630\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Editorial\", \"creator\": [\"Illman, Ruth\", \"Lundgren, Svante\"], \"doi\": \"10.30752/nj.100124\", \"type_coar\": \"editorial\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Editorial\", \"year\": \"2021\", \"publisher\": [\"Novia University of Applied Sciences\"], \"doi\": \"10.30752/nj.100124\", \"p-issn\": \"1947-70\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Judiskt liv i Helsingfors\", \"creator\": [\"Lundgren, Svante\"], \"doi\": \"10.30752/nj.91511\", \"type_coar\": \"book review\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Som alla andra : min judiska familj och jag\", \"creator\": [\"Odrischinsky, Eva\"], \"year\": \"2019\", \"doi\": \"10.30752/nj.91511\", \"type_coar\": \"book review\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen : vasabladet\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Torka eller ensilera? : Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Yvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Torka eller ensilera? Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Vyvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"V\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\", \"creator\": [\"\\u00c5kerback, Nina\", \"\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"Engblom, Sten\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"\\\"V\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\\\" : Vaasa Insider\", \"creator\": [\"\\u00c5kerback, Nina\", \"\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"\\u00d6ngbrumm, Sten\"], \"year\": \"2019\", \"type_coar\": \"insider article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Demokrati och handel : en empirisk studie \\u00f6ver hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Demokrati och handel : en empirisk studie \\u00f6ver hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6r samh\\u00e4llsvetenskaper och ekonomi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"En l\\u00e5ng resa : en litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av br\\u00f6stcancer\", \"alt_title\": [\"A long journey : a literature review of women's experiences with breast reconstruction after mastectomy due to breast cancer {en}\"], \"creator\": [\"Zvidrina, Arita\", \"Uzelac-Varda, Silvija\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"En l\\u00e5ng resa : en litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av\", \"alt_title\": [\"The scarf of the mind : a study on women\\u00fs experiences with reconstructive surgery after mastectomy {en}\"], \"creator\": [\"Uzelac-Varda, Silvija\", \"Zvidrina, Arita\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Fr\\u00e5n \\u00c5lands Sj\\u00f6fartsl\\u00e4roverk till H\\u00f6gskolan p\\u00e5 \\u00c5land : en studie om intresset f\\u00f6r sj\\u00f6kaptensstudier \\u00f6ver tid\", \"alt_title\": [\"From Maritime Institute to the \\u00c5land University of Applied Sciences : a study of the interest in master mariner studies over time {en}\"], \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Skoglund, Wilhelm\", \"alt_title\": [\"Academic supervisor : Bengt Malmberg\", \"Research supervisor : Bengt Malmberg\"], \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhantering : modell och praktik\", \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhanteringen : modell och praktik\", \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"GDPR i praktiken\", \"alt_title\": [\"GDPR in practice {en}\"], \"creator\": [\"Kahrimanovic, Arnel\", \"Mesic, Selma\"], \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"GDPR i praktiken\", \"alt_title\": [\"Gdpr i pr\\u00f6drik {sv}\"], \"creator\": [\"Kahrimanovic, Arnel\"], \"mescic, Selma\", \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-2015\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00e5llbara ink\\u00f6p hos tv\\u00e5 \\u00e5l\\u00e4ndska f\\u00f6retag : verksamma inom plastindustrin\", \"alt_title\": [\"Sustainable purchases at two \\u00c5land companies : active in the plastics industry {en}\"], \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Sustainable purchases at two \\u00c5land companies : active in the plastics industry\", \"alt_title\": [\"Sustainable purchasing at two \\u00c5land companies : active in the plastic industry {en}\"], \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor \\u00f6ver tid\", \"creator\": [\"Backlund, Emma\", \"\\u00c5kerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor : \\u00f6ver tid\", \"creator\": [\"Backlund, Emma\", \"\\u00c5kerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rares synvinkel : en intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rares synvinkel : Susanne Eklund\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Vasa\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av  processer i IT-f\\u00f6retag : en modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring\", \"alt_title\": [\"Prosessien kartoitus ja kehitys IT-yrityksess\\u00e4 {fi}\", \"Mapping and improving of processes in an IT-company {en}\"], \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av processer i IT-f\\u00f6retag : en modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring\", \"alt_title\": [\"Ondemand-ingeniernas kurs om modellf\\u00f6rsing och f\\u00f6rb\\u00e4tgenerering i IT-f\\u00f6retaget : en modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring {sv}\", \"Process management and process mapping as a model for project management in an IT company : a tool for improving constancy {en}\"], \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Raseborg IT大学\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Monitorering av biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Holmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Monitorering biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Holmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Musik och r\\u00f6relse som plattform f\\u00f6r kreativitet : en intervjustudie med fyra l\\u00e4rare i \\u00e5rskurserna 7-9\", \"alt_title\": [\"Music and movement as a platform for creativity: an interview study involving four teachers in grades 7-9 {en}\"], \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Sibelius-Akademin, Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Musik och r\\u00f6relse som plattform f\\u00f6r kreativitet : en intervjustudie med fyra l\\u00e4rare i \\u00e5rskurserna 7-\\u00ad\\u20109\", \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Sibelius-Akademin Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Naturliga, rytmiska och holistiska individer : diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Naturliga, rytmiska och holistiska individer : diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Orderhantering f\\u00f6r automationstruckssystem med Siemens S7-1500 Logik\", \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Orderhantering f\\u00f6r automationstruckssystem med Siemens S7-1500 logik\", \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Resultatmanipulering : en studie om f\\u00f6ruts\\u00e4ttningarna p\\u00e5 den finska marknaden\", \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Resultatmanipulering : en studie om f\\u00f6ruts\\u00e4ttningarna p\\u00e5 den finska marknaden\", \"alt_title\": [\"Earnings management : a study on financial market performance of listed companies {en}\"], \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? : ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? : ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"sv\", \"title\": \"Vikingakvinnan som husmor : en filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa universitet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"sv\", \"title\": \"Vikingakvinnan som husmor : en filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa Universitet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"se\", \"title\": \"Davvis\\u00e1megiela goalloss\\u00e1tnegerunddat : \\u201dmun ohppen suoidnec\\u00e1medettiin, duddjodettiin, s\\u00e1lmmaid l\\u00e1vllodettiin, nuohti geasedettiin ja heargevuojedettiin.\\u201d\", \"creator\": [\"Rauhala, Mira\"], \"year\": \"2017\", \"publisher\": [\"Oulu universitehta Giellagas-instituhtta\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"se\", \"title\": \"Davvis\\u00e1megiela goalloss\\u00e1tnerungddat : mun ohppen suoidnecmedettiin, duddjodettiin, s\\u00e1lmmaid l\\u00e1vllodettiin, nuohti geasedettiin ja heargevuojedettiin.\", \"creator\": [\"Rauhala, Mira\"], \"year\": \"2017\", \"publisher\": [\"Oulu universitehta Giellagas-instituhtta\"], \"type_coar\": \"doctoral thesis\"}\n",
      "CPU times: user 5min 1s, sys: 21.9 s, total: 5min 23s\n",
      "Wall time: 5min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "from itertools import batched\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def rec_to_messages(rec):\n",
    "    return [\n",
    "        {\"role\": msg[\"from\"], \"content\": msg[\"value\"]}\n",
    "        for msg in rec[\"conversations\"]\n",
    "        if msg[\"from\"] != \"gpt\"\n",
    "    ]\n",
    "\n",
    "# read the eval records from file\n",
    "test_recs = []\n",
    "with open(\"axolotl-test.jsonl\") as testfile:\n",
    "    for line in testfile:\n",
    "        test_recs.append(json.loads(line))\n",
    "\n",
    "with open(f'test-records-{MODEL_SHORT_NAME}-{SUFFIX}.jsonl', 'w') as outfile:\n",
    "\n",
    "    for batchno, rec_batch in enumerate(batched(test_recs, BATCH_SIZE)):\n",
    "        messages_batch = [rec_to_messages(rec) for rec in rec_batch]\n",
    "        responses = generate(messages_batch)\n",
    "        gt_batch = [rec['conversations'][-1][\"value\"] for rec in rec_batch]\n",
    "\n",
    "        for ground_truth, response in zip(gt_batch, responses):\n",
    "            print(100 * \"-\")\n",
    "            print(\"Ground Truth:\")\n",
    "            print(ground_truth)\n",
    "            print(\"Prediction:\")\n",
    "            print(response)\n",
    "\n",
    "            ground_truth = json.loads(ground_truth)\n",
    "\n",
    "            try:\n",
    "                prediction = json.loads(response)\n",
    "            except json.JSONDecodeError:\n",
    "                prediction = {}\n",
    "        \n",
    "            # rowid is set to unknown as we've lost it somewhere along the way...\n",
    "            record = {\"ground_truth\": ground_truth, \"prediction\": prediction, \"rowid\": \"unknown\"}\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the statistics of the extracted metadata and save to file\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from eval import MetadataEvaluator\n",
    "\n",
    "evaluator = MetadataEvaluator(f'test-records-{MODEL_SHORT_NAME}-{SUFFIX}.jsonl')\n",
    "results = evaluator.evaluate_records() #prediction_records[:9])\n",
    "\n",
    "model_name = MODEL_SHORT_NAME.replace('.', '_')  # avoid . as it causes problems when merging result files\n",
    "\n",
    "statistics_filename = f'../results-axolotl-{model_name}-{SUFFIX}.md'\n",
    "evaluator.save_md(results, statistics_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('merged-Qwen2-0.5B-Instruct-FinGreyLit/tokenizer_config.json',\n",
       " 'merged-Qwen2-0.5B-Instruct-FinGreyLit/special_tokens_map.json',\n",
       " 'merged-Qwen2-0.5B-Instruct-FinGreyLit/vocab.json',\n",
       " 'merged-Qwen2-0.5B-Instruct-FinGreyLit/merges.txt',\n",
       " 'merged-Qwen2-0.5B-Instruct-FinGreyLit/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the merged model to a directory (along with tokenizer)\n",
    "\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "model.save_pretrained(merged_model_dir)\n",
    "tokenizer.save_pretrained(merged_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: merged-Qwen2-0.5B-Instruct\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> F16, shape = {896, 151936}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 32768\n",
      "INFO:hf-to-gguf:gguf: embedding length = 896\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 4864\n",
      "INFO:hf-to-gguf:gguf: head count = 14\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 2\n",
      "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 151387 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 151643\n",
      "INFO:gguf.vocab:Setting special token type eos to 151645\n",
      "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf: n_tensors = 290, total_size = 988.2M\n",
      "Writing: 100%|████████████████████████████| 988M/988M [00:00<00:00, 1.17Gbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf\n",
      "CPU times: user 146 ms, sys: 50.4 ms, total: 196 ms\n",
      "Wall time: 21.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert the merged model to GGUF using llama.cpp tools (installed separately)\n",
    "\n",
    "LLAMA_CPP_PATH = \"../../../llama.cpp\"\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/venv/bin/python {LLAMA_CPP_PATH}/convert_hf_to_gguf.py {merged_model_dir} --outfile {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: build = 3492 (7c27a19b)\n",
      "main: built with cc (GCC) 13.3.0 for x86_64-pc-linux-gnu\n",
      "main: quantizing 'Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf' to 'Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf' as Q4_K_M\n",
      "llama_model_loader: loaded meta data with 25 key-value pairs and 290 tensors from Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2 0.5B Instruct\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Qwen\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   5:                           general.basename str              = Qwen2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 0.5B\n",
      "llama_model_loader: - kv   7:                          qwen2.block_count u32              = 24\n",
      "llama_model_loader: - kv   8:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv   9:                     qwen2.embedding_length u32              = 896\n",
      "llama_model_loader: - kv  10:                  qwen2.feed_forward_length u32              = 4864\n",
      "llama_model_loader: - kv  11:                 qwen2.attention.head_count u32              = 14\n",
      "llama_model_loader: - kv  12:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  13:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  14:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ġ Ġ\", \"ĠĠ ĠĠ\", \"i n\", \"Ġ t\",...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  121 tensors\n",
      "llama_model_loader: - type  f16:  169 tensors\n",
      "[   1/ 290]                    token_embd.weight - [  896, 151936,     1,     1], type =    f16, converting to q8_0 .. size =   259.66 MiB ->   137.94 MiB\n",
      "[   2/ 290]               blk.0.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[   3/ 290]                blk.0.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[   4/ 290]                blk.0.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[   5/ 290]                  blk.0.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[   6/ 290]                blk.0.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[   7/ 290]                    blk.0.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   8/ 290]                  blk.0.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[   9/ 290]             blk.0.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  10/ 290]                    blk.0.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  11/ 290]                  blk.0.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  12/ 290]                    blk.0.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  13/ 290]                  blk.0.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  14/ 290]               blk.1.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  15/ 290]                blk.1.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  16/ 290]                blk.1.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  17/ 290]                  blk.1.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  18/ 290]                blk.1.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  19/ 290]                    blk.1.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  20/ 290]                  blk.1.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  21/ 290]             blk.1.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  22/ 290]                    blk.1.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  23/ 290]                  blk.1.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  24/ 290]                    blk.1.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  25/ 290]                  blk.1.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  26/ 290]              blk.10.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  27/ 290]               blk.10.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  28/ 290]               blk.10.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  29/ 290]                 blk.10.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  30/ 290]               blk.10.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  31/ 290]                   blk.10.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  32/ 290]                 blk.10.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  33/ 290]            blk.10.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  34/ 290]                   blk.10.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  35/ 290]                 blk.10.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  36/ 290]                   blk.10.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  37/ 290]                 blk.10.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  38/ 290]              blk.11.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  39/ 290]               blk.11.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  40/ 290]               blk.11.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  41/ 290]                 blk.11.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  42/ 290]               blk.11.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  43/ 290]                   blk.11.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  44/ 290]                 blk.11.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  45/ 290]            blk.11.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  46/ 290]                   blk.11.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  47/ 290]                 blk.11.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  48/ 290]                   blk.11.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  49/ 290]                 blk.11.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  50/ 290]              blk.12.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  51/ 290]               blk.12.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  52/ 290]               blk.12.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  53/ 290]                 blk.12.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  54/ 290]               blk.12.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  55/ 290]                   blk.12.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  56/ 290]                 blk.12.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  57/ 290]            blk.12.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  58/ 290]                   blk.12.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  59/ 290]                 blk.12.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  60/ 290]                   blk.12.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  61/ 290]                 blk.12.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  62/ 290]              blk.13.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  63/ 290]               blk.13.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  64/ 290]               blk.13.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  65/ 290]                 blk.13.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  66/ 290]               blk.13.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  67/ 290]                   blk.13.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  68/ 290]                 blk.13.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  69/ 290]            blk.13.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  70/ 290]                   blk.13.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  71/ 290]                 blk.13.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  72/ 290]                   blk.13.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  73/ 290]                 blk.13.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  74/ 290]              blk.14.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  75/ 290]               blk.14.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  76/ 290]               blk.14.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  77/ 290]                 blk.14.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  78/ 290]               blk.14.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  79/ 290]                   blk.14.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  80/ 290]                 blk.14.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  81/ 290]            blk.14.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  82/ 290]                   blk.14.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  83/ 290]                 blk.14.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  84/ 290]                   blk.14.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  85/ 290]                 blk.14.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  86/ 290]              blk.15.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  87/ 290]               blk.15.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  88/ 290]               blk.15.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  89/ 290]                 blk.15.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  90/ 290]               blk.15.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  91/ 290]                   blk.15.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  92/ 290]                 blk.15.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  93/ 290]            blk.15.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  94/ 290]                   blk.15.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  95/ 290]                 blk.15.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  96/ 290]                   blk.15.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  97/ 290]                 blk.15.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  98/ 290]              blk.16.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  99/ 290]               blk.16.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 100/ 290]               blk.16.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 101/ 290]                 blk.16.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 102/ 290]               blk.16.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 103/ 290]                   blk.16.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 104/ 290]                 blk.16.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 105/ 290]            blk.16.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 106/ 290]                   blk.16.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 107/ 290]                 blk.16.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 108/ 290]                   blk.16.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 109/ 290]                 blk.16.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 110/ 290]              blk.17.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 111/ 290]               blk.17.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 112/ 290]               blk.17.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 113/ 290]                 blk.17.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 114/ 290]               blk.17.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 115/ 290]                   blk.17.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 116/ 290]                 blk.17.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 117/ 290]            blk.17.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 118/ 290]                   blk.17.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 119/ 290]                 blk.17.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 120/ 290]                   blk.17.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 121/ 290]                 blk.17.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 122/ 290]              blk.18.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 123/ 290]               blk.18.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 124/ 290]               blk.18.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 125/ 290]                 blk.18.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 126/ 290]               blk.18.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 127/ 290]                   blk.18.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 128/ 290]                 blk.18.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 129/ 290]            blk.18.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 130/ 290]                   blk.18.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 131/ 290]                 blk.18.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 132/ 290]                   blk.18.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 133/ 290]                 blk.18.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 134/ 290]              blk.19.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 135/ 290]               blk.19.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 136/ 290]               blk.19.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 137/ 290]                 blk.19.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 138/ 290]               blk.19.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 139/ 290]                   blk.19.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 140/ 290]                 blk.19.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 141/ 290]            blk.19.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 142/ 290]                   blk.19.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 143/ 290]                 blk.19.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 144/ 290]                   blk.19.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 145/ 290]                 blk.19.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 146/ 290]               blk.2.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 147/ 290]                blk.2.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 148/ 290]                blk.2.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 149/ 290]                  blk.2.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 150/ 290]                blk.2.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 151/ 290]                    blk.2.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 152/ 290]                  blk.2.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 153/ 290]             blk.2.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 154/ 290]                    blk.2.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 155/ 290]                  blk.2.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 156/ 290]                    blk.2.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 157/ 290]                  blk.2.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 158/ 290]              blk.20.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 159/ 290]               blk.20.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 160/ 290]               blk.20.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 161/ 290]                 blk.20.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 162/ 290]               blk.20.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 163/ 290]                   blk.20.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 164/ 290]                 blk.20.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 165/ 290]            blk.20.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 166/ 290]                   blk.20.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 167/ 290]                 blk.20.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 168/ 290]                   blk.20.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 169/ 290]                 blk.20.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 170/ 290]              blk.21.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 171/ 290]               blk.21.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 172/ 290]               blk.21.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 173/ 290]                 blk.21.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 174/ 290]               blk.21.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 175/ 290]                   blk.21.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 176/ 290]                 blk.21.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 177/ 290]            blk.21.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 178/ 290]                   blk.21.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 179/ 290]                 blk.21.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 180/ 290]                   blk.21.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 181/ 290]                 blk.21.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 182/ 290]              blk.22.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 183/ 290]               blk.22.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 184/ 290]               blk.22.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 185/ 290]                 blk.22.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 186/ 290]               blk.22.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 187/ 290]                   blk.22.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 188/ 290]                 blk.22.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 189/ 290]            blk.22.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 190/ 290]                   blk.22.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 191/ 290]                 blk.22.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 192/ 290]                   blk.22.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 193/ 290]                 blk.22.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 194/ 290]              blk.23.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 195/ 290]               blk.23.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 196/ 290]               blk.23.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 197/ 290]                 blk.23.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 198/ 290]               blk.23.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 199/ 290]                   blk.23.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 200/ 290]                 blk.23.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 201/ 290]            blk.23.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 202/ 290]                   blk.23.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 203/ 290]                 blk.23.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 204/ 290]                   blk.23.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 205/ 290]                 blk.23.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 206/ 290]               blk.3.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 207/ 290]                blk.3.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 208/ 290]                blk.3.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 209/ 290]                  blk.3.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 210/ 290]                blk.3.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 211/ 290]                    blk.3.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 212/ 290]                  blk.3.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 213/ 290]             blk.3.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 214/ 290]                    blk.3.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 215/ 290]                  blk.3.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 216/ 290]                    blk.3.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 217/ 290]                  blk.3.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 218/ 290]               blk.4.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 219/ 290]                blk.4.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 220/ 290]                blk.4.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 221/ 290]                  blk.4.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 222/ 290]                blk.4.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 223/ 290]                    blk.4.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 224/ 290]                  blk.4.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 225/ 290]             blk.4.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 226/ 290]                    blk.4.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 227/ 290]                  blk.4.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 228/ 290]                    blk.4.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 229/ 290]                  blk.4.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 230/ 290]               blk.5.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 231/ 290]                blk.5.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 232/ 290]                blk.5.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 233/ 290]                  blk.5.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 234/ 290]                blk.5.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 235/ 290]                    blk.5.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 236/ 290]                  blk.5.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 237/ 290]             blk.5.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 238/ 290]                    blk.5.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 239/ 290]                  blk.5.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 240/ 290]                    blk.5.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 241/ 290]                  blk.5.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 242/ 290]               blk.6.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 243/ 290]                blk.6.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 244/ 290]                blk.6.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 245/ 290]                  blk.6.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 246/ 290]                blk.6.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 247/ 290]                    blk.6.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 248/ 290]                  blk.6.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 249/ 290]             blk.6.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 250/ 290]                    blk.6.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 251/ 290]                  blk.6.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 252/ 290]                    blk.6.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 253/ 290]                  blk.6.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 254/ 290]               blk.7.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 255/ 290]                blk.7.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 256/ 290]                blk.7.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 257/ 290]                  blk.7.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 258/ 290]                blk.7.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 259/ 290]                    blk.7.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 260/ 290]                  blk.7.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 261/ 290]             blk.7.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 262/ 290]                    blk.7.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 263/ 290]                  blk.7.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 264/ 290]                    blk.7.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 265/ 290]                  blk.7.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 266/ 290]               blk.8.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 267/ 290]                blk.8.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 268/ 290]                blk.8.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 269/ 290]                  blk.8.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 270/ 290]                blk.8.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 271/ 290]                    blk.8.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 272/ 290]                  blk.8.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 273/ 290]             blk.8.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 274/ 290]                    blk.8.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 275/ 290]                  blk.8.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 276/ 290]                    blk.8.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 277/ 290]                  blk.8.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 278/ 290]               blk.9.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 279/ 290]                blk.9.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 280/ 290]                blk.9.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 281/ 290]                  blk.9.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 282/ 290]                blk.9.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 283/ 290]                    blk.9.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 284/ 290]                  blk.9.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 285/ 290]             blk.9.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 286/ 290]                    blk.9.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 287/ 290]                  blk.9.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 288/ 290]                    blk.9.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 289/ 290]                  blk.9.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 290/ 290]                   output_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "llama_model_quantize_internal: model size  =   942.43 MB\n",
      "llama_model_quantize_internal: quant size  =   373.71 MB\n",
      "llama_model_quantize_internal: WARNING: 144 of 168 tensor(s) required fallback quantization\n",
      "\n",
      "main: quantize time =  3876.16 ms\n",
      "main:    total time =  3876.16 ms\n",
      "CPU times: user 65.2 ms, sys: 45.4 ms, total: 111 ms\n",
      "Wall time: 4.18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Quantize the F16 GGUF model to the 4+ bit Q4_K_M format\n",
    "QTYPE = \"Q4_K_M\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/llama-quantize {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf {MODEL_SHORT_NAME}-{SUFFIX}-{QTYPE}.gguf {QTYPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using `hf_transfer` for faster uploads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
      "Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf: 100%|█| 398M/398M [00:13<00:00, 28.5\n",
      "https://huggingface.co/NatLibFi/Qwen2-0.5B-Instruct-FinGreyLit-GGUF/blob/main/Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "# Upload the quantized GGUF file to HF Hub\n",
    "\n",
    "FINAL_MODEL_NAME = f\"NatLibFi/{MODEL_SHORT_NAME}-{SUFFIX}-GGUF\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/venv/bin/huggingface-cli upload {FINAL_MODEL_NAME} {MODEL_SHORT_NAME}-{SUFFIX}-{QTYPE}.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingreylit-axolotl",
   "language": "python",
   "name": "fingreylit-axolotl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
