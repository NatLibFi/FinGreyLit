{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune Qwen2-0.5B-Instruct model using Axolotl framework\n",
    "\n",
    "How to install dependencies (in HPC environment):\n",
    "\n",
    "- load Python and cuDNN modules\n",
    "- create a Python venv and activate it\n",
    "- install dependencies from requirements.txt (e.g. torch)\n",
    "- install Axolotl from git clone (pip won't work, see [this issue](https://github.com/OpenAccess-AI-Collective/axolotl/issues/945)):\n",
    "\n",
    "```\n",
    "git clone git@github.com:OpenAccess-AI-Collective/axolotl.git\n",
    "cd axolotl\n",
    "pip install -e '.[flash-attn,deepspeed]'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n",
      "BF16 is supported? True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print('GPU available?', torch.cuda.is_available())\n",
    "print('BF16 is supported?', torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name etc.\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2-0.5B-Instruct\"\n",
    "MODEL_SHORT_NAME = MODEL_NAME.split('/')[-1]\n",
    "SUFFIX = \"FinGreyLit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 620 train records\n",
      "Wrote 180 test records\n",
      "Wrote 32 eval records\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare fine-tuning dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of test set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "EVAL_SIZE = 32  # how many documents to evaluate (i.e. calculate loss) on during fine-tuning\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    output = json.dumps(sample[\"ground_truth\"])\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    # ShareGPT format\n",
    "    conversations = [\n",
    "        {'from': 'system', 'value': SYSTEM_PROMPT},\n",
    "        {'from': 'user', 'value': INSTRUCTION + \"\\n\\n\" + input_},\n",
    "        {'from': 'gpt', 'value': output}\n",
    "    ]\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "def write_jsonl(records, filename):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for record in records:\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "train_recs = dataset_to_records(train_files)\n",
    "random.shuffle(train_recs)\n",
    "write_jsonl(train_recs, \"axolotl-train.jsonl\")\n",
    "print(f\"Wrote {len(train_recs)} train records\")\n",
    "\n",
    "test_recs = dataset_to_records(test_files)\n",
    "write_jsonl(test_recs, \"axolotl-test.jsonl\")\n",
    "print(f\"Wrote {len(test_recs)} test records\")\n",
    "\n",
    "eval_recs = random.sample(test_recs, EVAL_SIZE)\n",
    "write_jsonl(eval_recs, \"axolotl-eval.jsonl\")\n",
    "print(f\"Wrote {len(eval_recs)} eval records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Axolotl configuration file\n",
    "\n",
    "CONFIG_FILE = f\"config-{MODEL_SHORT_NAME}.yml\"\n",
    "\n",
    "\n",
    "CONFIG = f\"\"\"\n",
    "base_model: {MODEL_NAME}\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: false\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: axolotl-train.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "test_datasets:\n",
    "  - path: axolotl-eval.jsonl\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    type: sharegpt\n",
    "    conversation: chatml\n",
    "\n",
    "output_dir: ./out-{MODEL_SHORT_NAME}\n",
    "\n",
    "#chat_template: chatml\n",
    "\n",
    "adapter: lora\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "eval_batch_size: 2\n",
    "num_epochs: 8\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: true\n",
    "fp16: false\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true  # true: saves VRAM but is slower to train\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 2\n",
    "eval_table_size:\n",
    "eval_table_max_new_tokens: 128\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "special_tokens:\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as outfile:\n",
    "    print(CONFIG, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024-08-08 15:40:26,698] [INFO] [datasets.<module>:58] [PID:2996755] PyTorch version 2.3.1 available.\n",
      "[2024-08-08 15:40:35,623] [INFO] [axolotl.utils.config.models.input.check_eval_packing:958] [PID:2996755] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "\u001b[33m[2024-08-08 15:40:35,624] [WARNING] [axolotl.utils.config.models.input.hint_lora_8bit:1044] [PID:2996755] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2024-08-08 15:40:36,079] [INFO] [axolotl.normalize_config:183] [PID:2996755] [RANK:0] GPU memory usage baseline: 0.000GB (+0.818GB misc)\u001b[39m\n",
      "                                 dP            dP   dP \n",
      "                                 88            88   88 \n",
      "      .d8888b. dP.  .dP .d8888b. 88 .d8888b. d8888P 88 \n",
      "      88'  `88  `8bd8'  88'  `88 88 88'  `88   88   88 \n",
      "      88.  .88  .d88b.  88.  .88 88 88.  .88   88   88 \n",
      "      `88888P8 dP'  `dP `88888P' dP `88888P'   dP   dP \n",
      "                                                       \n",
      "                                                       \n",
      "\n",
      "****************************************\n",
      "**** Axolotl Dependency Versions *****\n",
      "  accelerate: 0.32.0         \n",
      "        peft: 0.11.1         \n",
      "transformers: 4.43.0.dev0    \n",
      "         trl: 0.9.6          \n",
      "       torch: 2.3.1          \n",
      "bitsandbytes: 0.43.1         \n",
      "****************************************\n",
      "\u001b[33m[2024-08-08 15:40:36,102] [WARNING] [axolotl.scripts.check_accelerate_default_config:468] [PID:2996755] [RANK:0] accelerate config file found at /home/oisuomin/.cache/huggingface/accelerate/default_config.yaml. This can lead to unexpected errors\u001b[39m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-08-08 15:40:36,683] [DEBUG] [axolotl.load_tokenizer:280] [PID:2996755] [RANK:0] EOS: 151645 / <|im_end|>\u001b[39m\n",
      "[2024-08-08 15:40:36,683] [DEBUG] [axolotl.load_tokenizer:281] [PID:2996755] [RANK:0] BOS: None / None\u001b[39m\n",
      "[2024-08-08 15:40:36,683] [DEBUG] [axolotl.load_tokenizer:282] [PID:2996755] [RANK:0] PAD: 151643 / <|endoftext|>\u001b[39m\n",
      "[2024-08-08 15:40:36,683] [DEBUG] [axolotl.load_tokenizer:283] [PID:2996755] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-08-08 15:40:36,683] [INFO] [axolotl.load_tokenizer:294] [PID:2996755] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2024-08-08 15:40:36,683] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:2996755] [RANK:0] Unable to find prepared dataset in last_run_prepared/a483be133f8a1d68761ef634ff3e062f\u001b[39m\n",
      "[2024-08-08 15:40:36,683] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:2996755] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2024-08-08 15:40:36,683] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:2996755] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2024-08-08 15:40:36,683] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:2996755] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 620 examples [00:00, 21966.76 examples/s]\n",
      "[2024-08-08 15:40:37,318] [INFO] [axolotl.get_dataset_wrapper:540] [PID:2996755] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "Tokenizing Prompts (num_proc=64): 100%|â–ˆ| 620/620 [00:07<00:00, 87.48 examples/s\n",
      "[2024-08-08 15:40:44,921] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:2996755] [RANK:0] merging datasets\u001b[39m\n",
      "Dropping Long Sequences (num_proc=128): 100%|â–ˆ| 620/620 [00:01<00:00, 510.41 exa\n",
      "Add position_id column (Sample Packing) (num_proc=128): 100%|â–ˆ| 608/608 [00:02<0\n",
      "[2024-08-08 15:40:50,372] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:2996755] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/a483be133f8a1d68761ef634ff3e062f\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆ| 608/608 [00:00<00:00, 14116.06 examples\n",
      "[2024-08-08 15:40:50,441] [INFO] [axolotl.load_tokenized_prepared_datasets:183] [PID:2996755] [RANK:0] Unable to find prepared dataset in last_run_prepared/216b4dd617b95176c0bbcb3df0e1bccc\u001b[39m\n",
      "[2024-08-08 15:40:50,441] [INFO] [axolotl.load_tokenized_prepared_datasets:184] [PID:2996755] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2024-08-08 15:40:50,442] [WARNING] [axolotl.load_tokenized_prepared_datasets:186] [PID:2996755] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset.\u001b[39m\n",
      "[2024-08-08 15:40:50,442] [INFO] [axolotl.load_tokenized_prepared_datasets:193] [PID:2996755] [RANK:0] No seed provided, using default seed of 42\u001b[39m\n",
      "Generating train split: 32 examples [00:00, 8537.48 examples/s]\n",
      "[2024-08-08 15:40:50,963] [INFO] [axolotl.get_dataset_wrapper:540] [PID:2996755] [RANK:0] Loading dataset with base_type: sharegpt and prompt_style: None\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-08-08 15:40:50,963] [WARNING] [datasets.arrow_dataset.map:3087] [PID:2996755] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Tokenizing Prompts (num_proc=32): 100%|â–ˆâ–ˆ| 32/32 [00:03<00:00,  9.53 examples/s]\n",
      "[2024-08-08 15:40:54,619] [INFO] [axolotl.load_tokenized_prepared_datasets:414] [PID:2996755] [RANK:0] merging datasets\u001b[39m\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-08-08 15:40:54,622] [WARNING] [datasets.arrow_dataset.map:3087] [PID:2996755] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Dropping Long Sequences (num_proc=32): 100%|â–ˆ| 32/32 [00:00<00:00, 114.15 exampl\n",
      "num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "[2024-08-08 15:40:55,146] [WARNING] [datasets.arrow_dataset.map:3087] [PID:2996755] num_proc must be <= 32. Reducing num_proc to 32 for dataset of size 32.\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|â–ˆ| 32/32 [00:00<00:0\n",
      "[2024-08-08 15:40:55,849] [INFO] [axolotl.load_tokenized_prepared_datasets:427] [PID:2996755] [RANK:0] Saving merged prepared dataset to disk... last_run_prepared/216b4dd617b95176c0bbcb3df0e1bccc\u001b[39m\n",
      "Saving the dataset (1/1 shards): 100%|â–ˆ| 32/32 [00:00<00:00, 2638.91 examples/s]\n",
      "[2024-08-08 15:40:55,877] [DEBUG] [axolotl.calculate_total_num_steps:297] [PID:2996755] [RANK:0] total_num_tokens: 869_680\u001b[39m\n",
      "[2024-08-08 15:40:55,885] [DEBUG] [axolotl.calculate_total_num_steps:310] [PID:2996755] [RANK:0] `total_supervised_tokens: 71_711`\u001b[39m\n",
      "[2024-08-08 15:41:01,721] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 1.0 total_num_tokens per device: 869680\u001b[39m\n",
      "[2024-08-08 15:41:01,722] [DEBUG] [axolotl.calculate_total_num_steps:362] [PID:2996755] [RANK:0] data_loader_len: 26\u001b[39m\n",
      "[2024-08-08 15:41:01,722] [INFO] [axolotl.calc_sample_packing_eff_est:368] [PID:2996755] [RANK:0] sample_packing_eff_est across ranks: [0.8921185661764706]\u001b[39m\n",
      "[2024-08-08 15:41:01,722] [DEBUG] [axolotl.calculate_total_num_steps:380] [PID:2996755] [RANK:0] sample_packing_eff_est: 0.9\u001b[39m\n",
      "[2024-08-08 15:41:01,722] [DEBUG] [axolotl.calculate_total_num_steps:388] [PID:2996755] [RANK:0] total_num_steps: 208\u001b[39m\n",
      "[2024-08-08 15:41:01,741] [DEBUG] [axolotl.train.train:66] [PID:2996755] [RANK:0] loading tokenizer... Qwen/Qwen2-0.5B-Instruct\u001b[39m\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "[2024-08-08 15:41:02,182] [DEBUG] [axolotl.load_tokenizer:280] [PID:2996755] [RANK:0] EOS: 151645 / <|im_end|>\u001b[39m\n",
      "[2024-08-08 15:41:02,182] [DEBUG] [axolotl.load_tokenizer:281] [PID:2996755] [RANK:0] BOS: None / None\u001b[39m\n",
      "[2024-08-08 15:41:02,182] [DEBUG] [axolotl.load_tokenizer:282] [PID:2996755] [RANK:0] PAD: 151643 / <|endoftext|>\u001b[39m\n",
      "[2024-08-08 15:41:02,182] [DEBUG] [axolotl.load_tokenizer:283] [PID:2996755] [RANK:0] UNK: None / None\u001b[39m\n",
      "[2024-08-08 15:41:02,182] [INFO] [axolotl.load_tokenizer:294] [PID:2996755] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2024-08-08 15:41:02,182] [DEBUG] [axolotl.train.train:95] [PID:2996755] [RANK:0] loading model and peft_config...\u001b[39m\n",
      "[2024-08-08 15:41:02,187] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:2996755] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[2024-08-08 15:41:03,565] [INFO] [axolotl.load_model:824] [PID:2996755] [RANK:0] converting modules to torch.bfloat16 for flash attention\u001b[39m\n",
      "[2024-08-08 15:41:03,613] [INFO] [axolotl.load_lora:986] [PID:2996755] [RANK:0] found linear modules: ['k_proj', 'o_proj', 'q_proj', 'gate_proj', 'v_proj', 'up_proj', 'down_proj']\u001b[39m\n",
      "trainable params: 8,798,208 || all params: 502,830,976 || trainable%: 1.7497\n",
      "[2024-08-08 15:41:03,757] [INFO] [axolotl.load_model:869] [PID:2996755] [RANK:0] GPU memory usage after adapters: 0.000GB ()\u001b[39m\n",
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/transformers/training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "[2024-08-08 15:41:04,308] [WARNING] [accelerate.utils.other.check_os_kernel:349] [PID:2996755] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[2024-08-08 15:41:05,664] [INFO] [axolotl.train.train:136] [PID:2996755] [RANK:0] Pre-saving adapter config to ./out-Qwen2-0.5B-Instruct\u001b[39m\n",
      "[2024-08-08 15:41:05,784] [INFO] [axolotl.train.train:173] [PID:2996755] [RANK:0] Starting trainer...\u001b[39m\n",
      "[2024-08-08 15:41:05,991] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "[2024-08-08 15:41:05,992] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "  0%|                                                   | 0/224 [00:00<?, ?it/s][2024-08-08 15:41:06,040] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "{'loss': 1.3071, 'grad_norm': 5.15625, 'learning_rate': 2e-05, 'epoch': 0.03}   \n",
      "  0%|â–                                          | 1/224 [00:02<10:12,  2.75s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.45it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.95it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.99it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.58it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.52it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.07it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.25it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:01<00:00,  5.94it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.10it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-08-08 15:41:11,393] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.1950528621673584, 'eval_runtime': 2.6492, 'eval_samples_per_second': 12.079, 'eval_steps_per_second': 6.04, 'epoch': 0.03}\n",
      "  0%|â–                                          | 1/224 [00:05<10:12,  2.75s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.23it/s]\u001b[A\n",
      "                                                                                \u001b[A[2024-08-08 15:41:13,461] [INFO] [axolotl.callbacks.on_step_end:128] [PID:2996755] [RANK:0] GPU memory usage while training: 1.165GB (+17.114GB cache, +1.326GB misc)\u001b[39m\n",
      "{'loss': 1.1341, 'grad_norm': 4.09375, 'learning_rate': 4e-05, 'epoch': 0.07}   \n",
      "{'loss': 1.0651, 'grad_norm': 3.671875, 'learning_rate': 6e-05, 'epoch': 0.1}   \n",
      "{'loss': 1.0783, 'grad_norm': 2.4375, 'learning_rate': 8e-05, 'epoch': 0.14}    \n",
      "{'loss': 1.0184, 'grad_norm': 2.296875, 'learning_rate': 0.0001, 'epoch': 0.17} \n",
      "{'loss': 0.9021, 'grad_norm': 1.7734375, 'learning_rate': 0.00012, 'epoch': 0.21}\n",
      "{'loss': 0.8039, 'grad_norm': 1.6015625, 'learning_rate': 0.00014, 'epoch': 0.24}\n",
      "{'loss': 0.754, 'grad_norm': 1.6484375, 'learning_rate': 0.00016, 'epoch': 0.28}\n",
      "{'loss': 0.492, 'grad_norm': 1.5, 'learning_rate': 0.00018, 'epoch': 0.31}      \n",
      "{'loss': 0.4318, 'grad_norm': 1.3828125, 'learning_rate': 0.0002, 'epoch': 0.35}\n",
      "{'loss': 0.3442, 'grad_norm': 1.21875, 'learning_rate': 0.00019998922457512607, 'epoch': 0.38}\n",
      "{'loss': 0.3466, 'grad_norm': 1.2890625, 'learning_rate': 0.00019995690062269984, 'epoch': 0.42}\n",
      "{'loss': 0.317, 'grad_norm': 1.140625, 'learning_rate': 0.0001999030351088078, 'epoch': 0.45}\n",
      "{'loss': 0.2169, 'grad_norm': 0.78125, 'learning_rate': 0.00019982763964192585, 'epoch': 0.49}\n",
      "  6%|â–ˆâ–ˆâ–‹                                       | 14/224 [00:31<07:06,  2.03s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.39it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.93it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.71it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.35it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  5.99it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.14it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.14it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.89it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.02it/s]\u001b[A[2024-08-08 15:41:40,281] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.29101479053497314, 'eval_runtime': 2.675, 'eval_samples_per_second': 11.963, 'eval_steps_per_second': 5.981, 'epoch': 0.49}\n",
      "  6%|â–ˆâ–ˆâ–‹                                       | 14/224 [00:34<07:06,  2.03s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.18it/s]\u001b[A\n",
      "{'loss': 0.1773, 'grad_norm': 1.1171875, 'learning_rate': 0.00019973073047041778, 'epoch': 0.52}\n",
      "{'loss': 0.2237, 'grad_norm': 0.85546875, 'learning_rate': 0.0001996123284790336, 'epoch': 0.56}\n",
      "{'loss': 0.267, 'grad_norm': 1.0625, 'learning_rate': 0.0001994724591844085, 'epoch': 0.59}\n",
      "{'loss': 0.1377, 'grad_norm': 0.64453125, 'learning_rate': 0.00019931115272956405, 'epoch': 0.63}\n",
      "{'loss': 0.2008, 'grad_norm': 0.81640625, 'learning_rate': 0.00019912844387741195, 'epoch': 0.66}\n",
      "{'loss': 0.2109, 'grad_norm': 0.7421875, 'learning_rate': 0.0001989243720032624, 'epoch': 0.7}\n",
      "{'loss': 0.2118, 'grad_norm': 0.6875, 'learning_rate': 0.00019869898108633836, 'epoch': 0.73}\n",
      "{'loss': 0.188, 'grad_norm': 1.03125, 'learning_rate': 0.00019845231970029773, 'epoch': 0.77}\n",
      "{'loss': 0.1801, 'grad_norm': 0.765625, 'learning_rate': 0.00019818444100276516, 'epoch': 0.8}\n",
      "{'loss': 0.1472, 'grad_norm': 0.77734375, 'learning_rate': 0.0001978954027238763, 'epoch': 0.83}\n",
      "{'loss': 0.1704, 'grad_norm': 0.73828125, 'learning_rate': 0.00019758526715383628, 'epoch': 0.87}\n",
      "{'loss': 0.2475, 'grad_norm': 0.96484375, 'learning_rate': 0.0001972541011294959, 'epoch': 0.9}\n",
      "{'loss': 0.1331, 'grad_norm': 0.8046875, 'learning_rate': 0.0001969019760199474, 'epoch': 0.94}\n",
      "{'loss': 0.0971, 'grad_norm': 0.62890625, 'learning_rate': 0.00019652896771114414, 'epoch': 0.97}\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                    | 28/224 [01:02<06:36,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.37it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.88it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.54it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.49it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:01,  5.39it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  5.59it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  5.80it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.65it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  5.86it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  5.91it/s]\u001b[A[2024-08-08 15:42:11,247] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.20808567106723785, 'eval_runtime': 2.7696, 'eval_samples_per_second': 11.554, 'eval_steps_per_second': 5.777, 'epoch': 0.97}\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                    | 28/224 [01:05<06:36,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.10it/s]\u001b[A\n",
      "{'loss': 0.1705, 'grad_norm': 0.69921875, 'learning_rate': 0.00019613515658954624, 'epoch': 1.01}\n",
      "{'loss': 0.1433, 'grad_norm': 0.9609375, 'learning_rate': 0.00019572062752479683, 'epoch': 1.04}\n",
      " 13%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹                                    | 30/224 [01:10<08:57,  2.77s/it][2024-08-08 15:42:16,448] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "{'loss': 0.0876, 'grad_norm': 0.5078125, 'learning_rate': 0.0001952854698514318, 'epoch': 1.03}\n",
      "{'loss': 0.1603, 'grad_norm': 0.6875, 'learning_rate': 0.00019482977734962753, 'epoch': 1.06}\n",
      "{'loss': 0.1161, 'grad_norm': 0.51171875, 'learning_rate': 0.00019435364822499037, 'epoch': 1.1}\n",
      "{'loss': 0.1282, 'grad_norm': 0.51171875, 'learning_rate': 0.00019385718508739262, 'epoch': 1.13}\n",
      "{'loss': 0.1203, 'grad_norm': 0.455078125, 'learning_rate': 0.00019334049492885903, 'epoch': 1.17}\n",
      "{'loss': 0.1802, 'grad_norm': 0.65625, 'learning_rate': 0.00019280368910050942, 'epoch': 1.2}\n",
      "{'loss': 0.1146, 'grad_norm': 0.6484375, 'learning_rate': 0.00019224688328856127, 'epoch': 1.23}\n",
      "{'loss': 0.0776, 'grad_norm': 0.51953125, 'learning_rate': 0.00019167019748939846, 'epoch': 1.27}\n",
      "{'loss': 0.1321, 'grad_norm': 0.6328125, 'learning_rate': 0.00019107375598371112, 'epoch': 1.3}\n",
      "{'loss': 0.1596, 'grad_norm': 0.58984375, 'learning_rate': 0.00019045768730971196, 'epoch': 1.34}\n",
      "{'loss': 0.1004, 'grad_norm': 0.486328125, 'learning_rate': 0.00018982212423543528, 'epoch': 1.37}\n",
      "{'loss': 0.0979, 'grad_norm': 0.51953125, 'learning_rate': 0.00018916720373012426, 'epoch': 1.41}\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  | 42/224 [01:34<06:06,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.36it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.88it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.76it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.53it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.07it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.21it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.25it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:01<00:00,  5.95it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.09it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-08-08 15:42:42,710] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18727552890777588, 'eval_runtime': 2.6508, 'eval_samples_per_second': 12.072, 'eval_steps_per_second': 6.036, 'epoch': 1.41}\n",
      " 19%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                                  | 42/224 [01:36<06:06,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.22it/s]\u001b[A\n",
      "{'loss': 0.0751, 'grad_norm': 0.37890625, 'learning_rate': 0.00018849306693471295, 'epoch': 1.44}\n",
      "{'loss': 0.0686, 'grad_norm': 0.4296875, 'learning_rate': 0.00018779985913140924, 'epoch': 1.48}\n",
      "{'loss': 0.0994, 'grad_norm': 0.494140625, 'learning_rate': 0.00018708772971238528, 'epoch': 1.51}\n",
      "{'loss': 0.0735, 'grad_norm': 0.478515625, 'learning_rate': 0.00018635683214758214, 'epoch': 1.55}\n",
      "{'loss': 0.0839, 'grad_norm': 0.41796875, 'learning_rate': 0.00018560732395163582, 'epoch': 1.58}\n",
      "{'loss': 0.0641, 'grad_norm': 0.412109375, 'learning_rate': 0.0001848393666499315, 'epoch': 1.62}\n",
      "{'loss': 0.0946, 'grad_norm': 0.6953125, 'learning_rate': 0.0001840531257437934, 'epoch': 1.65}\n",
      "{'loss': 0.0903, 'grad_norm': 0.515625, 'learning_rate': 0.00018324877067481783, 'epoch': 1.69}\n",
      "{'loss': 0.0802, 'grad_norm': 0.54296875, 'learning_rate': 0.00018242647478835717, 'epoch': 1.72}\n",
      "{'loss': 0.0813, 'grad_norm': 0.421875, 'learning_rate': 0.0001815864152961624, 'epoch': 1.76}\n",
      "{'loss': 0.1312, 'grad_norm': 0.61328125, 'learning_rate': 0.00018072877323819245, 'epoch': 1.79}\n",
      "{'loss': 0.1063, 'grad_norm': 0.39453125, 'learning_rate': 0.0001798537334435986, 'epoch': 1.83}\n",
      "{'loss': 0.1031, 'grad_norm': 0.5390625, 'learning_rate': 0.00017896148449089228, 'epoch': 1.86}\n",
      "{'loss': 0.1618, 'grad_norm': 0.59765625, 'learning_rate': 0.00017805221866730458, 'epoch': 1.9}\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 56/224 [02:04<05:40,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.44it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.54it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.45it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  5.04it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:01,  5.41it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  5.61it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  5.83it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.68it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  5.88it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  5.93it/s]\u001b[A[2024-08-08 15:43:13,670] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1710321605205536, 'eval_runtime': 2.7634, 'eval_samples_per_second': 11.58, 'eval_steps_per_second': 5.79, 'epoch': 1.9}\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                               | 56/224 [02:07<05:40,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.11it/s]\u001b[A\n",
      "{'loss': 0.0832, 'grad_norm': 0.419921875, 'learning_rate': 0.00017712613192734703, 'epoch': 1.93}\n",
      "{'loss': 0.0927, 'grad_norm': 0.5546875, 'learning_rate': 0.00017618342385058145, 'epoch': 1.97}\n",
      "{'loss': 0.0904, 'grad_norm': 0.474609375, 'learning_rate': 0.000175224297598609, 'epoch': 2.0}\n",
      "{'loss': 0.0905, 'grad_norm': 0.54296875, 'learning_rate': 0.00017424895987128722, 'epoch': 2.03}\n",
      " 27%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                              | 60/224 [02:16<06:28,  2.37s/it][2024-08-08 15:43:23,243] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "{'loss': 0.0694, 'grad_norm': 0.455078125, 'learning_rate': 0.00017325762086218416, 'epoch': 2.02}\n",
      "{'loss': 0.0729, 'grad_norm': 0.44140625, 'learning_rate': 0.00017225049421328023, 'epoch': 2.05}\n",
      "{'loss': 0.0973, 'grad_norm': 0.41796875, 'learning_rate': 0.00017122779696892627, 'epoch': 2.09}\n",
      "{'loss': 0.0363, 'grad_norm': 0.4453125, 'learning_rate': 0.00017018974952906884, 'epoch': 2.12}\n",
      "{'loss': 0.0522, 'grad_norm': 0.57421875, 'learning_rate': 0.00016913657560175196, 'epoch': 2.16}\n",
      "{'loss': 0.0668, 'grad_norm': 0.357421875, 'learning_rate': 0.0001680685021549063, 'epoch': 2.19}\n",
      "{'loss': 0.0795, 'grad_norm': 0.396484375, 'learning_rate': 0.00016698575936743558, 'epoch': 2.23}\n",
      "{'loss': 0.0617, 'grad_norm': 0.349609375, 'learning_rate': 0.00016588858057961113, 'epoch': 2.26}\n",
      "{'loss': 0.0896, 'grad_norm': 0.40234375, 'learning_rate': 0.00016477720224278492, 'epoch': 2.3}\n",
      "{'loss': 0.0656, 'grad_norm': 0.375, 'learning_rate': 0.0001636518638684325, 'epoch': 2.33}\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 70/224 [02:36<05:10,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.41it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.95it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.49it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.08it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.21it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.26it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:01<00:00,  5.95it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.10it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-08-08 15:43:44,966] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.16809368133544922, 'eval_runtime': 2.6487, 'eval_samples_per_second': 12.081, 'eval_steps_per_second': 6.041, 'epoch': 2.33}\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                            | 70/224 [02:38<05:10,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.22it/s]\u001b[A\n",
      "{'loss': 0.051, 'grad_norm': 0.353515625, 'learning_rate': 0.00016251280797653606, 'epoch': 2.37}\n",
      "{'loss': 0.0608, 'grad_norm': 0.353515625, 'learning_rate': 0.0001613602800433194, 'epoch': 2.4}\n",
      "{'loss': 0.0463, 'grad_norm': 0.294921875, 'learning_rate': 0.00016019452844834572, 'epoch': 2.43}\n",
      "{'loss': 0.0253, 'grad_norm': 0.2314453125, 'learning_rate': 0.00015901580442098968, 'epoch': 2.47}\n",
      "{'loss': 0.0585, 'grad_norm': 0.322265625, 'learning_rate': 0.0001578243619862954, 'epoch': 2.5}\n",
      "{'loss': 0.037, 'grad_norm': 0.3203125, 'learning_rate': 0.00015662045791023173, 'epoch': 2.54}\n",
      "{'loss': 0.06, 'grad_norm': 0.341796875, 'learning_rate': 0.00015540435164435726, 'epoch': 2.57}\n",
      "{'loss': 0.0977, 'grad_norm': 0.64453125, 'learning_rate': 0.00015417630526990615, 'epoch': 2.61}\n",
      "{'loss': 0.0519, 'grad_norm': 0.498046875, 'learning_rate': 0.00015293658344130734, 'epoch': 2.64}\n",
      "{'loss': 0.0643, 'grad_norm': 0.494140625, 'learning_rate': 0.0001516854533291494, 'epoch': 2.68}\n",
      "{'loss': 0.0642, 'grad_norm': 0.44140625, 'learning_rate': 0.00015042318456260305, 'epoch': 2.71}\n",
      "{'loss': 0.0734, 'grad_norm': 0.59765625, 'learning_rate': 0.00014915004917131344, 'epoch': 2.75}\n",
      "{'loss': 0.0646, 'grad_norm': 0.453125, 'learning_rate': 0.00014786632152677596, 'epoch': 2.78}\n",
      "{'loss': 0.0518, 'grad_norm': 0.421875, 'learning_rate': 0.00014657227828320635, 'epoch': 2.82}\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 84/224 [03:07<04:43,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.35it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.85it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.91it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.75it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.53it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  4.61it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:01,  5.13it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  5.45it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  5.70it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.60it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  5.83it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  5.89it/s]\u001b[A[2024-08-08 15:44:15,947] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1675075888633728, 'eval_runtime': 2.8116, 'eval_samples_per_second': 11.382, 'eval_steps_per_second': 5.691, 'epoch': 2.82}\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                          | 84/224 [03:09<04:43,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.08it/s]\u001b[A\n",
      "{'loss': 0.0749, 'grad_norm': 0.384765625, 'learning_rate': 0.00014526819831791983, 'epoch': 2.85}\n",
      "{'loss': 0.053, 'grad_norm': 0.47265625, 'learning_rate': 0.00014395436267123016, 'epoch': 2.89}\n",
      "{'loss': 0.0599, 'grad_norm': 0.37890625, 'learning_rate': 0.0001426310544858836, 'epoch': 2.92}\n",
      "{'loss': 0.0609, 'grad_norm': 0.4296875, 'learning_rate': 0.00014129855894603886, 'epoch': 2.96}\n",
      "{'loss': 0.0385, 'grad_norm': 0.3671875, 'learning_rate': 0.0001399571632158076, 'epoch': 2.99}\n",
      "{'loss': 0.0939, 'grad_norm': 0.5703125, 'learning_rate': 0.00013860715637736818, 'epoch': 3.03}\n",
      " 40%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                         | 90/224 [03:22<04:52,  2.18s/it][2024-08-08 15:44:30,090] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "{'loss': 0.0625, 'grad_norm': 0.328125, 'learning_rate': 0.00013724882936866595, 'epoch': 3.01}\n",
      "{'loss': 0.0529, 'grad_norm': 0.2734375, 'learning_rate': 0.0001358824749207136, 'epoch': 3.04}\n",
      "{'loss': 0.0381, 'grad_norm': 0.232421875, 'learning_rate': 0.0001345083874945053, 'epoch': 3.08}\n",
      "{'loss': 0.0464, 'grad_norm': 0.392578125, 'learning_rate': 0.00013312686321755761, 'epoch': 3.11}\n",
      "{'loss': 0.0344, 'grad_norm': 0.2373046875, 'learning_rate': 0.0001317381998200917, 'epoch': 3.15}\n",
      "{'loss': 0.0337, 'grad_norm': 0.2333984375, 'learning_rate': 0.00013034269657086992, 'epoch': 3.18}\n",
      "{'loss': 0.0306, 'grad_norm': 0.2373046875, 'learning_rate': 0.0001289406542127007, 'epoch': 3.22}\n",
      "{'loss': 0.0218, 'grad_norm': 0.2177734375, 'learning_rate': 0.000127532374897626, 'epoch': 3.25}\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 98/224 [03:38<04:14,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.42it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.89it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.93it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.77it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.54it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.47it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.23it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:01<00:00,  5.94it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.07it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.04it/s]\u001b[A[2024-08-08 15:44:47,343] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17152151465415955, 'eval_runtime': 2.6549, 'eval_samples_per_second': 12.053, 'eval_steps_per_second': 6.027, 'epoch': 3.25}\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                       | 98/224 [03:41<04:14,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.20it/s]\u001b[A\n",
      "{'loss': 0.0533, 'grad_norm': 0.359375, 'learning_rate': 0.0001261181621218051, 'epoch': 3.29}\n",
      "{'loss': 0.047, 'grad_norm': 0.283203125, 'learning_rate': 0.00012469832066010843, 'epoch': 3.32}\n",
      "{'loss': 0.0311, 'grad_norm': 0.34765625, 'learning_rate': 0.00012327315650043606, 'epoch': 3.36}\n",
      "{'loss': 0.0341, 'grad_norm': 0.25390625, 'learning_rate': 0.00012184297677777463, 'epoch': 3.39}\n",
      "{'loss': 0.0213, 'grad_norm': 0.24609375, 'learning_rate': 0.00012040808970800741, 'epoch': 3.43}\n",
      "{'loss': 0.0325, 'grad_norm': 0.291015625, 'learning_rate': 0.00011896880452149077, 'epoch': 3.46}\n",
      "{'loss': 0.0446, 'grad_norm': 0.380859375, 'learning_rate': 0.00011752543139641277, 'epoch': 3.5}\n",
      "{'loss': 0.0238, 'grad_norm': 0.2333984375, 'learning_rate': 0.00011607828139194683, 'epoch': 3.53}\n",
      "{'loss': 0.0289, 'grad_norm': 0.236328125, 'learning_rate': 0.00011462766638121609, 'epoch': 3.57}\n",
      "{'loss': 0.06, 'grad_norm': 0.322265625, 'learning_rate': 0.00011317389898408189, 'epoch': 3.6}\n",
      "{'loss': 0.0336, 'grad_norm': 0.3359375, 'learning_rate': 0.00011171729249977169, 'epoch': 3.63}\n",
      "{'loss': 0.0489, 'grad_norm': 0.388671875, 'learning_rate': 0.00011025816083936036, 'epoch': 3.67}\n",
      "{'loss': 0.0312, 'grad_norm': 0.298828125, 'learning_rate': 0.00010879681845811964, 'epoch': 3.7}\n",
      "{'loss': 0.0357, 'grad_norm': 0.296875, 'learning_rate': 0.0001073335802877504, 'epoch': 3.74}\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 112/224 [04:09<03:46,  2.03s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.41it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.50it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  4.72it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:01,  5.15it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  5.46it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  5.71it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.60it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  5.83it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  5.89it/s]\u001b[A[2024-08-08 15:45:18,388] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1777370721101761, 'eval_runtime': 2.7997, 'eval_samples_per_second': 11.43, 'eval_steps_per_second': 5.715, 'epoch': 3.74}\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                    | 112/224 [04:12<03:46,  2.03s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.08it/s]\u001b[A\n",
      "{'loss': 0.0253, 'grad_norm': 0.4140625, 'learning_rate': 0.00010586876166851223, 'epoch': 3.77}\n",
      "{'loss': 0.0331, 'grad_norm': 0.359375, 'learning_rate': 0.00010440267828126478, 'epoch': 3.81}\n",
      "{'loss': 0.0243, 'grad_norm': 0.337890625, 'learning_rate': 0.00010293564607943609, 'epoch': 3.84}\n",
      "{'loss': 0.0607, 'grad_norm': 0.404296875, 'learning_rate': 0.00010146798122093166, 'epoch': 3.88}\n",
      "{'loss': 0.0353, 'grad_norm': 0.3671875, 'learning_rate': 0.0001, 'epoch': 3.91}\n",
      "{'loss': 0.0542, 'grad_norm': 0.330078125, 'learning_rate': 9.853201877906836e-05, 'epoch': 3.95}\n",
      "{'loss': 0.0731, 'grad_norm': 0.8828125, 'learning_rate': 9.706435392056394e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0276, 'grad_norm': 0.3671875, 'learning_rate': 9.559732171873523e-05, 'epoch': 4.02}\n",
      " 54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                   | 120/224 [04:29<03:38,  2.10s/it][2024-08-08 15:45:35,589] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "{'loss': 0.018, 'grad_norm': 0.2890625, 'learning_rate': 9.41312383314878e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0536, 'grad_norm': 0.357421875, 'learning_rate': 9.266641971224963e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0175, 'grad_norm': 0.283203125, 'learning_rate': 9.120318154188039e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0306, 'grad_norm': 0.3125, 'learning_rate': 8.974183916063968e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0186, 'grad_norm': 0.2109375, 'learning_rate': 8.828270750022832e-05, 'epoch': 4.17}\n",
      "{'loss': 0.0317, 'grad_norm': 0.28125, 'learning_rate': 8.682610101591814e-05, 'epoch': 4.2}\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 126/224 [04:41<03:18,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.43it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.91it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.48it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.33it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  5.98it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.13it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.13it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.21it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.92it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.07it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.06it/s]\u001b[A[2024-08-08 15:45:49,807] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17889504134655, 'eval_runtime': 2.6638, 'eval_samples_per_second': 12.013, 'eval_steps_per_second': 6.006, 'epoch': 4.2}\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                  | 126/224 [04:43<03:18,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.21it/s]\u001b[A\n",
      "{'loss': 0.0254, 'grad_norm': 0.28125, 'learning_rate': 8.537233361878393e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0237, 'grad_norm': 0.26171875, 'learning_rate': 8.392171860805319e-05, 'epoch': 4.27}\n",
      "{'loss': 0.0201, 'grad_norm': 0.375, 'learning_rate': 8.247456860358725e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0258, 'grad_norm': 0.27734375, 'learning_rate': 8.103119547850924e-05, 'epoch': 4.34}\n",
      "{'loss': 0.0321, 'grad_norm': 0.3125, 'learning_rate': 7.959191029199261e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0299, 'grad_norm': 0.232421875, 'learning_rate': 7.815702322222538e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0259, 'grad_norm': 0.333984375, 'learning_rate': 7.672684349956399e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0086, 'grad_norm': 0.240234375, 'learning_rate': 7.530167933989161e-05, 'epoch': 4.48}\n",
      "{'loss': 0.0141, 'grad_norm': 0.365234375, 'learning_rate': 7.388183787819492e-05, 'epoch': 4.51}\n",
      "{'loss': 0.0165, 'grad_norm': 0.2099609375, 'learning_rate': 7.246762510237403e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0404, 'grad_norm': 0.392578125, 'learning_rate': 7.105934578729933e-05, 'epoch': 4.58}\n",
      "{'loss': 0.037, 'grad_norm': 0.3671875, 'learning_rate': 6.96573034291301e-05, 'epoch': 4.62}\n",
      "{'loss': 0.0303, 'grad_norm': 0.357421875, 'learning_rate': 6.826180017990828e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0337, 'grad_norm': 0.267578125, 'learning_rate': 6.687313678244242e-05, 'epoch': 4.69}\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 140/224 [05:12<02:49,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.42it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.91it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.80it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.56it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.51it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  4.74it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:01,  5.16it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  5.47it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  5.72it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.62it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  5.84it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  5.90it/s]\u001b[A[2024-08-08 15:46:20,795] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18609632551670074, 'eval_runtime': 2.7954, 'eval_samples_per_second': 11.447, 'eval_steps_per_second': 5.724, 'epoch': 4.69}\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹               | 140/224 [05:14<02:49,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.09it/s]\u001b[A\n",
      "{'loss': 0.0299, 'grad_norm': 0.27734375, 'learning_rate': 6.549161250549474e-05, 'epoch': 4.72}\n",
      "{'loss': 0.0179, 'grad_norm': 0.2275390625, 'learning_rate': 6.411752507928642e-05, 'epoch': 4.76}\n",
      "{'loss': 0.0389, 'grad_norm': 0.478515625, 'learning_rate': 6.275117063133409e-05, 'epoch': 4.79}\n",
      "{'loss': 0.0154, 'grad_norm': 0.2119140625, 'learning_rate': 6.139284362263185e-05, 'epoch': 4.83}\n",
      "{'loss': 0.0378, 'grad_norm': 0.390625, 'learning_rate': 6.0042836784192426e-05, 'epoch': 4.86}\n",
      "{'loss': 0.028, 'grad_norm': 0.2216796875, 'learning_rate': 5.870144105396118e-05, 'epoch': 4.9}\n",
      "{'loss': 0.0116, 'grad_norm': 0.189453125, 'learning_rate': 5.736894551411642e-05, 'epoch': 4.93}\n",
      "{'loss': 0.0325, 'grad_norm': 0.4140625, 'learning_rate': 5.604563732876989e-05, 'epoch': 4.97}\n",
      "{'loss': 0.0325, 'grad_norm': 0.29296875, 'learning_rate': 5.4731801682080206e-05, 'epoch': 5.0}\n",
      "{'loss': 0.0159, 'grad_norm': 0.2138671875, 'learning_rate': 5.342772171679364e-05, 'epoch': 5.03}\n",
      " 67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–             | 150/224 [05:35<02:32,  2.06s/it][2024-08-08 15:46:41,852] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "{'loss': 0.0219, 'grad_norm': 0.2197265625, 'learning_rate': 5.213367847322408e-05, 'epoch': 5.03}\n",
      "{'loss': 0.0203, 'grad_norm': 0.177734375, 'learning_rate': 5.084995082868658e-05, 'epoch': 5.06}\n",
      "{'loss': 0.0097, 'grad_norm': 0.140625, 'learning_rate': 4.9576815437396976e-05, 'epoch': 5.1}\n",
      "{'loss': 0.0186, 'grad_norm': 0.177734375, 'learning_rate': 4.8314546670850594e-05, 'epoch': 5.13}\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 154/224 [05:43<02:20,  2.01s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.42it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.91it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.80it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.57it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.51it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  4.92it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:01,  5.31it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  5.55it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  5.77it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.63it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  5.86it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  5.91it/s]\u001b[A[2024-08-08 15:46:52,151] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18346205353736877, 'eval_runtime': 2.7762, 'eval_samples_per_second': 11.526, 'eval_steps_per_second': 5.763, 'epoch': 5.13}\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–            | 154/224 [05:46<02:20,  2.01s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.10it/s]\u001b[A\n",
      "{'loss': 0.0237, 'grad_norm': 0.2119140625, 'learning_rate': 4.70634165586927e-05, 'epoch': 5.17}\n",
      "{'loss': 0.0081, 'grad_norm': 0.12158203125, 'learning_rate': 4.58236947300939e-05, 'epoch': 5.2}\n",
      "{'loss': 0.0062, 'grad_norm': 0.1494140625, 'learning_rate': 4.459564835564275e-05, 'epoch': 5.23}\n",
      "{'loss': 0.0266, 'grad_norm': 0.2158203125, 'learning_rate': 4.3379542089768296e-05, 'epoch': 5.27}\n",
      "{'loss': 0.0292, 'grad_norm': 0.1513671875, 'learning_rate': 4.2175638013704655e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0207, 'grad_norm': 0.173828125, 'learning_rate': 4.0984195579010357e-05, 'epoch': 5.34}\n",
      "{'loss': 0.0166, 'grad_norm': 0.212890625, 'learning_rate': 3.9805471551654294e-05, 'epoch': 5.37}\n",
      "{'loss': 0.0204, 'grad_norm': 0.2109375, 'learning_rate': 3.863971995668062e-05, 'epoch': 5.41}\n",
      "{'loss': 0.014, 'grad_norm': 0.1279296875, 'learning_rate': 3.7487192023463965e-05, 'epoch': 5.44}\n",
      "{'loss': 0.0145, 'grad_norm': 0.212890625, 'learning_rate': 3.634813613156753e-05, 'epoch': 5.48}\n",
      "{'loss': 0.0215, 'grad_norm': 0.21875, 'learning_rate': 3.522279775721509e-05, 'epoch': 5.51}\n",
      "{'loss': 0.0215, 'grad_norm': 0.216796875, 'learning_rate': 3.41114194203889e-05, 'epoch': 5.55}\n",
      "{'loss': 0.0204, 'grad_norm': 0.40234375, 'learning_rate': 3.3014240632564445e-05, 'epoch': 5.58}\n",
      "{'loss': 0.0106, 'grad_norm': 0.1884765625, 'learning_rate': 3.193149784509375e-05, 'epoch': 5.62}\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 168/224 [06:14<01:53,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.41it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.96it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.55it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.49it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  4.70it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:01,  5.12it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  5.44it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  5.69it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.59it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  5.83it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  5.89it/s]\u001b[A[2024-08-08 15:47:23,191] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18667319416999817, 'eval_runtime': 2.8042, 'eval_samples_per_second': 11.411, 'eval_steps_per_second': 5.706, 'epoch': 5.62}\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š          | 168/224 [06:17<01:53,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.09it/s]\u001b[A\n",
      "{'loss': 0.0237, 'grad_norm': 0.2294921875, 'learning_rate': 3.0863424398248064e-05, 'epoch': 5.65}\n",
      "{'loss': 0.0127, 'grad_norm': 0.216796875, 'learning_rate': 2.9810250470931177e-05, 'epoch': 5.69}\n",
      "{'loss': 0.014, 'grad_norm': 0.23828125, 'learning_rate': 2.877220303107373e-05, 'epoch': 5.72}\n",
      "{'loss': 0.0135, 'grad_norm': 0.1328125, 'learning_rate': 2.77495057867198e-05, 'epoch': 5.76}\n",
      "{'loss': 0.0114, 'grad_norm': 0.1630859375, 'learning_rate': 2.674237913781583e-05, 'epoch': 5.79}\n",
      "{'loss': 0.0139, 'grad_norm': 0.1875, 'learning_rate': 2.57510401287128e-05, 'epoch': 5.83}\n",
      "{'loss': 0.0145, 'grad_norm': 0.205078125, 'learning_rate': 2.4775702401391e-05, 'epoch': 5.86}\n",
      "{'loss': 0.0079, 'grad_norm': 0.2353515625, 'learning_rate': 2.381657614941858e-05, 'epoch': 5.9}\n",
      "{'loss': 0.0124, 'grad_norm': 0.1650390625, 'learning_rate': 2.287386807265297e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0245, 'grad_norm': 0.2294921875, 'learning_rate': 2.1947781332695404e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0279, 'grad_norm': 0.3359375, 'learning_rate': 2.1038515509107736e-05, 'epoch': 6.0}\n",
      "{'loss': 0.0223, 'grad_norm': 0.236328125, 'learning_rate': 2.0146266556401405e-05, 'epoch': 6.03}\n",
      " 80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 180/224 [06:42<01:29,  2.04s/it][2024-08-08 15:47:48,999] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "{'loss': 0.0126, 'grad_norm': 0.140625, 'learning_rate': 1.927122676180756e-05, 'epoch': 6.03}\n",
      "{'loss': 0.0117, 'grad_norm': 0.1669921875, 'learning_rate': 1.8413584703837615e-05, 'epoch': 6.07}\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 182/224 [06:47<01:25,  2.03s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 11.97it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.83it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.90it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.75it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.52it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.48it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.06it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.24it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:01<00:00,  5.93it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.08it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.06it/s]\u001b[A[2024-08-08 15:47:55,671] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19162937998771667, 'eval_runtime': 2.6697, 'eval_samples_per_second': 11.986, 'eval_steps_per_second': 5.993, 'epoch': 6.07}\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž       | 182/224 [06:49<01:25,  2.03s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.21it/s]\u001b[A\n",
      "{'loss': 0.0099, 'grad_norm': 0.2578125, 'learning_rate': 1.757352521164284e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0085, 'grad_norm': 0.1015625, 'learning_rate': 1.6751229325182195e-05, 'epoch': 6.14}\n",
      "{'loss': 0.0331, 'grad_norm': 0.205078125, 'learning_rate': 1.5946874256206613e-05, 'epoch': 6.17}\n",
      "{'loss': 0.0173, 'grad_norm': 0.197265625, 'learning_rate': 1.5160633350068509e-05, 'epoch': 6.21}\n",
      "{'loss': 0.0194, 'grad_norm': 0.216796875, 'learning_rate': 1.4392676048364195e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0158, 'grad_norm': 0.1484375, 'learning_rate': 1.3643167852417893e-05, 'epoch': 6.28}\n",
      "{'loss': 0.0072, 'grad_norm': 0.12890625, 'learning_rate': 1.2912270287614736e-05, 'epoch': 6.31}\n",
      "{'loss': 0.0181, 'grad_norm': 0.1748046875, 'learning_rate': 1.2200140868590759e-05, 'epoch': 6.35}\n",
      "{'loss': 0.0196, 'grad_norm': 0.1904296875, 'learning_rate': 1.1506933065287062e-05, 'epoch': 6.38}\n",
      "{'loss': 0.0171, 'grad_norm': 0.1962890625, 'learning_rate': 1.0832796269875756e-05, 'epoch': 6.42}\n",
      "{'loss': 0.0147, 'grad_norm': 0.2021484375, 'learning_rate': 1.0177875764564714e-05, 'epoch': 6.45}\n",
      "{'loss': 0.0211, 'grad_norm': 0.1845703125, 'learning_rate': 9.542312690288036e-06, 'epoch': 6.49}\n",
      "{'loss': 0.0196, 'grad_norm': 0.2041015625, 'learning_rate': 8.926244016288899e-06, 'epoch': 6.52}\n",
      "{'loss': 0.0103, 'grad_norm': 0.1611328125, 'learning_rate': 8.329802510601559e-06, 'epoch': 6.56}\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 196/224 [07:18<00:56,  2.02s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.37it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.88it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.78it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.53it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.49it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.07it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.17it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.23it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:01<00:00,  5.92it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.07it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.06it/s]\u001b[A[2024-08-08 15:48:26,655] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19290871918201447, 'eval_runtime': 2.6531, 'eval_samples_per_second': 12.062, 'eval_steps_per_second': 6.031, 'epoch': 6.56}\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 196/224 [07:20<00:56,  2.02s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.21it/s]\u001b[A\n",
      "{'loss': 0.0127, 'grad_norm': 0.189453125, 'learning_rate': 7.753116711438747e-06, 'epoch': 6.59}\n",
      "{'loss': 0.0134, 'grad_norm': 0.140625, 'learning_rate': 7.196310899490577e-06, 'epoch': 6.63}\n",
      "{'loss': 0.0138, 'grad_norm': 0.322265625, 'learning_rate': 6.659505071140959e-06, 'epoch': 6.66}\n",
      "{'loss': 0.0104, 'grad_norm': 0.130859375, 'learning_rate': 6.142814912607409e-06, 'epoch': 6.7}\n",
      "{'loss': 0.0041, 'grad_norm': 0.07958984375, 'learning_rate': 5.646351775009617e-06, 'epoch': 6.73}\n",
      "{'loss': 0.0119, 'grad_norm': 0.1826171875, 'learning_rate': 5.170222650372469e-06, 'epoch': 6.77}\n",
      "{'loss': 0.0166, 'grad_norm': 0.18359375, 'learning_rate': 4.714530148568197e-06, 'epoch': 6.8}\n",
      "{'loss': 0.0153, 'grad_norm': 0.2099609375, 'learning_rate': 4.279372475203181e-06, 'epoch': 6.83}\n",
      "{'loss': 0.0163, 'grad_norm': 0.1875, 'learning_rate': 3.864843410453767e-06, 'epoch': 6.87}\n",
      "{'loss': 0.0125, 'grad_norm': 0.1904296875, 'learning_rate': 3.471032288855869e-06, 'epoch': 6.9}\n",
      "{'loss': 0.0154, 'grad_norm': 0.154296875, 'learning_rate': 3.0980239800526e-06, 'epoch': 6.94}\n",
      "{'loss': 0.0271, 'grad_norm': 0.169921875, 'learning_rate': 2.7458988705041157e-06, 'epoch': 6.97}\n",
      "{'loss': 0.0212, 'grad_norm': 0.2255859375, 'learning_rate': 2.4147328461637144e-06, 'epoch': 7.01}\n",
      " 93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 209/224 [07:47<00:30,  2.03s/it][2024-08-08 15:48:54,405] [INFO] [axolotl.utils.samplers.multipack._len_est:185] [PID:2996755] [RANK:0] packing_efficiency_estimate: 0.9 total_num_tokens per device: 869680\u001b[39m\n",
      "{'loss': 0.0113, 'grad_norm': 0.193359375, 'learning_rate': 2.104597276123721e-06, 'epoch': 7.02}\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 210/224 [07:49<00:27,  1.97s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 11.59it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.75it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.87it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.73it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.51it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.47it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.05it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.19it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.18it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.23it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:02<00:00,  5.94it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.08it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.05it/s]\u001b[A[2024-08-08 15:48:58,069] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19293397665023804, 'eval_runtime': 2.6685, 'eval_samples_per_second': 11.992, 'eval_steps_per_second': 5.996, 'epoch': 7.02}\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 210/224 [07:52<00:27,  1.97s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.20it/s]\u001b[A\n",
      "{'loss': 0.0279, 'grad_norm': 0.23046875, 'learning_rate': 1.8155589972348452e-06, 'epoch': 7.05}\n",
      "{'loss': 0.0089, 'grad_norm': 0.177734375, 'learning_rate': 1.547680299702281e-06, 'epoch': 7.09}\n",
      "{'loss': 0.0164, 'grad_norm': 0.1982421875, 'learning_rate': 1.3010189136616446e-06, 'epoch': 7.12}\n",
      "{'loss': 0.0108, 'grad_norm': 0.1962890625, 'learning_rate': 1.075627996737627e-06, 'epoch': 7.16}\n",
      "{'loss': 0.0127, 'grad_norm': 0.2021484375, 'learning_rate': 8.715561225880686e-07, 'epoch': 7.19}\n",
      "{'loss': 0.0089, 'grad_norm': 0.1494140625, 'learning_rate': 6.888472704359661e-07, 'epoch': 7.23}\n",
      "{'loss': 0.0089, 'grad_norm': 0.103515625, 'learning_rate': 5.275408155914985e-07, 'epoch': 7.26}\n",
      "{'loss': 0.0168, 'grad_norm': 0.1689453125, 'learning_rate': 3.87671520966415e-07, 'epoch': 7.3}\n",
      "{'loss': 0.0098, 'grad_norm': 0.1455078125, 'learning_rate': 2.6926952958221674e-07, 'epoch': 7.33}\n",
      "{'loss': 0.0062, 'grad_norm': 0.15625, 'learning_rate': 1.7236035807416395e-07, 'epoch': 7.37}\n",
      "{'loss': 0.0186, 'grad_norm': 0.28515625, 'learning_rate': 9.696489119221941e-08, 'epoch': 7.4}\n",
      "{'loss': 0.0111, 'grad_norm': 0.205078125, 'learning_rate': 4.309937730015978e-08, 'epoch': 7.43}\n",
      "{'loss': 0.0161, 'grad_norm': 0.1640625, 'learning_rate': 1.0775424873943341e-08, 'epoch': 7.47}\n",
      "{'loss': 0.0148, 'grad_norm': 0.1435546875, 'learning_rate': 0.0, 'epoch': 7.5} \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [08:20<00:00,  2.03s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                                      | 2/16 [00:00<00:01, 12.42it/s]\u001b[A\n",
      " 25%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                                 | 4/16 [00:00<00:01,  7.88it/s]\u001b[A\n",
      " 31%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                              | 5/16 [00:00<00:01,  6.94it/s]\u001b[A\n",
      " 38%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ                           | 6/16 [00:00<00:01,  6.76it/s]\u001b[A\n",
      " 44%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                        | 7/16 [00:00<00:01,  6.54it/s]\u001b[A\n",
      " 50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                      | 8/16 [00:01<00:01,  6.49it/s]\u001b[A\n",
      " 56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                   | 9/16 [00:01<00:01,  6.08it/s]\u001b[A\n",
      " 62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰                | 10/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ             | 11/16 [00:01<00:00,  6.20it/s]\u001b[A\n",
      " 75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž          | 12/16 [00:01<00:00,  6.25it/s]\u001b[A\n",
      " 81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰        | 13/16 [00:01<00:00,  5.95it/s]\u001b[A\n",
      " 88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 14/16 [00:02<00:00,  6.10it/s]\u001b[A\n",
      " 94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž  | 15/16 [00:02<00:00,  6.07it/s]\u001b[A[2024-08-08 15:49:29,067] [INFO] [accelerate.accelerator.gather_for_metrics:2406] [PID:2996755] The used dataset had no length, returning gathered tensors. You should drop the remainder yourself.\n",
      "\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19255928695201874, 'eval_runtime': 2.6509, 'eval_samples_per_second': 12.071, 'eval_steps_per_second': 6.036, 'epoch': 7.5}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [08:23<00:00,  2.03s/it]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16/16 [00:02<00:00,  6.21it/s]\u001b[A\n",
      "{'train_runtime': 503.7732, 'train_samples_per_second': 9.655, 'train_steps_per_second': 0.445, 'train_loss': 0.09502525212883484, 'epoch': 7.5}\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 224/224 [08:23<00:00,  2.25s/it]\n",
      "[2024-08-08 15:49:29,871] [INFO] [axolotl.train.train:190] [PID:2996755] [RANK:0] Training Completed!!! Saving pre-trained model to ./out-Qwen2-0.5B-Instruct\u001b[39m\n",
      "(PeftModelForCausalLM(   (base_model): LoraModel(     (model): Qwen2ForCausalLM(       (model): Qwen2Model(         (embed_tokens): Embedding(151936, 896)         (layers): ModuleList(           (0-23): 24 x Qwen2DecoderLayer(             (self_attn): Qwen2FlashAttention2(               (q_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=896, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (k_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=128, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=128, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (v_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=128, bias=True)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=128, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (o_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=896, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (rotary_emb): Qwen2RotaryEmbedding()             )             (mlp): Qwen2MLP(               (gate_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=4864, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4864, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (up_proj): lora.Linear(                 (base_layer): Linear(in_features=896, out_features=4864, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=896, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=4864, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (down_proj): lora.Linear(                 (base_layer): Linear(in_features=4864, out_features=896, bias=False)                 (lora_dropout): ModuleDict(                   (default): Dropout(p=0.05, inplace=False)                 )                 (lora_A): ModuleDict(                   (default): Linear(in_features=4864, out_features=16, bias=False)                 )                 (lora_B): ModuleDict(                   (default): Linear(in_features=16, out_features=896, bias=False)                 )                 (lora_embedding_A): ParameterDict()                 (lora_embedding_B): ParameterDict()               )               (act_fn): SiLU()             )             (input_layernorm): Qwen2RMSNorm()             (post_attention_layernorm): Qwen2RMSNorm()           )         )         (norm): Qwen2RMSNorm()       )       (lm_head): Linear(in_features=896, out_features=151936, bias=False)     )   ) ), Qwen2TokenizerFast(name_or_path='Qwen/Qwen2-0.5B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={ \t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), \t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True), })\n",
      "\u001b[0mCPU times: user 3.81 s, sys: 629 ms, total: 4.44 s\n",
      "Wall time: 9min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/accelerate launch -m axolotl.cli.train {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/axolotl-finetune-llm/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "qlora_model = f\"./out-{MODEL_SHORT_NAME}\"\n",
    "base_model = MODEL_NAME\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model, use_fast=False)\n",
    "base_model = AutoModelForCausalLM.from_pretrained(base_model, device_map=\"auto\", torch_dtype=torch.float16, attn_implementation=\"flash_attention_2\").eval()\n",
    "model = PeftModel.from_pretrained(base_model, qlora_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# push the LoRA model (PEFT adapter) to HF Hub\n",
    "\n",
    "#hub_model_id = f\"NatLibFi/{MODEL_SHORT_NAME}-{SUFFIX}\"\n",
    "#model.push_to_hub(hub_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the LoRA into the base model for inference\n",
    "model = model.merge_and_unload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(messages):\n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True)\n",
    "    output_ids = model.generate(\n",
    "        torch.as_tensor(input_ids).cuda(),\n",
    "        #input_ids,\n",
    "        max_new_tokens=512,\n",
    "        pad_token_id=tokenizer.pad_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    output_ids = output_ids[0][len(input_ids[0]):]\n",
    "    return tokenizer.decode(output_ids, skip_special_tokens=True).strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Ammattikielisten tekstien tutkimisesta - esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Katajam\\u00e4ki, Heli\", \"Koskela, Merja\"], \"year\": \"2012\", \"publisher\": [\"Kotimaisten kielten keskus\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Ammattikielisten tekstien tutkimisesta : esimerkkin\\u00e4 tilintarkastuskertomus\", \"creator\": [\"Koskela, Merja\", \"Katajam\\u00e4ki, Heli\"], \"year\": \"2012\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"FAQ : Taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t\", \"year\": \"2018\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"e-isbn\": [\"9789527266076\"], \"p-issn\": \"1456-002X\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Taiteen digitaaliset toimintaymp\\u00e4rist\\u00f6t 2018\", \"creator\": [\"Suonp\\u00e4\\u00e4, Juha\"], \"publisher\": [\"Taideyliampik\\u00e4ikkiampaan\"], \"e-isbn\": [\"9789527266076\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Julkisen tilan taiteen tilasta. Puheenvuoroja julkisen taiteen konteksteista\", \"year\": \"2021\", \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Taideyliopiston s\\u00e4hk\\u00f6isess\\u00e4 julkaisuarkistossa : Kirjan teemat, artikkelien kirjoittajat ja taideyliopisto-julkisten taidevitaloisuuun.\", \"creator\": [\"Pekkil\\u00e4, Sirke\", \"Kaverma, Petri\", \"Lampela, Kalle\", \"Nisunen, Petteri\", \"Ziegler, Denise\", \"Niemi, Siina\", \"Rauhala, Patti\", \"Hultman, Rosa\", \"Ihalainen, Kirsi\", \"Kannen kuva, Miika\"], \"publisher\": [\"Taideyliopisto\"], \"e-isbn\": [\"9789523534100\"], \"p-isbn\": [\"9789523534094\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Karelia.fi - Karelia-ammattikorkeakoulun tutkimus- ja kehitt\\u00e4mistoimintaa EU-ohjelmakaudella 2014-2020\", \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Karelia-ammattikorkeakoulu : tutkimus- ja hedelmistoaajaudeilla 2014-2020\", \"year\": \"2023\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789524769782\"], \"p-isbn\": [\"9789524769782\"], \"e-issn\": \"2323-8461\", \"p-issn\": \"2323-8453\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia  Kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksee : kevill\\u00f6minen, valmioiden opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283541\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksia : Kulttuurituotanto (ylempi AMK) tutkinnon opinn\\u00e4ytety\\u00f6n opas\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Kulttuurituotannon ty\\u00f6papereita : kehitt\\u00e4misty\\u00f6st\\u00e4 oivalluksee\", \"creator\": [\"Halonen, Katri\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283107\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Monimuotoinen ansioty\\u00f6 : N\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"year\": \"2022\", \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Monimuotoinen ansioty\\u00f6 : N\\u00e4k\\u00f6kulmia monista l\\u00e4hteist\\u00e4 ansaintaan\", \"year\": \"2022\", \"publisher\": [\"Tampere University Press\"], \"e-isbn\": [\"9789523590403\"], \"p-isbn\": [\"9789523590410\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Osuma-peli \\u2013 Innostusta yhteiskehittelyyn!\", \"creator\": [\"Halonen, Katri\", \"Salmenkangas, Mai\", \"Wallin, Riikka\"], \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Osuma-peli : Innostusta yhteiskehittelyyn!\", \"year\": \"2019\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Pk-yritysten liiketoiminnan muotoilun CookBook\", \"creator\": [\"Jaakola, Hanna\", \"Pietik\\u00e4inen, Minna\", \"Rinta-Jouppi, Laura\", \"Viljanen, Jenni\"], \"year\": \"2021\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"CookBook : Liiketoiminnan muotoilun\", \"creator\": [\"Jaakola, Hanna\", \"Pietik\\u00e4inen, Minna\", \"Rinta-Jouppi, Laura\", \"Viljanen, Jenni\"], \"year\": \"2021\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"e-isbn\": [\"9789517996051\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Suomen Pankki 200 vuotta II: Parlamentin pankki\", \"creator\": [\"Kuuster\\u00e4, Antti\", \"Tarkka, Juha\"], \"year\": \"2012\", \"publisher\": [\"Otava\"], \"e-isbn\": [\"9789511242727\"], \"p-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Suomen Pankki 200 vuotta parlamentin pankki : II\", \"year\": \"2014\", \"publisher\": [\"Suomen Pankki\"], \"e-isbn\": [\"9789511242727\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4rittelyt\", \"creator\": [\"Aalto, Anna\", \"Virkkunen, Heikki\", \"Turunen, Seppo\", \"Saarela, Hanna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Suun terveydenhuollon potilaskertomusmerkint\\u00f6jen toiminnalliset m\\u00e4\\u00e4rittelyt\", \"creator\": [\"Anna, Thelma A.\", \"Heikki, Virkkunen Heikki\", \"Turunen Seppo\", \"Saarela, Hanna-Leena\", \"Tarja R\\u00e4ty\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"TARU-SANOMAT\", \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"e-issn\": \"2490-2055\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Taru-sanomat : toimittaja P\\u00e4ivi Rahmel\", \"creator\": [\"Rahmel, P\\u00e4ivi\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283244\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset\", \"creator\": [\"Haarala, P\\u00e4ivi\"], \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"e-issn\": \"2669-8021\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Terveydenhoitajan ammatilliset osaamisvaatimukset : Metropolia Ammattikorkeakoulu & tekij\\u00e4 2022\", \"year\": \"2022\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"e-isbn\": [\"9789523283411\"], \"p-isbn\": [\"9789523283406\"], \"p-issn\": \"2669-8021\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Editorial\", \"creator\": [\"Illman, Ruth\", \"Lundgren, Svante\"], \"type_coar\": \"editorial\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Editorial\", \"year\": \"2020\", \"type_coar\": \"editorial\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Judiskt liv i Helsingfors\", \"creator\": [\"Lundgren, Svante\"], \"type_coar\": \"book review\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Som alla andra : Min judiska familj och jag\", \"creator\": [\"Odrischinsky, Eva\"], \"year\": \"2019\", \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"L\\u00e5t havet forts\\u00e4tta vara v\\u00e4gen : Vasabladet\", \"creator\": [\"Karlsson, Rasmus\"], \"year\": \"2019\", \"publisher\": [\"Vasabladet\"], \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Mod och gl\\u00e4dje att prata svenska online\", \"creator\": [\"Linna, Mari\", \"Mets\\u00e4vainio, Marita\", \"Valtonen, Ida\", \"Kazaka, Signe\", \"Kihlbom, Liselotte\", \"Lempinen, Katja\", \"Suvila, Jari\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Mod och gl\\u00e4dje att prata svenska online\", \"creator\": [\"Linna, Mari\", \"Mets\\u00e4vainio, Marita\", \"Valtonen, Ida\", \"Kazaka, Signe\", \"Kihlbom, Liselotte\", \"Lempinen, Katja\", \"Suvila, Jari\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Torka eller ensilera? Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Yvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Torka eller ensilera? Novia j\\u00e4mf\\u00f6r lagringsmetoder och utvecklar handelsmodell f\\u00f6r spannm\\u00e5l\", \"creator\": [\"Dahlb\\u00e4ck, Yvonne\", \"Fr\\u00e4nde, Niklas\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"V\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\", \"creator\": [\"\\u00c5kerback, Nina\", \"\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"Engblom, Sten\"], \"year\": \"2019\", \"publisher\": [\"Vaasa Insider\"], \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"\\\"V\\u00e4xtbehovsanpassade g\\u00f6dselmedel fr\\u00e5n biogasanl\\u00e4ggningar\\\" - Vaasa Insider\", \"creator\": [\"\\u00c5kerback, Nina\", \"\\u00d6ling-W\\u00e4rn\\u00e5, Viveka\", \"\\u00d6ling, Sten\"], \"year\": \"2019\", \"publisher\": [\"Vaasan kaupunki\"], \"type_coar\": \"newspaper interview\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"\\u2018The wrath of God on children of disobedience\\u2019\", \"creator\": [\"\\u00d6stling, Erik\"], \"year\": \"2021\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"\\u2018The wrath of God on children of disobedience\\u2019 : COVID-19 in the theology and ideology of the Westboro Baptist Church\", \"creator\": [\"Wittgenstein, Ludwig\"], \"year\": \"2021\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"\\\"Great Horizons Flooded with the Alien Light of the Sun\\\" : Le Sacre du Printemps in the Russian context\", \"creator\": [\"J\\u00e4rvinen, Hanna\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"\\\"Great Horizons Flooded with the Alien Light of the Sun\\\": Le Sacre du Printemps in the Russian context\", \"creator\": [\"Kern, Ian\"], \"year\": \"2020\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A Dynamic Collusion Analysis Framework Considering Generation and Transmission Systems Maintenance Constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/EEM49802.2020.9221905\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Dynamic Collusion Analysis Framework Considering Generation and Transmission Systems Maintenance Constraints\", \"creator\": [\"Tabatabaei, Mostafa\", \"Setayesh Nazar, Mehrdad\", \"Shafie-khah, Miadreza\", \"Catal\\u00e3o, Jo\\u00e3o P. S.\"], \"year\": \"2020\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/IEEESTAT.2020.3032278\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A review of optical nondestructive visual and near-infrared methods for food quality and safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\", \"Mantere, Timo\"], \"year\": \"2013\", \"publisher\": [\"Hindawi\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Review Article : A Review of Optical Nondestructive Visual and Near-Infrared Methods for Food Quality and Safety\", \"creator\": [\"Alander, Jarmo T.\", \"Bochko, Vladimir\", \"Martinkauppi, Birgitta\", \"Saranwong, Sirinnapa\"], \"year\": \"2013\", \"publisher\": [\"Hindawi\"], \"doi\": \"10.1155/2013/341402\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Assessing Trustworthy AI in times of COVID-19. Deep Learning for predicting a multi-regional score conveying the degree of lung compromise in COVID-19 patients\", \"creator\": [\"Allahabadi, Himanshi\", \"Amann, Julia\", \"Balot, Isabelle\", \"Beretta, Andrea\", \"Binkley, Charles\", \"Bozenhard, Jonas\", \"Bruneault, Fr\\u00e9d\\u00e9rick\", \"Brusseau, James\", \"Candemir, Sema\", \"Cappellini, Luca Alessandro\", \"Castagnet, Genevieve Fieux\", \"Chakraborty, Subrata\", \"Cherciu, Nicoleta\", \"Cociancig, Christina\", \"Coffee, Megan\", \"Ek, Irene\", \"Espinosa-Leal, Leonardo\", \"Farina, Davide\", \"Fieux-Castagnet, Genevieve\", \"Frauenfelder, Thomas\", \"Gallucci, Alessio\", \"Giuliani, Guya\", \"Golda, Adam\", \"van Halem, Irmhild\", \"Hildt, Elisabeth\", \"Holm, Sune\", \"Kararigas, Georgios\", \"Krier, Sebastien A.\", \"K\\u00fchne, Ulrich\", \"Lizzi, Francesca\", \"Madai, Vince I.\", \"Markus, Aniek F.\", \"Masis, Serg\", \"Mathez, Emilie Wiinblad\", \"Mureddu, Francesco\", \"Neri, Emanuele\", \"Osika, Walter\", \"Ozols, Matiss\", \"Panigutti, Cecilia\", \"Parent, Brendan\", \"Pratesi, Francesca\", \"Moreno-S\\u00e1nchez, Pedro A.\", \"Sartor, Giovanni\", \"Savardi, Mattia\", \"Signoroni, Alberto\", \"Sormunen, Hanna\", \"Spezzatti, Andy\", \"Srivastava, Adarsh\", \"Stephansen, Annette F.\", \"Theng, Lau Bee\", \"Tithi, Jesmin Jahan\", \"Tuominen, Jarno\", \"Umbrello, Steven\", \"Vaccher, Filippo\", \"Vetter, Dennis\", \"Westerlund, Magnus\", \"Wurth, Renee\", \"Zicari, Roberto V.\"], \"year\": \"2022\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/TTS.2022.3195114\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Assessing Trustworthy AI in times of COVID-19\", \"creator\": [\"Westerlund, Magnus\", \"Wurth, Renee\", \"Zicari, Roberto\"], \"year\": \"2022\", \"publisher\": [\"IEEE\"], \"doi\": \"10.1109/TTS.2022.3195114\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Competence-based education development\", \"creator\": [\"Lahti, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Tajik State University of Commerce\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring : a qualitative study\", \"creator\": [\"Korhonen, H.\", \"Tuomikoski, A-M.\", \"Oikarainen, A.\", \"K\\u00e4\\u00e4ri\\u00e4inen, M.\", \"Elo, S.\", \"Kyng\\u00e4s, H.\", \"Liikanen, E.\", \"Mikkonen, K.\"], \"year\": \"2019\", \"doi\": \"10.1016/j.nepr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Culturally and linguistically diverse healthcare students\\u2019 experiences of the clinical learning environment and mentoring : a qualitative study\", \"creator\": [\"Korhonen, Hannele\", \"Tuomikoski, Alvaro-Matti\", \"Oikarainen, Antti\", \"K\\u00e4\\u00e4ri\\u00e4inen, Matti\", \"Elo, Susanna\", \"Kyng\\u00e4s, Helga\", \"Liikanen, Elina\", \"Mikkonen, Kaisa\"], \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"doi\": \"10.1016/j.nepr.2019.102637\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Engaging audio based mobile applications\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"e-isbn\": [\"9788409147557\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Engaging audio based mobile applications : Iceri 2019 proceedings\", \"creator\": [\"Salo, Kari\", \"Neuvonen, Aura\"], \"year\": \"2019\", \"publisher\": [\"Metropolia University of Applied Sciences\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Epistemically tuned-in?\", \"creator\": [\"St\\u00e5hl, Tore\"], \"year\": \"2020\", \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Epistemically Tuned-in? EAPRIL 2019 Conference proceedings\", \"year\": \"2020\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"In the shadows : Phenomenological choreographic writing\", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"doi\": \"10.1386/chor_00042_1\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"In the Shadows : Phenomenological Choreographic Writing\", \"creator\": [\"Heimonen, Kirsi\", \"Rouhiainen, Leena\"], \"year\": \"2022\", \"publisher\": [\"Choreographic Practices\"], \"doi\": \"10.1386/chor.00042.1\", \"p-isbn\": [\"9789523551774\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"MARISA Ethical, Legal and Societal Aspects\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"European Commission\"], \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Marisa ethical, legal and societal aspects\", \"creator\": [\"Sarlio-Siintola, Sari\"], \"year\": \"2019\", \"publisher\": [\"Maritima\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Memories from the EAHIL Workshop\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Katri\", \"Mann, Mala\", \"Ferrinho, Ana Maria\", \"Ottjes, Robin\"], \"year\": \"2019\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Memories from the EAHIL Workshop\", \"creator\": [\"Hagstr\\u00f6m, Sarah\", \"Larmo, Kati\", \"Mann, Maja\", \"Ferrinho, Ana-Maria\", \"Ottjes, Robin\"], \"year\": \"2019\", \"publisher\": [\"Ee- ahil\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Supporting Transformative Agency among Urban Actors in the Change Laboratory Intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"e-issn\": \"2328-4919\", \"p-issn\": \"2328-4900\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Supporting Transformative Agency among Urban Actors in the Change Laboratory Intervention\", \"creator\": [\"Lund, Virpi\"], \"year\": \"2021\", \"publisher\": [\"Scientific Research Publishing\"], \"doi\": \"10.4236/cus.2021.93025\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"The roles of temperature, nest predators and information parasites for geographical variation in egg covering behaviour of tits (Paridae)\", \"creator\": [\"Loukola, Olli J.\", \"Adamik, Peter\", \"Adriaensen, Frank\", \"Barba, Emilio\", \"Doligez, Blandine\", \"Flensted-Jensen, Einar\", \"Eeva, Tapio\", \"Kivel\\u00e4, Sami M.\", \"Laaksonen, Toni\", \"Morosinotto, Chiara\", \"M\\u00e4nd, Raivo\", \"Niemel\\u00e4, Petri T.\", \"Reme\\u0161, Vladimir\", \"Samplonius, Jelmer M.\", \"Sebastiano, Manrico\", \"Senar, Juan Carlos\", \"Slagsvold, Tore\", \"Sorace, Alberto\", \"Tschirren, Barbara\", \"T\\u00f6r\\u00f6k, J\\u00e1nos\", \"Forsman, Jukka T.\"], \"year\": \"2020\", \"publisher\": [\"John Wiley & Sons\"], \"doi\": \"10.1111/jbi.13830\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"The roles of temperature, nest predators and information parasites for geographical variation in egg covering behaviour of tits (Paridae)\", \"creator\": [\"Loukola, Olli J.\", \"Adamik, Peter\", \"Adriaensen, Frank\", \"Barba, Emilio\", \"Flensted-Jensen, Blandine\", \"Eeva, Tapio\", \"M\\u00e4nd, Sami\", \"Laaksonen, Toni\"], \"year\": \"2020\", \"publisher\": [\"Wiley\"], \"doi\": \"10.1111/jbi.13830\", \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Why Is CryptoKitties (Not) Gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Why Is CryptoKitties (Not) Gambling?\", \"creator\": [\"Serada, Alesja\"], \"year\": \"2020\", \"publisher\": [\"Academy of Digital Games\"], \"doi\": \"10.1145/3402942.3402985\", \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Demokrati och handel : En empirisk studie \\u00f6ver hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Demokrati och handel : En empirisk studie \\u00f6ver hur Hongkongs nedg\\u00e5ende demokrati p\\u00e5verkar handeln med EU\", \"creator\": [\"Eriksson, Anna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"EN L\\u00c5NG RESA En litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av br\\u00f6stcancer\", \"creator\": [\"Zvidrina, Arita\", \"Uzelac-Varda, Silvija\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"En l\\u00e5ng resa : En litteratur\\u00f6versikt om kvinnors erfarenheter i samband med br\\u00f6strekonstruktion efter mastektomi till f\\u00f6ljd av\", \"creator\": [\"Uzelac-Varda, Silvija\", \"Zvidrina, Arita\"], \"year\": \"2022\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Fr\\u00e5n \\u00c5lands Sj\\u00f6fartsl\\u00e4roverk till H\\u00f6gskolan p\\u00e5 \\u00c5land: En studie om intresset f\\u00f6r sj\\u00f6kaptensstudier \\u00f6ver tid\", \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Intresset f\\u00f6r sj\\u00f6kaptensstudier till H\\u00f6gskolan p\\u00e5 \\u00c5land : En studie om intresset f\\u00f6r sj\\u00f6kaptensstudier \\u00f6ver tid.\", \"creator\": [\"Skoglund, Wilhelm\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhantering - modell och praktik\", \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"F\\u00f6retags\\u00f6vergripande riskhanteringen \\u2013 modell och praktik\", \"creator\": [\"Ahonen, Noora\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"GDPR i praktiken\", \"creator\": [\"Kahrimanovic, Arnel\", \"Mesic, Selma\"], \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"GDRP-Guidellisk pr\\u00f6gskolan p\\u00e5 \\u00c5land : GDPR i praktiken\", \"creator\": [\"Kahrimanovic, Arnel\"], \"miller, Selma\", \"year\": \"2020\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-2023\", \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00e5llbara ink\\u00f6p hos tv\\u00e5 \\u00e5l\\u00e4ndska f\\u00f6retag : verksamma inom plastindustrin\", \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00f6gskolan p\\u00e5 \\u00c5land : Utbildningsprogramm : F\\u00f6retagsekonomi. H\\u00c5LLBARA INK\\u00f6P hos tv\\u00e5 \\u00e5l\\u00e4ndska f\\u00f6retag - verksamma inom plastindustrin\", \"creator\": [\"Eklund, Liz\", \"Marjanen, Emma\"], \"year\": \"2021\", \"publisher\": [\"H\\u00f6gskolan p\\u00e5 \\u00c5land\"], \"e-issn\": \"1458-1531\", \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor \\u00f6ver tid\", \"creator\": [\"Backlund, Emma\", \"\\u00c5kerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00f6gstadieelevers s\\u00f6mn- och kostvanor \\u00f6ver tid\", \"creator\": [\"Backlund, Emma\", \"\\u00c5kerlund, Hanna\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rares synvinkel : En intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Inskolningens  och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rarens synvinkel : en intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Vasa\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av  processer i IT-f\\u00f6retag: En modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring\", \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Kartl\\u00e4ggning och f\\u00f6rb\\u00e4ttring av processer i IT-f\\u00f6retag : En modell f\\u00f6r verksamhetsf\\u00f6rb\\u00e4ttring\", \"creator\": [\"Etzell, Emilia\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Raseborg\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Monitorering av biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Holmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Monitorering biofilmbildning med kvartskristallmikrobalans (QCM) och ytplasmonresonans (SPR)\", \"creator\": [\"Halmstr\\u00f6m, Ellinoora\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Musik och r\\u00f6relse som plattform f\\u00f6r kreativitet : en intervjustudie med fyra l\\u00e4rare i \\u00e5rskurserna 7-9\", \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Sibelius-Akademin, Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Musik och r\\u00f6relse som plattform f\\u00f6r kreativitet : en intervjustudie med fyra l\\u00e4rare i \\u00e5rskurserna 7-\\u00ad\\u20109\", \"creator\": [\"Henriksson, Amanda\"], \"year\": \"2015\", \"publisher\": [\"Konstuniversitetet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Naturliga, rytmiska och holistiska individer : Diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Naturliga, rytmiska och holistiska individer : diskurser om pedagogik i Waldorfskolor i Sverige\", \"creator\": [\"Jansson, Charlotte\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Orderhantering f\\u00f6r  automationstruckssystem med  Siemens S7-1500 Logik\", \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Orderhantering f\\u00f6r automationstruckssystem med Siemens S7-1500 Logik\", \"creator\": [\"Wargh, Tobias\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Novia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Resultatmanipulering : En studie om f\\u00f6ruts\\u00e4ttningarna p\\u00e5 den finska marknaden\", \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Resultatmanipulering : En studie om f\\u00f6ruts\\u00e4ttningarna p\\u00e5 den finska marknaden\", \"creator\": [\"Lindqvist, Robert\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? : Ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Vem \\u00e4ger sj\\u00e4lens ranka? Ayahuascaturism utifr\\u00e5n tre dokument\\u00e4rer\", \"creator\": [\"Andersson, Tove\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Vikingakvinnan som husmor: En filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa universitet\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Vikaakvinnan som husmor : En filologisk n\\u00e4rl\\u00e4sning av Njals saga\", \"creator\": [\"Meinhart, Barbara\"], \"year\": \"2020\", \"publisher\": [\"Vasa universitet\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A Discourse Analytic Approach to HEI Leadership in Finland : The What and How of Rectors\\u2019 Leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521241864\", \"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Discourse Analytic Approach to HEI Leadership in Finland : The What and How of Rectors\\u2019 Leadership\", \"creator\": [\"Tigerstedt, Christa\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521241864\"], \"p-isbn\": [\"9789521241857\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A Jungian Theory of Mind : Individuality, lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Jungian Theory of Mind : Individuality lost, gained, and transcended\", \"creator\": [\"Alho, P\\u00e4ivi\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239083\"], \"p-isbn\": [\"9789521239076\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Aminophenolato complexes of Mo, W and V In catalytic alkene epoxidation and catechol oxidation\", \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Aminophenolato Complexes of Mo, W, and V : In Catalytic Alkene Epoxidation and Catechol Oxidation\", \"creator\": [\"Salonen, Pasi\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986552\"], \"p-isbn\": [\"9789512986545\"], \"e-issn\": \"2343-3175\", \"p-issn\": \"0082-7002\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Causes and consequences of variation in blue tit nest construction\", \"creator\": [\"J\\u00e4rvinen, Pauliina\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512980673\"], \"p-isbn\": [\"9789512980666\"], \"e-issn\": \"2343-3183\", \"p-issn\": \"0082-6979\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : A population-based study\", \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Changes in mental health symptoms, bullying involvement, loneliness and service use among Finnish-speaking children aged 8-9 years over a 24-year period : A population-based study\", \"creator\": [\"Lempinen, Lotta\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512986767\"], \"p-isbn\": [\"9789512986750\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Educating global citizens : a study of interaction between NGOs and schools in Finland\", \"creator\": [\"Henriksson, Heidi\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi University Press\"], \"e-isbn\": [\"9789523890299\"], \"p-isbn\": [\"9789523890282\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"University of Helsinki\"], \"e-isbn\": [\"9789515176912\"], \"p-isbn\": [\"9789515176905\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Effect measures, their estimation and interpretation : applications to pneumococcal conjugate vaccination.\", \"creator\": [\"Rinta-Kokko, Hanna\"], \"year\": \"2022\", \"publisher\": [\"University of Helsinki\"], \"e-isbn\": [\"9789515176912\"], \"p-isbn\": [\"9789515176905\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Employee trust repair in the context of organizational change \\u2013 identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Employee trust repair in the context of organizational change : identification and measurement of active trust repair practices\", \"creator\": [\"K\\u00e4hk\\u00f6nen, Tiina\"], \"year\": \"2022\", \"publisher\": [\"Lappeenranta-Lahti University of Technology LUT\"], \"e-isbn\": [\"9789523357761\"], \"p-isbn\": [\"9789523357754\"], \"p-issn\": \"1456-4491\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Essays on economic productivity\", \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Essays on economic productivity\", \"creator\": [\"L\\u00e4hdem\\u00e4ki, Sakari\"], \"year\": \"2021\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512983490\"], \"p-isbn\": [\"9789512983483\"], \"e-issn\": \"2343-3167\", \"p-issn\": \"2343-3159\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Light Field Compression Using Disparity-Based 4D Predictive Coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Light Field Compression Using Disparity-Based 4D Predictive Coding\", \"creator\": [\"Astola, Pekka\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520315825\"], \"p-isbn\": [\"9789520315818\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Light Manipulation in Multilayer Metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Light Manipulation in Multilayer Metamaterials\", \"creator\": [\"Habib, Mohsin\"], \"year\": \"2022\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520324513\"], \"p-isbn\": [\"9789520324506\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Performance Exploration and Testing of Web-based Software Systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521239991\"], \"p-isbn\": [\"9789521240003\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Performance Exploration and Testing of Web-based Software Systems\", \"creator\": [\"Ahmad, Tanwir\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521240003\"], \"p-isbn\": [\"9789521239991\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Power of Myths in Energy Transition : Unveiling Timeless Mythologies in Finnish Energy Agora\", \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"University of Vaasa\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Power of Myths in Energy Transition : Unveiling Timeless Mythologies in Finnish Energy Agora\", \"creator\": [\"Berg, Petra\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769495\"], \"p-isbn\": [\"9789524769488\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Problem gambling in a Nordic context : Moving from social factors to a psychosocial perspective\", \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521238700\"], \"p-isbn\": [\"9789521238694\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Problem gambling in a Nordic context : Moving from social factors to a psychosocial perspective\", \"creator\": [\"Nordmyr, Johanna\"], \"year\": \"2020\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"e-isbn\": [\"9789521238700\"], \"p-isbn\": [\"9789521238694\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Rescheduling sudden absences of nursing staff in hospital settings\", \"creator\": [\"Tuominen, Outi\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512979615\"], \"p-isbn\": [\"9789512979608\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Rescheduling sudden absences of nursing staff in hospital settings\", \"creator\": [\"Tuominen, Outi\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"e-isbn\": [\"9789512979615\"], \"p-isbn\": [\"9789512979608\"], \"e-issn\": \"2343-3213\", \"p-issn\": \"0355-9483\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Role of Urinary Findings and Adipokines in Puumala Virus-induced Acute Kidney Injury\", \"creator\": [\"Mantula, Paula\"], \"year\": \"2021\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520318802\"], \"p-isbn\": [\"978\\u00ad952\\u00ad03\\u00ad1879\\u00ad6\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Role of Urinary Findings and Adipokines in Puumala Virus-induced Acute Kidney Injury\", \"creator\": [\"Mantula, Paula\"], \"year\": \"2021\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789523518802\"], \"p-isbn\": [\"9789523518797\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-8860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Surgical, Oncological and Reconstructive Outcomes After Complex Oncological Pelvic Resections : The Development of an Algorithm Based on a Multidisciplinary Approach\", \"creator\": [\"Kiiski, Juha\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520316549\"], \"p-isbn\": [\"9789520316532\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Surgical, Oncological and Reconstructive Outcomes After Complex Oncological Pelvic Resections : The Development of an Algorithm Based on a Multidisciplinary Approach\", \"creator\": [\"Laitinen, Finna\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"e-isbn\": [\"9789520316549\"], \"p-isbn\": [\"9789520316532\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Elevers matematiska utmaningar i sl\\u00f6jd : \\u00c4mnes\\u00f6verskridande l\\u00e4rande via handens arbete\", \"creator\": [\"Hjelm, \\u00c5sa\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789523890435\"], \"p-isbn\": [\"9789523890428\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Elevers matematiska utmaningar i sl\\u00f6jd : \\u00e4mnes\\u00f6verskridande l\\u00e4rande via handens arbete\", \"creator\": [\"Hjelm, \\u00c5sa\"], \"year\": \"2023\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789523890435\"], \"p-isbn\": [\"9789523890428\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Hantera frihet och ansvar : om unga personers liv, h\\u00e4lsa och behov av st\\u00f6d\", \"creator\": [\"\\u00d6stman, Lillemor\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240874\"], \"p-isbn\": [\"9789521240867\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Hantera frihet och ansvar : om unga personers liv, h\\u00e4lsa och behov av st\\u00f6d\", \"creator\": [\"Lillemor, \\u00d6stman\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240874\"], \"p-isbn\": [\"9789521240867\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00e4lsans tomrum : En hermeneutisk studie om f\\u00f6rsakelsens betydelse f\\u00f6r h\\u00e4lsan\", \"creator\": [\"Koskinen, Monika\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789517659932\"], \"p-isbn\": [\"9789517659925\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"H\\u00e4lsans tomrum : En hermeneutisk studie om f\\u00f6rsakelsens betydelse f\\u00f6r h\\u00e4lsan\", \"creator\": [\"Koskinen, Monika\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis f\\u00f6rlag\"], \"e-isbn\": [\"9789517659932\"], \"p-isbn\": [\"9789517659925\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"L\\u00e4rmilj\\u00f6ns betydelse f\\u00f6r barns ut\\u00f6vande och l\\u00e4rande av grundl\\u00e4ggande motoriska f\\u00e4rdigheter i sm\\u00e5barnspedagogik\", \"creator\": [\"Svanb\\u00e4ck-Laaksonen, Mikaela\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242236\"], \"p-isbn\": [\"9789521242229\"], \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"L\\u00e4rmilj\\u00f6ns betydelse f\\u00f6r barns ut\\u00f6vande och l\\u00e4rande av grundl\\u00e4ggande motoriska f\\u00e4rdigheter i sm\\u00e5barnspedagogik\", \"creator\": [\"Svanb\\u00e4ck-Laaksonen, Mikaela\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242236\"], \"p-isbn\": [\"9789521242229\"], \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Musikerr\\u00f6ster i Betsy Jolas musik : dialoger och spelerfarenheter i analys\", \"creator\": [\"Korhonen-Bj\\u00f6rkman, Heidi\"], \"year\": \"2016\", \"publisher\": [\"Sibelius-Akademin, Konstuniversitetet\", \"Musikvetenskapliga s\\u00e4llskapet i Finland\"], \"e-isbn\": [\"9789526834726\"], \"p-isbn\": [\"9789526834719\"], \"p-issn\": \"0587-2448\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Musikerr\\u00d6ster i betsy jolas musik : dialoger och spelerfarenheter i analys\", \"creator\": [\"Korhonen-Bj\\u00f6rkman, Heidi\"], \"year\": \"2016\", \"publisher\": [\"Acta Musicologica Fennica\"], \"e-isbn\": [\"9789526834726\"], \"p-isbn\": [\"9789526834719\"], \"p-issn\": \"0587-2448\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Att v\\u00e5rda vattendrag tillsammans : Kommunikation och anpassning till klimatf\\u00f6r\\u00e4ndringens utmaningar i Herts\\u00e5nger\\u00e4lven och Toby \\u00e5 (Laihianjoki)\", \"creator\": [\"Nordberg, Kenneth\", \"Ghorbanzadeh, Sakineh\"], \"publisher\": [\"Regionalvetenskap, \\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242328\"], \"p-isbn\": [\"9789521242328\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Att v\\u00e5rda vattendrag tillsammans : Kommunikation och anpassning till klimatf\\u00f6r\\u00e4ndringens utmaningar i Herts\\u00e5nger\\u00e4lven och Toby \\u00e5 (Laihianjoki)\", \"creator\": [\"Nordberg, Kenneth\", \"Ghorbanzadeh, Sakineh\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi\"], \"e-isbn\": [\"9789521242328\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Direktionens ber\\u00e4ttelse till bankfullm\\u00e4ktige om Finansinspektionens verksamhet 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Direktionens ber\\u00e4ttelse till bankfullm\\u00e4ktige om Finansinspektionens verksamhet 2012 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Egentliga Finland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Egentliga Finland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Finland i siffror 2014\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522444943\"], \"p-isbn\": [\"9789522444745\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Finland i siffror 2014\", \"year\": \"2014\", \"publisher\": [\"Statistiken\"], \"e-isbn\": [\"9789522449439\"], \"p-isbn\": [\"9789522449426\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Finland i siffror 2020\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446534\"], \"p-isbn\": [\"9789522446527\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Finland i siffror 2020\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"978\\u2212952\\u2212244\\u2212652\\u22127\"], \"p-isbn\": [\"978\\u2212952\\u2212244\\u2212653\\u22124\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Finland i siffror 2022\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446961\"], \"p-isbn\": [\"9789522446954\"], \"e-issn\": \"2242-8488\", \"p-issn\": \"0357-4962\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Finland i siffror 2022\", \"publisher\": [\"Statistikcentralen\"], \"e-isbn\": [\"9789522446961\"], \"p-isbn\": [\"9789522446954\"], \"e-issn\": \"0357-4962\", \"p-issn\": \"2242-8488\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Kompetens i palliativ v\\u00e5rd och v\\u00e5rd i livets slutskede i sjuksk\\u00f6tarexamen : rekommendation f\\u00f6r l\\u00e4roplan i palliativ v\\u00e5rd och v\\u00e5rd i livets slutskede\", \"creator\": [\"H\\u00f6kk\\u00e4, Minna\", \"Lehto, Juho\", \"Joutsia, Karoliina\", \"Kallio, Suvi\", \"Kiiski, Katri\", \"Kurunsaari, Merja\", \"Lifl\\u00e4nder, Birgit\", \"L\\u00e4hdetniemi, Marika\", \"Matilainen, Irmeli\", \"Mikkonen, Heli\", \"Muurinen, Katja\", \"Pyk\\u00e4l\\u00e4inen, Tarja\", \"P\\u00e4\\u00e4llysaho, Annikki\", \"Sunikka, Tuulia\", \"Tohmola, Anniina\", \"Turunen, Elina\", \"V\\u00e4is\\u00e4nen, Irja\", \"Ylinen, Eeva-Riitta\", \"\\u00d6hberg, Isa\"], \"publisher\": [\"Kajaanin Ammattikorkeakoulu Oy\"], \"e-isbn\": [\"9789527219607\"], \"p-isbn\": [\"9789527219560\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Spetsprojekt finansierat av undervisnings- och kulturministeriet : tv\\u00e4rsektoriellt och arbetslivsorienterat utvecklande av palliativt v\\u00e5rdarbete och medicinsk utbildning \\u2013 EduPal 2018-2021\", \"creator\": [\"H\\u00f6kk\\u00e4, Minna\", \"Lehto, Juho\", \"Joutsia, Karoliina\", \"Kallio, Suvi\", \"Kiiski, Katri\", \"Kurunsaari, Merja\", \"Lifl\\u00e4nder, Birgit\"], \"year\": \"2020\", \"publisher\": [\"Kajaanin Ammattikorkeakoulu\"], \"e-isbn\": [\"9789527219607\"], \"p-isbn\": [\"9789527219560\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Norra Karelen och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Norra Karelen och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Norra \\u00d6sterbotten och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Norra \\u00d6sterbotten och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"P\\u00e4ij\\u00e4nne-Tavastland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"P\\u00e4ij\\u00e4nne-Tavastland och oj\\u00e4mlikhet\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Unders\\u00f6kning av l\\u00f6nsamheten inom lagstadgad olycksfallsf\\u00f6rs\\u00e4kring 2004-2013 : analys\", \"year\": \"2014\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Unders\\u00f6kning av l\\u00f6nsamheten inom lagstadgad olycksfallsf\\u00f6rs\\u00e4kring 2004-2013 : analys\", \"year\": \"2014\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Verksamhetsber\\u00e4ttelse 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Verksamhetsber\\u00e4ttelse 2012\", \"year\": \"2013\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Verksamhetsber\\u00e4ttelse 2018\", \"creator\": [\"Lahnalammi-Vesivalo, Milka\", \"Alhonsuo, Sampo\", \"Armila-Paalasmaa, Miia\", \"Heikkinen, Raakel\", \"Heiskanen, Hanna\", \"Juutinen, Anne-Mari\", \"Korpiaho, Teija\", \"Rantama, Jaana\", \"Rautanen, Erja\", \"Tulonen, Tommi\", \"Tuomikoski, Kristiina\"], \"year\": \"2019\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Verksamhetsber\\u00e4ttelse 2018\", \"publisher\": [\"Finansinspektionen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Constellations\", \"creator\": [\"Feehily, Fergus\", \"Suutari, Inkeri\", \"Demozay, Annie May\", \"Winters, Terry\", \"Long, Declan\", \"Paavilainen, Kukka\", \"Hutchinson, John\"], \"year\": \"2018\", \"publisher\": [\"Academy of Fine Arts of the University of the Arts Helsinki\"], \"e-isbn\": [\"9789527131510\"], \"p-isbn\": [\"9789527131503\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"The New School for Social Research : The Story of the Graduate Program and its Transformation\", \"year\": \"2018\", \"publisher\": [\"New York University\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Creating Opportunity Spaces for Co-Production : Professional Co-Producers in Inter-Organizational Collaborations\", \"creator\": [\"Brix, Jacob\", \"Tuurnas, Sanna\", \"Mortensen, Nanna M\\u00f8ller\"], \"year\": \"2021\", \"publisher\": [\"IGI Global\"], \"doi\": \"10.4018/978-1-7998-4975-9.ch009\", \"p-isbn\": [\"9781799849759\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Creating Opportunity Spaces for Co-Production : Professional Co-Producers in Inter-Organizational Collaborations\", \"creator\": [\"Brix, Jacob\", \"Tuurnas, Sanna\", \"Mortensen, Nanna M\\u00f8ller\"], \"year\": \"2021\", \"publisher\": [\"IGI Global\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Full-Body Interaction in a Remote Context : Adapting a Dance Piece to a Browser-Based Installation\", \"creator\": [\"Masu, Raul\", \"Pajala-Assefa, Hanna\", \"Correia, Nuno N.\", \"Rom\\u00e3o, Teresa\"], \"publisher\": [\"ACM\"], \"doi\": \"10.1145/3483529.3483747\", \"p-isbn\": [\"9781450384209\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Full-body interaction in a remote context : adapting a dance piece to a browser-based installation\", \"creator\": [\"Masu, Raul\", \"Pajala-Assefa, Hanna\", \"N correia, Nuno\", \"Rom\\u00e3o, Teresa\"], \"year\": \"2021\", \"publisher\": [\"New York\"], \"e-isbn\": [\"9781450384209\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Gender inequalities in family leaves, employment and pensions in Finland\", \"creator\": [\"Kuitto, Kati\", \"Kuivalainen, Susan\"], \"year\": \"2021\", \"publisher\": [\"Edward Elgar\"], \"p-isbn\": [\"9781839106101\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Gender inequalities in family leaves, employment and pensions in Finland\", \"creator\": [\"Kuitto, Kati\", \"Kuivalainen, Susan\"], \"year\": \"2021\", \"publisher\": [\"Edward Elgar Publishing\"], \"e-isbn\": [\"9781839106101\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Germany as a Cultural Paragon. Transferring Modern Musical Life from Central Europe to Finland\", \"creator\": [\"Kurkela, Vesa\", \"Rantanen, Saijaleena\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Germany as a Cultural Paragon\", \"creator\": [\"Kurkela, Vesa\", \"Rantanen, Saijaleena\"], \"year\": \"2019\", \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Introduction\", \"creator\": [\"Anttila, Eeva\", \"Suominen, Anniina\"], \"year\": \"2018\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9781351111195\", \"e-isbn\": [\"9781351111195\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Critical articulations of hope from the margins of arts education\", \"creator\": [\"Anttila, Eeva\", \"Suominen, Anniina\"], \"year\": \"2018\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9781351111195\", \"e-isbn\": [\"9781351111195\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Musical engagement in one-to-one contexts\", \"creator\": [\"Gaunt, Helena\", \"L\\u00f3pez-\\u00cd\\u00f1iguez, Guadalupe\", \"Creech, Andrea\"], \"year\": \"2021\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9780429295362-29\", \"e-isbn\": [\"9780429295362\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Musical engagement in one-to-one contexts\", \"creator\": [\"Gaunt, Helena\", \"L\\u00f3pez-\\u00cd\\u00f1iguez, Guadalupe\", \"Creech, Andrea\"], \"year\": \"2021\", \"publisher\": [\"Routledge\"], \"doi\": \"10.4324/9780429295362-29\", \"p-isbn\": [\"9780429295362\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"The Dalcroze Approach : Experiencing and Knowing Music through Embodied Exploration\", \"creator\": [\"Juntunen, Marja-Leena\"], \"year\": \"2016\", \"publisher\": [\"Oxford University Press\"], \"doi\": \"10.1093/acprof:oso/9780199328093.001.0001\", \"p-isbn\": [\"9780199328093\"], \"type_coar\": \"book part\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"The Dalcroze Approach : Experiencing and Knowing Music Through Embodied Exploration\", \"creator\": [\"Juntunen, Marja-Leena\"], \"year\": \"2016\", \"publisher\": [\"Oxford University Press\"], \"doi\": \"10.1093/ acprof:oso/9780199328093.001.0001\", \"p-isbn\": [\"9780199328093\"], \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Traces of performance: opera, music theatre, and theatre music in the long 19th century\", \"year\": \"2013\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Traces' of performance : opera , music , theatre and the theatre music in the long 19th century !\", \"year\": \"2013\", \"type_coar\": \"book part\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Vitality in later years : food recommendation for older adults\", \"year\": \"2020\", \"publisher\": [\"Finnish Institute for Health and Welfare\"], \"e-isbn\": [\"9789523435179\"], \"p-issn\": \"2323-4172\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Vitality in later years : food recommendation for older adults\", \"creator\": [\"Nakano, Gerhard\", \"My\\u00f6h\\u00e4nen, Riikka\", \"Hautamaa, Petteri\", \"Heikkinen, Tarja\"], \"publisher\": [\"Finnish Institute for Health and Welfare\"], \"e-isbn\": [\"9789523435179\"], \"p-issn\": \"2323-4172\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"BOFIT Ven\\u00e4j\\u00e4-ennuste 2019-2021\", \"year\": \"2019\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"BOFIT Ven\\u00e4j\\u00e4-ennuste 2019-2021\", \"year\": \"2019\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Eduskunnan pankkivaltuuston kertomus 2013\", \"year\": \"2014\", \"publisher\": [\"Edita Prima Oy\"], \"p-issn\": \"1237-4334\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Eduskunnan pankkivaltuuston kertomus 2013\", \"year\": \"2014\", \"publisher\": [\"Eduskunnan yliopisto\"], \"e-issn\": \"1796-9794\", \"p-issn\": \"1237-4334\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Fyysisen toimintakyvyn mittaaminen ja arviointi v\\u00e4est\\u00f6tutkimuksissa\", \"creator\": [\"Sainio, P\\u00e4ivi\", \"Valkeinen, Heli\", \"Stenholm, Sari\", \"Vaara, Mariitta\", \"Rinne, Marjo\"], \"year\": \"2020\", \"publisher\": [\"TOIMIA\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Fyysisen toimintakyvyn mittaaminen ja arviointi v\\u00e4est\\u00f6tutkimuksissa\", \"creator\": [\"Sainio, Heli\", \"Valkeinen, Sari\", \"Stenholm, Mariitta\", \"Vaara, Marjo\", \"Rinne, Marjo\"], \"year\": \"2020\", \"publisher\": [\"Toiminta\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Hepolammen (Enon pit\\u00e4j\\u00e4/Joensuu) kalastorakenne loppukes\\u00e4ll\\u00e4 2022 ja kalastonhoidon suositukset\", \"creator\": [\"Tossavainen, Tarmo\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753809\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Hepolammen (Enon pit\\u00e4j\\u00e4/Joensuu) kalastorakenne loppukes\\u00e4ll\\u00e4 2022 ja kalastonhoidon suositukset\", \"creator\": [\"Tossavainen, Tarmo\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753809\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Hoidon tarpeen arviointi : nykytilan selvitys\", \"creator\": [\"Saukkonen, Sanna-Mari\", \"\\u00c5lander, Anne\"], \"year\": \"2021\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Hoidontarpeen arvioinnin nykytilan selvitys\", \"creator\": [\"Saukkonen, Sanna-Mari\", \"Alander, Anne\"], \"year\": \"2021\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Huomioi toimintarajoitteiset lapset ja nuoret hyvinvointikertomuksessa\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Huomioi toimintarajoitteiset lapset ja nuoret hyvinvointikertomuksessa : MIT\\u00c4?\", \"publisher\": [\"Vammaisfoorumi\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Johtokunnan kertomus pankkivaltuustolle Finanssivalvonnan toiminnasta 2022\", \"year\": \"2023\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Johtokunnan kertomus pankkivaltuustolle Finanssivalvonnan toiminnasta 2022\", \"year\": \"2023\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Koronaepidemian vaikutukset hyvinvointiin, palveluihin ja talouteen : THL:n seurantaraportti, viikot 49-50/2020, 16.12.2020\", \"publisher\": [\"THL\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Koronaepidemian vaikutukset hyvinvointiin, palveluihin ja talouteen : thl:n seurantaraportti, viikot 49\\u201350/2020\", \"year\": \"2020\", \"publisher\": [\"Thonnylyhannevaljoukseen\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Koulufysioterapialla hyvinvointia Pohjois-Karjalaan : Otsakorpi-hankkeen loppuraportti\", \"creator\": [\"Issakainen, Maiju\", \"Mustonen, Hilppa\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753410\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Koulufysioterapialla hyvin- vointia Pohjois-Karjalaan : Otsakorpi-hankkeen loppuraportti\", \"creator\": [\"Issakainen, Maiju\", \"Mustonen, Hilppa\"], \"year\": \"2021\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753410\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Lohkoketjuteknologian massa-adoption mahdollisuutta tutkimassa\", \"creator\": [\"Honkanen, Petri\"], \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"e-isbn\": [\"9789527365090\"], \"e-issn\": \"2342-3064\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Lohkoketjuteknologian massa-adoption mahdollisuutta tutkimassa\", \"creator\": [\"Honkanen, Petri\"], \"year\": \"2020\", \"publisher\": [\"Arcada\"], \"e-isbn\": [\"9789527365090\"], \"p-isbn\": [\"9789527365085\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Loppuraportti Koliikkivauvojen hoito vy\\u00f6hyketerapialla -pilottitutkimus 2017-2019\", \"creator\": [\"Hannula, Leena\", \"M\\u00e4kij\\u00e4rvi, Markku\"], \"publisher\": [\"Luonnonl\\u00e4\\u00e4ketieteen Keskusliitto LKL ry\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Loppuraportti Koliikkivauvojen hoito vy\\u00f6hyketerapialla : pilottitutkimus 2017-2019\", \"creator\": [\"Hannula, Leena\", \"M\\u00e4kij\\u00e4rvi, Markku\"], \"year\": \"2020\", \"publisher\": [\"Luonnonl\\u00e4\\u00e4ketieteen keskusliitto LKL\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"L\\u00e4\\u00e4kehoidon tiedonhallinnan konsepti\", \"creator\": [\"Virkkunen, Heikki\", \"Relander, Toni\", \"Malmivaara, Antti\", \"Hiltunen, Piritta\", \"Jalonen, Marko\", \"N\\u00e4rv\\u00e4nen, Jarkko\"], \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"L\\u00e4\\u00e4kehoidon tiedonhallinnan konsepti\", \"creator\": [\"Virkkunen, Heikki\", \"Relander, Toni\", \"Malmivaara, Antti\", \"Hiltunen, Piritta\", \"Jalonen, Marko\", \"N\\u00e4rv\\u00e4nen, Jarkko\"], \"year\": \"2020\", \"publisher\": [\"Institutet f\\u00f6r h\\u00e4lsa och v\\u00e4lf\\u00e4rd\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Mist\\u00e4 kohtuusperiaatteessa ja yhti\\u00f6iden lis\\u00e4etujen jakamisessa on kysymys?\", \"publisher\": [\"Finanssivalvonta\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Mist\\u00e4 kohtuusperiaatteessa ja yhti\\u00f6iden lis\\u00e4etujen jakamisessa on kysymys?\", \"creator\": [\"Sinnunsvallirantoinen, Jari\"], \"year\": \"2014\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Poliisikoulutuksen vaikuttavuusarviointi 2021 : vuosina 2018-2019 valmistuneiden poliisien ty\\u00f6llisyys ja arviot koulutuksen ty\\u00f6el\\u00e4m\\u00e4vastaavuudesta\", \"creator\": [\"Vuorensyrj\\u00e4, Matti\"], \"publisher\": [\"Poliisiammattikorkeakoulu\"], \"e-isbn\": [\"9789518153866\"], \"p-issn\": \"1797-5743\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Poliisikoulutuksen vaikuttavuusarviointi 2021 : Poliisiammattikorkeakoulu-raportteja 138\", \"creator\": [\"Vuorensyrj\\u00e4, Matti\"], \"year\": \"2021\", \"publisher\": [\"Poliisiammattikorkeakoulu\"], \"e-isbn\": [\"9789518153866\"], \"p-issn\": \"1797-5743\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta Etel\\u00e4-Savon kunnissa 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta : Terveyden ja hyvinvoinnin laitos \", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta Pohjois-Karjalan kunnissa 2020\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Terveytt\\u00e4 edist\\u00e4v\\u00e4 liikunta POHJOIS-\\KARNANNA 2020 : Liikunnan edist\\u00e4misaktiivisuus Suomen kunnissa\", \"year\": \"2020\", \"publisher\": [\"Terveyden ja hyvinvoinnin laitos\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Ymp\\u00e4rist\\u00f6vaikutusten arviointi 80-luvun liikerakennuksen kiinteist\\u00f6kehitt\\u00e4misess\\u00e4 : Elinkaariarvioinnin (LCA), elinkaarikustannusten (LCC) ja energiasimuloinnin arviointiraportti\", \"creator\": [\"Keskisalo, Mika\", \"Kuusisto, Jari\", \"Matveinen, Mikko\"], \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753656\"], \"e-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Ymp\\u00e4rist\\u00f6vaikutusten arviointi 80-luvun liikerakennuksen kiinteist\\u00f6kehitt\\u00e4misess\\u00e4 : Elinkaariarvioinnin (LCA), elinkaarikustannusten (LCC) ja energiasimuloinnin arviointiraportti\", \"creator\": [\"Keskisalo, Mika\", \"Kuusisto, Jari\", \"Matveinen, Mikko\"], \"year\": \"2022\", \"publisher\": [\"Karelia-ammattikorkeakoulu\"], \"e-isbn\": [\"9789522753656\"], \"p-issn\": \"2323-6914\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Dynaamisten kyvykkyyksien syntyminen ja kehittyminen hyvinvointialuevalmistelun yhteydess\\u00e4 : Kyvykkyysperusteinen n\\u00e4k\\u00f6kulma julkishallinnon organisaation muutosprosessiin\", \"creator\": [\"Post, Juha\"], \"year\": \"2023\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950740\"], \"p-isbn\": [\"9789523950733\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Dynaamisten kyvykkyyksien syntyminen ja kehittyminen hyvinvointialuevalmistelun yhteydess\\u00e4 : Kyvykkyysperusteinen n\\u00e4k\\u00f6kulma julkishallinnon organisaation muutosprosessiin\", \"creator\": [\"Post, Juha\"], \"year\": \"2023\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950740\"], \"p-isbn\": [\"9789523950733\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Edess\\u00e4 ja edell\\u00e4: Suomen ete-vartaloisten tilagrammien merkitykset ja metaforisuus\", \"creator\": [\"Teeri-Niknammoghadam, Krista\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512984374\"], \"p-isbn\": [\"9789512984367\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Edess\\u00e4 JA EDELL\\u00e4 : Suomen ete-vartaloisten tilagrammien merkitykset ja metaforisuus\", \"creator\": [\"Teeri-Niknammoghadam, Krista\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512984374\"], \"p-isbn\": [\"9789512984367\"], \"p-issn\": \"2343-3191\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kielellisesti tuettu opetus : Yl\\u00e4kouluik\\u00e4iset maahanmuuttajaoppilaat opetuskielt\\u00e4 ja oppiainesis\\u00e4lt\\u00f6j\\u00e4 oppimassa\", \"creator\": [\"Harju-Autti, Raisa\"], \"year\": \"2022\", \"publisher\": [\"Tampereen yliopisto\"], \"e-isbn\": [\"9789520326661\"], \"p-isbn\": [\"9789520326654\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Raisa Harju-autosivi : kielellisesti tuettu opetus\", \"year\": \"2022\", \"publisher\": [\"Tampereen yliopisto\"], \"e-isbn\": [\"9789520326661\"], \"p-isbn\": [\"9789520326654\"], \"e-issn\": \"2490-0028\", \"p-issn\": \"2489-9860\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"K\\u00e4tketty maisema : arkitieto l\\u00e4hiymp\\u00e4rist\\u00f6n kohtaamisessa\", \"creator\": [\"Puolam\\u00e4ki, Laura\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512979301\"], \"p-isbn\": [\"9789512979523\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"K\\u00e4tketty maisema : arkitieto l\\u00e4hiymp\\u00e4rist\\u00f6n kohtaamisessa\", \"creator\": [\"Puolam\\u00e4ki, Laura\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512979301\"], \"p-isbn\": [\"9789512979523\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"P\\u00e4ivitt\\u00e4inen johtaminen l\\u00e4hiesimiehen ty\\u00f6ss\\u00e4 leikkaus- ja anestesiaosastolla\", \"creator\": [\"Siirala, Eriikka\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512982967\"], \"p-isbn\": [\"9789512982950\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"P\\u00e4ivitt\\u00e4inen johtaminen l\\u00e4hiesimiehen ty\\u00f6ss\\u00e4 leikkaus- ja anestesiaosastolla\", \"creator\": [\"Siirala, Eriikka\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512982967\"], \"p-isbn\": [\"9789512982950\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Toimijat, taistelijat, tipahtaneet   \\u2013  Koulutus- ja ty\\u00f6toimijuus mielenterveyskuntoutujien el\\u00e4m\\u00e4nkerronnoissa\", \"creator\": [\"Vilppola, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512983025\"], \"p-isbn\": [\"9789512983018\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Toimijat, taistelijat, tipahtaneet : koulutus- ja ty\\u00f6toimijuus mielenterveyskuntoutujien el\\u00e4m\\u00e4nkerronnoissa\", \"creator\": [\"Vilppola, Johanna\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512983025\"], \"p-isbn\": [\"9789512983018\"], \"e-issn\": \"2343-3205\", \"p-issn\": \"0082-6995\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Vastuullinen julkinen johtaminen : Hallinto-oppien kommunikatiivinen arviointi\", \"creator\": [\"Autioniemi, Jari\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769655\"], \"p-isbn\": [\"9789524769648\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Vastuullinen julkinen johtaminen\", \"creator\": [\"Autioniemi, Jari\"], \"year\": \"2021\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789524769929\"], \"p-isbn\": [\"9789524769912\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Veron kiert\\u00e4misen tunnistaminen : oikeuden v\\u00e4\\u00e4rink\\u00e4yt\\u00f6n kielto VML 28 \\u00a7:n tulkinnassa\", \"creator\": [\"Kaunisto, Siru\"], \"year\": \"2022\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950276\"], \"p-isbn\": [\"9789523950269\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Veron kiert\\u00e4misen tunnistaminen : Oikeuden v\\u00e4\\u00e4rink\\u00e4yt\\u00f6n kielto VML 28 \\u00a7:n tulkinnassa\", \"creator\": [\"Kaunisto, Siru\"], \"year\": \"2022\", \"publisher\": [\"Vaasan yliopisto\"], \"e-isbn\": [\"9789523950276\"], \"p-isbn\": [\"9789523950269\"], \"e-issn\": \"2323-9123\", \"p-issn\": \"0355-2667\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"V\\u00e4litt\\u00e4v\\u00e4 kasvatus ja opetus peruskoulun yhdeks\\u00e4sluokkalaisten kokemana\", \"creator\": [\"Hosio, Maarit\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512986835\"], \"p-isbn\": [\"9789512986828\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"V\\u00e4litt\\u00e4v\\u00e4 kasvatus ja opetus peruskoulun yhdeks\\u00e4sluokkaisten kokemana : Turun yliopisto : Doctoral thesis\", \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"e-isbn\": [\"9789512986835\"], \"p-isbn\": [\"9789512986828\"], \"e-issn\": \"2343-3191\", \"p-issn\": \"0082-6987\", \"type_coar\": \"doctoral thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"\\\"Pit\\u00e4is varmaan sanoa, ett\\u00e4 Jumala se kutsuu\\\" -n\\u00e4k\\u00f6kulmia kanttorin kutsumukseen\", \"creator\": [\"Alasaarela, Laura\"], \"year\": \"2019\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"\\\"Pit\\u00e4is varmaan sanoa, ett\\u00e4 Jumala se\\\" -n\\u00e4k\\u00f6kulmia kanttorin kutsumukseen\", \"creator\": [\"Alasaarela, Laura\"], \"year\": \"2019\", \"publisher\": [\"Taideyliopiæ¬¡å­¦å£« academia\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"13\\u201317-vuotiaiden poikien plyometrinen harjoittelu jalkapallossa \\u2013opas valmentajille\", \"creator\": [\"Qvickstr\\u00f6m, Henri\", \"Silfverberg, Ville\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Laurea-ammattikorkeakoulu : fysioterapian koulutusohjelma\", \"creator\": [\"Qvickstr\\u00f6m, Henri\", \"Silfverberg, Ville\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Einojuhani Rautavaaran Lapsimessu (op. 71) : n\\u00e4k\\u00f6kulmia harjoittamiseen\", \"creator\": [\"Norjanen, Anna-Elina\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Einojuhani Rautavaaran Lapsimessu : n\\u00e4k\\u00f6kulmia harjoittamiseen Anna-\\u00ad\\u2010Elina Norjanen S-\\u00ad\\u2010KM25 Kirjallinen ty\\u00f6 Kirkkomusiikin ja urkujen aineryhm\\u00e4 Taideyliopiston Sibelius-\\u00ad\\u2010Akatemia 2021\", \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Esimiehen\\u00e4 muuttuvan organisaation aallokoissa : Organisaatio tuen merkitys muutoksen johtamisessa\", \"creator\": [\"Hihnala, Heidi\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Esimiehen\\u00e4 muuttuvan organisaation aallokoissa\", \"creator\": [\"Hihnala, Heidi\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Hoitajien ergonomiaosaaminen potilaan siirto- ja nostotilanteissa\", \"creator\": [\"Helander, Anna-Kaisa\", \"Koivisto, Tuomas-Heikki\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Hoitajien ergonomiaosaaminen potilaan siirto- ja nostotilanteissa\", \"creator\": [\"Helander, Anna-Kaisa\", \"Koivisto, Tuomas-Heikki\"], \"year\": \"2020\", \"publisher\": [\"Laurea-ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Hoitoty\\u00f6n vertaisarviointiprosessin testaaminen osana lasten spirometriatutkimuksen laadun kehitt\\u00e4mist\\u00e4\", \"creator\": [\"Kinnunen, Karoliina\"], \"year\": \"2021\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Hoitoty\\u00f6n vertaisarviointiprosessin tes- taaminen osana lasten spirometriatutkimuksen laadun kehitt\\u00e4mist\\u00e4\", \"creator\": [\"Kinnunen, Karoliina\"], \"year\": \"2021\", \"publisher\": [\"Kehitt\\u00e4v\\u00e4 tutkimusty\\u00f6\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Itsem\\u00e4\\u00e4r\\u00e4\\u00e4misoikeus lain n\\u00e4k\\u00f6kulmasta kehitysvammahuollon laitospalveluissa - Auditointisuunnitelma\", \"creator\": [\"Rahkj\\u00e4rvi, P\\u00e4ivi\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Itsem\\u00e4\\u00e4r\\u00e4\\u00e4misoikeus lain n\\u00e4k\\u00f6kulmasta kehitysvammahuollon laitospalveluissa : Auditointisuunnitelma\", \"creator\": [\"Rahkj\\u00e4rvi, P\\u00c4IVI\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kaisa Juhantytt\\u00e4ren (1782\\u20131856) el\\u00e4m\\u00e4nhistoria ja muistivihkoon k\\u00e4tketty minuus\", \"creator\": [\"Kautto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Kaisa Juhantytt\\u00e4ren (1782-1856) el\\u00e4m\\u00e4nhistoria ja muistivihkoon k\\u00e4tketty minuus : gradu -tutkielma\", \"year\": \"2020\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Laadunhallintaj\\u00e4rjestelm\\u00e4 Bluet Oy:lle\", \"creator\": [\"Ivanov, Slava\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Laadunhallintaj\\u00e4rjestelm\\u00e4 : Bluet Oy :lle\", \"creator\": [\"Ivanov, Slava\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Lahjakkaan lapsen erityisopetus : N\\u00e4k\\u00f6kulmana tasa-arvo\", \"creator\": [\"Niitamo, Katri\"], \"year\": \"2019\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Lahjakkaan lapsen erityisopetus : N\\u00e4k\\u00f6kulmana tasa-arvo\", \"creator\": [\"Nittimaki, Katri\"], \"year\": \"2019\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Mannerheimin Lastensuojeluliiton Tampereen osaston Eron ensiapupisteen ohjaus- ja neuvontaty\\u00f6 : perheiden ja ty\\u00f6ntekij\\u00f6iden kokemuksia palveluista\", \"creator\": [\"Annala, Riina\", \"Ryh\\u00e4nen, Juulia\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Mannerheimin Lastensuojeluliiton : Tampereen osaston Eron ensiapu- pisteen ohjaus- ja neuvontaty\\u00f6\", \"creator\": [\"Annala, Riina\", \"Ryh\\u00e4nen, Juilla\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Musiikinopettajan pedagogisten l\\u00e4hestymistapojen vaikutus murrosik\\u00e4isen oppilaan motivaatioon\", \"creator\": [\"Kauppinen, Sakari\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Musiikinopettajan pedagogisten l\\u00e4hestymistapojen vaikutus murrosik\\u00e4isen oppilaan motivaatioon\", \"creator\": [\"Kauppinen, Sakari\"], \"year\": \"2021\", \"publisher\": [\"Taideyliopiston Sibelius-Akatemia\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Ohjelmistorobotiikan k\\u00e4ytt\\u00f6\\u00f6notosta aiheutuneen muutoksen kokeminen : Tampereen kaupungin ty\\u00f6llisyys- ja kasvupalvelut\", \"creator\": [\"Toukola, Lilli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Ohjelmistorobotiikan k\\u00e4ytt\\u00f6\\u00f6notosta aiheutuneen muutoksen kokeminen\", \"creator\": [\"Toukola, Lilli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen kaupungin ty\\u00f6llisyys- ja kasvupalveluiden kunnattu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Osakkeen hinnassa tapahtuva muutos ennen tulosjulkistusta: Markkinoiden ennustuskyky\", \"creator\": [\"Viitala, Kalle\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Osakkeen hinnassapahtuva muutos ennen tulosjulkistusta : markkinoiden ennustuskyky\", \"creator\": [\"Viitala, Kalle\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Postresuskitaatiohoito ensihoidossa : tarkistuslista ensihoitajille\", \"creator\": [\"Jaakkola, Amanda\", \"Mattila, Janina\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Postresuskitaatiohoito ensihoidossa : Tarkistuslista ensihoitajille\", \"creator\": [\"Jaakkola, Amanda\", \"Mattila, Janina\"], \"year\": \"2021\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Ravitsemusprofilointi osana SOK:n Omat Ostot -palvelua\", \"creator\": [\"Valli, Nelli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Ravitsemusprofilointi osana SOK:n Omat Ostot -palvelua\", \"creator\": [\"Valli, Neli\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Suomalaisuuden reunaehdot sotien v\\u00e4lisen\\u00e4 aikana: Rajank\\u00e4ynti\\u00e4 menneisyyskuvilla Lauri Haarlan historiallisessa romaanissa Kurkien taru (1938\\u20131940)\", \"creator\": [\"Lepist\\u00f6, Vilma\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Suomen uuden reunaehtoja sotien v\\u00e4lisen\\u00e4 aikana : Rajank\\u00e4ynti\\u00e4 menneisyyskuvilla Lauri Haarlan historiallisessa romaanissa\", \"creator\": [\"Lepist\\u00f6, Vilma\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun : Tarkastusvaliokunnat suomalaisissa ja ruotsalaisissa p\\u00f6rssiyhti\\u00f6iss\\u00e4\", \"creator\": [\"Salminen, Heini\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun\", \"creator\": [\"Salminen, Heini\"], \"year\": \"2020\", \"publisher\": [\"Vaasan yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Terveys ja lihavuus Olet mit\\u00e4 sy\\u00f6t -ohjelmassa: \\u201dEt s\\u00e4 oo mik\\u00e4\\u00e4n l\\u00e4\\u00e4ketieteellinen ihme, vaikka s\\u00e4 oot luullu niin\\u201d\", \"creator\": [\"Nevalainen, Emmi\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Terveys ja lihou Suseltoiminnottimisesta ohjelmassa \\u201dEt s\\u00e4 oo mik\\u00e4\\u00e4n l\\u00e4\\u00e4ketieteellinen ihme, vaikka s\\u00e4 oot luullu niin\\u201d\", \"creator\": [\"Nevalainen, Emmi\"], \"year\": \"2020\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Ty\\u00f6hyvinvoinnin vaikutus sairauspoissaoloihin\", \"creator\": [\"Katajisto, Riikka\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Ty\\u00f6hyvinvoinnin vaikutus sairauspoissaoloihin\", \"creator\": [\"Katajisto, Riikka\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Villikasveista jalosteiksi\", \"creator\": [\"Kuusela, Sofia\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Villikasveista jalosteiksi\", \"creator\": [\"Kuusela, Sofia\"], \"year\": \"2020\", \"publisher\": [\"Metropolia Ammattikorkeakoulu\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"A Light Enterprise Information Security Architecture Model for Creating and Improving Security Architecture\", \"creator\": [\"Kossila, Johannes\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"A Light Enterprise Information Security Architecture Model for Creating and Improving Security Architecture\", \"creator\": [\"Kossila, Johannes\"], \"year\": \"2020\", \"publisher\": [\"Turun Kauppakorkeakoulu\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"An analysis of Facebook posts\", \"creator\": [\"To, My\"], \"year\": \"2020\", \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"An analysis of Facebook posts\", \"creator\": [\"My, Arcada\"], \"year\": \"2021\", \"publisher\": [\"Yrkesh\\u00f6gskolan Arcada\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Analysis of User Exploration Patterns during Scene Cuts in Omnidirectional Videos\", \"creator\": [\"Monakhov, Dmitrii\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Analysis of User Exploration Patterns during Scene Cuts in Omnidirectional Videos\", \"creator\": [\"Monakhov, Dmitrii\"], \"year\": \"2020\", \"publisher\": [\"Tampere University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"BENEFITS OF KINETICS AND PROXEMICS FOR A CONCEPTUAL VIRTUAL REALITY OBEYA : Exploratory research on virtual reality as a medium for interpersonal interaction\", \"creator\": [\"Mattila, Jaakko\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Benefits of Kinetics and Proxemics for a Conceptual Virtual Reality Obeya\", \"creator\": [\"Mattila, Jaakko\"], \"year\": \"2019\", \"publisher\": [\"Turun University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Black African Entrepreneurs in Finland: Structural Barriers\", \"creator\": [\"Vorobeva, Ekaterina\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Black African Entrepreneurs in Finland : Structural Barriers\", \"creator\": [\"Vorobeva, Ekaterina\"], \"year\": \"2019\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Creating and implementing a business process model\", \"creator\": [\"Skog, Patrik\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Creating and implementing a business process model\", \"creator\": [\"Skog, Patrik\"], \"year\": \"2020\", \"publisher\": [\"University of Vaasa\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Developing a football game for Android\", \"creator\": [\"Huhtam\\u00e4ki, Markus\"], \"year\": \"2021\", \"publisher\": [\"Tampere University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Developing a Football Game for Android\", \"creator\": [\"Huhtam\\u00e4ki, Markus\"], \"year\": \"2021\", \"publisher\": [\"Tampere University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Gender Differences in the Finnish Labour Market - Decomposing the Gender Wage Gap in Finland\", \"creator\": [\"Kortelainen, Julia\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Gender Differences in the Finnish Labour Market : Decomposing the Gender Wage Gap in Finland\", \"creator\": [\"Kortelainen, Julia\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"On the History and Future of Clarinet Systems\", \"creator\": [\"Agababa Shaked, Gil\"], \"year\": \"2018\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"On the History and Future of Clarinet Systems\", \"creator\": [\"Agababa-Shaked, Gil\"], \"year\": \"2018\", \"publisher\": [\"Sibelius Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Resource Productivity as the EU\\u00b4s Lead Resource Efficiency Indicator : a quantitative macro-comparative study on indicator drivers\", \"creator\": [\"J\\u00e4rnefelt, Elisabeth\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Resource Productivity as the EU\\u00b4s Lead Resource Efficiency Indicator : a quantitative macro-comparative study on indicator drivers\", \"creator\": [\"J\\u00e4rnefelt, Elisabeth\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi University\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Slippage between :  a common void\", \"creator\": [\"Oliva, Maya\"], \"year\": \"2022\", \"publisher\": [\"Theatre Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Slippage Between a Common Void : A Choreographic Practice by \\u201cI wish I was on planet earth\\u201d\", \"creator\": [\"Oliva, Maya\"], \"year\": \"2022\", \"publisher\": [\"Theatre Academy, University of the Arts Helsinki\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"The cultural history of politics in Swedish contemporary art.\", \"creator\": [\"Kozma, Madeleine\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"The cultural history of politics in Swedish contemporary art.\", \"creator\": [\"Kozma, Madeleine\"], \"year\": \"2020\", \"publisher\": [\"Novia University of Applied Sciences\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"The English-Finnish-Nepali-Arabic Dictionary for Nursing Students\", \"creator\": [\"Olundegun, Ololade\", \"Pokharel, Jyoti\", \"Al-Rammahi, Mohammed\"], \"year\": \"2021\", \"publisher\": [\"Laurea University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Laurea University of Applied Sciences : Degree program in Nursing : Bachelor thesis - March 2021\", \"creator\": [\"Pokharel, Jyoti\", \"AL-Rammahi, Mohammed\", \"Olundegun, Ololade\"], \"year\": \"2021\", \"publisher\": [\"Laurea University of Applied Sciences\"], \"type_coar\": \"bachelor thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Utopian Reconfiguration of the Nature/Culture Dualism in Ursula Le Guin\\u2019s Always Coming Home\", \"creator\": [\"Veistola, Atte\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Utopian reconfiguration of the nature/culture dualism in Ursula Le Guin's Always Coming Home\", \"creator\": [\"Veistola, Atte\"], \"year\": \"2020\", \"publisher\": [\"University of Turku\"], \"type_coar\": \"master thesis\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Bystr\\u00f6min Ohjaamon toimintaa kehitettiin asiakasl\\u00e4ht\\u00f6isesti\", \"creator\": [\"Visuri, Anna\", \"Koivisto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Bystr\\u00f6min Ohjaamon toimintaa kehitettiin asiakasl\\u00e4ht\\u00f6isesti\", \"creator\": [\"Visuri, Anna\", \"Koivisto, Kaisa\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Hahmottamisen laaja-alaisuus ja tiedon luonne\", \"creator\": [\"Sepp\\u00e4l\\u00e4, Mikael\"], \"year\": \"2022\", \"type_coar\": \"research article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Hahmottamisen laaja-alaisuus ja tiedon luonne\", \"creator\": [\"Sepp\\u00e4l\\u00e4, Mikaile\"], \"year\": \"2022\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"IMF ennustaa talouskasvua euroalueelle ja Suomelle\", \"creator\": [\"Toivanen, Mervi\"], \"year\": \"2015\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"blog post\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Blogi IMF ennustaa talouskasvvasa euro-alueelle ja Suomelle\", \"creator\": [\"Toivanen, Vemir\"], \"year\": \"2015\", \"type_coar\": \"blog post\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kansalliset keskuspankit tuntevat oman maansa markkinapaikat\", \"creator\": [\"Hievanen, Laura\"], \"year\": \"2015\", \"publisher\": [\"Suomen Pankki\"], \"type_coar\": \"blog post\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Blogi kansalliset keskuspankit tuntevat oman maansa markkinapaikat\", \"creator\": [\"Hievanen, Laura\"], \"year\": \"2015\", \"type_coar\": \"blog post\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Kest\\u00e4v\\u00e4n j\\u00e4tehuollon koulutusosaamista vahvistamassa Ven\\u00e4j\\u00e4ll\\u00e4 ja Kazakstanissa\", \"creator\": [\"Asikainen, Eveliina\", \"Kallio, Ella\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Kest\\u00e4v\\u00e4n j\\u00e4tehuollon koulutusosaamista vahvistamassa Ven\\u00e4j\\u00e4ll\\u00e4 ja Kazakstanissa\", \"creator\": [\"Asikainen, Eveliina\", \"Kallio, Ella\"], \"year\": \"2020\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Maamassojen tilavuuksien mittaamiseen uusia menetelmi\\u00e4 \\u2013 maan pinnalta ilmaan\", \"creator\": [\"Pesonen, Joonas\", \"J\\u00e4rvel\\u00e4inen, Titta\", \"K\\u00e4yhk\\u00f6, Virpi\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Maamassojen tilavuuksien mittaamiseen uusia menetelmi\\u00e4 \\u2013 maan pinnalta ilmaan\", \"creator\": [\"Pesonen, Joonas\", \"J\\u00e4rvel\\u00e4inen, Titta\", \"K\\u00e4yhk\\u00f6, Virpi\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Medianomit ehk\\u00e4isev\\u00e4t ennalta ty\\u00f6tt\\u00f6myytt\\u00e4\", \"creator\": [\"Karppinen, Anneli\", \"Ketonen, Emma\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Medianomit ehk\\u00e4isev\\u00e4t ennalta ty\\u00f6tt\\u00f6myytt\\u00e4\", \"creator\": [\"Karppinen, Anneli\", \"Ketonen, Emma\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Mik\\u00e4 saa myllypurolaisen voimaan hyvin?\", \"creator\": [\"Ruotsalainen, Taru\", \"Vuorij\\u00e4rvi, Aino\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Mik\\u00e4 saa myllypurolaisen voimaan hyvin.\", \"creator\": [\"Ruotsalainen, Taru\", \"Vuorij\\u00e4rvi, Aino\"], \"year\": \"2019\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Moodlen oppimisanalytiikkaa pedagogiikan tueksi\", \"creator\": [\"Kurttila, Jukka\", \"Aalto, Markus\"], \"year\": \"2021\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Moodlen oppimisanalytiikkaa pedagogiikan tueksi\", \"creator\": [\"Ahvenlampi, Sirpa\"], \"year\": \"2021\", \"publisher\": [\"Turun yliopisto\"], \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Oluenarviointisovellukset \\u2013 olutskenen siunaus vai kirous\", \"creator\": [\"Lehtinen, Aniko\"], \"year\": \"2020\", \"type_coar\": \"newspaper article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Oluenarviointisovellukset \\u2013 olutskenen siunaus vai kirous\", \"creator\": [\"Lehtinen, Sanat Anikko\"], \"year\": \"2020\", \"type_coar\": \"newspaper article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Opiskelija keikkaty\\u00f6n kiemuroissa\", \"creator\": [\"Pajula, Carolina\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Opiskelija keikkaty\\u00f6n kiemuroissa\", \"creator\": [\"Pajula, Ilona\"], \"year\": \"2019\", \"publisher\": [\"Tampereen ammattikorkeakoulu\"], \"type_coar\": \"research article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Pitk\\u00e4aikaissairauksien ja suun limakalvomuutosten yhteys\", \"creator\": [\"Tapio, Anni\", \"Sepp\\u00e4l\\u00e4, Anne-Mari\", \"Luoto, Annika\", \"Holappa-Girginkaya, Jaana\", \"Kuure, Marja-Helena\", \"Kein\\u00e4nen, Anna-Leena\"], \"year\": \"2020\", \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Pitk\\u00e4aikaissairauksiana ja suun limakalvomuutosten yhteys\", \"creator\": [\"Kein\\u00e4nen, Luoto, Aini, Sepp\\u00e4l\\u00e4, Anne-Mari, Luoto, Annika, Jaana Holappa-Girginkaya, Marja-Helena, Anna-Leena\"], \"publisher\": [\"Oulun ammattikorkeakoulu\"], \"e-issn\": \"1798-2022\", \"type_coar\": \"journal article\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"fin\", \"title\": \"Siivouskemikaalien ja \\u2013menetelmien vaikutukset koulu- ja p\\u00e4iv\\u00e4kotiymp\\u00e4rist\\u00f6n mikrobistoon ja sis\\u00e4ilman laatuun\", \"creator\": [\"Kakko, Leila\", \"Reunanen, Eija\", \"Kylm\\u00e4korpi, Paula\", \"Alapieti, Tuomas\", \"T\\u00e4ubel, Martin\", \"Mikkola, Raimo\", \"Salonen, Heidi\"], \"year\": \"2019\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"conference paper\"}\n",
      "Prediction:\n",
      "{\"language\": \"fin\", \"title\": \"Siivouskemikaalien ja \\u2013menetelmien vaikutukset koulu- ja p\\u00e4iv\\u00e4kotiymp\\u00e4rist\\u00f6n mikrobistoon ja sis\\u00e4mman laatuun\", \"creator\": [\"Kakko, Laina\", \"Reunanen, Elina\", \"Kylm\\u00e4korpi, Petri\", \"Alapieti, Taina\", \"T\\u00e4ubel, Mikko\", \"Mikkola, Reinisalo\", \"Salonen, Helela\"], \"year\": \"2019\", \"publisher\": [\"Tampereen yliopisto\"], \"type_coar\": \"conference paper\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Bothnian Bay Hydrogen Valley \\u2013  Research report\", \"year\": \"2021\", \"publisher\": [\"LUT University\"], \"e-isbn\": [\"9789523357631\"], \"p-issn\": \"2243-3376\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Bothnian Bay Hydrogen Valley : Research report\", \"creator\": [\"Karjunen, Hannu\", \"Lassila, Jukka\", \"Tynj\\u00e4l\\u00e4, Tero\", \"Laaksonen, Petteri\", \"Tuomaala, Mari\", \"Vilppo, Julius\", \"Taulasto, Kimmo\", \"Karppanen, Janne\", \"Laari, Arto\", \"Kosonen, Antti\", \"Ahola, Jero\"], \"year\": \"2021\", \"publisher\": [\"Lappeenrannan-Lahti University of Technology, Lutskouyliopiston LUT\"], \"e-isbn\": [\"9789523357631\"], \"p-isbn\": [\"9789523357631\"], \"p-issn\": \"2243-3376\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Channels of dialogue between international businesses and national governments : The implications for domestic reforms and international relations in the case of Russia\", \"creator\": [\"Yakovlev, Andrei\", \"Freinkman, Lev\", \"Ershova, Nina\"], \"year\": \"2018\", \"publisher\": [\"Bank of Finland\"], \"e-issn\": \"2342-205X\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Channels of dialogue between international businesses and national governments : The implications for domestic reforms and international relations in the case of Russia\", \"creator\": [\"Yakovlev, Andrei\", \"Freinkman, Lev\", \"Ershova, Nina\"], \"year\": \"2018\", \"publisher\": [\"Bank of Finland\"], \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Finland in Figures 2015\", \"publisher\": [\"Statistics Finland\"], \"e-isbn\": [\"9789522445896\"], \"p-isbn\": [\"978\\u2212952\\u2212244\\u2212522\\u22123\"], \"e-issn\": \"2242-8496\", \"p-issn\": \"0357\\u22120371\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Finland in figures 2015\", \"year\": \"2017\", \"publisher\": [\"Statistics Finland\"], \"type_coar\": \"report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"Housing market and current account imbalances in the international economy\", \"creator\": [\"Punzi, Maria Teresa\"], \"year\": \"2012\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789524627849\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"Housing market and current account imbalances in the international economy\", \"creator\": [\"Punzi, Maria Teresa\"], \"year\": \"2012\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789524627849\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"eng\", \"title\": \"How to explain errors in budget balance forecasts in euro area countries? Empirical evidence based on real-time data\", \"creator\": [\"Paloviita, Maritta\", \"Ikonen, Pasi\"], \"year\": \"2016\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789523231146\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "Prediction:\n",
      "{\"language\": \"eng\", \"title\": \"How to explain errors in budget balance forecasts in euro area countries? Empirical evidence based on real-time data\", \"creator\": [\"Paloviita, Maritta\", \"Ikonen, Pasi\"], \"year\": \"2016\", \"publisher\": [\"Bank of Finland\"], \"e-isbn\": [\"9789523231146\"], \"e-issn\": \"1456-6184\", \"type_coar\": \"research report\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"D\\u00e4r kunskapen t\\u00e4tnar som moln : Ess\\u00e4er om litteraturen som kunskapsf\\u00e4lt och kunskapsform\", \"year\": \"2021\", \"publisher\": [\"Litteraturvetenskap och filosofi vid \\u00c5bo Akademi\"], \"e-isbn\": [\"9789521240201\"], \"p-isbn\": [\"9789521240195\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"D\\u00e4r kunskapen t\\u00e4tnar som moln : Ess\\u00e4er om litteraturen som kunskapsf\\u00e4lt och kunskapsform\", \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademis \\u2014 Finansinspektion\"], \"e-isbn\": [\"9789521240201\"], \"p-isbn\": [\"9789521240195\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Finsk straffr\\u00e4tt : grundkurs i straffr\\u00e4ttens allm\\u00e4nna l\\u00e4ror\", \"creator\": [\"Boucht, Johan\", \"Fr\\u00e4nde, Dan\"], \"year\": \"2020\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518153767\"], \"p-isbn\": [\"9789518153750\"], \"e-issn\": \"1455-8270\", \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Finsk straffr\\u00e4tt : Grundkurs i straffr\\u00e4ttens allm\\u00e4nna l\\u00e4ror\", \"creator\": [\"Boucht, Johan\", \"Fr\\u00e4nde, Dan\"], \"year\": \"2020\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518153767\"], \"p-isbn\": [\"9789518153750\"], \"p-issn\": \"1455-8270\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"N\\u00e4r man g\\u00e5r i stora skor l\\u00e4mnar man stora sp\\u00e5r efter sig : aderton perspektiv p\\u00e5 polisarbetet : studiematerial f\\u00f6r Polisyrkesh\\u00f6gskolans intr\\u00e4desprov 2014\", \"year\": \"2014\", \"publisher\": [\"Polisyrkesh\\u00f6gskolan\"], \"e-isbn\": [\"9789518152630\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"N\\u00e4r man g\\u00e5r i stora skor l\\u00e4mnar man stora sp\\u00e5r efter sig : 1-3 : Aderton perspektiv p\\u00e5 polisarbetet. Polisyrkesh\\u00f6gskolan. Studiematerial f\\u00f6r Polisyrkesh\\u00f6gskolans intr\\u00e4desprov 2014\", \"year\": \"2014\", \"publisher\": [\"Aderton perspektiv\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Kartering av fisksamh\\u00e4llen och f\\u00f6rekomst av plattfiskar och n\\u00e4bbg\\u00e4dda (Belone belone) p\\u00e5 exponerade str\\u00e4nder p\\u00e5 \\u00c5land\", \"creator\": [\"Finnb\\u00e4ck, Lars\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521240249\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Kartering av fisksamh\\u00e4llen och f\\u00f6rekomst av plattfiskar och n\\u00e4bbg\\u00e4dda : Belone belone p\\u00e5 exponerade str\\u00e4nder p\\u00e5 \\u00c5land (mapping of fish communities and the occurrence of flatfish and garpike (Belone belone))\", \"creator\": [\"Finnb\\u00e4ck, Lars\"], \"year\": \"2021\", \"publisher\": [\"\\u00c5bo Akademi, \\u00c5land\"], \"e-isbn\": [\"9789521240249\"], \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Uppf\\u00f6ljningsstudie av g\\u00f6sens (Sander lucioperca (L.)) och de allm\\u00e4nna fiskbest\\u00e5ndens f\\u00f6rekomst i \\u00c5lands inre sk\\u00e4rg\\u00e5rd\", \"creator\": [\"\\u00d6sterlund, Jonas\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521242496\"], \"p-isbn\": [\"9789521242489\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Uppf\\u00f6ljningsstudie av g\\u00f6sens (Sander lucioperca (L.) ) och de allm\\u00e4nna fiskbest\\u00e5ndens f\\u00f6rekomst i \\u00c5lands inre sk\\u00e4rg\\u00e5rd\", \"creator\": [\"\\u00d6sterlund, Jonas\"], \"year\": \"2022\", \"publisher\": [\"\\u00c5bo Akademi, Hus\\u00f6 biologiska station\"], \"e-isbn\": [\"9789521242489\"], \"p-isbn\": [\"9789521242496\"], \"p-issn\": \"0787-5460\", \"type_coar\": \"book\"}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Ground Truth:\n",
      "{\"language\": \"swe\", \"title\": \"Svenskfinland i pandemitider : Resultat fr\\u00e5n den finlandssvenska medborgarpanelen Barometern 2020\\u20132022\", \"creator\": [\"Backstr\\u00f6m, Jenny\", \"Backstr\\u00f6m, Kim\", \"Karv, Thomas\", \"Lindell, Marina\", \"Malmberg, Fredrik\", \"Schauman, Jonas\", \"Sir\\u00e9n, Rasmus\", \"Weckman, Albert\"], \"year\": \"2022\", \"publisher\": [\"Institutet f\\u00f6r samh\\u00e4llsforskning (Samforsk), \\u00c5bo Akademi, Vasa\"], \"e-isbn\": [\"9789521242106\"], \"p-isbn\": [\"9789521242090\"], \"type_coar\": \"book\"}\n",
      "Prediction:\n",
      "{\"language\": \"swe\", \"title\": \"Svenskfinland i pandemitider : Resultat fr\\u00e5n den finlandssvenska medborgarpanelen Barometern 2020-2022\", \"year\": \"2022\", \"publisher\": [\"Institutet f\\u00f6r samh\\u00e4llsforskning\"], \"e-isbn\": [\"9789521242106\"], \"p-isbn\": [\"9789521242090\"], \"type_coar\": \"research report\"}\n",
      "CPU times: user 16min 9s, sys: 1min 22s, total: 17min 32s\n",
      "Wall time: 17min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import json\n",
    "\n",
    "with open(f'test-records-{MODEL_SHORT_NAME}.jsonl', 'w') as outfile:\n",
    "    for rec in test_recs:\n",
    "        messages = [\n",
    "            {\"role\": msg[\"from\"], \"content\": msg[\"value\"]}\n",
    "            for msg in rec[\"conversations\"]\n",
    "            if msg[\"from\"] != \"gpt\"\n",
    "        ]\n",
    "        response = generate(messages)\n",
    "\n",
    "        ground_truth = rec['conversations'][-1][\"value\"]\n",
    "\n",
    "        print(100 * \"-\")\n",
    "        print(\"Ground Truth:\")\n",
    "        print(ground_truth)\n",
    "        print(\"Prediction:\")\n",
    "        print(response)\n",
    "\n",
    "        ground_truth = json.loads(ground_truth)\n",
    "\n",
    "        try:\n",
    "            prediction = json.loads(response)\n",
    "        except json.JSONDecodeError:\n",
    "            prediction = {}\n",
    "        \n",
    "        # rowid is set to unknown as we've lost it somewhere along the way...\n",
    "        record = {\"ground_truth\": ground_truth, \"prediction\": prediction, \"rowid\": \"unknown\"}\n",
    "        json.dump(record, outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing statistics to ../results-axolotl-Qwen2-0_5B-Instruct.md\n"
     ]
    }
   ],
   "source": [
    "# Analyze the statistics of the extracted metadata and save to file\n",
    "\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from eval import MetadataEvaluator\n",
    "\n",
    "evaluator = MetadataEvaluator(f'test-records-{MODEL_SHORT_NAME}.jsonl')\n",
    "results = evaluator.evaluate_records() #prediction_records[:9])\n",
    "\n",
    "statistics_filename = '../results-axolotl-' + MODEL_SHORT_NAME.replace('.', '_') + '.md'\n",
    "evaluator.save_md(results, statistics_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('merged-Qwen2-0.5B-Instruct/tokenizer_config.json',\n",
       " 'merged-Qwen2-0.5B-Instruct/special_tokens_map.json',\n",
       " 'merged-Qwen2-0.5B-Instruct/vocab.json',\n",
       " 'merged-Qwen2-0.5B-Instruct/merges.txt',\n",
       " 'merged-Qwen2-0.5B-Instruct/added_tokens.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the merged model to a directory (along with tokenizer)\n",
    "\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}\"\n",
    "model.save_pretrained(merged_model_dir)\n",
    "tokenizer.save_pretrained(merged_model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: merged-Qwen2-0.5B-Instruct\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> F16, shape = {896, 151936}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> F16, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> F16, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> F16, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> F16, shape = {896, 128}\n",
      "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 32768\n",
      "INFO:hf-to-gguf:gguf: embedding length = 896\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 4864\n",
      "INFO:hf-to-gguf:gguf: head count = 14\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 2\n",
      "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
      "INFO:hf-to-gguf:gguf: file type = 1\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 151387 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type bos to 151643\n",
      "INFO:gguf.vocab:Setting special token type eos to 151645\n",
      "INFO:gguf.vocab:Setting chat_template to {% for message in messages %}{% if loop.first and messages[0]['role'] != 'system' %}{{ '<|im_start|>system\n",
      "You are a helpful assistant.<|im_end|>\n",
      "' }}{% endif %}{{'<|im_start|>' + message['role'] + '\n",
      "' + message['content'] + '<|im_end|>' + '\n",
      "'}}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf: n_tensors = 290, total_size = 988.2M\n",
      "Writing: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 988M/988M [00:00<00:00, 1.31Gbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf\n",
      "CPU times: user 117 ms, sys: 36.4 ms, total: 154 ms\n",
      "Wall time: 17.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# convert the merged model to GGUF using llama.cpp tools (installed separately)\n",
    "\n",
    "LLAMA_CPP_PATH = \"../../../llama.cpp\"\n",
    "merged_model_dir = f\"merged-{MODEL_SHORT_NAME}\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/venv/bin/python {LLAMA_CPP_PATH}/convert_hf_to_gguf.py {merged_model_dir} --outfile {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main: build = 3492 (7c27a19b)\n",
      "main: built with cc (GCC) 13.3.0 for x86_64-pc-linux-gnu\n",
      "main: quantizing 'Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf' to 'Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf' as Q4_K_M\n",
      "llama_model_loader: loaded meta data with 25 key-value pairs and 290 tensors from Qwen2-0.5B-Instruct-FinGreyLit-f16.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = qwen2\n",
      "llama_model_loader: - kv   1:                               general.type str              = model\n",
      "llama_model_loader: - kv   2:                               general.name str              = Qwen2 0.5B Instruct\n",
      "llama_model_loader: - kv   3:                       general.organization str              = Qwen\n",
      "llama_model_loader: - kv   4:                           general.finetune str              = Instruct\n",
      "llama_model_loader: - kv   5:                           general.basename str              = Qwen2\n",
      "llama_model_loader: - kv   6:                         general.size_label str              = 0.5B\n",
      "llama_model_loader: - kv   7:                          qwen2.block_count u32              = 24\n",
      "llama_model_loader: - kv   8:                       qwen2.context_length u32              = 32768\n",
      "llama_model_loader: - kv   9:                     qwen2.embedding_length u32              = 896\n",
      "llama_model_loader: - kv  10:                  qwen2.feed_forward_length u32              = 4864\n",
      "llama_model_loader: - kv  11:                 qwen2.attention.head_count u32              = 14\n",
      "llama_model_loader: - kv  12:              qwen2.attention.head_count_kv u32              = 2\n",
      "llama_model_loader: - kv  13:                       qwen2.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  14:     qwen2.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  15:                          general.file_type u32              = 1\n",
      "llama_model_loader: - kv  16:                       tokenizer.ggml.model str              = gpt2\n",
      "llama_model_loader: - kv  17:                         tokenizer.ggml.pre str              = qwen2\n",
      "llama_model_loader: - kv  18:                      tokenizer.ggml.tokens arr[str,151936]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
      "llama_model_loader: - kv  19:                  tokenizer.ggml.token_type arr[i32,151936]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
      "llama_model_loader: - kv  20:                      tokenizer.ggml.merges arr[str,151387]  = [\"Ä  Ä \", \"Ä Ä  Ä Ä \", \"i n\", \"Ä  t\",...\n",
      "llama_model_loader: - kv  21:                tokenizer.ggml.bos_token_id u32              = 151643\n",
      "llama_model_loader: - kv  22:                tokenizer.ggml.eos_token_id u32              = 151645\n",
      "llama_model_loader: - kv  23:                    tokenizer.chat_template str              = {% for message in messages %}{% if lo...\n",
      "llama_model_loader: - kv  24:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:  121 tensors\n",
      "llama_model_loader: - type  f16:  169 tensors\n",
      "[   1/ 290]                    token_embd.weight - [  896, 151936,     1,     1], type =    f16, converting to q8_0 .. size =   259.66 MiB ->   137.94 MiB\n",
      "[   2/ 290]               blk.0.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[   3/ 290]                blk.0.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[   4/ 290]                blk.0.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[   5/ 290]                  blk.0.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[   6/ 290]                blk.0.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[   7/ 290]                    blk.0.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[   8/ 290]                  blk.0.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[   9/ 290]             blk.0.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  10/ 290]                    blk.0.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  11/ 290]                  blk.0.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  12/ 290]                    blk.0.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  13/ 290]                  blk.0.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  14/ 290]               blk.1.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  15/ 290]                blk.1.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  16/ 290]                blk.1.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  17/ 290]                  blk.1.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  18/ 290]                blk.1.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  19/ 290]                    blk.1.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  20/ 290]                  blk.1.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  21/ 290]             blk.1.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  22/ 290]                    blk.1.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  23/ 290]                  blk.1.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  24/ 290]                    blk.1.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  25/ 290]                  blk.1.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  26/ 290]              blk.10.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  27/ 290]               blk.10.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  28/ 290]               blk.10.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  29/ 290]                 blk.10.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  30/ 290]               blk.10.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  31/ 290]                   blk.10.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  32/ 290]                 blk.10.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  33/ 290]            blk.10.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  34/ 290]                   blk.10.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  35/ 290]                 blk.10.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  36/ 290]                   blk.10.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  37/ 290]                 blk.10.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  38/ 290]              blk.11.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  39/ 290]               blk.11.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  40/ 290]               blk.11.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  41/ 290]                 blk.11.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  42/ 290]               blk.11.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  43/ 290]                   blk.11.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  44/ 290]                 blk.11.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  45/ 290]            blk.11.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  46/ 290]                   blk.11.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  47/ 290]                 blk.11.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  48/ 290]                   blk.11.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  49/ 290]                 blk.11.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  50/ 290]              blk.12.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  51/ 290]               blk.12.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  52/ 290]               blk.12.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  53/ 290]                 blk.12.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  54/ 290]               blk.12.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  55/ 290]                   blk.12.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  56/ 290]                 blk.12.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  57/ 290]            blk.12.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  58/ 290]                   blk.12.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  59/ 290]                 blk.12.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  60/ 290]                   blk.12.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  61/ 290]                 blk.12.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  62/ 290]              blk.13.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  63/ 290]               blk.13.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[  64/ 290]               blk.13.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  65/ 290]                 blk.13.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  66/ 290]               blk.13.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  67/ 290]                   blk.13.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  68/ 290]                 blk.13.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  69/ 290]            blk.13.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  70/ 290]                   blk.13.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  71/ 290]                 blk.13.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  72/ 290]                   blk.13.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  73/ 290]                 blk.13.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[  74/ 290]              blk.14.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  75/ 290]               blk.14.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  76/ 290]               blk.14.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  77/ 290]                 blk.14.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  78/ 290]               blk.14.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  79/ 290]                   blk.14.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  80/ 290]                 blk.14.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  81/ 290]            blk.14.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  82/ 290]                   blk.14.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  83/ 290]                 blk.14.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  84/ 290]                   blk.14.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  85/ 290]                 blk.14.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  86/ 290]              blk.15.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  87/ 290]               blk.15.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[  88/ 290]               blk.15.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  89/ 290]                 blk.15.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[  90/ 290]               blk.15.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  91/ 290]                   blk.15.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  92/ 290]                 blk.15.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  93/ 290]            blk.15.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  94/ 290]                   blk.15.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  95/ 290]                 blk.15.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[  96/ 290]                   blk.15.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[  97/ 290]                 blk.15.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[  98/ 290]              blk.16.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[  99/ 290]               blk.16.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 100/ 290]               blk.16.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 101/ 290]                 blk.16.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 102/ 290]               blk.16.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 103/ 290]                   blk.16.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 104/ 290]                 blk.16.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 105/ 290]            blk.16.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 106/ 290]                   blk.16.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 107/ 290]                 blk.16.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 108/ 290]                   blk.16.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 109/ 290]                 blk.16.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 110/ 290]              blk.17.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 111/ 290]               blk.17.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 112/ 290]               blk.17.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 113/ 290]                 blk.17.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 114/ 290]               blk.17.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 115/ 290]                   blk.17.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 116/ 290]                 blk.17.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 117/ 290]            blk.17.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 118/ 290]                   blk.17.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 119/ 290]                 blk.17.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 120/ 290]                   blk.17.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 121/ 290]                 blk.17.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 122/ 290]              blk.18.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 123/ 290]               blk.18.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 124/ 290]               blk.18.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 125/ 290]                 blk.18.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 126/ 290]               blk.18.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 127/ 290]                   blk.18.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 128/ 290]                 blk.18.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 129/ 290]            blk.18.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 130/ 290]                   blk.18.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 131/ 290]                 blk.18.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 132/ 290]                   blk.18.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 133/ 290]                 blk.18.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 134/ 290]              blk.19.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 135/ 290]               blk.19.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 136/ 290]               blk.19.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 137/ 290]                 blk.19.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 138/ 290]               blk.19.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 139/ 290]                   blk.19.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 140/ 290]                 blk.19.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 141/ 290]            blk.19.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 142/ 290]                   blk.19.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 143/ 290]                 blk.19.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 144/ 290]                   blk.19.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 145/ 290]                 blk.19.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 146/ 290]               blk.2.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 147/ 290]                blk.2.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 148/ 290]                blk.2.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 149/ 290]                  blk.2.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 150/ 290]                blk.2.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 151/ 290]                    blk.2.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 152/ 290]                  blk.2.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 153/ 290]             blk.2.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 154/ 290]                    blk.2.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 155/ 290]                  blk.2.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 156/ 290]                    blk.2.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 157/ 290]                  blk.2.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 158/ 290]              blk.20.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 159/ 290]               blk.20.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 160/ 290]               blk.20.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 161/ 290]                 blk.20.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 162/ 290]               blk.20.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 163/ 290]                   blk.20.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 164/ 290]                 blk.20.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 165/ 290]            blk.20.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 166/ 290]                   blk.20.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 167/ 290]                 blk.20.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 168/ 290]                   blk.20.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 169/ 290]                 blk.20.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 170/ 290]              blk.21.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 171/ 290]               blk.21.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 172/ 290]               blk.21.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 173/ 290]                 blk.21.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 174/ 290]               blk.21.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 175/ 290]                   blk.21.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 176/ 290]                 blk.21.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 177/ 290]            blk.21.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 178/ 290]                   blk.21.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 179/ 290]                 blk.21.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 180/ 290]                   blk.21.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 181/ 290]                 blk.21.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 182/ 290]              blk.22.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 183/ 290]               blk.22.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 184/ 290]               blk.22.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 185/ 290]                 blk.22.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 186/ 290]               blk.22.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 187/ 290]                   blk.22.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 188/ 290]                 blk.22.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 189/ 290]            blk.22.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 190/ 290]                   blk.22.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 191/ 290]                 blk.22.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 192/ 290]                   blk.22.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 193/ 290]                 blk.22.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 194/ 290]              blk.23.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 195/ 290]               blk.23.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 196/ 290]               blk.23.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 197/ 290]                 blk.23.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 198/ 290]               blk.23.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 199/ 290]                   blk.23.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 200/ 290]                 blk.23.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 201/ 290]            blk.23.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 202/ 290]                   blk.23.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 203/ 290]                 blk.23.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 204/ 290]                   blk.23.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 205/ 290]                 blk.23.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 206/ 290]               blk.3.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 207/ 290]                blk.3.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 208/ 290]                blk.3.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 209/ 290]                  blk.3.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 210/ 290]                blk.3.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 211/ 290]                    blk.3.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 212/ 290]                  blk.3.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 213/ 290]             blk.3.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 214/ 290]                    blk.3.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 215/ 290]                  blk.3.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 216/ 290]                    blk.3.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 217/ 290]                  blk.3.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 218/ 290]               blk.4.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 219/ 290]                blk.4.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 220/ 290]                blk.4.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 221/ 290]                  blk.4.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 222/ 290]                blk.4.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 223/ 290]                    blk.4.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 224/ 290]                  blk.4.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 225/ 290]             blk.4.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 226/ 290]                    blk.4.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 227/ 290]                  blk.4.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 228/ 290]                    blk.4.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 229/ 290]                  blk.4.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 230/ 290]               blk.5.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 231/ 290]                blk.5.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q4_K .. size =     8.31 MiB ->     2.34 MiB\n",
      "[ 232/ 290]                blk.5.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 233/ 290]                  blk.5.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 234/ 290]                blk.5.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 235/ 290]                    blk.5.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 236/ 290]                  blk.5.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 237/ 290]             blk.5.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 238/ 290]                    blk.5.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 239/ 290]                  blk.5.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 240/ 290]                    blk.5.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 241/ 290]                  blk.5.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 242/ 290]               blk.6.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 243/ 290]                blk.6.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 244/ 290]                blk.6.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 245/ 290]                  blk.6.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 246/ 290]                blk.6.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 247/ 290]                    blk.6.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 248/ 290]                  blk.6.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 249/ 290]             blk.6.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 250/ 290]                    blk.6.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 251/ 290]                  blk.6.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 252/ 290]                    blk.6.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 253/ 290]                  blk.6.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 254/ 290]               blk.7.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 255/ 290]                blk.7.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 256/ 290]                blk.7.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 257/ 290]                  blk.7.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 258/ 290]                blk.7.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 259/ 290]                    blk.7.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 260/ 290]                  blk.7.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 261/ 290]             blk.7.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 262/ 290]                    blk.7.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 263/ 290]                  blk.7.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 264/ 290]                    blk.7.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 265/ 290]                  blk.7.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 266/ 290]               blk.8.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 267/ 290]                blk.8.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 268/ 290]                blk.8.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 269/ 290]                  blk.8.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 270/ 290]                blk.8.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 271/ 290]                    blk.8.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 272/ 290]                  blk.8.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 273/ 290]             blk.8.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 274/ 290]                    blk.8.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 275/ 290]                  blk.8.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 276/ 290]                    blk.8.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 277/ 290]                  blk.8.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 278/ 290]               blk.9.attn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 279/ 290]                blk.9.ffn_down.weight - [ 4864,   896,     1,     1], type =    f16, converting to q6_K .. size =     8.31 MiB ->     3.41 MiB\n",
      "[ 280/ 290]                blk.9.ffn_gate.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 281/ 290]                  blk.9.ffn_up.weight - [  896,  4864,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 4864 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     8.31 MiB ->     2.86 MiB\n",
      "[ 282/ 290]                blk.9.ffn_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 283/ 290]                    blk.9.attn_k.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 284/ 290]                  blk.9.attn_k.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     0.22 MiB ->     0.08 MiB\n",
      "[ 285/ 290]             blk.9.attn_output.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 286/ 290]                    blk.9.attn_q.bias - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "[ 287/ 290]                  blk.9.attn_q.weight - [  896,   896,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 896 are not divisible by 256, required for q4_K - using fallback quantization q5_0\n",
      "converting to q5_0 .. size =     1.53 MiB ->     0.53 MiB\n",
      "[ 288/ 290]                    blk.9.attn_v.bias - [  128,     1,     1,     1], type =    f32, size =    0.000 MB\n",
      "[ 289/ 290]                  blk.9.attn_v.weight - [  896,   128,     1,     1], type =    f16, \n",
      "\n",
      "llama_tensor_get_type : tensor cols 896 x 128 are not divisible by 256, required for q6_K - using fallback quantization q8_0\n",
      "converting to q8_0 .. size =     0.22 MiB ->     0.12 MiB\n",
      "[ 290/ 290]                   output_norm.weight - [  896,     1,     1,     1], type =    f32, size =    0.003 MB\n",
      "llama_model_quantize_internal: model size  =   942.43 MB\n",
      "llama_model_quantize_internal: quant size  =   373.71 MB\n",
      "llama_model_quantize_internal: WARNING: 144 of 168 tensor(s) required fallback quantization\n",
      "\n",
      "main: quantize time =  3610.40 ms\n",
      "main:    total time =  3610.40 ms\n",
      "CPU times: user 70.8 ms, sys: 26.6 ms, total: 97.4 ms\n",
      "Wall time: 3.86 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Quantize the F16 GGUF model to the 4+ bit Q4_K_M format\n",
    "QTYPE = \"Q4_K_M\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/llama-quantize {MODEL_SHORT_NAME}-{SUFFIX}-f16.gguf {MODEL_SHORT_NAME}-{SUFFIX}-{QTYPE}.gguf {QTYPE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consider using `hf_transfer` for faster uploads. This solution comes with some limitations. See https://huggingface.co/docs/huggingface_hub/hf_transfer for more details.\n",
      "Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf: 100%|â–ˆ| 398M/398M [00:15<00:00, 26.3\n",
      "https://huggingface.co/NatLibFi/Qwen2-0.5B-Instruct-FinGreyLit-GGUF/blob/main/Qwen2-0.5B-Instruct-FinGreyLit-Q4_K_M.gguf\n"
     ]
    }
   ],
   "source": [
    "# Upload the quantized GGUF file to HF Hub\n",
    "\n",
    "FINAL_MODEL_NAME = f\"NatLibFi/{MODEL_SHORT_NAME}-{SUFFIX}-GGUF\"\n",
    "\n",
    "!{LLAMA_CPP_PATH}/venv/bin/huggingface-cli upload {FINAL_MODEL_NAME} {MODEL_SHORT_NAME}-{SUFFIX}-{QTYPE}.gguf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingreylit-axolotl",
   "language": "python",
   "name": "fingreylit-axolotl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
