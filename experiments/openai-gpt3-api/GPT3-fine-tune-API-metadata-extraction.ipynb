{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e52dc6-68a0-4082-9fe0-73c4a8cb6708",
   "metadata": {},
   "source": [
    "# Test the connection and API key\n",
    "\n",
    "Make sure it's possible to use the OpenAI API. For this to work, the environment variable OPENAI_API_KEY must be set to a valid API key which has available credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762d1a22-1db3-474b-a880-8437cad22a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject text_completion id=cmpl-7jMCZdObPXH3HW3Q8e31ho9fPUVNv at 0x7fb34084af20> JSON: {\n",
       "  \"warning\": \"This model version is deprecated. Migrate before January 4, 2024 to avoid disruption of service. Learn more https://platform.openai.com/docs/deprecations\",\n",
       "  \"id\": \"cmpl-7jMCZdObPXH3HW3Q8e31ho9fPUVNv\",\n",
       "  \"object\": \"text_completion\",\n",
       "  \"created\": 1691044459,\n",
       "  \"model\": \"text-curie-001\",\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"text\": \"\\n\\nThis is a test.\",\n",
       "      \"index\": 0,\n",
       "      \"logprobs\": null,\n",
       "      \"finish_reason\": \"length\"\n",
       "    }\n",
       "  ],\n",
       "  \"usage\": {\n",
       "    \"prompt_tokens\": 5,\n",
       "    \"completion_tokens\": 7,\n",
       "    \"total_tokens\": 12\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# read the OpenAI API key from an environment variable\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# test the API connection by making a simple request\n",
    "response = openai.Completion.create(model=\"text-curie-001\", prompt=\"Say this is a test\", temperature=0, max_tokens=7)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59823f6-ea2e-467f-a438-93a69652daaf",
   "metadata": {},
   "source": [
    "# Prepare the fine-tuning set\n",
    "\n",
    "Prepare a fine-tuning dataset and use it to fine-tune a GPT3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d035bad1-13d2-4ebe-beee-159991adfe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fine-tune.jsonl\n",
      "- processing ../../llm-dataset/train/docthes-swe.jsonl\n",
      "- processing ../../llm-dataset/train/serial-swe.jsonl\n",
      "- processing ../../llm-dataset/train/thes-swe.jsonl\n",
      "- processing ../../llm-dataset/train/mono-fin.jsonl\n",
      "- processing ../../llm-dataset/train/serial-eng.jsonl\n",
      "- processing ../../llm-dataset/train/thes-fin.jsonl\n",
      "- processing ../../llm-dataset/train/mono-eng.jsonl\n",
      "- processing ../../llm-dataset/train/mono-swe.jsonl\n",
      "- processing ../../llm-dataset/train/thes-eng.jsonl\n",
      "- processing ../../llm-dataset/train/docthes-eng.jsonl\n",
      "- processing ../../llm-dataset/train/serial-fin.jsonl\n",
      "- processing ../../llm-dataset/train/docthes-fin.jsonl\n",
      "373 records converted\n",
      "\n",
      "Creating validate.jsonl\n",
      "- processing ../../llm-dataset/test/docthes-swe.jsonl\n",
      "- processing ../../llm-dataset/test/serial-swe.jsonl\n",
      "- processing ../../llm-dataset/test/thes-swe.jsonl\n",
      "- processing ../../llm-dataset/test/mono-fin.jsonl\n",
      "- processing ../../llm-dataset/test/serial-eng.jsonl\n",
      "- processing ../../llm-dataset/test/thes-fin.jsonl\n",
      "- processing ../../llm-dataset/test/mono-eng.jsonl\n",
      "- processing ../../llm-dataset/test/mono-swe.jsonl\n",
      "- processing ../../llm-dataset/test/thes-eng.jsonl\n",
      "- processing ../../llm-dataset/test/docthes-eng.jsonl\n",
      "- processing ../../llm-dataset/test/serial-fin.jsonl\n",
      "- processing ../../llm-dataset/test/docthes-fin.jsonl\n",
      "113 records converted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "PROMPT_SUFFIX = '\\n\\n###\\n\\n'\n",
    "COMPLETION_STOP = '\\n###'\n",
    "TRAINFILE = 'fine-tune.jsonl'\n",
    "VALIDATEFILE = 'validate.jsonl'\n",
    "BASE_MODEL = 'babbage'\n",
    "MAX_TOKENS = 1450  # empirically chosen so that prepare_data doesn't complain in the cell below\n",
    "\n",
    "dataset_train_files = glob.glob(\"../../llm-dataset/train/*.jsonl\")\n",
    "dataset_test_files = glob.glob(\"../../llm-dataset/test/*.jsonl\")\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(BASE_MODEL)\n",
    "\n",
    "def truncate_text(text):\n",
    "    \"\"\"truncate text so it contains at most MAX_TOKENS according to the OpenAI tokenizer\"\"\"\n",
    "    tokens = encoding.encode(text)\n",
    "    return encoding.decode(tokens[:MAX_TOKENS])\n",
    "\n",
    "def create_sample(text, metadata):\n",
    "    \"\"\"create a fine-tuning sample from text and metadata about a single document\"\"\"\n",
    "    return {'prompt': truncate_text(text) + PROMPT_SUFFIX,\n",
    "            'completion': \" \" + metadata + COMPLETION_STOP}\n",
    "\n",
    "def convert_to_samples(infiles, outfile):\n",
    "    print(f\"Creating {outfile}\")\n",
    "    nrec = 0\n",
    "    with open(outfile, \"w\") as outf:\n",
    "        for infile in infiles:\n",
    "            print(f\"- processing {infile}\")\n",
    "            with open(infile) as inf:\n",
    "                for line in inf:\n",
    "                    rec = json.loads(line)\n",
    "                    sample = create_sample(rec[\"text\"], rec[\"metadata\"])\n",
    "                    print(json.dumps(sample), file=outf)\n",
    "                    nrec += 1\n",
    "    print(f\"{nrec} records converted\")\n",
    "    print()\n",
    "\n",
    "convert_to_samples(dataset_train_files, TRAINFILE)\n",
    "convert_to_samples(dataset_test_files, VALIDATEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc70c8a-1ab3-4a9e-8d76-b73b718751ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 373 prompt-completion pairs\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions start with prefix ` dc.contributor`. Most of the time you should only add the output data into the completion, without any prefix\n",
      "- All completions end with suffix `\\n###`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove prefix ` dc.contributor` from all completions [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `fine-tune_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"fine-tune_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 7.57 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 113 prompt-completion pairs\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions start with prefix ` dc.contributor`. Most of the time you should only add the output data into the completion, without any prefix\n",
      "- All completions end with suffix `\\n###`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove prefix ` dc.contributor` from all completions [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `validate_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"validate_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 4.0 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# Check that the fine-tuning data set is OK using the prepare_data tool.\n",
    "# It will complain that all completions start with the same \" dc.contributor\" prefix, this can be ignored.\n",
    "# We will only use prepare_data as a validation aid and delete the \"prepared\" files that ithelpfully creates.\n",
    "!openai tools fine_tunes.prepare_data -f fine-tune.jsonl -q\n",
    "!rm -f fine-tune_prepared.jsonl\n",
    "\n",
    "!openai tools fine_tunes.prepare_data -f validate.jsonl -q\n",
    "!rm -f validate_prepared.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46b3b6ee-f99e-47e5-a22d-4024dc5de38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload progress: 100%|████████████████████| 1.78M/1.78M [00:00<00:00, 2.22Git/s]\n",
      "Uploaded file from fine-tune.jsonl: file-HRqztdzuQaW0k46ZELzDmZQn\n",
      "Upload progress: 100%|███████████████████████| 565k/565k [00:00<00:00, 813Mit/s]\n",
      "Uploaded file from validate.jsonl: file-sAAV2B2B3V4jNlnJJsiRalSK\n",
      "Created fine-tune: ft-XivxNCEeiqRQNiRhSc9RAMfu\n",
      "Streaming events until fine-tuning is complete...\n",
      "\n",
      "(Ctrl-C will interrupt the stream, but not cancel the fine-tune)\n",
      "[2023-08-03 09:36:07] Created fine-tune: ft-XivxNCEeiqRQNiRhSc9RAMfu\n",
      "\n",
      "Stream interrupted (client disconnected).\n",
      "To resume the stream, run:\n",
      "\n",
      "  openai api fine_tunes.follow -i ft-XivxNCEeiqRQNiRhSc9RAMfu\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Perform the actual finetuning via the API. This can take a while, there can be a long queue.\n",
    "!openai api fine_tunes.create -t fine-tune.jsonl -v validate.jsonl -m {BASE_MODEL}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4352c4f-276f-4893-a5c2-acb94572b4d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-03 09:36:07] Created fine-tune: ft-XivxNCEeiqRQNiRhSc9RAMfu\n",
      "[2023-08-03 11:48:36] Fine-tune costs $1.39\n",
      "[2023-08-03 11:48:36] Fine-tune enqueued. Queue number: 6\n",
      "[2023-08-03 11:50:31] Fine-tune is in the queue. Queue number: 5\n",
      "[2023-08-03 11:50:33] Fine-tune is in the queue. Queue number: 4\n",
      "[2023-08-03 11:51:17] Fine-tune is in the queue. Queue number: 3\n",
      "[2023-08-03 11:51:40] Fine-tune is in the queue. Queue number: 2\n",
      "[2023-08-03 11:52:17] Fine-tune is in the queue. Queue number: 1\n",
      "[2023-08-03 11:52:31] Fine-tune is in the queue. Queue number: 0\n",
      "[2023-08-03 11:52:35] Fine-tune started\n",
      "[2023-08-03 11:55:03] Completed epoch 1/4\n",
      "[2023-08-03 11:57:06] Completed epoch 2/4\n",
      "[2023-08-03 11:59:09] Completed epoch 3/4\n",
      "[2023-08-03 12:01:13] Completed epoch 4/4\n",
      "[2023-08-03 12:01:33] Uploaded model: babbage:ft-personal-2023-08-03-09-01-32\n",
      "[2023-08-03 12:01:34] Uploaded result file: file-l7O6EqcqDWgaZyvl7qyrKSfA\n",
      "[2023-08-03 12:01:34] Fine-tune succeeded\n",
      "\n",
      "Job complete! Status: succeeded 🎉\n",
      "Try out your fine-tuned model:\n",
      "\n",
      "openai api completions.create -m babbage:ft-personal-2023-08-03-09-01-32 -p <YOUR_PROMPT>\n"
     ]
    }
   ],
   "source": [
    "!openai api fine_tunes.follow -i ft-XivxNCEeiqRQNiRhSc9RAMfu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cc0c7fb-3785-4223-a4ff-97f4d058afd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# copy the model name from above output and store it in a variable\n",
    "model_name = \"babbage:ft-personal-2023-08-03-09-01-32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0875b0c7-b561-48c1-a9b8-c115f6a7537e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on https://www.doria.fi/handle/10024/181210 with PDF https://www.doria.fi/bitstream/handle/10024/181210/koskinen_monika.pdf\n",
      "---\n",
      "Curated metadata:\n",
      "dc.contributor.author: Koskinen, Monika\n",
      "dc.contributor.faculty: Faculty of Education and Welfare Studies\n",
      "dc.contributor.faculty: Fakulteten för pedagogik och välfärdsstudier\n",
      "dc.contributor.faculty: Kasvatustieteiden ja hyvinvointialojen tiedekunta\n",
      "dc.contributor.opponent: Professor Ulrica Hörberg, Linnéuniversitetet, Växjö, Sverige\n",
      "dc.contributor.organization: Åbo Akademi\n",
      "dc.contributor.supervisor: Professor Camilla Koskinen, Universitetet i Stavanger, Stavanger, Norge\n",
      "dc.contributor.supervisor: TD Mårten Björkgren, Åbo Akademi, Vasa\n",
      "dc.date.issued: 2021-06-17\n",
      "dc.format.content: fulltext\n",
      "dc.identifier.isbn: 978-951-765-993-2\n",
      "dc.identifier.urn: URN:ISBN:978-951-765-993-2\n",
      "dc.language.iso: swe\n",
      "dc.publisher: Åbo Akademis förlag - Åbo Akademi University Press\n",
      "dc.relation.isbn: 978-951-765-992-5\n",
      "dc.title: Hälsans tomrum : En hermeneutisk studie om försakelsens betydelse för hälsan\n",
      "dc.title.alternative: A void for health - A hermeneutic study of the significance of renunciation for health\n",
      "dc.type.coar: väitöskirja\n",
      "dc.type.okm: G4 Doctoral dissertation (monograph) {en}\n",
      "dc.type.okm: G4 Monografiavhandling {sv}\n",
      "dc.type.okm: G4 Monografiaväitöskirja {fi}\n",
      "dc.type.ontasot: Doctoral dissertation (monograph)\n",
      "dc.type.ontasot: Doktorsavhandling (monografi)\n",
      "dc.type.ontasot: Väitöskirja (monografia)\n",
      "---\n",
      "Generated metadata:\n",
      "dc.contributor.author: Koskinen, Monika\n",
      "dc.contributor.faculty: Fakulteten för pedagogik och välfärdsstudier\n",
      "dc.contributor.opponent: Docent Anna-Karin Eriksson, Uppsala universitet\n",
      "dc.contributor.organization: Åbo Akademi\n",
      "dc.contributor.supervisor: Docent Anna-Karin Eriksson, Uppsala universitet\n",
      "dc.date.issued: 2021-11-23\n",
      "dc.format.content: fulltext\n",
      "dc.identifier.isbn: 978-951-765-964-2\n",
      "dc.identifier.urn: URN:ISBN:978-951-765-964-2\n",
      "dc.language.iso: swe\n",
      "dc.publisher: Åbo Akademis förlag - Åbo Akademi University Press\n",
      "dc.relation.isbn: 978-951-765-963-5\n",
      "dc.title: Hälsans tomrum : En hermeneutisk studie om försakelsens betydelse för hälsan\n",
      "dc.type.coar: väitöskirja\n",
      "dc.type.okm: G4 Doctoral dissertation (monograph) {en}\n",
      "dc.type.okm: G4 Monografiavhandling {sv}\n",
      "dc.type.okm: G4 Monografiaväitöskirja {fi}\n",
      "dc.type.ontasot: Doctoral dissertation (monograph)\n",
      "dc.type.ontasot: Doktorsavhandling (monografi)\n",
      "dc.type.ontasot: Väitöskirja (monografia)\n"
     ]
    }
   ],
   "source": [
    "# Try out the fine-tuned model on a random test set record\n",
    "\n",
    "import random\n",
    "\n",
    "def get_completions(text):\n",
    "    response = openai.Completion.create(model=model_name,\n",
    "                                    prompt=truncate_text(text) + PROMPT_SUFFIX,\n",
    "                                    temperature=0,  # no fooling around!\n",
    "                                    max_tokens=2048 - MAX_TOKENS - 5, # should be plenty\n",
    "                                    stop=[COMPLETION_STOP])  # stop at ###\n",
    "    return response['choices'][0]['text'].strip()\n",
    "\n",
    "\n",
    "test_set_file = random.choice(dataset_test_files)\n",
    "with open(test_set_file) as testfile:\n",
    "    records = [json.loads(line) for line in testfile]\n",
    "rec = random.choice(records)\n",
    "\n",
    "print(f\"Testing on {rec['id']} with PDF {rec['url']}\")\n",
    "print(\"---\")\n",
    "print(\"Curated metadata:\")\n",
    "print(rec[\"metadata\"])\n",
    "print(\"---\")\n",
    "print(\"Generated metadata:\")\n",
    "print(get_completions(rec[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "048e1e68-304f-4885-9ba9-5e85c92dda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating metadata for ../../llm-dataset/test/docthes-swe.jsonl into gpt3-docthes-swe.jsonl\n",
      "completed 5 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/serial-swe.jsonl into gpt3-serial-swe.jsonl\n",
      "completed 7 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/thes-swe.jsonl into gpt3-thes-swe.jsonl\n",
      "completed 10 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/mono-fin.jsonl into gpt3-mono-fin.jsonl\n",
      "completed 8 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/serial-eng.jsonl into gpt3-serial-eng.jsonl\n",
      "completed 9 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/thes-fin.jsonl into gpt3-thes-fin.jsonl\n",
      "completed 20 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/mono-eng.jsonl into gpt3-mono-eng.jsonl\n",
      "completed 9 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/mono-swe.jsonl into gpt3-mono-swe.jsonl\n",
      "completed 0 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/thes-eng.jsonl into gpt3-thes-eng.jsonl\n",
      "completed 11 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/docthes-eng.jsonl into gpt3-docthes-eng.jsonl\n",
      "completed 16 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/serial-fin.jsonl into gpt3-serial-fin.jsonl\n",
      "completed 11 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/test/docthes-fin.jsonl into gpt3-docthes-fin.jsonl\n",
      "completed 7 records\n",
      "\n",
      "CPU times: user 824 ms, sys: 26.4 ms, total: 851 ms\n",
      "Wall time: 6min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os.path\n",
    "\n",
    "for test_file in dataset_test_files:\n",
    "    output_file = \"gpt3-\" + os.path.basename(test_file)\n",
    "    print(f\"generating metadata for {test_file} into {output_file}\")\n",
    "    nrec = 0\n",
    "    with open(test_file) as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            rec = json.loads(line)\n",
    "            generated_metadata = get_completions(rec[\"text\"])\n",
    "            outrec = {\"id\": rec[\"id\"], \"url\": rec[\"url\"], \"metadata_orig\": rec[\"metadata\"], \"metadata_gen\": generated_metadata}\n",
    "            json.dump(outrec, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "            nrec += 1\n",
    "    print(f\"completed {nrec} records\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e947bea0-1f37-44b4-9a21-75de1278ac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall similarity: 0.7886717084961832\n"
     ]
    }
   ],
   "source": [
    "# Calculate rough similarity between original and generated metadata using Levenshtein normalized indel similarity\n",
    "\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "\n",
    "data = []\n",
    "for test_file in dataset_test_files:\n",
    "    gen_file = \"gpt3-\" + os.path.basename(test_file)\n",
    "    _, subset, lang = os.path.splitext(gen_file)[0].split('-')\n",
    "    with open(gen_file) as gfile:\n",
    "        for line in gfile:\n",
    "            rec = json.loads(line)\n",
    "            similarity = Levenshtein.ratio(rec[\"metadata_orig\"], rec[\"metadata_gen\"])\n",
    "            data.append([subset, lang, rec[\"id\"], rec[\"url\"], similarity])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"subset\", \"lang\", \"id\", \"url\", \"similarity\"])\n",
    "\n",
    "print(\"Overall similarity:\", df[\"similarity\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cd3d989e-1b65-42a1-bffd-07ed4dc7ab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "docthes    0.820709\n",
       "mono       0.665335\n",
       "serial     0.763267\n",
       "thes       0.834662\n",
       "Name: similarity, dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['subset'])[\"similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b9fb423-e6f1-4e07-928e-d2f0649f808c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang\n",
       "eng    0.768135\n",
       "fin    0.784264\n",
       "swe    0.839895\n",
       "Name: similarity, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['lang'])[\"similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc925e69-5920-41a6-a0e9-43b492cbcd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset   lang\n",
       "docthes  eng     0.841979\n",
       "         fin     0.803360\n",
       "         swe     0.776932\n",
       "mono     eng     0.674078\n",
       "         fin     0.655498\n",
       "serial   eng     0.762734\n",
       "         fin     0.735521\n",
       "         swe     0.807553\n",
       "thes     eng     0.742101\n",
       "         fin     0.855895\n",
       "         swe     0.894015\n",
       "Name: similarity, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['subset','lang'])[\"similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f036a5-0456-4e5f-aa4a-37c9e6f6d0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
