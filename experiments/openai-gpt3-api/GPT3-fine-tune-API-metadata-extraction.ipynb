{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e52dc6-68a0-4082-9fe0-73c4a8cb6708",
   "metadata": {},
   "source": [
    "# Test the connection and API key\n",
    "\n",
    "Make sure it's possible to use the OpenAI API. For this to work, the environment variable OPENAI_API_KEY must be set to a valid API key which has available credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762d1a22-1db3-474b-a880-8437cad22a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-8T6I3BMP97D6HKkwtlUadVJimIfWw', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=\". I'm gonna say this is\")], created=1701946383, model='davinci-002', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=5, total_tokens=12))\n",
      ". I'm gonna say this is\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# read the OpenAI API key from an environment variable\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# test the API connection by making a simple request\n",
    "response = openai.completions.create(model=\"davinci-002\", prompt=\"Say this is a test\", temperature=0, max_tokens=7)\n",
    "print(response)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59823f6-ea2e-467f-a438-93a69652daaf",
   "metadata": {},
   "source": [
    "# Prepare the fine-tuning set\n",
    "\n",
    "Prepare a fine-tuning dataset and use it to fine-tune a GPT3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d035bad1-13d2-4ebe-beee-159991adfe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fine-tune.jsonl\n",
      "- processing ../../llm-dataset/serial-fin-train.jsonl\n",
      "- processing ../../llm-dataset/serial-swe-train.jsonl\n",
      "- processing ../../llm-dataset/docthes-eng-train.jsonl\n",
      "- processing ../../llm-dataset/docthes-fin-train.jsonl\n",
      "- processing ../../llm-dataset/thes-fin-train.jsonl\n",
      "- processing ../../llm-dataset/thes-swe-train.jsonl\n",
      "- processing ../../llm-dataset/mono-swe-train.jsonl\n",
      "- processing ../../llm-dataset/docthes-swe-train.jsonl\n",
      "- processing ../../llm-dataset/mono-eng-train.jsonl\n",
      "- processing ../../llm-dataset/mono-fin-train.jsonl\n",
      "- processing ../../llm-dataset/thes-eng-train.jsonl\n",
      "- processing ../../llm-dataset/serial-eng-train.jsonl\n",
      "557 records converted\n",
      "\n",
      "Creating validate.jsonl\n",
      "- processing ../../llm-dataset/mono-swe-test.jsonl\n",
      "- processing ../../llm-dataset/docthes-swe-test.jsonl\n",
      "- processing ../../llm-dataset/thes-eng-test.jsonl\n",
      "- processing ../../llm-dataset/thes-swe-test.jsonl\n",
      "- processing ../../llm-dataset/thes-fin-test.jsonl\n",
      "- processing ../../llm-dataset/docthes-fin-test.jsonl\n",
      "- processing ../../llm-dataset/serial-fin-test.jsonl\n",
      "- processing ../../llm-dataset/serial-swe-test.jsonl\n",
      "- processing ../../llm-dataset/mono-fin-test.jsonl\n",
      "- processing ../../llm-dataset/serial-eng-test.jsonl\n",
      "- processing ../../llm-dataset/docthes-eng-test.jsonl\n",
      "- processing ../../llm-dataset/mono-eng-test.jsonl\n",
      "167 records converted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "PROMPT_SUFFIX = '\\n\\n###\\n\\n'\n",
    "COMPLETION_STOP = '\\n###'\n",
    "TRAINFILE = 'fine-tune.jsonl'\n",
    "VALIDATEFILE = 'validate.jsonl'\n",
    "BASE_MODEL = 'babbage-002'\n",
    "MAX_TOKENS = 12000  # Increased for babbage-002 model\n",
    "\n",
    "dataset_train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "dataset_test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(BASE_MODEL)\n",
    "\n",
    "def truncate_text(text):\n",
    "    \"\"\"truncate text so it contains at most MAX_TOKENS according to the OpenAI tokenizer\"\"\"\n",
    "    tokens = encoding.encode(text)\n",
    "    return encoding.decode(tokens[:MAX_TOKENS])\n",
    "\n",
    "def create_sample(text, metadata):\n",
    "    \"\"\"create a fine-tuning sample from text and metadata about a single document\"\"\"\n",
    "    return {'prompt': truncate_text(text) + PROMPT_SUFFIX,\n",
    "            'completion': \" \" + metadata + COMPLETION_STOP}\n",
    "\n",
    "def convert_to_samples(infiles, outfile):\n",
    "    print(f\"Creating {outfile}\")\n",
    "    nrec = 0\n",
    "    with open(outfile, \"w\") as outf:\n",
    "        for infile in infiles:\n",
    "            print(f\"- processing {infile}\")\n",
    "            with open(infile) as inf:\n",
    "                for line in inf:\n",
    "                    rec = json.loads(line)\n",
    "                    sample = create_sample(rec[\"text\"], rec[\"metadata\"])\n",
    "                    print(json.dumps(sample), file=outf)\n",
    "                    nrec += 1\n",
    "    print(f\"{nrec} records converted\")\n",
    "    print()\n",
    "\n",
    "convert_to_samples(dataset_train_files, TRAINFILE)\n",
    "convert_to_samples(dataset_test_files, VALIDATEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc70c8a-1ab3-4a9e-8d76-b73b718751ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 557 prompt-completion pairs\n",
      "- There are 7 examples that are very long. These are rows: [231, 257, 258, 268, 333, 468, 504]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix `\\n###`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 7 long examples [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `fine-tune_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"fine-tune_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 27.87 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 167 prompt-completion pairs\n",
      "- There are 3 examples that are very long. These are rows: [28, 30, 31]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix `\\n###`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 3 long examples [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `validate_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"validate_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 9.29 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# Check that the fine-tuning data set is OK using the prepare_data tool.\n",
    "# We will only use prepare_data as a validation aid and delete the \"prepared\"\n",
    "# files that it helpfully creates.\n",
    "!openai tools fine_tunes.prepare_data -f fine-tune.jsonl -q\n",
    "!rm -f fine-tune_prepared.jsonl\n",
    "\n",
    "!openai tools fine_tunes.prepare_data -f validate.jsonl -q\n",
    "!rm -f validate_prepared.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b3b6ee-f99e-47e5-a22d-4024dc5de38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-tiZAgq70qPmQa7KDYHFP5Bzg', bytes=2970399, created_at=1701947205, filename='fine-tune.jsonl', object='file', purpose='fine-tune', status='uploaded', status_details=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenAI API and client have changed, now finetuning can or needs to be done\n",
    "# with Python code, not CLI client\n",
    "\n",
    "# Upload training data\n",
    "\n",
    "upload_response = openai.files.create(\n",
    "    file=open(TRAINFILE, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "trainfile_id = upload_response.id\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4352c4f-276f-4893-a5c2-acb94572b4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-f3Plu07lCRlZlZYaWjCiWKLR', created_at=1701947281, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-5QEUW2DacClOLTNQvTEKMHdV', result_files=[], status='validating_files', trained_tokens=None, training_file='file-tiZAgq70qPmQa7KDYHFP5Bzg', validation_file=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the actual finetuning via the API. This can take a while, there can be a long queue.\n",
    "\n",
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=trainfile_id,\n",
    "    model=\"babbage-002\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc0c7fb-3785-4223-a4ff-97f4d058afd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FineTuningJobEvent(id='ftevent-uZAdFSd2qHjZsgf2DOe4LwN9', created_at=1701949004, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'),\n",
       " FineTuningJobEvent(id='ftevent-ChGZH2rgFtkoibq4ygIhNu5G', created_at=1701949002, level='info', message='New fine-tuned model created: ft:babbage-002:personal::8T6yHGdp', object='fine_tuning.job.event', data={}, type='message'),\n",
       " FineTuningJobEvent(id='ftevent-5w8o0kPU98fSSZ6BHZXWU3HK', created_at=1701948982, level='info', message='Step 1601/1671: training loss=0.47', object='fine_tuning.job.event', data={'step': 1601, 'train_loss': 0.47158852219581604, 'train_mean_token_accuracy': 0.8634920716285706}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-v36VuJqsnsZHi7MkVEZctCPA', created_at=1701948963, level='info', message='Step 1501/1671: training loss=0.22', object='fine_tuning.job.event', data={'step': 1501, 'train_loss': 0.2230607271194458, 'train_mean_token_accuracy': 0.9497487545013428}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-FGzcKzW5Gyione7THZdWqRgk', created_at=1701948944, level='info', message='Step 1401/1671: training loss=0.09', object='fine_tuning.job.event', data={'step': 1401, 'train_loss': 0.09154736250638962, 'train_mean_token_accuracy': 0.9793103337287903}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-ia3if0ujrWRnuoVevAZlSb6d', created_at=1701948927, level='info', message='Step 1301/1671: training loss=0.17', object='fine_tuning.job.event', data={'step': 1301, 'train_loss': 0.1699811965227127, 'train_mean_token_accuracy': 0.9609755873680115}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-1y0mOi0wCvBLmyMScG75s1Xt', created_at=1701948909, level='info', message='Step 1201/1671: training loss=0.04', object='fine_tuning.job.event', data={'step': 1201, 'train_loss': 0.038225434720516205, 'train_mean_token_accuracy': 0.9931972622871399}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-66DJetAbtK5rxFHyUGCeASMp', created_at=1701948889, level='info', message='Step 1101/1671: training loss=0.26', object='fine_tuning.job.event', data={'step': 1101, 'train_loss': 0.2551744878292084, 'train_mean_token_accuracy': 0.9345238208770752}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-oRy5qlqWXEYAb6guqxCBmBwM', created_at=1701948870, level='info', message='Step 1001/1671: training loss=0.64', object='fine_tuning.job.event', data={'step': 1001, 'train_loss': 0.6393063068389893, 'train_mean_token_accuracy': 0.8478260636329651}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-Dal59WVeiVFxKq0e5ZfIJVgt', created_at=1701948851, level='info', message='Step 901/1671: training loss=0.28', object='fine_tuning.job.event', data={'step': 901, 'train_loss': 0.2831694483757019, 'train_mean_token_accuracy': 0.9352226853370667}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-P1OjDFgpytJ36x7bOwzssbLj', created_at=1701948835, level='info', message='Step 801/1671: training loss=0.13', object='fine_tuning.job.event', data={'step': 801, 'train_loss': 0.13209879398345947, 'train_mean_token_accuracy': 0.9715909361839294}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-Cs7nx9dD8KONPRqE8Ph4HLYf', created_at=1701948816, level='info', message='Step 701/1671: training loss=0.37', object='fine_tuning.job.event', data={'step': 701, 'train_loss': 0.36541152000427246, 'train_mean_token_accuracy': 0.9145299196243286}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-1L9YXz3E7Fwc6kAtatTAjYdw', created_at=1701948797, level='info', message='Step 601/1671: training loss=0.48', object='fine_tuning.job.event', data={'step': 601, 'train_loss': 0.4809528887271881, 'train_mean_token_accuracy': 0.8917526006698608}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-bmxk1YI3ywNWQx0NgTgbbmgD', created_at=1701948777, level='info', message='Step 501/1671: training loss=0.07', object='fine_tuning.job.event', data={'step': 501, 'train_loss': 0.07233993709087372, 'train_mean_token_accuracy': 0.9803149700164795}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-CHLsJp0MgJNyFHGd0y2Nmuui', created_at=1701948759, level='info', message='Step 401/1671: training loss=0.17', object='fine_tuning.job.event', data={'step': 401, 'train_loss': 0.16854888200759888, 'train_mean_token_accuracy': 0.9580419659614563}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-TnXjtN0Wg1o3FRvxsauEslKw', created_at=1701948742, level='info', message='Step 301/1671: training loss=0.59', object='fine_tuning.job.event', data={'step': 301, 'train_loss': 0.5917478799819946, 'train_mean_token_accuracy': 0.8647342920303345}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-aIeDZtKSrSxcsmXQQtgtTG3W', created_at=1701948723, level='info', message='Step 201/1671: training loss=1.32', object='fine_tuning.job.event', data={'step': 201, 'train_loss': 1.3232041597366333, 'train_mean_token_accuracy': 0.7010869383811951}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-mpDBEJGpQf0MPUjvRh6FJIHL', created_at=1701948704, level='info', message='Step 101/1671: training loss=0.00', object='fine_tuning.job.event', data={'step': 101, 'train_loss': 0.0, 'train_mean_token_accuracy': 0.0}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-WmOcvI85q3eHXNWFqty5TpXW', created_at=1701948685, level='info', message='Step 1/1671: training loss=2.08', object='fine_tuning.job.event', data={'step': 1, 'train_loss': 2.075146436691284, 'train_mean_token_accuracy': 0.6639344096183777}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-7y59GvsMcQrw8bQ13zgY0ewZ', created_at=1701948624, level='info', message='Fine-tuning job started', object='fine_tuning.job.event', data=None, type='message')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_job_id = openai.fine_tuning.jobs.list(limit=10).data[0].id\n",
    "openai.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tuning_job_id, limit=20).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0875b0c7-b561-48c1-a9b8-c115f6a7537e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:babbage-002:personal::8T6yHGdp'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the model name from above fine tuning job\n",
    "\n",
    "model_name = openai.fine_tuning.jobs.retrieve(fine_tuning_job_id).fine_tuned_model\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on https://www.theseus.fi/handle/10024/498793 with PDF https://www.theseus.fi/bitstream/handle/10024/498793/Eklund_Liz_Marjanen_Emma.pdf\n",
      "---\n",
      "Curated metadata:\n",
      "Author: Eklund, Liz\n",
      "Author: Marjanen, Emma\n",
      "Organization: Högskolan på Åland\n",
      "Issued: 2021\n",
      "URN: URN:NBN:fi:amk-2021052110375\n",
      "Language: swe\n",
      "Publisher: Högskolan på Åland\n",
      "ISSN (online): 1458-1531\n",
      "Degree program: Utbildningsprogrammet för företagsekonomi\n",
      "Discipline: Företagsekonomi, förvaltning och marknadsföring\n",
      "Title: Hållbara inköp hos två åländska företag : verksamma inom plastindustrin\n",
      "Alternative title: Sustainable Purchases at two Åland Companies - active in the plastics industry\n",
      "COAR type: bachelor thesis\n",
      "OKM type: G1 Ammattikorkeakoulututkinnon opinnäytetyö, kandidaatintyö\n",
      "Thesis level: AMK-opinnäytetyö\n",
      "---\n",
      "Generated metadata:\n",
      "Author: Eklund, Emma\n",
      "Author: Marjanen, Emma\n",
      "Organization: Högskolan på Åland\n",
      "Issued: 2021\n",
      "URN: URN:NBN:fi-fe2021051922434\n",
      "Language: swe\n",
      "Publisher: Högskolan på Åland\n",
      "ISSN (online): 1458-1531\n",
      "Degree program: Företagsekonomi\n",
      "Discipline: Ekonomi\n",
      "Title: Hållbara inköp hos två åländska företag : verksamma inom plastindustrin\n",
      "Alternative title: Sustainable Purchases at two Åland Companies - active in the plastics industry\n",
      "COAR type: bachelor thesis\n",
      "OKM type: G1 Ammattikorkeakoulututkinnon opinnäytetyö, kandidaatintyö\n",
      "Thesis level: AMK-opinnäytetyö\n"
     ]
    }
   ],
   "source": [
    "# Try out the fine-tuned model on a random test set record\n",
    "\n",
    "import random\n",
    "\n",
    "def get_completions(text):\n",
    "    response = openai.completions.create(\n",
    "                                    model=model_name,\n",
    "                                    prompt=truncate_text(text) + PROMPT_SUFFIX,\n",
    "                                    temperature=0,  # no fooling around!\n",
    "                                    max_tokens=2048, # should be very plenty\n",
    "                                    stop=[COMPLETION_STOP])  # stop at ###\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "test_set_file = random.choice(dataset_test_files)\n",
    "with open(test_set_file) as testfile:\n",
    "    records = [json.loads(line) for line in testfile]\n",
    "rec = random.choice(records)\n",
    "\n",
    "print(f\"Testing on {rec['id']} with PDF {rec['url']}\")\n",
    "print(\"---\")\n",
    "print(\"Curated metadata:\")\n",
    "print(rec[\"metadata\"])\n",
    "print(\"---\")\n",
    "print(\"Generated metadata:\")\n",
    "print(get_completions(rec[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "048e1e68-304f-4885-9ba9-5e85c92dda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating metadata for ../../llm-dataset/mono-swe-test.jsonl into gpt3-mono-swe-test.jsonl\n",
      "completed 8 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/docthes-swe-test.jsonl into gpt3-docthes-swe-test.jsonl\n",
      "completed 5 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/thes-eng-test.jsonl into gpt3-thes-eng-test.jsonl\n",
      "completed 14 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/thes-swe-test.jsonl into gpt3-thes-swe-test.jsonl\n",
      "completed 16 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/thes-fin-test.jsonl into gpt3-thes-fin-test.jsonl\n",
      "completed 21 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/docthes-fin-test.jsonl into gpt3-docthes-fin-test.jsonl\n",
      "completed 9 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/serial-fin-test.jsonl into gpt3-serial-fin-test.jsonl\n",
      "completed 18 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/serial-swe-test.jsonl into gpt3-serial-swe-test.jsonl\n",
      "completed 14 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/mono-fin-test.jsonl into gpt3-mono-fin-test.jsonl\n",
      "completed 17 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/serial-eng-test.jsonl into gpt3-serial-eng-test.jsonl\n",
      "completed 17 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/docthes-eng-test.jsonl into gpt3-docthes-eng-test.jsonl\n",
      "completed 15 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/mono-eng-test.jsonl into gpt3-mono-eng-test.jsonl\n",
      "completed 13 records\n",
      "\n",
      "CPU times: user 2.95 s, sys: 54 ms, total: 3 s\n",
      "Wall time: 10min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os.path\n",
    "\n",
    "for test_file in dataset_test_files:\n",
    "    output_file = \"gpt3-\" + os.path.basename(test_file)\n",
    "    print(f\"generating metadata for {test_file} into {output_file}\")\n",
    "    nrec = 0\n",
    "    with open(test_file) as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            rec = json.loads(line)\n",
    "            generated_metadata = get_completions(rec[\"text\"])\n",
    "            outrec = {\"id\": rec[\"id\"], \"url\": rec[\"url\"], \"metadata_orig\": rec[\"metadata\"], \"metadata_gen\": generated_metadata}\n",
    "            json.dump(outrec, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "            nrec += 1\n",
    "    print(f\"completed {nrec} records\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e947bea0-1f37-44b4-9a21-75de1278ac9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall similarity: 0.721646225749584\n"
     ]
    }
   ],
   "source": [
    "# Calculate rough similarity between original and generated metadata using Levenshtein normalized indel similarity\n",
    "\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "\n",
    "data = []\n",
    "for test_file in dataset_test_files:\n",
    "    gen_file = \"gpt3-\" + os.path.basename(test_file)\n",
    "    _, subset, lang, _ = os.path.splitext(gen_file)[0].split('-')\n",
    "    with open(gen_file) as gfile:\n",
    "        for line in gfile:\n",
    "            rec = json.loads(line)\n",
    "            similarity = Levenshtein.ratio(rec[\"metadata_orig\"], rec[\"metadata_gen\"])\n",
    "            data.append([subset, lang, rec[\"id\"], rec[\"url\"], similarity])\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"subset\", \"lang\", \"id\", \"url\", \"similarity\"])\n",
    "\n",
    "print(\"Overall similarity:\", df[\"similarity\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd3d989e-1b65-42a1-bffd-07ed4dc7ab46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset\n",
       "docthes    0.778195\n",
       "mono       0.655294\n",
       "serial     0.633551\n",
       "thes       0.823571\n",
       "Name: similarity, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['subset'])[\"similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b9fb423-e6f1-4e07-928e-d2f0649f808c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lang\n",
       "eng    0.671907\n",
       "fin    0.743314\n",
       "swe    0.757140\n",
       "Name: similarity, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['lang'])[\"similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc925e69-5920-41a6-a0e9-43b492cbcd7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subset   lang\n",
       "docthes  eng     0.786059\n",
       "         fin     0.792288\n",
       "         swe     0.729233\n",
       "mono     eng     0.645852\n",
       "         fin     0.637751\n",
       "         swe     0.707916\n",
       "serial   eng     0.526967\n",
       "         fin     0.703911\n",
       "         swe     0.672509\n",
       "thes     eng     0.749791\n",
       "         fin     0.841554\n",
       "         swe     0.864525\n",
       "Name: similarity, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['subset','lang'])[\"similarity\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f036a5-0456-4e5f-aa4a-37c9e6f6d0af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
