{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39e52dc6-68a0-4082-9fe0-73c4a8cb6708",
   "metadata": {},
   "source": [
    "# Test the connection and API key\n",
    "\n",
    "Make sure it's possible to use the OpenAI API. For this to work, the environment variable OPENAI_API_KEY must be set to a valid API key which has available credits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762d1a22-1db3-474b-a880-8437cad22a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completion(id='cmpl-8iMPpy4gsam414yEpV1b3KISLPj0U', choices=[CompletionChoice(finish_reason='length', index=0, logprobs=None, text=\". I'm gonna say this is\")], created=1705583289, model='davinci-002', object='text_completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=7, prompt_tokens=5, total_tokens=12))\n",
      ". I'm gonna say this is\n"
     ]
    }
   ],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "# read the OpenAI API key from an environment variable\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "\n",
    "# test the API connection by making a simple request\n",
    "response = openai.completions.create(model=\"davinci-002\", prompt=\"Say this is a test\", temperature=0, max_tokens=7)\n",
    "print(response)\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59823f6-ea2e-467f-a438-93a69652daaf",
   "metadata": {},
   "source": [
    "# Prepare the fine-tuning set\n",
    "\n",
    "Prepare a fine-tuning dataset and use it to fine-tune a GPT3 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d035bad1-13d2-4ebe-beee-159991adfe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating fine-tune.jsonl\n",
      "- processing ../../llm-dataset/serial-fin-train.jsonl\n",
      "- processing ../../llm-dataset/serial-swe-train.jsonl\n",
      "- processing ../../llm-dataset/docthes-eng-train.jsonl\n",
      "- processing ../../llm-dataset/docthes-fin-train.jsonl\n",
      "- processing ../../llm-dataset/thes-fin-train.jsonl\n",
      "- processing ../../llm-dataset/thes-swe-train.jsonl\n",
      "- processing ../../llm-dataset/mono-swe-train.jsonl\n",
      "- processing ../../llm-dataset/docthes-swe-train.jsonl\n",
      "- processing ../../llm-dataset/mono-eng-train.jsonl\n",
      "- processing ../../llm-dataset/mono-fin-train.jsonl\n",
      "- processing ../../llm-dataset/thes-eng-train.jsonl\n",
      "- processing ../../llm-dataset/serial-eng-train.jsonl\n",
      "557 records converted\n",
      "\n",
      "Creating validate.jsonl\n",
      "- processing ../../llm-dataset/mono-swe-test.jsonl\n",
      "- processing ../../llm-dataset/docthes-swe-test.jsonl\n",
      "- processing ../../llm-dataset/thes-eng-test.jsonl\n",
      "- processing ../../llm-dataset/thes-swe-test.jsonl\n",
      "- processing ../../llm-dataset/thes-fin-test.jsonl\n",
      "- processing ../../llm-dataset/docthes-fin-test.jsonl\n",
      "- processing ../../llm-dataset/serial-fin-test.jsonl\n",
      "- processing ../../llm-dataset/serial-swe-test.jsonl\n",
      "- processing ../../llm-dataset/mono-fin-test.jsonl\n",
      "- processing ../../llm-dataset/serial-eng-test.jsonl\n",
      "- processing ../../llm-dataset/docthes-eng-test.jsonl\n",
      "- processing ../../llm-dataset/mono-eng-test.jsonl\n",
      "167 records converted\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "import tiktoken\n",
    "\n",
    "PROMPT_SUFFIX = '\\n\\n###\\n\\n'\n",
    "COMPLETION_STOP = '\\n###'\n",
    "TRAINFILE = 'fine-tune.jsonl'\n",
    "VALIDATEFILE = 'validate.jsonl'\n",
    "BASE_MODEL = 'babbage-002'\n",
    "MAX_TOKENS = 12000  # Increased for babbage-002 model\n",
    "\n",
    "dataset_train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "dataset_test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "encoding = tiktoken.encoding_for_model(BASE_MODEL)\n",
    "\n",
    "def truncate_text(text):\n",
    "    \"\"\"truncate text so it contains at most MAX_TOKENS according to the OpenAI tokenizer\"\"\"\n",
    "    tokens = encoding.encode(text)\n",
    "    return encoding.decode(tokens[:MAX_TOKENS])\n",
    "\n",
    "def create_sample(text, metadata):\n",
    "    \"\"\"create a fine-tuning sample from text and metadata about a single document\"\"\"\n",
    "    return {'prompt': truncate_text(text) + PROMPT_SUFFIX,\n",
    "            'completion': \" \" + metadata + COMPLETION_STOP}\n",
    "\n",
    "def convert_to_samples(infiles, outfile):\n",
    "    print(f\"Creating {outfile}\")\n",
    "    nrec = 0\n",
    "    with open(outfile, \"w\") as outf:\n",
    "        for infile in infiles:\n",
    "            print(f\"- processing {infile}\")\n",
    "            with open(infile) as inf:\n",
    "                for line in inf:\n",
    "                    rec = json.loads(line)\n",
    "                    sample = create_sample(rec[\"text\"], rec[\"metadata\"])\n",
    "                    print(json.dumps(sample), file=outf)\n",
    "                    nrec += 1\n",
    "    print(f\"{nrec} records converted\")\n",
    "    print()\n",
    "\n",
    "convert_to_samples(dataset_train_files, TRAINFILE)\n",
    "convert_to_samples(dataset_test_files, VALIDATEFILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cc70c8a-1ab3-4a9e-8d76-b73b718751ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing...\n",
      "\n",
      "- Your file contains 557 prompt-completion pairs\n",
      "- There are 7 examples that are very long. These are rows: [231, 257, 258, 268, 333, 468, 504]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix `\\n###`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 7 long examples [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `fine-tune_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"fine-tune_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 27.87 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n",
      "Analyzing...\n",
      "\n",
      "- Your file contains 167 prompt-completion pairs\n",
      "- There are 3 examples that are very long. These are rows: [28, 30, 31]\n",
      "For conditional generation, and for classification the examples shouldn't be longer than 2048 tokens.\n",
      "- All prompts end with suffix `\\n\\n###\\n\\n`\n",
      "- All completions end with suffix `\\n###`\n",
      "\n",
      "Based on the analysis we will perform the following actions:\n",
      "- [Recommended] Remove 3 long examples [Y/n]: Y\n",
      "\n",
      "\n",
      "Your data will be written to a new JSONL file. Proceed [Y/n]: Y\n",
      "\n",
      "Wrote modified file to `validate_prepared.jsonl`\n",
      "Feel free to take a look!\n",
      "\n",
      "Now use that file when fine-tuning:\n",
      "> openai api fine_tunes.create -t \"validate_prepared.jsonl\"\n",
      "\n",
      "After you’ve fine-tuned a model, remember that your prompt has to end with the indicator string `\\n\\n###\\n\\n` for the model to start generating completions, rather than continuing with the prompt. Make sure to include `stop=[\"\\n###\"]` so that the generated texts ends at the expected place.\n",
      "Once your model starts training, it'll approximately take 9.29 minutes to train a `curie` model, and less for `ada` and `babbage`. Queue will approximately take half an hour per job ahead of you.\n"
     ]
    }
   ],
   "source": [
    "# Check that the fine-tuning data set is OK using the prepare_data tool.\n",
    "# We will only use prepare_data as a validation aid and delete the \"prepared\"\n",
    "# files that it helpfully creates.\n",
    "!openai tools fine_tunes.prepare_data -f fine-tune.jsonl -q\n",
    "!rm -f fine-tune_prepared.jsonl\n",
    "\n",
    "!openai tools fine_tunes.prepare_data -f validate.jsonl -q\n",
    "!rm -f validate_prepared.jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46b3b6ee-f99e-47e5-a22d-4024dc5de38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileObject(id='file-tiZAgq70qPmQa7KDYHFP5Bzg', bytes=2970399, created_at=1701947205, filename='fine-tune.jsonl', object='file', purpose='fine-tune', status='uploaded', status_details=None)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OpenAI API and client have changed, now finetuning can or needs to be done\n",
    "# with Python code, not CLI client\n",
    "\n",
    "# Upload training data\n",
    "\n",
    "upload_response = openai.files.create(\n",
    "    file=open(TRAINFILE, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "trainfile_id = upload_response.id\n",
    "upload_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4352c4f-276f-4893-a5c2-acb94572b4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FineTuningJob(id='ftjob-f3Plu07lCRlZlZYaWjCiWKLR', created_at=1701947281, error=None, fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='babbage-002', object='fine_tuning.job', organization_id='org-5QEUW2DacClOLTNQvTEKMHdV', result_files=[], status='validating_files', trained_tokens=None, training_file='file-tiZAgq70qPmQa7KDYHFP5Bzg', validation_file=None)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform the actual finetuning via the API. This can take a while, there can be a long queue.\n",
    "\n",
    "openai.fine_tuning.jobs.create(\n",
    "    training_file=trainfile_id,\n",
    "    model=\"babbage-002\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0cc0c7fb-3785-4223-a4ff-97f4d058afd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[FineTuningJobEvent(id='ftevent-uZAdFSd2qHjZsgf2DOe4LwN9', created_at=1701949004, level='info', message='The job has successfully completed', object='fine_tuning.job.event', data={}, type='message'),\n",
       " FineTuningJobEvent(id='ftevent-ChGZH2rgFtkoibq4ygIhNu5G', created_at=1701949002, level='info', message='New fine-tuned model created: ft:babbage-002:personal::8T6yHGdp', object='fine_tuning.job.event', data={}, type='message'),\n",
       " FineTuningJobEvent(id='ftevent-5w8o0kPU98fSSZ6BHZXWU3HK', created_at=1701948982, level='info', message='Step 1601/1671: training loss=0.47', object='fine_tuning.job.event', data={'step': 1601, 'train_loss': 0.47158852219581604, 'train_mean_token_accuracy': 0.8634920716285706}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-v36VuJqsnsZHi7MkVEZctCPA', created_at=1701948963, level='info', message='Step 1501/1671: training loss=0.22', object='fine_tuning.job.event', data={'step': 1501, 'train_loss': 0.2230607271194458, 'train_mean_token_accuracy': 0.9497487545013428}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-FGzcKzW5Gyione7THZdWqRgk', created_at=1701948944, level='info', message='Step 1401/1671: training loss=0.09', object='fine_tuning.job.event', data={'step': 1401, 'train_loss': 0.09154736250638962, 'train_mean_token_accuracy': 0.9793103337287903}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-ia3if0ujrWRnuoVevAZlSb6d', created_at=1701948927, level='info', message='Step 1301/1671: training loss=0.17', object='fine_tuning.job.event', data={'step': 1301, 'train_loss': 0.1699811965227127, 'train_mean_token_accuracy': 0.9609755873680115}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-1y0mOi0wCvBLmyMScG75s1Xt', created_at=1701948909, level='info', message='Step 1201/1671: training loss=0.04', object='fine_tuning.job.event', data={'step': 1201, 'train_loss': 0.038225434720516205, 'train_mean_token_accuracy': 0.9931972622871399}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-66DJetAbtK5rxFHyUGCeASMp', created_at=1701948889, level='info', message='Step 1101/1671: training loss=0.26', object='fine_tuning.job.event', data={'step': 1101, 'train_loss': 0.2551744878292084, 'train_mean_token_accuracy': 0.9345238208770752}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-oRy5qlqWXEYAb6guqxCBmBwM', created_at=1701948870, level='info', message='Step 1001/1671: training loss=0.64', object='fine_tuning.job.event', data={'step': 1001, 'train_loss': 0.6393063068389893, 'train_mean_token_accuracy': 0.8478260636329651}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-Dal59WVeiVFxKq0e5ZfIJVgt', created_at=1701948851, level='info', message='Step 901/1671: training loss=0.28', object='fine_tuning.job.event', data={'step': 901, 'train_loss': 0.2831694483757019, 'train_mean_token_accuracy': 0.9352226853370667}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-P1OjDFgpytJ36x7bOwzssbLj', created_at=1701948835, level='info', message='Step 801/1671: training loss=0.13', object='fine_tuning.job.event', data={'step': 801, 'train_loss': 0.13209879398345947, 'train_mean_token_accuracy': 0.9715909361839294}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-Cs7nx9dD8KONPRqE8Ph4HLYf', created_at=1701948816, level='info', message='Step 701/1671: training loss=0.37', object='fine_tuning.job.event', data={'step': 701, 'train_loss': 0.36541152000427246, 'train_mean_token_accuracy': 0.9145299196243286}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-1L9YXz3E7Fwc6kAtatTAjYdw', created_at=1701948797, level='info', message='Step 601/1671: training loss=0.48', object='fine_tuning.job.event', data={'step': 601, 'train_loss': 0.4809528887271881, 'train_mean_token_accuracy': 0.8917526006698608}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-bmxk1YI3ywNWQx0NgTgbbmgD', created_at=1701948777, level='info', message='Step 501/1671: training loss=0.07', object='fine_tuning.job.event', data={'step': 501, 'train_loss': 0.07233993709087372, 'train_mean_token_accuracy': 0.9803149700164795}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-CHLsJp0MgJNyFHGd0y2Nmuui', created_at=1701948759, level='info', message='Step 401/1671: training loss=0.17', object='fine_tuning.job.event', data={'step': 401, 'train_loss': 0.16854888200759888, 'train_mean_token_accuracy': 0.9580419659614563}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-TnXjtN0Wg1o3FRvxsauEslKw', created_at=1701948742, level='info', message='Step 301/1671: training loss=0.59', object='fine_tuning.job.event', data={'step': 301, 'train_loss': 0.5917478799819946, 'train_mean_token_accuracy': 0.8647342920303345}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-aIeDZtKSrSxcsmXQQtgtTG3W', created_at=1701948723, level='info', message='Step 201/1671: training loss=1.32', object='fine_tuning.job.event', data={'step': 201, 'train_loss': 1.3232041597366333, 'train_mean_token_accuracy': 0.7010869383811951}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-mpDBEJGpQf0MPUjvRh6FJIHL', created_at=1701948704, level='info', message='Step 101/1671: training loss=0.00', object='fine_tuning.job.event', data={'step': 101, 'train_loss': 0.0, 'train_mean_token_accuracy': 0.0}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-WmOcvI85q3eHXNWFqty5TpXW', created_at=1701948685, level='info', message='Step 1/1671: training loss=2.08', object='fine_tuning.job.event', data={'step': 1, 'train_loss': 2.075146436691284, 'train_mean_token_accuracy': 0.6639344096183777}, type='metrics'),\n",
       " FineTuningJobEvent(id='ftevent-7y59GvsMcQrw8bQ13zgY0ewZ', created_at=1701948624, level='info', message='Fine-tuning job started', object='fine_tuning.job.event', data=None, type='message')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fine_tuning_job_id = openai.fine_tuning.jobs.list(limit=10).data[0].id\n",
    "openai.fine_tuning.jobs.list_events(fine_tuning_job_id=fine_tuning_job_id, limit=20).data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0875b0c7-b561-48c1-a9b8-c115f6a7537e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ft:babbage-002:personal::8T6yHGdp'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# store the model name from above fine tuning job\n",
    "\n",
    "model_name = openai.fine_tuning.jobs.retrieve(fine_tuning_job_id).fine_tuned_model\n",
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "79224713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on https://osuva.uwasa.fi/handle/10024/11334 with PDF https://osuva.uwasa.fi/bitstream/handle/10024/11334/UVA_2020_Salminen_Heini.pdf\n",
      "---\n",
      "Curated metadata:\n",
      "Author: Salminen, Heini\n",
      "Faculty: Laskentatoimen ja rahoituksen yksikkö\n",
      "Organization: Vaasan yliopisto\n",
      "Issued: 2020-08-27\n",
      "URN: URN:NBN:fi-fe2020082764516\n",
      "Language: fin\n",
      "Publisher: Vaasan yliopisto\n",
      "Degree program: Laskentatoimen ja tilintarkastuksen maisteriohjelma\n",
      "Discipline: Laskentatoimi ja rahoitus\n",
      "Title: Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun : Tarkastusvaliokunnat suomalaisissa ja ruotsalaisissa pörssiyhtiöissä\n",
      "COAR type: master thesis\n",
      "OKM type: G2 Pro gradu, diplomityö, ylempi amk-opinnäytetyö\n",
      "Thesis level: Pro gradu -tutkielma\n",
      "---\n",
      "Generated metadata:\n",
      "Author: Salminen, Heini\n",
      "Faculty: Laskentatoimen ja tilintarkastuksen\n",
      "Organization: Vaasan yliopisto\n",
      "Issued: 2020-05-05\n",
      "URN: URN:NBN:fi:amk-202005062048\n",
      "Language: fin\n",
      "Publisher: Vaasan yliopisto\n",
      "Degree program: Laskentatoimen ja tilintarkastuksen maisteriohjelma\n",
      "Discipline: Tilintarkastus ja hallinto\n",
      "Title: Tarkastusvaliokunnan vaikutus taloudellisen raportoinnin laatuun\n",
      "COAR type: master thesis\n",
      "OKM type: G2 Pro gradu, diplomityö, ylempi amk-opinnäytetyö\n",
      "Thesis level: Pro gradu -tutkielma\n"
     ]
    }
   ],
   "source": [
    "# Try out the fine-tuned model on a random test set record\n",
    "\n",
    "import random\n",
    "\n",
    "model_name = 'ft:babbage-002:personal::8T6yHGdp'\n",
    "\n",
    "def get_completions(text):\n",
    "    response = openai.completions.create(\n",
    "                                    model=model_name,\n",
    "                                    prompt=truncate_text(text) + PROMPT_SUFFIX,\n",
    "                                    temperature=0,  # no fooling around!\n",
    "                                    max_tokens=2048, # should be very plenty\n",
    "                                    stop=[COMPLETION_STOP])  # stop at ###\n",
    "    return response.choices[0].text.strip()\n",
    "\n",
    "test_set_file = random.choice(dataset_test_files)\n",
    "with open(test_set_file) as testfile:\n",
    "    records = [json.loads(line) for line in testfile]\n",
    "rec = random.choice(records)\n",
    "\n",
    "print(f\"Testing on {rec['id']} with PDF {rec['url']}\")\n",
    "print(\"---\")\n",
    "print(\"Curated metadata:\")\n",
    "print(rec[\"metadata\"])\n",
    "print(\"---\")\n",
    "print(\"Generated metadata:\")\n",
    "print(get_completions(rec[\"text\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "048e1e68-304f-4885-9ba9-5e85c92dda0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating metadata for ../../llm-dataset/mono-swe-test.jsonl into gpt3-mono-swe-test.jsonl\n",
      "completed 8 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/docthes-swe-test.jsonl into gpt3-docthes-swe-test.jsonl\n",
      "completed 5 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/thes-eng-test.jsonl into gpt3-thes-eng-test.jsonl\n",
      "completed 14 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/thes-swe-test.jsonl into gpt3-thes-swe-test.jsonl\n",
      "completed 16 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/thes-fin-test.jsonl into gpt3-thes-fin-test.jsonl\n",
      "completed 21 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/docthes-fin-test.jsonl into gpt3-docthes-fin-test.jsonl\n",
      "completed 9 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/serial-fin-test.jsonl into gpt3-serial-fin-test.jsonl\n",
      "completed 18 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/serial-swe-test.jsonl into gpt3-serial-swe-test.jsonl\n",
      "completed 14 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/mono-fin-test.jsonl into gpt3-mono-fin-test.jsonl\n",
      "completed 17 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/serial-eng-test.jsonl into gpt3-serial-eng-test.jsonl\n",
      "completed 17 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/docthes-eng-test.jsonl into gpt3-docthes-eng-test.jsonl\n",
      "completed 15 records\n",
      "\n",
      "generating metadata for ../../llm-dataset/mono-eng-test.jsonl into gpt3-mono-eng-test.jsonl\n",
      "completed 13 records\n",
      "\n",
      "CPU times: user 3 s, sys: 52.3 ms, total: 3.05 s\n",
      "Wall time: 9min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os.path\n",
    "\n",
    "for test_file in dataset_test_files:\n",
    "    output_file = \"gpt3-\" + os.path.basename(test_file)\n",
    "    print(f\"generating metadata for {test_file} into {output_file}\")\n",
    "    nrec = 0\n",
    "    with open(test_file) as infile, open(output_file, \"w\") as outfile:\n",
    "        for line in infile:\n",
    "            rec = json.loads(line)\n",
    "            generated_metadata = get_completions(rec[\"text\"])\n",
    "            outrec = {\"id\": rec[\"id\"], \"url\": rec[\"url\"], \"ground_truth\": rec[\"metadata\"], \"prediction\": generated_metadata}\n",
    "            json.dump(outrec, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "            nrec += 1\n",
    "    print(f\"completed {nrec} records\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f036a5-0456-4e5f-aa4a-37c9e6f6d0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpt3-thes-swe-test.jsonl\n",
      "gpt3-mono-eng-test.jsonl\n",
      "Invalid line: The following is a list of the 2017-2018 winners of the National Book Awards. The winners will be announced on April 25, 2018, at a ceremony in New York City. The National Book Foundation is a private, nonprofit organization that promotes the reading public and the creation and appreciation of books. The Foundation is based in New York City and was founded in 1937 by Aldo Leopold, author of A Sand County Almanac. The Foundation’s mission is to recognize and honor the best books of the year and to foster the creation and appreciation of books. The Foundation is supported by the National Endowment for the Arts, the National Endowment for the Humanities, and the John S. and James L. Knight Foundation. The Foundation also receives generous support from the City of New York, the New York State Council on the Arts with the support of Governor Andrew M. Cuomo and the New York State Legislature, and the National Endowment for the Humanities. The Foundation is also supported by the Corporation for Public Broadcasting, the National Endowment for the Humanities, and the National Endowment for the Arts. The Foundation is a private, nonprofit organization. The Foundation does not accept unsolicited manuscripts, and does not consider unsolicited poetry, fiction, or creative nonfiction. The Foundation does not consider unsolicited artwork, photographs, or other visual art. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials. The Foundation does not consider unsolicited letters, notes, or other materials.\n",
      "Invalid line: and$Theatre$Music$in$the$Long$19th$Century!\n",
      "Invalid line: ### Author: Anderson, John\n",
      "gpt3-docthes-swe-test.jsonl\n",
      "gpt3-mono-fin-test.jsonl\n",
      "Invalid line: (Tampere University Press, Tampere, Suomi)\n",
      "Invalid line: ISBN: 978-952-359-040-3\n",
      "Invalid line: Kohta 3: Hallinnollinen alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskuntapolitiikan alue\n",
      "Invalid line: Hallinto- ja yhteiskunt\n",
      "gpt3-serial-eng-test.jsonl\n",
      "Invalid line: University: University of Turku\n",
      "Invalid line: City: Turku\n",
      "Invalid line: Country: Finland\n",
      "Invalid line: University: University of Turku\n",
      "Invalid line: Issn: 2343-3442 (Print)\n",
      "Invalid line: issn: 2343-3450 (Online)\n",
      "Invalid line: Number: 4\n",
      "Invalid line: COARSA:  4\n",
      "Invalid line: Number: 4\n",
      "Invalid line: COARSA:  4\n",
      "Invalid line: COARSA:  4\n",
      "Invalid line: COARSA org: COARSA\n",
      "Invalid line: COARSA org: COARSA\n",
      "Invalid line: Publisher's website: https://journal.fjrs.eu/\n",
      "Invalid line: COARSA:  4\n",
      "Invalid line: COARSA id: coaras\n",
      "Invalid line: COARSA:  4\n",
      "Invalid line: COARSA id: coaras\n",
      "Invalid line: COARSA:  4\n",
      "Invalid line: COARSA id: coaras\n",
      "Invalid line: COARSA:  4\n",
      "Invalid line: COARSA id: coaras\n",
      "Invalid line: ISBN: 978-1-4666-2454-0\n",
      "Invalid line: Citation: Alander, J. T., Vladimir Bochko, Birgitta Martinkauppi, Sirinnapa Saranwong, and Timo Mantere. 2013. A Review of Optical Nondestructive Visual and Near-Infrared Methods for Food Quality and Safety. Int. J. Spectrosc. 2013, Article ID 341402, 36 pages. http://dx.doi.org/10.1155/2013/341402\n",
      "Invalid line: Online publication date: 30 Jan. 2013\n",
      "Invalid line: Print publication date: 31 Jan. 2013\n",
      "Invalid line: Citation: Lund, V. (2021).  Supporting Transformative Agency among  Urban Actors in the Change Laboratory Intervention . Current Urban Studies, 9:3, 403-418. https://doi.org/10.4236/cus.2021.93025\n",
      "Invalid line: Abstract: How to cite this paper: Lund,  V.  (2021).  Supporting Transformative Agency among  Urban Actors in the Change Laboratory Intervention . Current Urban Studies, 9:3, 403-418. https://doi.org/10.4236/cus.2021.93025\n",
      "Invalid line: COin code:  2002  .  . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "gpt3-serial-swe-test.jsonl\n",
      "gpt3-docthes-fin-test.jsonl\n",
      "Invalid line: dekunta, Sosiaali- ja terveysjohtamisen laitos.\n",
      "gpt3-docthes-eng-test.jsonl\n",
      "Invalid line: ISBN: 978-952-389-006-3\n",
      "Invalid line: ISBN (E-book): 978-952-389-005-6\n",
      "Invalid line: \n",
      "gpt3-mono-swe-test.jsonl\n",
      "gpt3-thes-eng-test.jsonl\n",
      "Invalid line: University: University of Turku\n",
      "Invalid line: City: Turku\n",
      "gpt3-serial-fin-test.jsonl\n",
      "gpt3-thes-fin-test.jsonl\n"
     ]
    }
   ],
   "source": [
    "# Convert the results FinGreyLit dataschema and save to file\n",
    "\n",
    "from glob import glob\n",
    "import json\n",
    "\n",
    "\n",
    "records =[]\n",
    "prediction_records_files = glob(\"gpt3-*.jsonl\")\n",
    "\n",
    "KEYS_MAP = {\n",
    "    \"Contributor\":\t\t\"dc.contributor\",\n",
    "    \"Author\":\t\t    \"dc.contributor.author\",\n",
    "    \"Supervisor\":\t\t\"dc.contributor.degreeSupervisor\",\n",
    "    \"Department\":\t\t\"dc.contributor.department\",\n",
    "    \"Editor\":\t\t    \"dc.contributor.editor\",\n",
    "    \"Faculty\":\t\t    \"dc.contributor.faculty\",\n",
    "    \"Opponent\":\t\t    \"dc.contributor.opponent\",\n",
    "    \"Organization\":\t\t\"dc.contributor.organization\",\n",
    "    \"Org. unit\":\t\t\"dc.contributor.orgunit\",\n",
    "    \"Reviewer\":\t\t    \"dc.contributor.reviewer\",\n",
    "    \"Issued\":\t\t    \"dc.date.issued\",\n",
    "    \"extent\":\t\t    \"dc.format.extent\",\n",
    "    \"Page range\":\t\t\"dc.format.pagerange\",\n",
    "    \"ISBN (printed)\":\t\"dc.identifier.isbn\",\n",
    "    \"ISBN (online)\":\t\"dc.identifier.isbn\",\n",
    "    \"URN\":\t\t        \"dc.identifier.urn\",\n",
    "    \"Language\":\t\t    \"dc.language.iso\",\n",
    "    \"Publisher\":\t\t\"dc.publisher\",\n",
    "    \"Publisher (online)\":\"dc.publisher\",\n",
    "    \"Contractor\":\t\t\"dc.relation.contractor\",\n",
    "    \"DOI\":\t\t        \"dc.relation.doi\",\n",
    "    \"ISSN (online)\":\t\"dc.relation.eissn\",\n",
    "    \"risbn\":\t\t    \"dc.relation.isbn\",\n",
    "    \"Journal name\":\t\"reladc.tion.ispartofjournal\",\n",
    "    \"Series name\":\t\t\"dc.relation.ispartofseries\",\n",
    "    \"Issue\":\t\t    \"dc.relation.issue\",\n",
    "    \"Number in series\":\t\"dc.relationnumberinseries\",\n",
    "    \"ISSN (printed)\":\t\"dc.relation.pissn\",\n",
    "    \"Volume\":\t\t    \"dc.relation.volume\",\n",
    "    \"Series year\":\t\t\"dc.series.year\",\n",
    "    \"Degree program\":\t\"dc.subject.degreeprogram\",\n",
    "    \"Discipline\":\t\t\"dc.subject.discipline\",\n",
    "    \"Title\":\t\t    \"dc.title\",\n",
    "    \"Alternative title\":\"dc.title.alternative\",\n",
    "    \"COAR type\":\t\t\"dc.type.coar\",\n",
    "    \"OKM type\":\t\t    \"dc.type.okm\",\n",
    "    \"Thesis level\":\t\t\"dc.type.ontasot\",\n",
    "}\n",
    "\n",
    "LIST_FIELDS = [\n",
    "    \"dc.contributor.author\",\n",
    "    \"dc.identifier.isbn\",\n",
    "    \"dc.publisher\",\n",
    "]\n",
    "\n",
    "def convert_to_scheme(metadata_str):\n",
    "    field_lines = metadata_str.split('\\n')\n",
    "    out = {}\n",
    "\n",
    "    for fl in field_lines:\n",
    "        try:\n",
    "            key, value = fl.split(\":\", maxsplit=1)\n",
    "            dc_key = KEYS_MAP[key.strip()]\n",
    "        except (KeyError, ValueError):\n",
    "            print(f\"Invalid line: {fl}\")\n",
    "            continue\n",
    "        value = value.strip()\n",
    "        if dc_key in LIST_FIELDS:\n",
    "            if not dc_key in out:\n",
    "                out[dc_key] = []\n",
    "            out[dc_key].append(value)\n",
    "        else:\n",
    "            out[dc_key] = value\n",
    "    return out\n",
    "\n",
    "prediction_records = []\n",
    "for rec_file in prediction_records_files:\n",
    "    print(rec_file)\n",
    "    doctype = rec_file.split(\"-\")[1]\n",
    "    with open(rec_file, \"rt\") as rf:\n",
    "        for line in rf:\n",
    "            rec_in = json.loads(line)\n",
    "            rec_out = {\n",
    "                \"rowid\": rec_in[\"id\"],\n",
    "                \"url\": rec_in[\"url\"],\n",
    "                \"doctype\": doctype,\n",
    "                }\n",
    "            rec_out[\"ground_truth\"] = convert_to_scheme(rec_in[\"ground_truth\"])\n",
    "            rec_out[\"prediction\"] = convert_to_scheme(rec_in[\"prediction\"])\n",
    "            prediction_records.append(rec_out)\n",
    "\n",
    "\n",
    "# write output to JSONL file\n",
    "with open('test-records.jsonl', 'w') as outfile:\n",
    "    for rec in prediction_records:\n",
    "        json.dump(rec, outfile)\n",
    "        outfile.write(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1bb51f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the statistics of the extracted metadata and save to file\n",
    "\n",
    "import sys\n",
    "from glob import glob\n",
    "sys.path.append('..')\n",
    "from eval import MetadataEvaluator\n",
    "\n",
    "evaluator = MetadataEvaluator(prediction_records)\n",
    "results = evaluator.evaluate_records(prediction_records)\n",
    "# Use only the same fields that Meteor extracts\n",
    "fields = [\n",
    "        \"dc.contributor.author\",\n",
    "        \"dc.date.issued\",\n",
    "        \"dc.identifier.isbn\",\n",
    "        \"dc.language.iso\",\n",
    "        \"dc.publisher\",\n",
    "        \"dc.relation.eissn\",\n",
    "        \"dc.title\",\n",
    "    ]\n",
    "statistics_filename = '../results-openai-gpt3-api-' + model_name + '.md'\n",
    "evaluator.save_md(results, statistics_filename, fields)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
