{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Extraction using local LLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/llm-inference/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "#import transformers\n",
    "import requests\n",
    "import fitz\n",
    "import io\n",
    "import re\n",
    "import regex\n",
    "import peft\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a poem about Machine Learning. \n",
      "\n",
      "Machine Learning: A Journey Through the Digital Universe\n",
      "\n",
      "In the vast digital universe,  \n",
      "A machine learning journey begins  \n",
      "A neural network, a self-learning system  \n",
      "Guiding us through the unknown terrain  \n",
      "\n",
      "The first step, a dataset to feed  \n",
      "A vast sea of data, a treasure trove  \n",
      "Structured and unstructured,  \n",
      "A treasure trove of knowledge to explore  \n",
      "\n",
      "The algorithm, a master of learning  \n",
      "A self-adapting system,  \n",
      "A journey through the unknown  \n",
      "A journey of discovery, a journey of learning  \n",
      "\n",
      "The neural network, a self-learning system  \n",
      "A journey through the digital universe  \n",
      "A journey of discovery\n"
     ]
    }
   ],
   "source": [
    "# load and test the language model\n",
    "\n",
    "#MODEL = \"NatLibFi/Nous-Hermes-2-Mistral-7B-DPO-meteor\"\n",
    "MODEL = \"NatLibFi/stablelm-2-zephyr-1_6b-meteor\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftConfig\n",
    "\n",
    "config = PeftConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "#tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "input_text = \"Write a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=128, pad_token_id=tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a PDF URL:  https://ffi-publikasjoner.archive.knowledgearc.net/bitstream/handle/20.500.12242/3133/22-01384.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered: https://ffi-publikasjoner.archive.knowledgearc.net/bitstream/handle/20.500.12242/3133/22-01384.pdf\n"
     ]
    }
   ],
   "source": [
    "# ask for PDF URL\n",
    "\n",
    "url = input(\"Please enter a PDF URL: \")\n",
    "print(f\"You entered: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 2666 characters\n",
      "\n",
      "title: Bør vi samarbeide? – en litteraturstudie om valg av sourcingstrategi\n",
      "author: Olger Breivik Pedersen\n",
      "keywords: \n",
      "\n",
      "creationDate: D:20230110100249+01'00'\n",
      "modDate: D:20230110112249+01'00'\n",
      "encryption: Standard V4 R4 128-bit AES\n",
      "22/01384\n",
      "FFI-RAPPORT\n",
      "Bør vi samarbeide? – en litteraturstudie om valg av sourcingstrategi\n",
      "Olger Breivik Pedersen\n",
      "\n",
      "\n",
      "Bør vi samarbeide? – en litteraturstudie om valg av sourcingstrategi\n",
      "Olger Breivik Pedersen\n",
      "Forsvarets forskningsinstitutt (FFI) 2. januar 2023\n",
      "FFI-RAPPORT 22/01384 1\n",
      "\n",
      "Emneord\n",
      "Outsourcing\n",
      "Sourcing\n",
      "Industrisamarbeid\n",
      "Samarbeid\n",
      "Strategisk partnerskap\n",
      "Forsvarsanskaffelser\n",
      "FFI-rapport 22/01384\n",
      "Prosjektnummer 1545\n",
      "Elektronisk ISBN 978-82-464-3444-5\n",
      "Engelsk tittel\n",
      "Sourcing strategies – a literature review\n",
      "Godkjennere\n",
      "Ane Ofstad Presterud, forskningsleder\n",
      "Sverre Nyhus Kvalvik, forskningssjef\n",
      "Dokumentet er elektronisk godkjent og har derfor ikke håndskreven signatur\n",
      "FFI-RAPPORT 22/01384\n",
      "\n",
      "Sammendrag\n",
      "FFI-RAPPORT 22/01384 3\n",
      "\n",
      "Summary\n",
      "FFI-RAPPORT 22/01384\n",
      "\n",
      "Innhold\n",
      "Sammendrag 3\n",
      "Summary 4 1\n",
      "Innledning 7 1.1\n",
      "Bidrag og målgruppe 8 1.2\n",
      "Disposisjon 9 1.3\n",
      "Definisjoner 9 1.4\n",
      "Avgrensninger 10 1.5\n",
      "Relevante studier ved Forsvarets forskningsinstitutt 11 2\n",
      "Metode 13 2.1\n",
      "Forskningsfilosofi 13 2.2\n",
      "Fremgangsmåte 14 2.3\n",
      "Forskningsdesign 15 2.4\n",
      "Gjennomføring av studien 18 3\n",
      "Hva er en sourcingstrategi? 22 3.1\n",
      "Den utvidede verdikjeden 22 3.2\n",
      "Sourcing i litteraturen og i norsk offentlig sektor 26 3.3\n",
      "Outsourcing 28 4\n",
      "Tre teoretiske perspektiver på valg av sourcingstrategi 31 4.1\n",
      "Transaksjonskostnadsøkonomi 32 4.2\n",
      "Det ressursbaserte perspektivet 36 4.3\n",
      "Det relasjonelle perspektivet 38 4.4\n",
      "Kapitteloppsummering 41 5\n",
      "Leverandørforhold 43 5.1\n",
      "Hva er et leverandørforhold? 43 5.2\n",
      "Kategorisering av leverandørforhold 46 5.3\n",
      "Transaksjonsbaserte leverandørforhold 49 5.4\n",
      "Samarbeidsbaserte leverandørforhold 52\n",
      "FFI-RAPPORT 22/01384 5\n",
      "6\n",
      "Valg av sourcingstrategi 58 6.1\n",
      "En strukturert tilnærming til valg av sourcingstrategi i forsvarssektoren 58 6.2\n",
      "De fire segmentene 67 6.3\n",
      "Svakheter og begrensninger ved denne tilnærmingen 78 7\n",
      "Konklusjon 82 7.1\n",
      "Oppsummering 82 7.2\n",
      "Operasjonalisering av rapportens innhold 83 7.3\n",
      "Anbefaling om videre forskning 85\n",
      "Forkortelser 88\n",
      "Referanser 89 6\n",
      "FFI-RAPPORT 22/01384\n",
      "Forsvarets forskningsinstitutt (FFI)\n",
      "Postboks 25 2027 Kjeller\n",
      "Norwegian Defence Research Establishment (FFI)\n",
      "PO box 25\n",
      "NO-2027 Kjeller\n",
      "NORWAY\n",
      "Besøksadresse:\n",
      "Kjeller: Instituttveien 20, Kjeller\n",
      "Horten: Nedre vei 16, Karljohansvern, Horten\n",
      "Visitor address:\n",
      "Kjeller: Instituttveien 20, Kjeller\n",
      "Horten: Nedre vei 16, Karljohansvern, Horten\n",
      "Telefon: 91 50 30 03\n",
      "E-post: post@ffi.no ffi.no\n",
      "Telephone: +47 91 50 30 03\n",
      "E-mail: post@ffi.no ffi.no/en\n"
     ]
    }
   ],
   "source": [
    "# download the PDF and extract the relevant text\n",
    "\n",
    "# settings for text extraction\n",
    "PAGES = [0, 1, 2, 3, 4, 5, 6, 7, -1]  # pages to analyze: first 8 pages + last page\n",
    "THRESHOLD = 100                       # paragraphs shorter than this will always be kept\n",
    "LONG_PARAGRAPH_PAGES = [0, 1]         # on first two pages, some long paragraphs are accepted\n",
    "LONG_PARAGRAPH_MAX = 2                # how many long paragraphs to keep on the first two pages\n",
    "PDF_METADATA_SKIP = {'format', 'creator', 'producer'}  # PDF metadata fields not to include in extracted text\n",
    "\n",
    "def download_and_open_pdf(url):\n",
    "    response = requests.get(url)\n",
    "    pdf_stream = io.BytesIO(response.content)\n",
    "    return fitz.open(stream=pdf_stream, filetype=\"pdf\")\n",
    "\n",
    "def extract_text(pdf):\n",
    "    texts = []\n",
    "\n",
    "    for key in pdf.metadata.keys():\n",
    "        if key not in PDF_METADATA_SKIP and pdf.metadata.get(key):\n",
    "            texts.append(f\"{key}: {pdf.metadata.get(key)}\")\n",
    "\n",
    "    for page in PAGES:\n",
    "        if page > len(pdf) - 2:\n",
    "            continue\n",
    "\n",
    "        text = pdf[page].get_text(sort=True)\n",
    "        # Use regular expression to split text into paragraphs\n",
    "        # Delimiter: newline(s) followed by an upper case character\n",
    "        paragraphs = regex.split(r'\\n+(?=\\p{Lu})', text, flags=re.UNICODE)\n",
    "        long_paragraph_count = 0\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            paragraph = \" \".join(paragraph.strip().split())\n",
    "\n",
    "            if '.....' in paragraph or '. . . . .' in paragraph: # looks like a ToC entry, skip it\n",
    "                continue\n",
    "            elif len(paragraph) < THRESHOLD:  # short paragraph, keep it\n",
    "                texts.append(paragraph)\n",
    "            elif page in LONG_PARAGRAPH_PAGES and long_paragraph_count < LONG_PARAGRAPH_MAX:\n",
    "                # allow some long paragraphs on the first two pages\n",
    "                long_paragraph_count += 1\n",
    "                texts.append(paragraph)\n",
    "            else:  # must be a long paragraph, skip it\n",
    "                pass\n",
    "    return '\\n'.join(texts)\n",
    "pdf = download_and_open_pdf(url)\n",
    "\n",
    "doc_text = extract_text(pdf)\n",
    "print(f\"text length: {len(doc_text)} characters\")\n",
    "print()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length: 1250 tokens\n",
      "\n",
      "{   'dc.contributor.author': ['Pedersen, Olger Breivik'],\n",
      "    'dc.date.issued': '2023',\n",
      "    'dc.identifier.isbn': ['9788246434445'],\n",
      "    'dc.language.iso': 'swe',\n",
      "    'dc.publisher': ['Forsvarets forskningsinstitutt (FFI)'],\n",
      "    'dc.relation.eissn': '1545',\n",
      "    'dc.title': 'Bør vi samarbeide? å en litteraturstudie om valg av '\n",
      "                'sourcingstrategi'}\n",
      "\n",
      "CPU times: user 4.55 s, sys: 50.6 ms, total: 4.6 s\n",
      "Wall time: 4.63 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# submit the text to the LLM and display results\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def generate(doc_text):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'user', 'content': INSTRUCTION + \"\\n\\n\" + doc_text}\n",
    "    ]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
    "    print(f\"input length: {len(input_ids[0])} tokens\")\n",
    "\n",
    "    outputs = model.generate(input_ids,\n",
    "                             max_new_tokens=2048,\n",
    "                             pad_token_id=tokenizer.pad_token_id,\n",
    "                             eos_token_id=tokenizer.eos_token_id)\n",
    "    return tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True)\n",
    "\n",
    "response = generate(doc_text)\n",
    "#print(response)\n",
    "extracted_data = json.loads(response)\n",
    "print()\n",
    "pp.pprint(extracted_data)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Meteor output\n",
    "\n",
    "Command:\n",
    "\n",
    "    curl -s -d fileUrl=https://www.regjeringen.no/contentassets/7464f476cb4744e59554c2cb4b192df5/no/pdfs/dataspillstrategi.pdf http://127.0.0.1:5000/json|jq .\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"year\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PDFINFO\",\n",
    "      \"pageNumber\": 52\n",
    "    },\n",
    "    \"value\": 2023\n",
    "  },\n",
    "  \"language\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"LANGUAGE_MODEL\"\n",
    "    },\n",
    "    \"value\": \"no\"\n",
    "  },\n",
    "  \"title\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PDFINFO\",\n",
    "      \"pageNumber\": 1\n",
    "    },\n",
    "    \"value\": \"Tid for spill – regjeringens dataspillstrategi 2024–2026\"\n",
    "  },\n",
    "  \"publisher\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PAGE\",\n",
    "      \"pageNumber\": 52\n",
    "    },\n",
    "    \"value\": \"Kultur- og likestillingsdepartementet\"\n",
    "  },\n",
    "  \"publicationType\": null,\n",
    "  \"authors\": [],\n",
    "  \"isbn\": null,\n",
    "  \"issn\": null\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-inference)",
   "language": "python",
   "name": "llm-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
