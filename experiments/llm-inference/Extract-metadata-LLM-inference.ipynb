{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Extraction using local LLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/llm-inference/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "#import transformers\n",
    "import requests\n",
    "import fitz\n",
    "import io\n",
    "import re\n",
    "import regex\n",
    "import peft\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [02:38<00:00, 52.80s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write a poem about Machine Learning.\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "The machines are learning,\n",
      "Their minds are expanding,\n",
      "Their knowledge is growing,\n",
      "Their potential is landing.\n",
      "\n",
      "They learn from data,\n",
      "They learn from experience,\n",
      "They learn from patterns,\n",
      "They learn from persistence.\n",
      "\n",
      "They learn to recognize,\n",
      "They learn to predict,\n",
      "They learn to optimize,\n",
      "They learn to detect.\n",
      "\n",
      "They learn to classify,\n",
      "They learn to cluster,\n",
      "They learn to regress,\n",
      "They learn to forecast.\n",
      "\n",
      "They learn to recommend,\n",
      "They learn to segment,\n",
      "They learn to\n"
     ]
    }
   ],
   "source": [
    "# load and test the language model\n",
    "\n",
    "MODEL = \"NatLibFi/Nous-Hermes-2-Mistral-7B-DPO-meteor\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftConfig\n",
    "\n",
    "config = PeftConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "input_text = \"Write a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=128, pad_token_id=tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a PDF URL:  https://www.doria.fi/bitstream/handle/10024/180306/Automaattisen%20kuvailun%20palvelun%20integroiminen%20Kansalliskirjaston%20j%c3%a4rjestelm%c3%a4kokonaisuuteen.pdf?sequence=5&isAllowed=y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered: https://www.doria.fi/bitstream/handle/10024/180306/Automaattisen%20kuvailun%20palvelun%20integroiminen%20Kansalliskirjaston%20j%c3%a4rjestelm%c3%a4kokonaisuuteen.pdf?sequence=5&isAllowed=y\n"
     ]
    }
   ],
   "source": [
    "# ask for PDF URL\n",
    "\n",
    "url = input(\"Please enter a PDF URL: \")\n",
    "print(f\"You entered: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 1961 characters\n",
      "\n",
      "title: Automaattisen kuvailun palvelun integroiminen Kansalliskirjaston järjestelmäkokonaisuuteen \n",
      "author: Mona Lehtinen\n",
      "creationDate: D:20210211163354+02'00'\n",
      "modDate: D:20210211163359+02'00'\n",
      "Automaattisen kuvailun palvelun integroiminen\n",
      "Kansalliskirjaston järjestelmäkokonaisuuteen - tietovirrat ja prosessit\n",
      "Mona Lehtinen, Satu Niininen, Juho Inkinen, Mikko Lappalainen\n",
      "Image by DavidRockDesign from Pixabay\n",
      "Kansalliskirjaston raportteja ja selvityksiä 1/2021\n",
      "ISBN 978-951-51-6986-0\n",
      "ISSN 2242–8119\n",
      "Sisältö 1\n",
      "Johdanto 2\n",
      "Annif 2\n",
      "Kansalliskirjaston tietovirtoihin liittyvät järjestelmät 6\n",
      "Kansalliskirjaston tietovirrat ja kuvailuprosessit 8\n",
      "Annif-integraatioiden nykytila 9\n",
      "Johtopäätökset\n",
      "Johdanto\n",
      "Mona Lehtinen, Satu Niininen, Juho Inkinen, Mikko Lappalainen 1\n",
      "Annifin algoritmien toiminta perustuu koneoppi-\n",
      "Edellä mainitussa artikkelissa käydään myös läpi\n",
      "Kansalliskirjaston tietovirtoihin liittyvät järjestelmät\n",
      "Annifin käyttöönottoa suunniteltaessa on hyvä tuntea\n",
      "Automaattisen kuvailun palvelun integroiminen Kansalliskirjaston järjestelmäkokonaisuuteen 2\n",
      "Kansalliskirjaston järjestelmät lähteineen ja loppukäytäjineen.\n",
      "Mona Lehtinen, Satu Niininen, Juho Inkinen, Mikko Lappalainen 3\n",
      "Automaattisen kuvailun palvelun integroiminen Kansalliskirjaston järjestelmäkokonaisuuteen 4\n",
      "Mona Lehtinen, Satu Niininen, Juho Inkinen, Mikko Lappalainen 5\n",
      "Kansalliskirjaston tietovirrat ja kuvailuprosessit\n",
      "Sähköiset vapaakappaleet ja niiden käsittelyprosessi\n",
      "Verkkojulkaisujen osalta Kansalliskirjasto pyr-\n",
      "Digitaaliset aineistot kuvaillaan soveltuvin osin\n",
      "Variaan ja julkaisujen kuvailutietoihin lisätään aina\n",
      "Ennakkotietoprosessi kansallisbibliografia Fennicaan ja kansallisdiskografia\n",
      "Suurten julkaisijoiden sähköiset vapaakappaleet\n",
      "MARC 21 -muodossa, mutta jatkossa Kirjavälitys toimittaa ne ONIX-sanomana, joka konvertoidaan\n",
      "ONIX-muotoinen tuotetieto. ONIX konvertoidaan\n",
      "Automaattisen kuvailun palvelun integroiminen Kansalliskirjaston järjestelmäkokonaisuuteen 6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# download the PDF and extract the relevant text\n",
    "\n",
    "# settings for text extraction\n",
    "PAGES = [0, 1, 2, 3, 4, 5, 6, 7, -1]  # pages to analyze: first 8 pages + last page\n",
    "THRESHOLD = 100                       # paragraphs shorter than this will always be kept\n",
    "LONG_PARAGRAPH_PAGES = [0, 1]         # on first two pages, some long paragraphs are accepted\n",
    "LONG_PARAGRAPH_MAX = 2                # how many long paragraphs to keep on the first two pages\n",
    "PDF_METADATA_SKIP = {'format', 'creator', 'producer'}  # PDF metadata fields not to include in extracted text\n",
    "\n",
    "def download_and_open_pdf(url):\n",
    "    response = requests.get(url)\n",
    "    pdf_stream = io.BytesIO(response.content)\n",
    "    return fitz.open(stream=pdf_stream, filetype=\"pdf\")\n",
    "\n",
    "def extract_text(pdf):\n",
    "    texts = []\n",
    "\n",
    "    for key in pdf.metadata.keys():\n",
    "        if key not in PDF_METADATA_SKIP and pdf.metadata.get(key):\n",
    "            texts.append(f\"{key}: {pdf.metadata.get(key)}\")\n",
    "\n",
    "    for page in PAGES:\n",
    "        if page > len(pdf) - 2:\n",
    "            continue\n",
    "\n",
    "        text = pdf[page].get_text(sort=True)\n",
    "        # Use regular expression to split text into paragraphs\n",
    "        # Delimiter: newline(s) followed by an upper case character\n",
    "        paragraphs = regex.split(r'\\n+(?=\\p{Lu})', text, flags=re.UNICODE)\n",
    "        long_paragraph_count = 0\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            paragraph = \" \".join(paragraph.strip().split())\n",
    "\n",
    "            if '.....' in paragraph or '. . . . .' in paragraph: # looks like a ToC entry, skip it\n",
    "                continue\n",
    "            elif len(paragraph) < THRESHOLD:  # short paragraph, keep it\n",
    "                texts.append(paragraph)\n",
    "            elif page in LONG_PARAGRAPH_PAGES and long_paragraph_count < LONG_PARAGRAPH_MAX:\n",
    "                # allow some long paragraphs on the first two pages\n",
    "                long_paragraph_count += 1\n",
    "                texts.append(paragraph)\n",
    "            else:  # must be a long paragraph, skip it\n",
    "                pass\n",
    "    return '\\n'.join(texts)\n",
    "pdf = download_and_open_pdf(url)\n",
    "\n",
    "doc_text = extract_text(pdf)\n",
    "print(f\"text length: {len(doc_text)} characters\")\n",
    "print()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length: 944 tokens\n",
      "\n",
      "{   'dc.contributor.author': [   'Lehtinen, Mona',\n",
      "                                 'Niininen, Satu',\n",
      "                                 'Inkinen, Juho',\n",
      "                                 'Lappalainen, Mikko'],\n",
      "    'dc.date.issued': '2021',\n",
      "    'dc.identifier.isbn': ['9789515169860'],\n",
      "    'dc.language.iso': 'fin',\n",
      "    'dc.publisher': ['Kansalliskirjaston tiedotus- ja analyysioikeus'],\n",
      "    'dc.relation.eissn': '2242-8119',\n",
      "    'dc.title': 'Automaattisen kuvailun palvelun integroiminen '\n",
      "                'Kansalliskirjaston järjestelmäkokonaisuuteen'}\n",
      "\n",
      "CPU times: user 8.7 s, sys: 228 ms, total: 8.93 s\n",
      "Wall time: 9.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# submit the text to the LLM and display results\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def generate(doc_text):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'user', 'content': INSTRUCTION + \"\\n\\n\" + doc_text}\n",
    "    ]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
    "    print(f\"input length: {len(input_ids[0])} tokens\")\n",
    "\n",
    "    outputs = model.generate(input_ids,\n",
    "                             max_new_tokens=1024,\n",
    "                             pad_token_id=tokenizer.pad_token_id)\n",
    "    return tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True)\n",
    "\n",
    "response = generate(doc_text)\n",
    "extracted_data = json.loads(response)\n",
    "print()\n",
    "pp.pprint(extracted_data)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Meteor output\n",
    "\n",
    "Command:\n",
    "\n",
    "    curl -s -d fileUrl=https://www.regjeringen.no/contentassets/7464f476cb4744e59554c2cb4b192df5/no/pdfs/dataspillstrategi.pdf http://127.0.0.1:5000/json|jq .\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"year\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PDFINFO\",\n",
    "      \"pageNumber\": 52\n",
    "    },\n",
    "    \"value\": 2023\n",
    "  },\n",
    "  \"language\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"LANGUAGE_MODEL\"\n",
    "    },\n",
    "    \"value\": \"no\"\n",
    "  },\n",
    "  \"title\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PDFINFO\",\n",
    "      \"pageNumber\": 1\n",
    "    },\n",
    "    \"value\": \"Tid for spill – regjeringens dataspillstrategi 2024–2026\"\n",
    "  },\n",
    "  \"publisher\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PAGE\",\n",
    "      \"pageNumber\": 52\n",
    "    },\n",
    "    \"value\": \"Kultur- og likestillingsdepartementet\"\n",
    "  },\n",
    "  \"publicationType\": null,\n",
    "  \"authors\": [],\n",
    "  \"isbn\": null,\n",
    "  \"issn\": null\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-inference)",
   "language": "python",
   "name": "llm-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
