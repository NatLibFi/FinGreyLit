{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata Extraction using local LLM inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/experiments/llm-inference/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# import necessary libraries\n",
    "\n",
    "#import transformers\n",
    "import requests\n",
    "import fitz\n",
    "import io\n",
    "import re\n",
    "import regex\n",
    "import peft\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:08<00:00,  2.79s/it]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Write a poem about Machine Learning.\n",
      "\n",
      "Machine Learning\n",
      "\n",
      "The machines are learning,\n",
      "Their minds are expanding,\n",
      "Their knowledge is growing,\n",
      "Their potential is landing.\n",
      "\n",
      "They learn from data,\n",
      "They learn from experience,\n",
      "They learn from patterns,\n",
      "They learn from persistence.\n",
      "\n",
      "They learn to recognize,\n",
      "They learn to predict,\n",
      "They learn to optimize,\n",
      "They learn to detect.\n",
      "\n",
      "They learn to classify,\n",
      "They learn to cluster,\n",
      "They learn to regress,\n",
      "They learn to forecast.\n",
      "\n",
      "They learn to recommend,\n",
      "They learn to segment,\n",
      "They learn to\n"
     ]
    }
   ],
   "source": [
    "# load and test the language model\n",
    "\n",
    "MODEL = \"NatLibFi/Nous-Hermes-2-Mistral-7B-DPO-meteor\"\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftConfig\n",
    "\n",
    "config = PeftConfig.from_pretrained(MODEL)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL, device_map=\"auto\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
    "\n",
    "input_text = \"Write a poem about Machine Learning.\"\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**input_ids, max_new_tokens=128, pad_token_id=tokenizer.pad_token_id)\n",
    "print(tokenizer.decode(outputs[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a PDF URL:  https://www.regjeringen.no/contentassets/7464f476cb4744e59554c2cb4b192df5/no/pdfs/dataspillstrategi.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You entered: https://www.regjeringen.no/contentassets/7464f476cb4744e59554c2cb4b192df5/no/pdfs/dataspillstrategi.pdf\n"
     ]
    }
   ],
   "source": [
    "# ask for PDF URL\n",
    "\n",
    "url = input(\"Please enter a PDF URL: \")\n",
    "print(f\"You entered: {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text length: 1485 characters\n",
      "\n",
      "title: Tid for spill – regjeringens dataspillstrategi 2024–2026\n",
      "author: Kultur- og likestillingsdepartementet\n",
      "subject: Tid for spill – regjeringens dataspillstrategi 2024–2026\n",
      "creationDate: D:20231212102035+01'00'\n",
      "modDate: D:20231212150502+01'00'\n",
      "Kultur- og likestillingsdepartementet\n",
      "Strategi\n",
      "Tid for spill – regjeringens dataspillstrategi 2024–2026\n",
      "Illustrasjonsfoto: AdobeStock 2\n",
      "Vurdering av dagens virkemidler i\n",
      "Forsideillustrasjon: Sunlight, Krillbite Studio AS 3\n",
      "Illustrasjonsfoto: AdobeStock 4\n",
      "Forord\n",
      "Lubna Jaffery\n",
      "KULTUR- OG LIKESTILLINGSMINISTER\n",
      "Foto: Ilja C. Hendel/KUD\n",
      "Takk til Norsk filminstitutt (NFI), Medietilsynet, Kulturtanken, Innovasjon\n",
      "Illustrasjonsfoto: AdobeStock 6\n",
      "Statsminister Jonas Gahr Støre\n",
      "Dataspill er næring\n",
      "Dataspill er kultur\n",
      "Dataspill er internasjonalisering\n",
      "Dataspill er innovasjon\n",
      "Chart: Are You Not Entertained? | Statista 7\n",
      "Om dataspillstrategien\n",
      "Dataspill er kunnskap\n",
      "Arbeidet med regjeringens dataspillstrategi er ledet av Kultur- og likestillingsdepartementet.\n",
      "Kulturtanken og Innovasjon Norge.\n",
      "Dataspill er fellesskap\n",
      "Foto: Pexels\n",
      "Utgitt av:\n",
      "Kultur- og likestillingsdepartementet\n",
      "Bestilling av publikasjoner:\n",
      "Departementenes sikkerhets- og serviceorganisasjon publikasjoner.dep.no\n",
      "Telefon: 22 24 00 00\n",
      "Publikasjoner er også tilgjengelige på: www.regjeringen.no\n",
      "Publikasjonskode: V-1043 B\n",
      "M\n",
      "E\n",
      "E\n",
      "N\n",
      "R\n",
      "A\n",
      "K\n",
      "V\n",
      "E\n",
      "S\n",
      "T\n",
      "Design: Melkeveien Designkontor AS\n",
      "Trykk: Departementenes sikkerhets- og serviceorganisasjon\n",
      "Trykksak 12/2023 – opplag 150 2041 0446\n"
     ]
    }
   ],
   "source": [
    "# download the PDF and extract the relevant text\n",
    "\n",
    "# settings for text extraction\n",
    "PAGES = [0, 1, 2, 3, 4, 5, 6, 7, -1]  # pages to analyze: first 8 pages + last page\n",
    "THRESHOLD = 100                       # paragraphs shorter than this will always be kept\n",
    "LONG_PARAGRAPH_PAGES = [0, 1]         # on first two pages, some long paragraphs are accepted\n",
    "LONG_PARAGRAPH_MAX = 2                # how many long paragraphs to keep on the first two pages\n",
    "PDF_METADATA_SKIP = {'format', 'creator', 'producer'}  # PDF metadata fields not to include in extracted text\n",
    "\n",
    "def download_and_open_pdf(url):\n",
    "    response = requests.get(url)\n",
    "    pdf_stream = io.BytesIO(response.content)\n",
    "    return fitz.open(stream=pdf_stream, filetype=\"pdf\")\n",
    "\n",
    "def extract_text(pdf):\n",
    "    texts = []\n",
    "\n",
    "    for key in pdf.metadata.keys():\n",
    "        if key not in PDF_METADATA_SKIP and pdf.metadata.get(key):\n",
    "            texts.append(f\"{key}: {pdf.metadata.get(key)}\")\n",
    "\n",
    "    for page in PAGES:\n",
    "        if page > len(pdf) - 2:\n",
    "            continue\n",
    "\n",
    "        text = pdf[page].get_text(sort=True)\n",
    "        # Use regular expression to split text into paragraphs\n",
    "        # Delimiter: newline(s) followed by an upper case character\n",
    "        paragraphs = regex.split(r'\\n+(?=\\p{Lu})', text, flags=re.UNICODE)\n",
    "        long_paragraph_count = 0\n",
    "\n",
    "        for paragraph in paragraphs:\n",
    "            paragraph = \" \".join(paragraph.strip().split())\n",
    "\n",
    "            if '.....' in paragraph or '. . . . .' in paragraph: # looks like a ToC entry, skip it\n",
    "                continue\n",
    "            elif len(paragraph) < THRESHOLD:  # short paragraph, keep it\n",
    "                texts.append(paragraph)\n",
    "            elif page in LONG_PARAGRAPH_PAGES and long_paragraph_count < LONG_PARAGRAPH_MAX:\n",
    "                # allow some long paragraphs on the first two pages\n",
    "                long_paragraph_count += 1\n",
    "                texts.append(paragraph)\n",
    "            else:  # must be a long paragraph, skip it\n",
    "                pass\n",
    "    return '\\n'.join(texts)\n",
    "pdf = download_and_open_pdf(url)\n",
    "\n",
    "doc_text = extract_text(pdf)\n",
    "print(f\"text length: {len(doc_text)} characters\")\n",
    "print()\n",
    "print(doc_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input length: 696 tokens\n",
      "\n",
      "{   'dc.date.issued': '2023',\n",
      "    'dc.language.iso': 'nor',\n",
      "    'dc.publisher': ['Kultur- og likestillingsdepartementet'],\n",
      "    'dc.title': 'Tid for spill : regjeringens dataspillstrategi 2024-2026'}\n",
      "\n",
      "CPU times: user 4.19 s, sys: 139 ms, total: 4.33 s\n",
      "Wall time: 4.54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# submit the text to the LLM and display results\n",
    "\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def generate(doc_text):\n",
    "    messages = [\n",
    "        {'role': 'system', 'content': SYSTEM_PROMPT},\n",
    "        {'role': 'user', 'content': INSTRUCTION + \"\\n\\n\" + doc_text}\n",
    "    ]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(messages, return_tensors=\"pt\", add_generation_prompt=True).to(\"cuda\")\n",
    "    print(f\"input length: {len(input_ids[0])} tokens\")\n",
    "\n",
    "    outputs = model.generate(input_ids,\n",
    "                             max_new_tokens=1024,\n",
    "                             pad_token_id=tokenizer.pad_token_id)\n",
    "    return tokenizer.decode(outputs[0][len(input_ids[0]):], skip_special_tokens=True)\n",
    "\n",
    "response = generate(doc_text)\n",
    "extracted_data = json.loads(response)\n",
    "print()\n",
    "pp.pprint(extracted_data)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison with Meteor output\n",
    "\n",
    "Command:\n",
    "\n",
    "    curl -s -d fileUrl=https://www.regjeringen.no/contentassets/7464f476cb4744e59554c2cb4b192df5/no/pdfs/dataspillstrategi.pdf http://127.0.0.1:5000/json|jq .\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "```json\n",
    "{\n",
    "  \"year\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PDFINFO\",\n",
    "      \"pageNumber\": 52\n",
    "    },\n",
    "    \"value\": 2023\n",
    "  },\n",
    "  \"language\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"LANGUAGE_MODEL\"\n",
    "    },\n",
    "    \"value\": \"no\"\n",
    "  },\n",
    "  \"title\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PDFINFO\",\n",
    "      \"pageNumber\": 1\n",
    "    },\n",
    "    \"value\": \"Tid for spill – regjeringens dataspillstrategi 2024–2026\"\n",
    "  },\n",
    "  \"publisher\": {\n",
    "    \"origin\": {\n",
    "      \"type\": \"PAGE\",\n",
    "      \"pageNumber\": 52\n",
    "    },\n",
    "    \"value\": \"Kultur- og likestillingsdepartementet\"\n",
    "  },\n",
    "  \"publicationType\": null,\n",
    "  \"authors\": [],\n",
    "  \"isbn\": null,\n",
    "  \"issn\": null\n",
    "}\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (llm-inference)",
   "language": "python",
   "name": "llm-inference"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
