{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7f02b8f-e591-495f-b5fd-e248e089c866",
   "metadata": {},
   "source": [
    "# Metadata extraction using Meteor\n",
    "\n",
    "This notebook attempts to extract metadata from the FinGreyLit test set documents using [Meteor](https://github.com/NationalLibraryOfNorway/meteor), an open source metadata extraction tool developed by the National Library of Norway.\n",
    "\n",
    "It assumes that Meteor is installed and running locally on http://127.0.0.1:5000/ (the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "451f94cd-081c-4677-966a-1bdd2a8a83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import json\n",
    "\n",
    "metadata_files = glob.glob(\"../../metadata/*.jsonl\")  # train + test (used for refining code & fixing dataset)\n",
    "#metadata_files = glob.glob(\"../../metadata/*-test.jsonl\")  # test set only (used for final evaluation)\n",
    "records = []\n",
    "\n",
    "for mdfile in metadata_files:\n",
    "    with open(mdfile) as inf:\n",
    "        for line in inf:\n",
    "            rec = json.loads(line)\n",
    "            records.append(rec)\n",
    "\n",
    "print(len(records))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c4bad0a-1bb1-4d6f-84ae-b08e369365ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON decode error for https://www.doria.fi/handle/10024/181710 / https://www.doria.fi/bitstream/handle/10024/181710/Laura Hollsten ÅBO AKADEMI OCH KUNSKAPEN doria 23.8.2021.pdf\n",
      "JSON decode error for https://www.doria.fi/handle/10024/181709 / https://www.doria.fi/bitstream/handle/10024/181709/Nils Villstrand ÅBO AKADEMI I SIN BÖRJAN doria 2021.pdf\n",
      "CPU times: user 2.28 s, sys: 2.88 s, total: 5.16 s\n",
      "Wall time: 3min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import os\n",
    "import requests\n",
    "\n",
    "METEOR_API_URL = 'http://127.0.0.1:5000/json'\n",
    "\n",
    "def id_to_fn(identifier):\n",
    "    \"\"\"convert a URI identifier to a simpler string we can use as a filename for the PDF\"\"\"\n",
    "    return '../../pdfs/' + identifier.replace('https://', '').replace('/','_') + \".pdf\"\n",
    "\n",
    "def download(file_url, identifier):\n",
    "    \"\"\"download a PDF file, with the given identifier, from the given URL (unless this was done already)\n",
    "    and return a path to the PDF file\"\"\"\n",
    "    path = id_to_fn(identifier)\n",
    "    if os.path.exists(path) and os.path.getsize(path) > 0:\n",
    "        return path\n",
    "\n",
    "    response = requests.get(file_url)\n",
    "    with open(path, \"wb\") as f:\n",
    "        f.write(response.content)\n",
    "        print(f\"wrote {file_url} as {path}\")\n",
    "    return path\n",
    "\n",
    "out_records = []\n",
    "\n",
    "for rec in records:\n",
    "    path = download(rec['url'], rec['id'])\n",
    "\n",
    "    # Create a dictionary containing the file to be sent\n",
    "    filedata = {'fileInput': (path, open(path, 'rb'), 'application/pdf')}\n",
    "\n",
    "    # Send the POST request with the file\n",
    "    response = requests.post(METEOR_API_URL, files=filedata)\n",
    "    try:\n",
    "        rec['meteor_output'] = response.json()\n",
    "    except requests.JSONDecodeError:\n",
    "        print(f\"JSON decode error for {rec['id']} / {rec['url']}\")\n",
    "        rec['meteor_output'] = {}\n",
    "    out_records.append(rec)\n",
    "\n",
    "# write output to JSONL file\n",
    "with open('test-records-meteor.jsonl', 'w') as outfile:\n",
    "    for rec in out_records:\n",
    "        json.dump(rec, outfile)\n",
    "        outfile.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7dc2a7bb-c1f1-4990-9488-f4c6e4dffbc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>field</th>\n",
       "      <th>match_type</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng</td>\n",
       "      <td>year</td>\n",
       "      <td>exact</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eng</td>\n",
       "      <td>language</td>\n",
       "      <td>exact</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eng</td>\n",
       "      <td>title</td>\n",
       "      <td>superset</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eng</td>\n",
       "      <td>publisher</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eng</td>\n",
       "      <td>authors</td>\n",
       "      <td>exact</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5175</th>\n",
       "      <td>eng</td>\n",
       "      <td>title</td>\n",
       "      <td>wrong</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5176</th>\n",
       "      <td>eng</td>\n",
       "      <td>publisher</td>\n",
       "      <td>not-found</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5177</th>\n",
       "      <td>eng</td>\n",
       "      <td>authors</td>\n",
       "      <td>not-found</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5178</th>\n",
       "      <td>eng</td>\n",
       "      <td>isbn</td>\n",
       "      <td>not-found</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5179</th>\n",
       "      <td>eng</td>\n",
       "      <td>issn</td>\n",
       "      <td>not-relevant</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5180 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     language      field    match_type  score\n",
       "0         eng       year         exact      1\n",
       "1         eng   language         exact      1\n",
       "2         eng      title      superset      1\n",
       "3         eng  publisher  not-relevant      1\n",
       "4         eng    authors         exact      1\n",
       "...       ...        ...           ...    ...\n",
       "5175      eng      title         wrong      0\n",
       "5176      eng  publisher     not-found      0\n",
       "5177      eng    authors     not-found      0\n",
       "5178      eng       isbn     not-found      0\n",
       "5179      eng       issn  not-relevant      1\n",
       "\n",
       "[5180 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Analyze the extracted metadata\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "import Levenshtein\n",
    "\n",
    "records_meteor = []\n",
    "\n",
    "ALMOST_THRESHOLD = 0.95  # similarity threshold to be considered \"almost correct\"\n",
    "\n",
    "LANGMAP = {\n",
    "    'fin': 'fi',\n",
    "    'swe': 'sv',\n",
    "    'eng': 'en'\n",
    "}\n",
    "\n",
    "FIELDS = {\n",
    "    'year': 'dc.date.issued',\n",
    "    'language': 'dc.language.iso',\n",
    "    'title': 'dc.title',\n",
    "    'publisher': 'dc.publisher',\n",
    "    'authors': 'dc.contributor.author',\n",
    "    'isbn': 'dc.identifier.isbn',\n",
    "    'issn': 'dc.relation.eissn'\n",
    "}\n",
    "\n",
    "with open('test-records-meteor.jsonl') as infile:\n",
    "    for line in infile:\n",
    "        rec = json.loads(line)\n",
    "        records_meteor.append(rec)\n",
    "\n",
    "def compare_authors(rec):\n",
    "    true_authors = set(rec.get('dc.contributor.author', []))\n",
    "    try:\n",
    "        predicted_authors = set([f\"{author['lastname']}, {author['firstname']}\"\n",
    "                                for author in rec['meteor_output']['authors']])\n",
    "    except (KeyError, TypeError):\n",
    "        predicted_authors = set()\n",
    "\n",
    "    if not true_authors and not predicted_authors:\n",
    "        return ('not-relevant', 1)\n",
    "    elif not true_authors:\n",
    "        return ('found-nonexistent', 0)\n",
    "    elif not predicted_authors:\n",
    "        return ('not-found', 0)\n",
    "    elif true_authors == predicted_authors:\n",
    "        return ('exact', 1)\n",
    "    elif true_authors.issubset(predicted_authors):\n",
    "        return ('superset', 1)\n",
    "    elif true_authors.issuperset(predicted_authors):\n",
    "        return ('subset', 0)\n",
    "    elif true_authors.intersection(predicted_authors):\n",
    "        return ('overlap', 0)\n",
    "    else:\n",
    "        return ('wrong', 0)\n",
    "\n",
    "def compare(rec, dc_key, meteor_key):\n",
    "    \n",
    "    true_val = rec.get(dc_key)\n",
    "\n",
    "    # special case for \"authors\" field which may contain multiple values\n",
    "    if dc_key == 'dc.contributor.author':\n",
    "        return compare_authors(rec)\n",
    "    \n",
    "    # field-specific adjustments\n",
    "    if dc_key == 'dc.language.iso':\n",
    "        true_val = LANGMAP[true_val]  # convert to ISO 639-1 2-letter language code\n",
    "    elif dc_key == 'dc.date.issued' and true_val is not None:\n",
    "        true_val = true_val[:4]  # compare only the year\n",
    "    elif dc_key == 'dc.identifier.isbn' and true_val:\n",
    "        true_val = true_val[0]  # compare only against first (usually only) ISBN\n",
    "    elif dc_key == 'dc.publisher' and true_val:\n",
    "        true_val = true_val[0]  # compare only against first (usually only) publisher\n",
    "\n",
    "    try:\n",
    "        predicted_val = str(rec['meteor_output'][meteor_key]['value'])\n",
    "    except (KeyError, TypeError):\n",
    "        predicted_val = None\n",
    "\n",
    "    if predicted_val is None and true_val is None:\n",
    "        return ('not-relevant', 1)\n",
    "    elif predicted_val == true_val:\n",
    "        return ('exact', 1)\n",
    "    elif predicted_val is None:\n",
    "        return ('not-found', 0)\n",
    "    elif true_val is None:\n",
    "        return ('found-nonexistent', 0)\n",
    "    elif true_val in predicted_val:\n",
    "        return ('superset', 1)\n",
    "    elif true_val.lower() == predicted_val.lower():\n",
    "        return ('case', 1)\n",
    "    elif true_val.lower() in predicted_val.lower():\n",
    "        return ('superset-case', 1)\n",
    "    elif Levenshtein.ratio(true_val, predicted_val) >= ALMOST_THRESHOLD:\n",
    "        return ('almost', 1)\n",
    "    elif Levenshtein.ratio(true_val.lower(), predicted_val.lower()) >= ALMOST_THRESHOLD:\n",
    "        return ('almost-case', 1)\n",
    "    else:\n",
    "        #if meteor_key not in ('title', 'language', 'year'):\n",
    "        #if meteor_key == 'issn':\n",
    "        #    print(rec['id'], meteor_key, repr(true_val), repr(predicted_val))\n",
    "        return ('wrong', 0)\n",
    "\n",
    "results = []\n",
    "\n",
    "for rec in records_meteor:\n",
    "    for meteor_field, dc_field in FIELDS.items():\n",
    "        match_type, score = compare(rec, dc_field, meteor_field)\n",
    "        results.append({\n",
    "            'language': rec['dc.language.iso'],\n",
    "            'field': meteor_field,\n",
    "            'match_type': match_type,\n",
    "            'score': score\n",
    "        })\n",
    "\n",
    "df = pd.DataFrame(results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e6021e40-6f95-42e7-81e0-0844b4b93811",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "language  field    \n",
       "eng       authors      0.597826\n",
       "          isbn         0.782609\n",
       "          issn         0.644928\n",
       "          language     0.956522\n",
       "          publisher    0.039855\n",
       "          title        0.608696\n",
       "          year         0.797101\n",
       "fin       authors      0.561056\n",
       "          isbn         0.686469\n",
       "          issn         0.712871\n",
       "          language     0.937294\n",
       "          publisher    0.112211\n",
       "          title        0.498350\n",
       "          year         0.788779\n",
       "swe       authors      0.664596\n",
       "          isbn         0.869565\n",
       "          issn         0.807453\n",
       "          language     0.888199\n",
       "          publisher    0.105590\n",
       "          title        0.322981\n",
       "          year         0.689441\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['language','field'])['score'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9c1b7de5-7cc5-4d51-beda-72bdfb39e6cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "language  field      score  match_type       \n",
      "eng       authors    0      not-found             65\n",
      "                            wrong                 36\n",
      "                            overlap                5\n",
      "                            found-nonexistent      4\n",
      "                            subset                 1\n",
      "                     1      exact                108\n",
      "                            superset              45\n",
      "                            not-relevant          12\n",
      "          isbn       0      wrong                 28\n",
      "                            not-found             20\n",
      "                            found-nonexistent     12\n",
      "                     1      not-relevant         119\n",
      "                            exact                 97\n",
      "          issn       0      wrong                 40\n",
      "                            not-found             35\n",
      "                            found-nonexistent     23\n",
      "                     1      not-relevant         148\n",
      "                            exact                 30\n",
      "          language   0      wrong                  9\n",
      "                            not-found              3\n",
      "                     1      exact                264\n",
      "          publisher  0      not-found            232\n",
      "                            wrong                 33\n",
      "                     1      superset               6\n",
      "                            not-relevant           4\n",
      "                            exact                  1\n",
      "          title      0      wrong                 99\n",
      "                            not-found              9\n",
      "                     1      exact                 71\n",
      "                            case                  45\n",
      "                            almost                20\n",
      "                            superset              16\n",
      "                            superset-case         10\n",
      "                            almost-case            6\n",
      "          year       0      not-found             39\n",
      "                            wrong                 17\n",
      "                     1      exact                220\n",
      "fin       authors    0      not-found             97\n",
      "                            wrong                 16\n",
      "                            found-nonexistent     15\n",
      "                            subset                 5\n",
      "                     1      exact                115\n",
      "                            not-relevant          36\n",
      "                            superset              19\n",
      "          isbn       0      wrong                 59\n",
      "                            not-found             24\n",
      "                            found-nonexistent     12\n",
      "                     1      not-relevant         157\n",
      "                            exact                 51\n",
      "          issn       0      wrong                 51\n",
      "                            not-found             19\n",
      "                            found-nonexistent     17\n",
      "                     1      not-relevant         203\n",
      "                            exact                 13\n",
      "          language   0      wrong                 19\n",
      "                     1      exact                284\n",
      "          publisher  0      not-found            246\n",
      "                            wrong                 22\n",
      "                            found-nonexistent      1\n",
      "                     1      superset              16\n",
      "                            not-relevant          11\n",
      "                            exact                  6\n",
      "                            superset-case          1\n",
      "          title      0      wrong                149\n",
      "                            not-found              3\n",
      "                     1      exact                 65\n",
      "                            almost                38\n",
      "                            superset              25\n",
      "                            case                  16\n",
      "                            almost-case            5\n",
      "                            superset-case          2\n",
      "          year       0      not-found             49\n",
      "                            wrong                 15\n",
      "                     1      exact                239\n",
      "swe       authors    0      not-found             35\n",
      "                            found-nonexistent     10\n",
      "                            wrong                  7\n",
      "                            subset                 2\n",
      "                     1      exact                 47\n",
      "                            superset              34\n",
      "                            not-relevant          26\n",
      "          isbn       0      not-found             12\n",
      "                            wrong                  7\n",
      "                            found-nonexistent      2\n",
      "                     1      not-relevant         110\n",
      "                            exact                 30\n",
      "          issn       0      not-found             16\n",
      "                            found-nonexistent     14\n",
      "                            wrong                  1\n",
      "                     1      not-relevant         125\n",
      "                            exact                  5\n",
      "          language   0      wrong                 16\n",
      "                            not-found              2\n",
      "                     1      exact                143\n",
      "          publisher  0      not-found            135\n",
      "                            wrong                  9\n",
      "                     1      not-relevant          16\n",
      "                            superset               1\n",
      "          title      0      wrong                104\n",
      "                            not-found              5\n",
      "                     1      exact                 30\n",
      "                            almost                12\n",
      "                            case                   6\n",
      "                            superset               2\n",
      "                            almost-case            2\n",
      "          year       0      not-found             45\n",
      "                            wrong                  5\n",
      "                     1      exact                111\n"
     ]
    }
   ],
   "source": [
    "value_counts_df = df.groupby(['language', 'field','score'])['match_type'].value_counts()\n",
    "print(value_counts_df.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
