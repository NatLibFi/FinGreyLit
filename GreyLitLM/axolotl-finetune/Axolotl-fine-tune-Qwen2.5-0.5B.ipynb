{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune Qwen2.5-0.5B-Instruct model using Axolotl framework\n",
    "\n",
    "How to install dependencies (in HPC environment):\n",
    "\n",
    "- load Python and cuDNN modules\n",
    "- create a Python venv and activate it\n",
    "- install dependencies from requirements.txt (e.g. torch)\n",
    "- install Axolotl from git clone (pip won't work, see [this issue](https://github.com/OpenAccess-AI-Collective/axolotl/issues/945)):\n",
    "\n",
    "```\n",
    "git clone git@github.com:OpenAccess-AI-Collective/axolotl.git\n",
    "cd axolotl\n",
    "pip install -e '.[flash-attn,deepspeed]'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n",
      "BF16 is supported? True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print('GPU available?', torch.cuda.is_available())\n",
    "print('BF16 is supported?', torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/appl/easybuild/opt/CUDA/12.6.0\n"
     ]
    }
   ],
   "source": [
    "!printenv CUDA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name etc.\n",
    "\n",
    "MODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "MODEL_SHORT_NAME = MODEL_NAME.split('/')[-1]\n",
    "SUFFIX = \"FinGreyLit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 640 train records\n",
      "Wrote 182 test records\n",
      "Wrote 32 eval records\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare fine-tuning dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of test set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "EVAL_SIZE = 32  # how many documents to evaluate (i.e. calculate loss) on during fine-tuning\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    output = json.dumps(sample[\"ground_truth\"])\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    # ShareGPT format\n",
    "    conversations = [\n",
    "        {'from': 'system', 'value': SYSTEM_PROMPT},\n",
    "        {'from': 'user', 'value': INSTRUCTION + \"\\n\\n\" + input_},\n",
    "        {'from': 'assistant', 'value': output}\n",
    "    ]\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "def write_jsonl(records, filename):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for record in records:\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "train_recs = dataset_to_records(train_files)\n",
    "random.shuffle(train_recs)\n",
    "write_jsonl(train_recs, \"axolotl-train.jsonl\")\n",
    "print(f\"Wrote {len(train_recs)} train records\")\n",
    "\n",
    "test_recs = dataset_to_records(test_files)\n",
    "write_jsonl(test_recs, \"axolotl-test.jsonl\")\n",
    "print(f\"Wrote {len(test_recs)} test records\")\n",
    "\n",
    "eval_recs = random.sample(test_recs, EVAL_SIZE)\n",
    "write_jsonl(eval_recs, \"axolotl-eval.jsonl\")\n",
    "print(f\"Wrote {len(eval_recs)} eval records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Axolotl configuration file\n",
    "\n",
    "CONFIG_FILE = f\"config-{MODEL_SHORT_NAME}.yml\"\n",
    "\n",
    "\n",
    "CONFIG = f\"\"\"\n",
    "base_model: {MODEL_NAME}\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: false\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: axolotl-train.jsonl\n",
    "    type: chat_template\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "\n",
    "test_datasets:\n",
    "  - path: axolotl-eval.jsonl\n",
    "    type: chat_template\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "\n",
    "output_dir: ./out-{MODEL_SHORT_NAME}\n",
    "\n",
    "#chat_template: chatml\n",
    "\n",
    "adapter: lora\n",
    "lora_r: 16\n",
    "lora_alpha: 32\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "pad_to_sequence_len: true\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "eval_batch_size: 2\n",
    "num_epochs: 8\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: true\n",
    "fp16: false\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true  # true: saves VRAM but is slower to train\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 2\n",
    "eval_table_size:\n",
    "eval_table_max_new_tokens: 128\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "special_tokens:\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as outfile:\n",
    "    print(CONFIG, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2025-10-07 10:06:30,809] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:3063140] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "\u001b[33m[2025-10-07 10:06:30,809] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:871] [PID:3063140] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2025-10-07 10:06:31,182] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:3063140] [RANK:0] cuda memory usage baseline: 0.000GB (+0.818GB misc)\u001b[39m\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-10-07 10:06:32,333] [INFO] [axolotl.loaders.tokenizer.load_tokenizer:294] [PID:3063140] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2025-10-07 10:06:32,337] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:3063140] [RANK:0] Unable to find prepared dataset in last_run_prepared/17cf1644cd1cdae47e6acfaa84bdba96\u001b[39m\n",
      "[2025-10-07 10:06:32,337] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:3063140] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-10-07 10:06:32,337] [WARNING] [axolotl.utils.data.sft._load_raw_datasets:312] [PID:3063140] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\u001b[39m\n",
      "Generating train split: 640 examples [00:00, 19071.52 examples/s]\n",
      "[2025-10-07 10:06:32,865] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:3063140] [RANK:0] Loading dataset: axolotl-train.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
      "[2025-10-07 10:06:32,900] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:3063140] [RANK:0] Using chat template:\n",
      "---\n",
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "---\u001b[39m\n",
      "Tokenizing Prompts (num_proc=32): 100%|█| 640/640 [00:04<00:00, 141.97 examples/\n",
      "[2025-10-07 10:06:37,733] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:3063140] [RANK:0] min_input_len: 387\u001b[39m\n",
      "[2025-10-07 10:06:37,733] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:3063140] [RANK:0] max_input_len: 6368\u001b[39m\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 640/640 [00:00<00:00, 2047.89 exa\n",
      "\u001b[33m[2025-10-07 10:06:38,553] [WARNING] [axolotl.utils.data.utils.drop_long_seq_in_dataset:201] [PID:3063140] [RANK:0] Dropped 2 long samples from dataset\u001b[39m\n",
      "Drop Samples with Zero Trainable Tokens (num_proc=32): 100%|█| 638/638 [00:00<00\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 638/638 [00:00<00\n",
      "Saving the dataset (1/1 shards): 100%|█| 638/638 [00:00<00:00, 5996.75 examples/\n",
      "[2025-10-07 10:06:40,366] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:3063140] [RANK:0] Unable to find prepared dataset in last_run_prepared/d1a000016f7de3936e986d6cb1ba7681\u001b[39m\n",
      "[2025-10-07 10:06:40,366] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:3063140] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-10-07 10:06:40,366] [WARNING] [axolotl.utils.data.sft._load_raw_datasets:312] [PID:3063140] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\u001b[39m\n",
      "Generating train split: 32 examples [00:00, 9054.69 examples/s]\n",
      "[2025-10-07 10:06:40,811] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:3063140] [RANK:0] Loading dataset: axolotl-eval.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
      "[2025-10-07 10:06:40,838] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:3063140] [RANK:0] Using chat template:\n",
      "---\n",
      "{%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "---\u001b[39m\n",
      "Tokenizing Prompts (num_proc=32): 100%|██| 32/32 [00:03<00:00,  8.91 examples/s]\n",
      "[2025-10-07 10:06:44,810] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:3063140] [RANK:0] min_input_len: 512\u001b[39m\n",
      "[2025-10-07 10:06:44,810] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:3063140] [RANK:0] max_input_len: 3204\u001b[39m\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 32/32 [00:00<00:00, 180.43 exampl\n",
      "Drop Samples with Zero Trainable Tokens (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "Saving the dataset (1/1 shards): 100%|██| 32/32 [00:00<00:00, 736.15 examples/s]\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m[2025-10-07 10:07:57,174] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:3063140] [RANK:0] gather_len_batches: [197]\u001b[39m\n",
      "[2025-10-07 10:07:57,174] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:123] [PID:3063140] [RANK:0] Maximum number of steps set at 392\u001b[39m\n",
      "[2025-10-07 10:07:57,787] [INFO] [axolotl.loaders.tokenizer.load_tokenizer:294] [PID:3063140] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "[2025-10-07 10:08:05,937] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:308] [PID:3063140] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-10-07 10:08:05,986] [INFO] [axolotl.loaders.adapter.load_lora:82] [PID:3063140] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
      "trainable params: 8,798,208 || all params: 502,830,976 || trainable%: 1.7497\n",
      "[2025-10-07 10:08:06,386] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:3063140] [RANK:0] cuda memory usage after adapters: 0.000GB ()\u001b[39m\n",
      "[2025-10-07 10:08:13,057] [WARNING] [accelerate.utils.other.check_os_kernel:441] [PID:3063140] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[2025-10-07 10:08:21,068] [INFO] [axolotl.train.save_initial_configs:403] [PID:3063140] [RANK:0] Pre-saving adapter config to ./out-Qwen2.5-0.5B-Instruct...\u001b[39m\n",
      "[2025-10-07 10:08:21,071] [INFO] [axolotl.train.save_initial_configs:407] [PID:3063140] [RANK:0] Pre-saving tokenizer to ./out-Qwen2.5-0.5B-Instruct...\u001b[39m\n",
      "[2025-10-07 10:08:21,240] [INFO] [axolotl.train.save_initial_configs:410] [PID:3063140] [RANK:0] Pre-saving model config to ./out-Qwen2.5-0.5B-Instruct...\u001b[39m\n",
      "[2025-10-07 10:08:21,247] [INFO] [axolotl.train.execute_training:225] [PID:3063140] [RANK:0] Starting trainer...\u001b[39m\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m[2025-10-07 10:09:23,889] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:3063140] [RANK:0] gather_len_batches: [197]\u001b[39m\n",
      "  0%|                                                   | 0/392 [00:00<?, ?it/s]You're using a Qwen2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:00, 16.32it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.76it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.33it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  7.05it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.91it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.51it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.55it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.56it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.59it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.27it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.38it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 1.3460670709609985, 'eval_runtime': 2.9725, 'eval_samples_per_second': 10.765, 'eval_steps_per_second': 5.383, 'epoch': 0}\n",
      "  0%|                                                   | 0/392 [00:02<?, ?it/s]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.61it/s]\u001b[A\n",
      "{'loss': 1.0966, 'grad_norm': 3.543052911758423, 'learning_rate': 0.0, 'epoch': 0.02}0m\u001b[0m\n",
      "  0%|                                         | 1/392 [00:19<2:04:48, 19.15s/it][2025-10-07 10:09:45,081] [INFO] [axolotl.utils.callbacks.log_gpu_memory_usage:107] [PID:3063140] [RANK:0] cuda memory usage while training: 0.995GB (+17.204GB cache, +1.326GB misc)\u001b[39m\n",
      "{'loss': 1.1244, 'grad_norm': 3.453244209289551, 'learning_rate': 2e-05, 'epoch': 0.04}\n",
      "{'loss': 1.1767, 'grad_norm': 3.8909058570861816, 'learning_rate': 4e-05, 'epoch': 0.06}\n",
      "{'loss': 1.2744, 'grad_norm': 3.883268356323242, 'learning_rate': 6e-05, 'epoch': 0.08}\n",
      "{'loss': 0.7519, 'grad_norm': 2.3697621822357178, 'learning_rate': 8e-05, 'epoch': 0.1}\n",
      "{'loss': 0.7545, 'grad_norm': 1.840187430381775, 'learning_rate': 0.0001, 'epoch': 0.12}\n",
      "{'loss': 0.7005, 'grad_norm': 1.6333774328231812, 'learning_rate': 0.00012, 'epoch': 0.14}\n",
      "{'loss': 0.8328, 'grad_norm': 1.7222585678100586, 'learning_rate': 0.00014, 'epoch': 0.16}\n",
      "{'loss': 0.5154, 'grad_norm': 1.8107484579086304, 'learning_rate': 0.00016, 'epoch': 0.18}\n",
      "{'loss': 0.3464, 'grad_norm': 1.321518063545227, 'learning_rate': 0.00018, 'epoch': 0.2}\n",
      "{'loss': 0.3266, 'grad_norm': 1.6694332361221313, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 0.3127, 'grad_norm': 1.5388340950012207, 'learning_rate': 0.00019999661825718406, 'epoch': 0.24}\n",
      "{'loss': 0.241, 'grad_norm': 1.5811418294906616, 'learning_rate': 0.00019998647325745995, 'epoch': 0.26}\n",
      "{'loss': 0.2741, 'grad_norm': 1.2567042112350464, 'learning_rate': 0.00019996956568698324, 'epoch': 0.28}\n",
      "{'loss': 0.2153, 'grad_norm': 1.0661824941635132, 'learning_rate': 0.000199945896689295, 'epoch': 0.3}\n",
      "{'loss': 0.2577, 'grad_norm': 1.0161041021347046, 'learning_rate': 0.00019991546786524457, 'epoch': 0.32}\n",
      "{'loss': 0.1835, 'grad_norm': 1.5936005115509033, 'learning_rate': 0.00019987828127288103, 'epoch': 0.35}\n",
      "{'loss': 0.2272, 'grad_norm': 0.9349890947341919, 'learning_rate': 0.00019983433942731427, 'epoch': 0.37}\n",
      "{'loss': 0.2099, 'grad_norm': 0.9094178080558777, 'learning_rate': 0.00019978364530054464, 'epoch': 0.39}\n",
      "{'loss': 0.167, 'grad_norm': 0.8625286221504211, 'learning_rate': 0.00019972620232126213, 'epoch': 0.41}\n",
      "{'loss': 0.2111, 'grad_norm': 1.086971640586853, 'learning_rate': 0.0001996620143746144, 'epoch': 0.43}\n",
      "{'loss': 0.165, 'grad_norm': 0.8662863969802856, 'learning_rate': 0.00019959108580194402, 'epoch': 0.45}\n",
      "{'loss': 0.1504, 'grad_norm': 0.8952876925468445, 'learning_rate': 0.0001995134214004948, 'epoch': 0.47}\n",
      "{'loss': 0.2764, 'grad_norm': 0.9671069979667664, 'learning_rate': 0.00019942902642308737, 'epoch': 0.49}\n",
      "{'loss': 0.232, 'grad_norm': 1.1398594379425049, 'learning_rate': 0.00019933790657776387, 'epoch': 0.51}\n",
      "  6%|██▋                                       | 25/392 [01:06<12:07,  1.98s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.29it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.32it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.50it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  5.80it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.04it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.17it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.2504578232765198, 'eval_runtime': 2.5732, 'eval_samples_per_second': 12.436, 'eval_steps_per_second': 6.218, 'epoch': 0.51}\n",
      "  6%|██▋                                       | 25/392 [01:09<12:07,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.43it/s]\u001b[A\n",
      "{'loss': 0.1649, 'grad_norm': 0.8822640776634216, 'learning_rate': 0.000199240068027402, 'epoch': 0.53}\n",
      "{'loss': 0.2563, 'grad_norm': 1.0350364446640015, 'learning_rate': 0.00019913551738929801, 'epoch': 0.55}\n",
      "{'loss': 0.1982, 'grad_norm': 0.7167745232582092, 'learning_rate': 0.00019902426173471933, 'epoch': 0.57}\n",
      "{'loss': 0.1314, 'grad_norm': 0.9225939512252808, 'learning_rate': 0.00019890630858842613, 'epoch': 0.59}\n",
      "{'loss': 0.273, 'grad_norm': 0.9192411303520203, 'learning_rate': 0.00019878166592816255, 'epoch': 0.61}\n",
      "{'loss': 0.1282, 'grad_norm': 0.5894527435302734, 'learning_rate': 0.00019865034218411698, 'epoch': 0.63}\n",
      "{'loss': 0.1821, 'grad_norm': 0.664422869682312, 'learning_rate': 0.00019851234623835198, 'epoch': 0.65}\n",
      "{'loss': 0.2325, 'grad_norm': 0.9439861178398132, 'learning_rate': 0.00019836768742420352, 'epoch': 0.67}\n",
      "{'loss': 0.1636, 'grad_norm': 0.7327688932418823, 'learning_rate': 0.00019821637552564972, 'epoch': 0.69}\n",
      "{'loss': 0.2592, 'grad_norm': 0.6904299259185791, 'learning_rate': 0.0001980584207766491, 'epoch': 0.71}\n",
      "{'loss': 0.1597, 'grad_norm': 0.6865159869194031, 'learning_rate': 0.0001978938338604484, 'epoch': 0.73}\n",
      "{'loss': 0.2163, 'grad_norm': 0.7370996475219727, 'learning_rate': 0.00019772262590886006, 'epoch': 0.75}\n",
      "{'loss': 0.0965, 'grad_norm': 0.8996708393096924, 'learning_rate': 0.0001975448085015093, 'epoch': 0.77}\n",
      "{'loss': 0.1268, 'grad_norm': 0.7132178544998169, 'learning_rate': 0.00019736039366505086, 'epoch': 0.79}\n",
      "{'loss': 0.1238, 'grad_norm': 0.7493921518325806, 'learning_rate': 0.00019716939387235573, 'epoch': 0.81}\n",
      "{'loss': 0.1553, 'grad_norm': 0.8505284786224365, 'learning_rate': 0.0001969718220416675, 'epoch': 0.83}\n",
      "{'loss': 0.1389, 'grad_norm': 0.6604854464530945, 'learning_rate': 0.0001967676915357285, 'epoch': 0.85}\n",
      "{'loss': 0.0681, 'grad_norm': 0.5828278064727783, 'learning_rate': 0.0001965570161608762, 'epoch': 0.87}\n",
      "{'loss': 0.2589, 'grad_norm': 0.7826542854309082, 'learning_rate': 0.00019633981016610924, 'epoch': 0.89}\n",
      "{'loss': 0.2264, 'grad_norm': 1.226867914199829, 'learning_rate': 0.00019611608824212395, 'epoch': 0.91}\n",
      "{'loss': 0.0789, 'grad_norm': 0.6656880378723145, 'learning_rate': 0.00019588586552032048, 'epoch': 0.93}\n",
      "{'loss': 0.2005, 'grad_norm': 0.8419880270957947, 'learning_rate': 0.00019564915757177954, 'epoch': 0.95}\n",
      "{'loss': 0.0943, 'grad_norm': 0.6602357625961304, 'learning_rate': 0.0001954059804062092, 'epoch': 0.97}\n",
      "{'loss': 0.22, 'grad_norm': 0.8597331643104553, 'learning_rate': 0.00019515635047086217, 'epoch': 0.99}\n",
      "{'loss': 0.3351, 'grad_norm': 2.1560347080230713, 'learning_rate': 0.0001949002846494232, 'epoch': 1.0}\n",
      " 13%|█████▎                                    | 50/392 [01:58<09:55,  1.74s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.31it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.50it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.26it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.38it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19405502080917358, 'eval_runtime': 2.5308, 'eval_samples_per_second': 12.644, 'eval_steps_per_second': 6.322, 'epoch': 1.0}\n",
      " 13%|█████▎                                    | 50/392 [02:00<09:55,  1.74s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.0782, 'grad_norm': 0.5163582563400269, 'learning_rate': 0.00019463780026086737, 'epoch': 1.02}\n",
      "{'loss': 0.0819, 'grad_norm': 0.5279605388641357, 'learning_rate': 0.00019436891505828855, 'epoch': 1.04}\n",
      "{'loss': 0.0698, 'grad_norm': 0.5145329236984253, 'learning_rate': 0.00019409364722769882, 'epoch': 1.06}\n",
      "{'loss': 0.1112, 'grad_norm': 0.5928593873977661, 'learning_rate': 0.00019381201538679833, 'epoch': 1.08}\n",
      "{'loss': 0.1273, 'grad_norm': 0.5109046101570129, 'learning_rate': 0.00019352403858371618, 'epoch': 1.1}\n",
      "{'loss': 0.1246, 'grad_norm': 0.6778556108474731, 'learning_rate': 0.00019322973629572204, 'epoch': 1.12}\n",
      "{'loss': 0.0624, 'grad_norm': 0.4612310528755188, 'learning_rate': 0.00019292912842790893, 'epoch': 1.14}\n",
      "{'loss': 0.1417, 'grad_norm': 0.46713507175445557, 'learning_rate': 0.0001926222353118468, 'epoch': 1.16}\n",
      "{'loss': 0.0892, 'grad_norm': 0.46430882811546326, 'learning_rate': 0.00019230907770420737, 'epoch': 1.18}\n",
      "{'loss': 0.0453, 'grad_norm': 0.42605194449424744, 'learning_rate': 0.00019198967678536052, 'epoch': 1.2}\n",
      "{'loss': 0.0736, 'grad_norm': 0.4676380753517151, 'learning_rate': 0.00019166405415794148, 'epoch': 1.22}\n",
      "{'loss': 0.0851, 'grad_norm': 0.5286380648612976, 'learning_rate': 0.0001913322318453899, 'epoch': 1.24}\n",
      "{'loss': 0.0729, 'grad_norm': 0.5422975420951843, 'learning_rate': 0.00019099423229046014, 'epoch': 1.26}\n",
      "{'loss': 0.0889, 'grad_norm': 0.8617875576019287, 'learning_rate': 0.0001906500783537036, 'epoch': 1.28}\n",
      "{'loss': 0.069, 'grad_norm': 0.40903759002685547, 'learning_rate': 0.00019029979331192229, 'epoch': 1.3}\n",
      "{'loss': 0.0563, 'grad_norm': 0.4255060851573944, 'learning_rate': 0.00018994340085659475, 'epoch': 1.32}\n",
      "{'loss': 0.3041, 'grad_norm': 0.9257211089134216, 'learning_rate': 0.00018958092509227347, 'epoch': 1.35}\n",
      "{'loss': 0.0939, 'grad_norm': 0.48123523592948914, 'learning_rate': 0.00018921239053495463, 'epoch': 1.37}\n",
      "{'loss': 0.124, 'grad_norm': 0.6473939418792725, 'learning_rate': 0.00018883782211042013, 'epoch': 1.39}\n",
      "{'loss': 0.1613, 'grad_norm': 0.6840522289276123, 'learning_rate': 0.00018845724515255147, 'epoch': 1.41}\n",
      "{'loss': 0.0885, 'grad_norm': 0.612200915813446, 'learning_rate': 0.00018807068540161657, 'epoch': 1.43}\n",
      "{'loss': 0.063, 'grad_norm': 0.4873299300670624, 'learning_rate': 0.0001876781690025287, 'epoch': 1.45}\n",
      "{'loss': 0.1169, 'grad_norm': 0.47733253240585327, 'learning_rate': 0.000187279722503078, 'epoch': 1.47}\n",
      "{'loss': 0.1023, 'grad_norm': 0.41677799820899963, 'learning_rate': 0.00018687537285213627, 'epoch': 1.49}\n",
      "{'loss': 0.1597, 'grad_norm': 0.7451187968254089, 'learning_rate': 0.00018646514739783406, 'epoch': 1.51}\n",
      " 19%|████████                                  | 75/392 [03:04<10:27,  1.98s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.32it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.50it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.25it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.38it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17064759135246277, 'eval_runtime': 2.5309, 'eval_samples_per_second': 12.644, 'eval_steps_per_second': 6.322, 'epoch': 1.51}\n",
      " 19%|████████                                  | 75/392 [03:06<10:27,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.61it/s]\u001b[A\n",
      "{'loss': 0.2187, 'grad_norm': 0.8642275333404541, 'learning_rate': 0.00018604907388571098, 'epoch': 1.53}\n",
      "{'loss': 0.0958, 'grad_norm': 0.7717521786689758, 'learning_rate': 0.0001856271804568393, 'epoch': 1.55}\n",
      "{'loss': 0.0579, 'grad_norm': 0.3771611154079437, 'learning_rate': 0.00018519949564592045, 'epoch': 1.57}\n",
      "{'loss': 0.1646, 'grad_norm': 0.5420191287994385, 'learning_rate': 0.00018476604837935513, 'epoch': 1.59}\n",
      "{'loss': 0.0951, 'grad_norm': 0.3936168849468231, 'learning_rate': 0.00018432686797328698, 'epoch': 1.61}\n",
      "{'loss': 0.0545, 'grad_norm': 0.30983850359916687, 'learning_rate': 0.00018388198413161965, 'epoch': 1.63}\n",
      "{'loss': 0.1492, 'grad_norm': 0.5577141046524048, 'learning_rate': 0.00018343142694400783, 'epoch': 1.65}\n",
      "{'loss': 0.0961, 'grad_norm': 0.4912794232368469, 'learning_rate': 0.00018297522688382218, 'epoch': 1.67}\n",
      "{'loss': 0.092, 'grad_norm': 0.44766828417778015, 'learning_rate': 0.00018251341480608822, 'epoch': 1.69}\n",
      "{'loss': 0.1038, 'grad_norm': 0.6433398723602295, 'learning_rate': 0.0001820460219453995, 'epoch': 1.71}\n",
      "{'loss': 0.2136, 'grad_norm': 0.7960034012794495, 'learning_rate': 0.00018157307991380493, 'epoch': 1.73}\n",
      "{'loss': 0.0623, 'grad_norm': 0.5008834600448608, 'learning_rate': 0.00018109462069867098, 'epoch': 1.75}\n",
      "{'loss': 0.059, 'grad_norm': 0.4190475344657898, 'learning_rate': 0.0001806106766605178, 'epoch': 1.77}\n",
      "{'loss': 0.0978, 'grad_norm': 0.44971832633018494, 'learning_rate': 0.00018012128053083095, 'epoch': 1.79}\n",
      "{'loss': 0.0702, 'grad_norm': 0.37152352929115295, 'learning_rate': 0.0001796264654098473, 'epoch': 1.81}\n",
      "{'loss': 0.3005, 'grad_norm': 0.8002328276634216, 'learning_rate': 0.00017912626476431647, 'epoch': 1.83}\n",
      "{'loss': 0.0536, 'grad_norm': 0.302671879529953, 'learning_rate': 0.00017862071242523731, 'epoch': 1.85}\n",
      "{'loss': 0.0476, 'grad_norm': 0.40400969982147217, 'learning_rate': 0.00017810984258556957, 'epoch': 1.87}\n",
      "{'loss': 0.0537, 'grad_norm': 0.43363893032073975, 'learning_rate': 0.00017759368979792142, 'epoch': 1.89}\n",
      "{'loss': 0.1675, 'grad_norm': 0.7068970799446106, 'learning_rate': 0.00017707228897221263, 'epoch': 1.91}\n",
      "{'loss': 0.1176, 'grad_norm': 0.5247775912284851, 'learning_rate': 0.00017654567537331298, 'epoch': 1.93}\n",
      "{'loss': 0.121, 'grad_norm': 0.49001190066337585, 'learning_rate': 0.0001760138846186577, 'epoch': 1.95}\n",
      "{'loss': 0.0721, 'grad_norm': 0.824250340461731, 'learning_rate': 0.00017547695267583791, 'epoch': 1.97}\n",
      "{'loss': 0.1627, 'grad_norm': 0.6819539070129395, 'learning_rate': 0.0001749349158601686, 'epoch': 1.99}\n",
      "{'loss': 0.0274, 'grad_norm': 1.1291505098342896, 'learning_rate': 0.00017438781083223178, 'epoch': 2.0}\n",
      " 26%|██████████▍                              | 100/392 [03:55<08:09,  1.68s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.31it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.32it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.47it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.52it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.23it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.35it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.15842187404632568, 'eval_runtime': 2.5325, 'eval_samples_per_second': 12.636, 'eval_steps_per_second': 6.318, 'epoch': 2.0}\n",
      " 26%|██████████▍                              | 100/392 [03:57<08:09,  1.68s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.095, 'grad_norm': 0.41577354073524475, 'learning_rate': 0.00017383567459539748, 'epoch': 2.02}\n",
      "{'loss': 0.0555, 'grad_norm': 0.40742290019989014, 'learning_rate': 0.00017327854449332067, 'epoch': 2.04}\n",
      "{'loss': 0.049, 'grad_norm': 0.4760349988937378, 'learning_rate': 0.00017271645820741583, 'epoch': 2.06}\n",
      "{'loss': 0.0251, 'grad_norm': 0.2714231610298157, 'learning_rate': 0.00017214945375430816, 'epoch': 2.08}\n",
      "{'loss': 0.1149, 'grad_norm': 0.45137929916381836, 'learning_rate': 0.0001715775694832623, 'epoch': 2.1}\n",
      "{'loss': 0.1007, 'grad_norm': 0.5160182118415833, 'learning_rate': 0.0001710008440735888, 'epoch': 2.12}\n",
      "{'loss': 0.0321, 'grad_norm': 0.29714158177375793, 'learning_rate': 0.00017041931653202788, 'epoch': 2.14}\n",
      "{'loss': 0.0415, 'grad_norm': 0.33313825726509094, 'learning_rate': 0.00016983302619011124, 'epoch': 2.16}\n",
      "{'loss': 0.0306, 'grad_norm': 0.31525665521621704, 'learning_rate': 0.00016924201270150194, 'epoch': 2.18}\n",
      "{'loss': 0.081, 'grad_norm': 0.42590418457984924, 'learning_rate': 0.0001686463160393123, 'epoch': 2.2}\n",
      "{'loss': 0.0495, 'grad_norm': 0.3501785397529602, 'learning_rate': 0.0001680459764934006, 'epoch': 2.22}\n",
      "{'loss': 0.0247, 'grad_norm': 0.37248554825782776, 'learning_rate': 0.00016744103466764565, 'epoch': 2.24}\n",
      "{'loss': 0.0579, 'grad_norm': 0.5511890649795532, 'learning_rate': 0.00016683153147720097, 'epoch': 2.26}\n",
      "{'loss': 0.078, 'grad_norm': 1.0118523836135864, 'learning_rate': 0.00016621750814572726, 'epoch': 2.28}\n",
      "{'loss': 0.0667, 'grad_norm': 0.34290003776550293, 'learning_rate': 0.00016559900620260435, 'epoch': 2.3}\n",
      "{'loss': 0.0386, 'grad_norm': 0.3540376126766205, 'learning_rate': 0.00016497606748012227, 'epoch': 2.32}\n",
      "{'loss': 0.1189, 'grad_norm': 0.5134285688400269, 'learning_rate': 0.000164348734110652, 'epoch': 2.35}\n",
      "{'loss': 0.0515, 'grad_norm': 0.501763641834259, 'learning_rate': 0.00016371704852379587, 'epoch': 2.37}\n",
      "{'loss': 0.0888, 'grad_norm': 0.48912313580513, 'learning_rate': 0.00016308105344351774, 'epoch': 2.39}\n",
      "{'loss': 0.0402, 'grad_norm': 0.31300464272499084, 'learning_rate': 0.00016244079188525357, 'epoch': 2.41}\n",
      "{'loss': 0.0552, 'grad_norm': 0.40761107206344604, 'learning_rate': 0.00016179630715300178, 'epoch': 2.43}\n",
      "{'loss': 0.081, 'grad_norm': 0.4139210879802704, 'learning_rate': 0.00016114764283639468, 'epoch': 2.45}\n",
      "{'loss': 0.0857, 'grad_norm': 0.46166497468948364, 'learning_rate': 0.00016049484280775012, 'epoch': 2.47}\n",
      "{'loss': 0.0158, 'grad_norm': 0.32329219579696655, 'learning_rate': 0.0001598379512191042, 'epoch': 2.49}\n",
      "{'loss': 0.0677, 'grad_norm': 0.44620856642723083, 'learning_rate': 0.0001591770124992252, 'epoch': 2.51}\n",
      " 32%|█████████████                            | 125/392 [05:01<08:49,  1.98s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.31it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.32it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.48it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.54it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.23it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.36it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.15963402390480042, 'eval_runtime': 2.5314, 'eval_samples_per_second': 12.641, 'eval_steps_per_second': 6.321, 'epoch': 2.51}\n",
      " 32%|█████████████                            | 125/392 [05:03<08:49,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.0563, 'grad_norm': 0.4763471782207489, 'learning_rate': 0.0001585120713506084, 'epoch': 2.53}\n",
      "{'loss': 0.1187, 'grad_norm': 0.48725125193595886, 'learning_rate': 0.00015784317274645292, 'epoch': 2.55}\n",
      "{'loss': 0.1168, 'grad_norm': 0.5062630772590637, 'learning_rate': 0.0001571703619276197, 'epoch': 2.57}\n",
      "{'loss': 0.1121, 'grad_norm': 0.443059504032135, 'learning_rate': 0.00015649368439957183, 'epoch': 2.59}\n",
      "{'loss': 0.0162, 'grad_norm': 0.2721712291240692, 'learning_rate': 0.00015581318592929662, 'epoch': 2.61}\n",
      "{'loss': 0.139, 'grad_norm': 0.6537314653396606, 'learning_rate': 0.00015512891254221045, 'epoch': 2.63}\n",
      "{'loss': 0.1387, 'grad_norm': 0.5440431833267212, 'learning_rate': 0.00015444091051904546, 'epoch': 2.65}\n",
      "{'loss': 0.0318, 'grad_norm': 0.557744026184082, 'learning_rate': 0.00015374922639271963, 'epoch': 2.67}\n",
      "{'loss': 0.0257, 'grad_norm': 0.36468321084976196, 'learning_rate': 0.0001530539069451895, 'epoch': 2.69}\n",
      "{'loss': 0.0591, 'grad_norm': 0.4650779962539673, 'learning_rate': 0.000152354999204286, 'epoch': 2.71}\n",
      "{'loss': 0.1048, 'grad_norm': 0.5641639232635498, 'learning_rate': 0.00015165255044053373, 'epoch': 2.73}\n",
      "{'loss': 0.0323, 'grad_norm': 0.36919134855270386, 'learning_rate': 0.0001509466081639539, 'epoch': 2.75}\n",
      "{'loss': 0.0204, 'grad_norm': 0.28421205282211304, 'learning_rate': 0.00015023722012085097, 'epoch': 2.77}\n",
      "{'loss': 0.0377, 'grad_norm': 0.4185687005519867, 'learning_rate': 0.00014952443429058334, 'epoch': 2.79}\n",
      "{'loss': 0.0316, 'grad_norm': 0.28274011611938477, 'learning_rate': 0.00014880829888231818, 'epoch': 2.81}\n",
      "{'loss': 0.0445, 'grad_norm': 0.3987163305282593, 'learning_rate': 0.00014808886233177095, 'epoch': 2.83}\n",
      "{'loss': 0.0546, 'grad_norm': 0.34676435589790344, 'learning_rate': 0.0001473661732979294, 'epoch': 2.85}\n",
      "{'loss': 0.1021, 'grad_norm': 0.49769365787506104, 'learning_rate': 0.00014664028065976246, 'epoch': 2.87}\n",
      "{'loss': 0.1124, 'grad_norm': 0.6097286343574524, 'learning_rate': 0.00014591123351291441, 'epoch': 2.89}\n",
      "{'loss': 0.0442, 'grad_norm': 0.4744409918785095, 'learning_rate': 0.00014517908116638432, 'epoch': 2.91}\n",
      "{'loss': 0.0478, 'grad_norm': 0.5674659609794617, 'learning_rate': 0.00014444387313919093, 'epoch': 2.93}\n",
      "{'loss': 0.0211, 'grad_norm': 0.32745105028152466, 'learning_rate': 0.0001437056591570235, 'epoch': 2.95}\n",
      "{'loss': 0.051, 'grad_norm': 0.9431582689285278, 'learning_rate': 0.00014296448914887866, 'epoch': 2.97}\n",
      "{'loss': 0.0394, 'grad_norm': 0.4326757490634918, 'learning_rate': 0.00014222041324368347, 'epoch': 2.99}\n",
      "{'loss': 0.0045, 'grad_norm': 0.2539397180080414, 'learning_rate': 0.00014147348176690478, 'epoch': 3.0}\n",
      " 38%|███████████████▋                         | 150/392 [05:52<06:32,  1.62s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.32it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.33it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.50it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.24it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.37it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.16253027319908142, 'eval_runtime': 2.5334, 'eval_samples_per_second': 12.631, 'eval_steps_per_second': 6.316, 'epoch': 3.0}\n",
      " 38%|███████████████▋                         | 150/392 [05:55<06:32,  1.62s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.0604, 'grad_norm': 0.40067222714424133, 'learning_rate': 0.00014072374523714577, 'epoch': 3.02}\n",
      "{'loss': 0.0419, 'grad_norm': 0.3716248869895935, 'learning_rate': 0.0001399712543627289, 'epoch': 3.04}\n",
      "{'loss': 0.0237, 'grad_norm': 0.3784445524215698, 'learning_rate': 0.00013921606003826627, 'epoch': 3.06}\n",
      "{'loss': 0.0519, 'grad_norm': 0.3568718433380127, 'learning_rate': 0.00013845821334121763, 'epoch': 3.08}\n",
      "{'loss': 0.0326, 'grad_norm': 0.2866244316101074, 'learning_rate': 0.0001376977655284353, 'epoch': 3.1}\n",
      "{'loss': 0.0425, 'grad_norm': 0.41607561707496643, 'learning_rate': 0.00013693476803269797, 'epoch': 3.12}\n",
      "{'loss': 0.09, 'grad_norm': 0.654643714427948, 'learning_rate': 0.00013616927245923156, 'epoch': 3.14}\n",
      "{'loss': 0.0338, 'grad_norm': 0.512787938117981, 'learning_rate': 0.00013540133058221926, 'epoch': 3.16}\n",
      "{'loss': 0.1048, 'grad_norm': 0.62282794713974, 'learning_rate': 0.0001346309943412995, 'epoch': 3.18}\n",
      "{'loss': 0.0529, 'grad_norm': 0.5350335240364075, 'learning_rate': 0.0001338583158380533, 'epoch': 3.2}\n",
      "{'loss': 0.029, 'grad_norm': 0.4413619041442871, 'learning_rate': 0.00013308334733248017, 'epoch': 3.22}\n",
      "{'loss': 0.0309, 'grad_norm': 0.3654489815235138, 'learning_rate': 0.0001323061412394637, 'epoch': 3.24}\n",
      "{'loss': 0.0139, 'grad_norm': 0.24141176044940948, 'learning_rate': 0.00013152675012522629, 'epoch': 3.26}\n",
      "{'loss': 0.0361, 'grad_norm': 0.30717146396636963, 'learning_rate': 0.00013074522670377393, 'epoch': 3.28}\n",
      "{'loss': 0.0145, 'grad_norm': 0.25331151485443115, 'learning_rate': 0.00012996162383333097, 'epoch': 3.3}\n",
      "{'loss': 0.0434, 'grad_norm': 0.49903783202171326, 'learning_rate': 0.00012917599451276498, 'epoch': 3.32}\n",
      "{'loss': 0.0297, 'grad_norm': 0.46873176097869873, 'learning_rate': 0.00012838839187800217, 'epoch': 3.35}\n",
      "{'loss': 0.0397, 'grad_norm': 0.5436562895774841, 'learning_rate': 0.00012759886919843353, 'epoch': 3.37}\n",
      "{'loss': 0.0461, 'grad_norm': 0.514128565788269, 'learning_rate': 0.00012680747987331214, 'epoch': 3.39}\n",
      "{'loss': 0.0791, 'grad_norm': 0.4867002069950104, 'learning_rate': 0.00012601427742814123, 'epoch': 3.41}\n",
      "{'loss': 0.0628, 'grad_norm': 0.5454930663108826, 'learning_rate': 0.00012521931551105425, 'epoch': 3.43}\n",
      "{'loss': 0.0503, 'grad_norm': 0.46854954957962036, 'learning_rate': 0.0001244226478891862, 'epoch': 3.45}\n",
      "{'loss': 0.0179, 'grad_norm': 0.43189042806625366, 'learning_rate': 0.00012362432844503725, 'epoch': 3.47}\n",
      "{'loss': 0.0249, 'grad_norm': 0.3920319676399231, 'learning_rate': 0.0001228244111728283, 'epoch': 3.49}\n",
      "{'loss': 0.02, 'grad_norm': 0.3770841956138611, 'learning_rate': 0.0001220229501748491, 'epoch': 3.51}\n",
      " 45%|██████████████████▎                      | 175/392 [06:58<07:10,  1.98s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.32it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.49it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.25it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.37it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.16129687428474426, 'eval_runtime': 2.5323, 'eval_samples_per_second': 12.637, 'eval_steps_per_second': 6.318, 'epoch': 3.51}\n",
      " 45%|██████████████████▎                      | 175/392 [07:01<07:10,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.0152, 'grad_norm': 0.2993764877319336, 'learning_rate': 0.00012121999965779909, 'epoch': 3.53}\n",
      "{'loss': 0.0289, 'grad_norm': 0.5107845067977905, 'learning_rate': 0.00012041561392912117, 'epoch': 3.55}\n",
      "{'loss': 0.0355, 'grad_norm': 0.4040687382221222, 'learning_rate': 0.0001196098473933285, 'epoch': 3.57}\n",
      "{'loss': 0.0225, 'grad_norm': 0.28021061420440674, 'learning_rate': 0.00011880275454832492, 'epoch': 3.59}\n",
      "{'loss': 0.0522, 'grad_norm': 0.4017408788204193, 'learning_rate': 0.00011799438998171907, 'epoch': 3.61}\n",
      "{'loss': 0.0615, 'grad_norm': 0.6941735148429871, 'learning_rate': 0.00011718480836713229, 'epoch': 3.63}\n",
      "{'loss': 0.0522, 'grad_norm': 0.4572114646434784, 'learning_rate': 0.00011637406446050072, 'epoch': 3.65}\n",
      "{'loss': 0.0195, 'grad_norm': 0.27819743752479553, 'learning_rate': 0.00011556221309637203, 'epoch': 3.67}\n",
      "{'loss': 0.0611, 'grad_norm': 0.4251250922679901, 'learning_rate': 0.00011474930918419651, 'epoch': 3.69}\n",
      "{'loss': 0.021, 'grad_norm': 0.319618284702301, 'learning_rate': 0.00011393540770461357, 'epoch': 3.71}\n",
      "{'loss': 0.0193, 'grad_norm': 0.44992920756340027, 'learning_rate': 0.00011312056370573277, 'epoch': 3.73}\n",
      "{'loss': 0.026, 'grad_norm': 0.29590272903442383, 'learning_rate': 0.00011230483229941091, 'epoch': 3.75}\n",
      "{'loss': 0.0733, 'grad_norm': 0.7148993611335754, 'learning_rate': 0.00011148826865752444, 'epoch': 3.77}\n",
      "{'loss': 0.0231, 'grad_norm': 0.33002814650535583, 'learning_rate': 0.00011067092800823797, 'epoch': 3.79}\n",
      "{'loss': 0.0197, 'grad_norm': 0.2897658050060272, 'learning_rate': 0.00010985286563226886, 'epoch': 3.81}\n",
      "{'loss': 0.014, 'grad_norm': 0.3615975081920624, 'learning_rate': 0.00010903413685914843, 'epoch': 3.83}\n",
      "{'loss': 0.0454, 'grad_norm': 0.48519670963287354, 'learning_rate': 0.00010821479706347953, 'epoch': 3.85}\n",
      "{'loss': 0.0812, 'grad_norm': 0.6043649315834045, 'learning_rate': 0.00010739490166119155, 'epoch': 3.87}\n",
      "{'loss': 0.0331, 'grad_norm': 0.47236526012420654, 'learning_rate': 0.00010657450610579224, 'epoch': 3.89}\n",
      "{'loss': 0.0342, 'grad_norm': 0.4456861615180969, 'learning_rate': 0.0001057536658846171, 'epoch': 3.91}\n",
      "{'loss': 0.0207, 'grad_norm': 0.33759650588035583, 'learning_rate': 0.00010493243651507654, 'epoch': 3.93}\n",
      "{'loss': 0.0479, 'grad_norm': 0.474262535572052, 'learning_rate': 0.00010411087354090098, 'epoch': 3.95}\n",
      "{'loss': 0.0234, 'grad_norm': 0.2695479989051819, 'learning_rate': 0.00010328903252838415, 'epoch': 3.97}\n",
      "{'loss': 0.0164, 'grad_norm': 0.26270225644111633, 'learning_rate': 0.00010246696906262483, 'epoch': 3.99}\n",
      "{'loss': 0.0115, 'grad_norm': 0.4978231191635132, 'learning_rate': 0.00010164473874376739, 'epoch': 4.0}\n",
      " 51%|████████████████████▉                    | 200/392 [07:49<05:06,  1.60s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.32it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.40it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  5.70it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  5.91it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.08it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  5.95it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.15it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.23it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.35it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  6.15it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.30it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.36it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1629495620727539, 'eval_runtime': 2.6871, 'eval_samples_per_second': 11.909, 'eval_steps_per_second': 5.954, 'epoch': 4.0}\n",
      " 51%|████████████████████▉                    | 200/392 [07:52<05:06,  1.60s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.57it/s]\u001b[A\n",
      "{'loss': 0.0612, 'grad_norm': 0.4264339506626129, 'learning_rate': 0.00010082239718324135, 'epoch': 4.02}\n",
      "{'loss': 0.0137, 'grad_norm': 0.2278057187795639, 'learning_rate': 0.0001, 'epoch': 4.04}\n",
      "{'loss': 0.0223, 'grad_norm': 0.3949087858200073, 'learning_rate': 9.917760281675866e-05, 'epoch': 4.06}\n",
      "{'loss': 0.011, 'grad_norm': 0.28258606791496277, 'learning_rate': 9.835526125623262e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0276, 'grad_norm': 0.28036338090896606, 'learning_rate': 9.753303093737518e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0295, 'grad_norm': 0.2978077828884125, 'learning_rate': 9.671096747161587e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0157, 'grad_norm': 0.33907854557037354, 'learning_rate': 9.588912645909904e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0643, 'grad_norm': 0.6151725053787231, 'learning_rate': 9.506756348492348e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0315, 'grad_norm': 0.33735424280166626, 'learning_rate': 9.42463341153829e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0084, 'grad_norm': 0.1913912296295166, 'learning_rate': 9.342549389420777e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0353, 'grad_norm': 0.33449727296829224, 'learning_rate': 9.260509833880848e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0129, 'grad_norm': 0.23617762327194214, 'learning_rate': 9.17852029365205e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0184, 'grad_norm': 0.30935749411582947, 'learning_rate': 9.096586314085162e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0083, 'grad_norm': 0.2185908406972885, 'learning_rate': 9.014713436773114e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0224, 'grad_norm': 0.38156118988990784, 'learning_rate': 8.932907199176206e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0225, 'grad_norm': 0.30542731285095215, 'learning_rate': 8.851173134247559e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0115, 'grad_norm': 0.18335631489753723, 'learning_rate': 8.769516770058914e-05, 'epoch': 4.35}\n",
      "{'loss': 0.0343, 'grad_norm': 0.3641875386238098, 'learning_rate': 8.687943629426724e-05, 'epoch': 4.37}\n",
      "{'loss': 0.0191, 'grad_norm': 0.2568590044975281, 'learning_rate': 8.606459229538645e-05, 'epoch': 4.39}\n",
      "{'loss': 0.0206, 'grad_norm': 0.3186340630054474, 'learning_rate': 8.52506908158035e-05, 'epoch': 4.41}\n",
      "{'loss': 0.0198, 'grad_norm': 0.34557151794433594, 'learning_rate': 8.443778690362801e-05, 'epoch': 4.43}\n",
      "{'loss': 0.0258, 'grad_norm': 0.29814374446868896, 'learning_rate': 8.362593553949926e-05, 'epoch': 4.45}\n",
      "{'loss': 0.032, 'grad_norm': 0.6072458624839783, 'learning_rate': 8.281519163286772e-05, 'epoch': 4.47}\n",
      "{'loss': 0.0267, 'grad_norm': 0.35184532403945923, 'learning_rate': 8.200561001828094e-05, 'epoch': 4.49}\n",
      "{'loss': 0.0628, 'grad_norm': 0.6605280637741089, 'learning_rate': 8.11972454516751e-05, 'epoch': 4.51}\n",
      " 57%|███████████████████████▌                 | 225/392 [08:55<05:31,  1.98s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.33it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.44it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.49it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.54it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.23it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.36it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.39it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1790664941072464, 'eval_runtime': 2.5314, 'eval_samples_per_second': 12.641, 'eval_steps_per_second': 6.321, 'epoch': 4.51}\n",
      " 57%|███████████████████████▌                 | 225/392 [08:58<05:31,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.59it/s]\u001b[A\n",
      "{'loss': 0.0203, 'grad_norm': 0.5640527606010437, 'learning_rate': 8.039015260667154e-05, 'epoch': 4.53}\n",
      "{'loss': 0.0183, 'grad_norm': 0.3084349036216736, 'learning_rate': 7.958438607087884e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0122, 'grad_norm': 0.23322442173957825, 'learning_rate': 7.878000034220092e-05, 'epoch': 4.57}\n",
      "{'loss': 0.0192, 'grad_norm': 0.7951399087905884, 'learning_rate': 7.797704982515092e-05, 'epoch': 4.59}\n",
      "{'loss': 0.0187, 'grad_norm': 0.18809735774993896, 'learning_rate': 7.717558882717175e-05, 'epoch': 4.61}\n",
      "{'loss': 0.0233, 'grad_norm': 0.3422822058200836, 'learning_rate': 7.637567155496276e-05, 'epoch': 4.63}\n",
      "{'loss': 0.0144, 'grad_norm': 0.2877279222011566, 'learning_rate': 7.557735211081383e-05, 'epoch': 4.65}\n",
      "{'loss': 0.0339, 'grad_norm': 0.3966618478298187, 'learning_rate': 7.478068448894577e-05, 'epoch': 4.67}\n",
      "{'loss': 0.0101, 'grad_norm': 0.1532048135995865, 'learning_rate': 7.398572257185878e-05, 'epoch': 4.69}\n",
      "{'loss': 0.0173, 'grad_norm': 0.26707515120506287, 'learning_rate': 7.31925201266879e-05, 'epoch': 4.71}\n",
      "{'loss': 0.007, 'grad_norm': 0.22126327455043793, 'learning_rate': 7.240113080156646e-05, 'epoch': 4.73}\n",
      "{'loss': 0.0123, 'grad_norm': 0.2619974911212921, 'learning_rate': 7.161160812199786e-05, 'epoch': 4.75}\n",
      "{'loss': 0.0254, 'grad_norm': 0.39595314860343933, 'learning_rate': 7.082400548723504e-05, 'epoch': 4.77}\n",
      "{'loss': 0.0217, 'grad_norm': 0.40307506918907166, 'learning_rate': 7.003837616666906e-05, 'epoch': 4.79}\n",
      "{'loss': 0.0126, 'grad_norm': 0.26851680874824524, 'learning_rate': 6.92547732962261e-05, 'epoch': 4.81}\n",
      "{'loss': 0.0209, 'grad_norm': 0.3508279621601105, 'learning_rate': 6.847324987477375e-05, 'epoch': 4.83}\n",
      "{'loss': 0.0147, 'grad_norm': 0.2788090109825134, 'learning_rate': 6.769385876053632e-05, 'epoch': 4.85}\n",
      "{'loss': 0.012, 'grad_norm': 0.2601330578327179, 'learning_rate': 6.691665266751985e-05, 'epoch': 4.87}\n",
      "{'loss': 0.0529, 'grad_norm': 0.46932774782180786, 'learning_rate': 6.614168416194674e-05, 'epoch': 4.89}\n",
      "{'loss': 0.0158, 'grad_norm': 0.4322907030582428, 'learning_rate': 6.536900565870052e-05, 'epoch': 4.91}\n",
      "{'loss': 0.028, 'grad_norm': 1.2484022378921509, 'learning_rate': 6.459866941778076e-05, 'epoch': 4.93}\n",
      "{'loss': 0.021, 'grad_norm': 0.39084234833717346, 'learning_rate': 6.383072754076844e-05, 'epoch': 4.95}\n",
      "{'loss': 0.0064, 'grad_norm': 0.17746035754680634, 'learning_rate': 6.306523196730205e-05, 'epoch': 4.97}\n",
      "{'loss': 0.0418, 'grad_norm': 0.41800785064697266, 'learning_rate': 6.23022344715647e-05, 'epoch': 4.99}\n",
      "{'loss': 0.0492, 'grad_norm': 0.6975647807121277, 'learning_rate': 6.154178665878241e-05, 'epoch': 5.0}\n",
      " 64%|██████████████████████████▏              | 250/392 [09:47<03:43,  1.57s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.31it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.32it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.28it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.33it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.42it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.49it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.24it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.37it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1705310195684433, 'eval_runtime': 2.5341, 'eval_samples_per_second': 12.628, 'eval_steps_per_second': 6.314, 'epoch': 5.0}\n",
      " 64%|██████████████████████████▏              | 250/392 [09:49<03:43,  1.57s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.0506, 'grad_norm': 0.34001022577285767, 'learning_rate': 6.078393996173375e-05, 'epoch': 5.02}\n",
      "{'loss': 0.0209, 'grad_norm': 0.4539879858493805, 'learning_rate': 6.002874563727115e-05, 'epoch': 5.04}\n",
      "{'loss': 0.0079, 'grad_norm': 0.21587663888931274, 'learning_rate': 5.927625476285426e-05, 'epoch': 5.06}\n",
      "{'loss': 0.0169, 'grad_norm': 0.2273208498954773, 'learning_rate': 5.8526518233095205e-05, 'epoch': 5.08}\n",
      "{'loss': 0.0165, 'grad_norm': 0.2844935655593872, 'learning_rate': 5.777958675631656e-05, 'epoch': 5.1}\n",
      "{'loss': 0.0192, 'grad_norm': 0.17690755426883698, 'learning_rate': 5.703551085112133e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0078, 'grad_norm': 0.16779141128063202, 'learning_rate': 5.6294340842976544e-05, 'epoch': 5.14}\n",
      "{'loss': 0.0127, 'grad_norm': 0.18063394725322723, 'learning_rate': 5.555612686080909e-05, 'epoch': 5.16}\n",
      "{'loss': 0.0033, 'grad_norm': 0.25052696466445923, 'learning_rate': 5.4820918833615706e-05, 'epoch': 5.18}\n",
      "{'loss': 0.0036, 'grad_norm': 0.17853577435016632, 'learning_rate': 5.408876648708561e-05, 'epoch': 5.2}\n",
      "{'loss': 0.0065, 'grad_norm': 0.20504780113697052, 'learning_rate': 5.3359719340237565e-05, 'epoch': 5.22}\n",
      "{'loss': 0.0061, 'grad_norm': 0.1845315843820572, 'learning_rate': 5.263382670207062e-05, 'epoch': 5.24}\n",
      "{'loss': 0.0107, 'grad_norm': 0.2612192928791046, 'learning_rate': 5.191113766822905e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0426, 'grad_norm': 0.43537840247154236, 'learning_rate': 5.1191701117681814e-05, 'epoch': 5.28}\n",
      "{'loss': 0.0025, 'grad_norm': 0.17112551629543304, 'learning_rate': 5.0475565709416696e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0065, 'grad_norm': 0.18318620324134827, 'learning_rate': 4.976277987914905e-05, 'epoch': 5.32}\n",
      "{'loss': 0.0197, 'grad_norm': 0.7020624279975891, 'learning_rate': 4.905339183604614e-05, 'epoch': 5.35}\n",
      "{'loss': 0.005, 'grad_norm': 0.16016747057437897, 'learning_rate': 4.834744955946631e-05, 'epoch': 5.37}\n",
      "{'loss': 0.0107, 'grad_norm': 0.22857072949409485, 'learning_rate': 4.7645000795714035e-05, 'epoch': 5.39}\n",
      "{'loss': 0.0046, 'grad_norm': 0.21484608948230743, 'learning_rate': 4.694609305481055e-05, 'epoch': 5.41}\n",
      "{'loss': 0.0304, 'grad_norm': 0.4899761378765106, 'learning_rate': 4.6250773607280374e-05, 'epoch': 5.43}\n",
      "{'loss': 0.0123, 'grad_norm': 0.3458097279071808, 'learning_rate': 4.5559089480954556e-05, 'epoch': 5.45}\n",
      "{'loss': 0.0199, 'grad_norm': 0.24089550971984863, 'learning_rate': 4.4871087457789584e-05, 'epoch': 5.47}\n",
      "{'loss': 0.0116, 'grad_norm': 0.47029340267181396, 'learning_rate': 4.4186814070703385e-05, 'epoch': 5.49}\n",
      "{'loss': 0.0086, 'grad_norm': 0.20562465488910675, 'learning_rate': 4.350631560042822e-05, 'epoch': 5.51}\n",
      " 70%|████████████████████████████▊            | 275/392 [10:53<03:52,  1.98s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.33it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.32it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.80it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.33it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.50it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.25it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.37it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.41it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18075862526893616, 'eval_runtime': 2.5322, 'eval_samples_per_second': 12.637, 'eval_steps_per_second': 6.319, 'epoch': 5.51}\n",
      " 70%|████████████████████████████▊            | 275/392 [10:55<03:52,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.0085, 'grad_norm': 0.5559150576591492, 'learning_rate': 4.282963807238032e-05, 'epoch': 5.53}\n",
      "{'loss': 0.0146, 'grad_norm': 0.420026034116745, 'learning_rate': 4.215682725354709e-05, 'epoch': 5.55}\n",
      "{'loss': 0.0122, 'grad_norm': 0.2337830513715744, 'learning_rate': 4.1487928649391636e-05, 'epoch': 5.57}\n",
      "{'loss': 0.0178, 'grad_norm': 0.38757187128067017, 'learning_rate': 4.0822987500774847e-05, 'epoch': 5.59}\n",
      "{'loss': 0.0195, 'grad_norm': 0.31237363815307617, 'learning_rate': 4.016204878089579e-05, 'epoch': 5.61}\n",
      "{'loss': 0.0051, 'grad_norm': 0.8698353171348572, 'learning_rate': 3.950515719224991e-05, 'epoch': 5.63}\n",
      "{'loss': 0.0186, 'grad_norm': 0.8430799841880798, 'learning_rate': 3.885235716360533e-05, 'epoch': 5.65}\n",
      "{'loss': 0.0076, 'grad_norm': 0.22982695698738098, 'learning_rate': 3.820369284699823e-05, 'epoch': 5.67}\n",
      "{'loss': 0.0049, 'grad_norm': 0.3796785771846771, 'learning_rate': 3.755920811474647e-05, 'epoch': 5.69}\n",
      "{'loss': 0.0096, 'grad_norm': 0.21557363867759705, 'learning_rate': 3.691894655648225e-05, 'epoch': 5.71}\n",
      "{'loss': 0.0113, 'grad_norm': 0.21929852664470673, 'learning_rate': 3.628295147620418e-05, 'epoch': 5.73}\n",
      "{'loss': 0.0205, 'grad_norm': 0.5419266223907471, 'learning_rate': 3.565126588934803e-05, 'epoch': 5.75}\n",
      "{'loss': 0.0088, 'grad_norm': 0.3383263945579529, 'learning_rate': 3.502393251987776e-05, 'epoch': 5.77}\n",
      "{'loss': 0.0136, 'grad_norm': 0.2899731993675232, 'learning_rate': 3.4400993797395664e-05, 'epoch': 5.79}\n",
      "{'loss': 0.0045, 'grad_norm': 0.1402403861284256, 'learning_rate': 3.3782491854272734e-05, 'epoch': 5.81}\n",
      "{'loss': 0.0125, 'grad_norm': 0.1712327003479004, 'learning_rate': 3.316846852279907e-05, 'epoch': 5.83}\n",
      "{'loss': 0.0076, 'grad_norm': 0.19711416959762573, 'learning_rate': 3.2558965332354385e-05, 'epoch': 5.85}\n",
      "{'loss': 0.0049, 'grad_norm': 0.15601642429828644, 'learning_rate': 3.195402350659945e-05, 'epoch': 5.87}\n",
      "{'loss': 0.034, 'grad_norm': 0.30480149388313293, 'learning_rate': 3.135368396068771e-05, 'epoch': 5.89}\n",
      "{'loss': 0.0083, 'grad_norm': 0.19253474473953247, 'learning_rate': 3.07579872984981e-05, 'epoch': 5.91}\n",
      "{'loss': 0.0119, 'grad_norm': 0.42847326397895813, 'learning_rate': 3.0166973809888778e-05, 'epoch': 5.93}\n",
      "{'loss': 0.0042, 'grad_norm': 0.17594587802886963, 'learning_rate': 2.958068346797217e-05, 'epoch': 5.95}\n",
      "{'loss': 0.0219, 'grad_norm': 0.3139571249485016, 'learning_rate': 2.8999155926411202e-05, 'epoch': 5.97}\n",
      "{'loss': 0.0262, 'grad_norm': 0.41087836027145386, 'learning_rate': 2.842243051673773e-05, 'epoch': 5.99}\n",
      "{'loss': 0.0014, 'grad_norm': 0.07929705083370209, 'learning_rate': 2.7850546245691867e-05, 'epoch': 6.0}\n",
      " 77%|███████████████████████████████▍         | 300/392 [11:44<02:25,  1.58s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.32it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.26it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.04it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.79it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.71it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.33it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.41it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.48it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.24it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.37it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.40it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17854225635528564, 'eval_runtime': 2.537, 'eval_samples_per_second': 12.613, 'eval_steps_per_second': 6.307, 'epoch': 6.0}\n",
      " 77%|███████████████████████████████▍         | 300/392 [11:46<02:25,  1.58s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.60it/s]\u001b[A\n",
      "{'loss': 0.0111, 'grad_norm': 0.1357814520597458, 'learning_rate': 2.7283541792584168e-05, 'epoch': 6.02}\n",
      "{'loss': 0.0116, 'grad_norm': 0.15902453660964966, 'learning_rate': 2.6721455506679326e-05, 'epoch': 6.04}\n",
      "{'loss': 0.0036, 'grad_norm': 0.1008058413863182, 'learning_rate': 2.616432540460255e-05, 'epoch': 6.06}\n",
      "{'loss': 0.0152, 'grad_norm': 0.17536728084087372, 'learning_rate': 2.561218916776823e-05, 'epoch': 6.08}\n",
      "{'loss': 0.0042, 'grad_norm': 0.17623299360275269, 'learning_rate': 2.506508413983144e-05, 'epoch': 6.1}\n",
      "{'loss': 0.009, 'grad_norm': 0.187102273106575, 'learning_rate': 2.4523047324162085e-05, 'epoch': 6.12}\n",
      "{'loss': 0.0037, 'grad_norm': 0.09126723557710648, 'learning_rate': 2.3986115381342346e-05, 'epoch': 6.14}\n",
      "{'loss': 0.0187, 'grad_norm': 0.1767386496067047, 'learning_rate': 2.345432462668702e-05, 'epoch': 6.16}\n",
      "{'loss': 0.029, 'grad_norm': 0.23899240791797638, 'learning_rate': 2.292771102778739e-05, 'epoch': 6.18}\n",
      "{'loss': 0.027, 'grad_norm': 0.3379804491996765, 'learning_rate': 2.2406310202078585e-05, 'epoch': 6.2}\n",
      "{'loss': 0.0063, 'grad_norm': 0.12954802811145782, 'learning_rate': 2.1890157414430444e-05, 'epoch': 6.22}\n",
      "{'loss': 0.006, 'grad_norm': 0.14672715961933136, 'learning_rate': 2.137928757476272e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0075, 'grad_norm': 0.11838405579328537, 'learning_rate': 2.0873735235683535e-05, 'epoch': 6.26}\n",
      "{'loss': 0.0036, 'grad_norm': 0.09507575631141663, 'learning_rate': 2.037353459015272e-05, 'epoch': 6.28}\n",
      "{'loss': 0.0187, 'grad_norm': 0.20038816332817078, 'learning_rate': 1.9878719469169105e-05, 'epoch': 6.3}\n",
      "{'loss': 0.0192, 'grad_norm': 0.30185237526893616, 'learning_rate': 1.9389323339482203e-05, 'epoch': 6.32}\n",
      "{'loss': 0.0064, 'grad_norm': 0.2837713956832886, 'learning_rate': 1.890537930132903e-05, 'epoch': 6.35}\n",
      "{'loss': 0.0033, 'grad_norm': 0.3998230993747711, 'learning_rate': 1.8426920086195065e-05, 'epoch': 6.37}\n",
      "{'loss': 0.0066, 'grad_norm': 0.20820575952529907, 'learning_rate': 1.7953978054600527e-05, 'epoch': 6.39}\n",
      "{'loss': 0.0058, 'grad_norm': 0.12287184596061707, 'learning_rate': 1.7486585193911786e-05, 'epoch': 6.41}\n",
      "{'loss': 0.0057, 'grad_norm': 0.12883567810058594, 'learning_rate': 1.702477311617784e-05, 'epoch': 6.43}\n",
      "{'loss': 0.0056, 'grad_norm': 0.16050441563129425, 'learning_rate': 1.6568573055992187e-05, 'epoch': 6.45}\n",
      "{'loss': 0.0034, 'grad_norm': 0.13514405488967896, 'learning_rate': 1.6118015868380388e-05, 'epoch': 6.47}\n",
      "{'loss': 0.0048, 'grad_norm': 0.1200065016746521, 'learning_rate': 1.5673132026713046e-05, 'epoch': 6.49}\n",
      "{'loss': 0.0061, 'grad_norm': 0.13234232366085052, 'learning_rate': 1.523395162064486e-05, 'epoch': 6.51}\n",
      " 83%|█████████████████████████████████▉       | 325/392 [12:51<02:13,  1.99s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.05it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.16it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.15it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  6.93it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.68it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.58it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.20it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.30it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.31it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.37it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.13it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.25it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.28it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18406644463539124, 'eval_runtime': 2.5823, 'eval_samples_per_second': 12.392, 'eval_steps_per_second': 6.196, 'epoch': 6.51}\n",
      " 83%|█████████████████████████████████▉       | 325/392 [12:54<02:13,  1.99s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.51it/s]\u001b[A\n",
      "{'loss': 0.0063, 'grad_norm': 0.3965851962566376, 'learning_rate': 1.480050435407957e-05, 'epoch': 6.53}\n",
      "{'loss': 0.0029, 'grad_norm': 0.08592263609170914, 'learning_rate': 1.4372819543160709e-05, 'epoch': 6.55}\n",
      "{'loss': 0.0042, 'grad_norm': 0.17821887135505676, 'learning_rate': 1.395092611428902e-05, 'epoch': 6.57}\n",
      "{'loss': 0.0045, 'grad_norm': 0.11630456149578094, 'learning_rate': 1.353485260216596e-05, 'epoch': 6.59}\n",
      "{'loss': 0.0017, 'grad_norm': 0.07981609553098679, 'learning_rate': 1.3124627147863733e-05, 'epoch': 6.61}\n",
      "{'loss': 0.0031, 'grad_norm': 0.12284409999847412, 'learning_rate': 1.2720277496922029e-05, 'epoch': 6.63}\n",
      "{'loss': 0.0027, 'grad_norm': 0.10406241565942764, 'learning_rate': 1.2321830997471328e-05, 'epoch': 6.65}\n",
      "{'loss': 0.0045, 'grad_norm': 0.14063760638237, 'learning_rate': 1.1929314598383423e-05, 'epoch': 6.67}\n",
      "{'loss': 0.0044, 'grad_norm': 0.10559327155351639, 'learning_rate': 1.1542754847448546e-05, 'epoch': 6.69}\n",
      "{'loss': 0.0029, 'grad_norm': 0.11581382900476456, 'learning_rate': 1.1162177889579905e-05, 'epoch': 6.71}\n",
      "{'loss': 0.0221, 'grad_norm': 0.35678839683532715, 'learning_rate': 1.0787609465045389e-05, 'epoch': 6.73}\n",
      "{'loss': 0.0187, 'grad_norm': 0.2389489859342575, 'learning_rate': 1.0419074907726579e-05, 'epoch': 6.75}\n",
      "{'loss': 0.004, 'grad_norm': 0.13368289172649384, 'learning_rate': 1.0056599143405243e-05, 'epoch': 6.77}\n",
      "{'loss': 0.0034, 'grad_norm': 0.12654997408390045, 'learning_rate': 9.700206688077706e-06, 'epoch': 6.79}\n",
      "{'loss': 0.0148, 'grad_norm': 0.20387041568756104, 'learning_rate': 9.349921646296423e-06, 'epoch': 6.81}\n",
      "{'loss': 0.0118, 'grad_norm': 0.20395894348621368, 'learning_rate': 9.00576770953987e-06, 'epoch': 6.83}\n",
      "{'loss': 0.0022, 'grad_norm': 0.08404043316841125, 'learning_rate': 8.667768154610123e-06, 'epoch': 6.85}\n",
      "{'loss': 0.0022, 'grad_norm': 0.09001162648200989, 'learning_rate': 8.335945842058523e-06, 'epoch': 6.87}\n",
      "{'loss': 0.0045, 'grad_norm': 0.15968875586986542, 'learning_rate': 8.010323214639492e-06, 'epoch': 6.89}\n",
      "{'loss': 0.0056, 'grad_norm': 0.13917836546897888, 'learning_rate': 7.690922295792646e-06, 'epoch': 6.91}\n",
      "{'loss': 0.0351, 'grad_norm': 0.4149051308631897, 'learning_rate': 7.377764688153243e-06, 'epoch': 6.93}\n",
      "{'loss': 0.0051, 'grad_norm': 0.47354087233543396, 'learning_rate': 7.070871572091076e-06, 'epoch': 6.95}\n",
      "{'loss': 0.0024, 'grad_norm': 0.08451277762651443, 'learning_rate': 6.770263704277957e-06, 'epoch': 6.97}\n",
      "{'loss': 0.0148, 'grad_norm': 0.27117273211479187, 'learning_rate': 6.4759614162838375e-06, 'epoch': 6.99}\n",
      "{'loss': 0.013, 'grad_norm': 0.1960122287273407, 'learning_rate': 6.187984613201703e-06, 'epoch': 7.02}\n",
      " 89%|████████████████████████████████████▌    | 350/392 [13:59<04:25,  6.33s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.32it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.08it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  5.50it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  5.80it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  5.78it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.02it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.15it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.18782468140125275, 'eval_runtime': 2.6197, 'eval_samples_per_second': 12.215, 'eval_steps_per_second': 6.107, 'epoch': 7.02}\n",
      " 89%|████████████████████████████████████▌    | 350/392 [14:01<04:25,  6.33s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.41it/s]\u001b[A\n",
      "{'loss': 0.005, 'grad_norm': 0.12101130187511444, 'learning_rate': 5.906352772301193e-06, 'epoch': 7.04}\n",
      "{'loss': 0.0035, 'grad_norm': 0.12571699917316437, 'learning_rate': 5.6310849417114734e-06, 'epoch': 7.06}\n",
      "{'loss': 0.004, 'grad_norm': 0.11701083928346634, 'learning_rate': 5.3621997391326565e-06, 'epoch': 7.08}\n",
      "{'loss': 0.0127, 'grad_norm': 0.18677416443824768, 'learning_rate': 5.099715350576817e-06, 'epoch': 7.1}\n",
      "{'loss': 0.004, 'grad_norm': 0.20231680572032928, 'learning_rate': 4.8436495291378615e-06, 'epoch': 7.12}\n",
      "{'loss': 0.0037, 'grad_norm': 0.11733204871416092, 'learning_rate': 4.594019593790799e-06, 'epoch': 7.14}\n",
      "{'loss': 0.0112, 'grad_norm': 0.15463045239448547, 'learning_rate': 4.350842428220469e-06, 'epoch': 7.16}\n",
      "{'loss': 0.012, 'grad_norm': 0.32215532660484314, 'learning_rate': 4.1141344796795436e-06, 'epoch': 7.18}\n",
      "{'loss': 0.0051, 'grad_norm': 0.13707734644412994, 'learning_rate': 3.883911757876058e-06, 'epoch': 7.2}\n",
      "{'loss': 0.0028, 'grad_norm': 0.09179352968931198, 'learning_rate': 3.6601898338907703e-06, 'epoch': 7.22}\n",
      "{'loss': 0.0016, 'grad_norm': 0.056140702217817307, 'learning_rate': 3.4429838391238255e-06, 'epoch': 7.24}\n",
      "{'loss': 0.0038, 'grad_norm': 0.12462849169969559, 'learning_rate': 3.232308464271505e-06, 'epoch': 7.26}\n",
      "{'loss': 0.0097, 'grad_norm': 0.13792628049850464, 'learning_rate': 3.028177958332512e-06, 'epoch': 7.28}\n",
      "{'loss': 0.0041, 'grad_norm': 0.11283168196678162, 'learning_rate': 2.8306061276442752e-06, 'epoch': 7.3}\n",
      "{'loss': 0.0183, 'grad_norm': 0.30881497263908386, 'learning_rate': 2.6396063349491627e-06, 'epoch': 7.32}\n",
      "{'loss': 0.0058, 'grad_norm': 0.14102855324745178, 'learning_rate': 2.455191498490739e-06, 'epoch': 7.35}\n",
      "{'loss': 0.0033, 'grad_norm': 0.10643517225980759, 'learning_rate': 2.27737409113995e-06, 'epoch': 7.37}\n",
      "{'loss': 0.0046, 'grad_norm': 0.14897513389587402, 'learning_rate': 2.1061661395516018e-06, 'epoch': 7.39}\n",
      "{'loss': 0.0026, 'grad_norm': 0.09592656046152115, 'learning_rate': 1.9415792233508977e-06, 'epoch': 7.41}\n",
      "{'loss': 0.0044, 'grad_norm': 0.12270628660917282, 'learning_rate': 1.783624474350276e-06, 'epoch': 7.43}\n",
      "{'loss': 0.0055, 'grad_norm': 0.11642420291900635, 'learning_rate': 1.6323125757964797e-06, 'epoch': 7.45}\n",
      "{'loss': 0.0018, 'grad_norm': 0.05360971763730049, 'learning_rate': 1.4876537616480334e-06, 'epoch': 7.47}\n",
      "{'loss': 0.0084, 'grad_norm': 0.11997837573289871, 'learning_rate': 1.349657815883032e-06, 'epoch': 7.49}\n",
      "{'loss': 0.0035, 'grad_norm': 0.13748043775558472, 'learning_rate': 1.2183340718374681e-06, 'epoch': 7.51}\n",
      "{'loss': 0.0063, 'grad_norm': 0.14650686085224152, 'learning_rate': 1.0936914115738717e-06, 'epoch': 7.53}\n",
      " 96%|███████████████████████████████████████▏ | 375/392 [14:51<00:33,  1.98s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.31it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.33it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.29it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.07it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  6.81it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.34it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  5.75it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  5.99it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  5.91it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.13it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.23it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1868133544921875, 'eval_runtime': 2.5931, 'eval_samples_per_second': 12.34, 'eval_steps_per_second': 6.17, 'epoch': 7.53}\n",
      " 96%|███████████████████████████████████████▏ | 375/392 [14:53<00:33,  1.98s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.47it/s]\u001b[A\n",
      "{'loss': 0.0028, 'grad_norm': 0.09993703663349152, 'learning_rate': 9.75738265280679e-07, 'epoch': 7.55}\n",
      "{'loss': 0.0146, 'grad_norm': 0.21268191933631897, 'learning_rate': 8.644826107019888e-07, 'epoch': 7.57}\n",
      "{'loss': 0.0056, 'grad_norm': 0.15130984783172607, 'learning_rate': 7.599319725980048e-07, 'epoch': 7.59}\n",
      "{'loss': 0.0053, 'grad_norm': 0.09816008061170578, 'learning_rate': 6.620934222361319e-07, 'epoch': 7.61}\n",
      "{'loss': 0.0167, 'grad_norm': 0.17171011865139008, 'learning_rate': 5.709735769126478e-07, 'epoch': 7.63}\n",
      "{'loss': 0.0364, 'grad_norm': 0.3565688729286194, 'learning_rate': 4.865785995052052e-07, 'epoch': 7.65}\n",
      "{'loss': 0.0035, 'grad_norm': 0.09895605593919754, 'learning_rate': 4.089141980559763e-07, 'epoch': 7.67}\n",
      "{'loss': 0.0035, 'grad_norm': 0.10779031366109848, 'learning_rate': 3.379856253855951e-07, 'epoch': 7.69}\n",
      "{'loss': 0.0092, 'grad_norm': 0.15122254192829132, 'learning_rate': 2.73797678737886e-07, 'epoch': 7.71}\n",
      "{'loss': 0.0034, 'grad_norm': 0.11130926012992859, 'learning_rate': 2.163546994553789e-07, 'epoch': 7.73}\n",
      "{'loss': 0.0032, 'grad_norm': 0.10637969523668289, 'learning_rate': 1.6566057268574408e-07, 'epoch': 7.75}\n",
      "{'loss': 0.013, 'grad_norm': 0.21042989194393158, 'learning_rate': 1.2171872711895794e-07, 'epoch': 7.77}\n",
      "{'loss': 0.0049, 'grad_norm': 0.1393221914768219, 'learning_rate': 8.453213475543287e-08, 'epoch': 7.79}\n",
      "{'loss': 0.0077, 'grad_norm': 0.10322490334510803, 'learning_rate': 5.4103310704989305e-08, 'epoch': 7.81}\n",
      "{'loss': 0.0089, 'grad_norm': 0.1787729263305664, 'learning_rate': 3.0434313016780567e-08, 'epoch': 7.83}\n",
      "{'loss': 0.0057, 'grad_norm': 0.12654027342796326, 'learning_rate': 1.3526742540070913e-08, 'epoch': 7.85}\n",
      "{'loss': 0.0086, 'grad_norm': 0.09367172420024872, 'learning_rate': 3.3817428159443886e-09, 'epoch': 7.87}\n",
      "{'train_runtime': 928.2708, 'train_samples_per_second': 3.378, 'train_steps_per_second': 0.422, 'train_loss': 0.07523051869541131, 'epoch': 7.87}\n",
      "100%|█████████████████████████████████████████| 392/392 [15:28<00:00,  2.37s/it]\n",
      "[2025-10-07 10:24:52,242] [INFO] [axolotl.train.save_trained_model:244] [PID:3063140] [RANK:0] Training completed! Saving trained model to ./out-Qwen2.5-0.5B-Instruct.\u001b[39m\n",
      "[2025-10-07 10:24:52,630] [INFO] [axolotl.train.save_trained_model:341] [PID:3063140] [RANK:0] Model successfully saved to ./out-Qwen2.5-0.5B-Instruct\u001b[39m\n",
      "\u001b[0mCPU times: user 5.81 s, sys: 710 ms, total: 6.52 s\n",
      "Wall time: 18min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/accelerate launch -m axolotl.cli.train {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the LoRA/DoRA into the base model (for inference & quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-07 10:25:00,767] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:3066238] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "\u001b[33m[2025-10-07 10:25:00,768] [WARNING] [axolotl.utils.schemas.config.check_sample_packing_wo_flash:482] [PID:3066238] [RANK:0] sample_packing without flash, sdp, xformers or flex attention does not handle cross sample decontamination.\u001b[39m\n",
      "\u001b[33m[2025-10-07 10:25:00,768] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:871] [PID:3066238] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2025-10-07 10:25:01,035] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:3066238] [RANK:0] cuda memory usage baseline: 0.000GB (+0.818GB misc)\u001b[39m\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-10-07 10:25:01,046] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:318] [PID:3066238] [RANK:0] loading tokenizer... Qwen/Qwen2.5-0.5B-Instruct\u001b[39m\n",
      "[2025-10-07 10:25:01,653] [INFO] [axolotl.loaders.tokenizer.load_tokenizer:294] [PID:3066238] [RANK:0] No Chat template selected. Consider adding a chat template for easier inference.\u001b[39m\n",
      "[2025-10-07 10:25:01,653] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:321] [PID:3066238] [RANK:0] loading model...\u001b[39m\n",
      "[2025-10-07 10:25:03,281] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:3066238] [RANK:0] cuda memory usage after model load: 0.920GB (+0.263GB cache, +1.223GB misc)\u001b[39m\n",
      "[2025-10-07 10:25:03,292] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:308] [PID:3066238] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-10-07 10:25:03,294] [INFO] [axolotl.loaders.adapter.load_lora:82] [PID:3066238] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
      "trainable params: 8,798,208 || all params: 502,830,976 || trainable%: 1.7497\n",
      "[2025-10-07 10:25:03,949] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:3066238] [RANK:0] cuda memory usage after adapters: 0.953GB (+0.805GB cache, +1.301GB misc)\u001b[39m\n",
      "[2025-10-07 10:25:04,357] [INFO] [axolotl.cli.merge_lora.do_merge_lora:31] [PID:3066238] [RANK:0] Running merge of LoRA with base model...\u001b[39m\n",
      "Unloading and merging model: 100%|██████████| 487/487 [00:00<00:00, 4224.62it/s]\n",
      "[2025-10-07 10:25:04,477] [INFO] [axolotl.cli.merge_lora.do_merge_lora:44] [PID:3066238] [RANK:0] Saving merged model to: out-Qwen2.5-0.5B-Instruct/merged...\u001b[39m\n",
      "\u001b[0mCPU times: user 105 ms, sys: 28.2 ms, total: 133 ms\n",
      "Wall time: 18 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/axolotl merge-lora {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the merged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-07 11:10:38 [__init__.py:216] Automatically detected platform cuda.\n",
      "INFO 10-07 11:10:43 [utils.py:328] non-default args: {'max_model_len': 8192, 'disable_log_stats': True, 'model': 'out-Qwen2.5-0.5B-Instruct/merged'}\n",
      "INFO 10-07 11:10:55 [__init__.py:742] Resolved architecture: Qwen2ForCausalLM\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "INFO 10-07 11:10:55 [__init__.py:1815] Using max model len 8192\n",
      "INFO 10-07 11:10:57 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:10:57 [core.py:654] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:10:57 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='out-Qwen2.5-0.5B-Instruct/merged', speculative_config=None, tokenizer='out-Qwen2.5-0.5B-Instruct/merged', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=out-Qwen2.5-0.5B-Instruct/merged, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "[W1007 11:11:01.912692551 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:01 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m WARNING 10-07 11:11:01 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:01 [gpu_model_runner.py:2338] Starting to load model out-Qwen2.5-0.5B-Instruct/merged...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:02 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:02 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.97it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  1.96it/s]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m \n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:02 [default_loader.py:268] Loading weights took 0.52 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:03 [gpu_model_runner.py:2392] Model loading took 0.9277 GiB and 0.799085 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:10 [backends.py:539] Using cache directory: /home/oisuomin/.cache/vllm/torch_compile_cache/25357a56fc/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:10 [backends.py:550] Dynamo bytecode transform time: 6.95 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:13 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 2.735 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:14 [monitor.py:34] torch.compile takes 6.95 s in total\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:14 [gpu_worker.py:298] Available KV cache memory: 68.92 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:15 [kv_cache_utils.py:864] GPU KV cache size: 6,022,416 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:15 [kv_cache_utils.py:868] Maximum concurrency for 8,192 tokens per request: 735.16x\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|█| 67/67 [00:01<00\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:17 [gpu_model_runner.py:3118] Graph capturing finished in 2 secs, took 1.37 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:17 [gpu_worker.py:391] Free memory on device (78.7/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.27 GiB). Actual usage is 0.93 GiB for weight, 1.4 GiB for peak activation, 0.02 GiB for non-torch memory, and 1.37 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=72378323968` to fit into requested memory, or `--kv-cache-memory=80359134208` to fully utilize gpu memory. Current kv cache memory in use is 74003616768 bytes.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3081130)\u001b[0;0m INFO 10-07 11:11:17 [core.py:218] init engine (profile, create kv cache, warmup model) took 14.36 seconds\n",
      "INFO 10-07 11:11:18 [llm.py:295] Supported_tasks: ['generate']\n",
      "INFO 10-07 11:11:18 [__init__.py:36] No IOProcessor plugins requested by the model\n",
      "Adding requests: 100%|███████████████████████| 182/182 [00:00<00:00, 310.42it/s]\n",
      "Processed prompts: 100%|█| 182/182 [00:12<00:00, 14.22it/s, est. speed input: 34\n",
      "Errors: 2 out of 182 records (1.10%)\n",
      "ERROR 10-07 11:11:32 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.\n",
      "| language   | field     |   mean |   size |\n",
      "|------------|-----------|--------|--------|\n",
      "| en         | alt_title | 0.7705 |     61 |\n",
      "| en         | creator   | 0.8117 |     61 |\n",
      "| en         | doi       | 0.9672 |     61 |\n",
      "| en         | e-isbn    | 0.8306 |     61 |\n",
      "| en         | e-issn    | 0.9344 |     61 |\n",
      "| en         | language  | 0.9672 |     61 |\n",
      "| en         | p-isbn    | 0.8361 |     61 |\n",
      "| en         | p-issn    | 0.9180 |     61 |\n",
      "| en         | publisher | 0.6393 |     61 |\n",
      "| en         | title     | 0.8525 |     61 |\n",
      "| en         | type_coar | 0.8197 |     61 |\n",
      "| en         | year      | 0.9016 |     61 |\n",
      "| fi         | alt_title | 0.7945 |     73 |\n",
      "| fi         | creator   | 0.7712 |     73 |\n",
      "| fi         | doi       | 1.0000 |     73 |\n",
      "| fi         | e-isbn    | 1.0000 |     73 |\n",
      "| fi         | e-issn    | 0.9452 |     73 |\n",
      "| fi         | language  | 0.9863 |     73 |\n",
      "| fi         | p-isbn    | 0.9863 |     73 |\n",
      "| fi         | p-issn    | 0.9726 |     73 |\n",
      "| fi         | publisher | 0.8447 |     73 |\n",
      "| fi         | title     | 0.6849 |     73 |\n",
      "| fi         | type_coar | 0.8493 |     73 |\n",
      "| fi         | year      | 0.8493 |     73 |\n",
      "| se         | alt_title | 1.0000 |      3 |\n",
      "| se         | creator   | 0.6667 |      3 |\n",
      "| se         | doi       | 1.0000 |      3 |\n",
      "| se         | e-isbn    | 1.0000 |      3 |\n",
      "| se         | e-issn    | 1.0000 |      3 |\n",
      "| se         | language  | 1.0000 |      3 |\n",
      "| se         | p-isbn    | 1.0000 |      3 |\n",
      "| se         | p-issn    | 1.0000 |      3 |\n",
      "| se         | publisher | 0.0000 |      3 |\n",
      "| se         | title     | 0.3333 |      3 |\n",
      "| se         | type_coar | 0.6667 |      3 |\n",
      "| se         | year      | 1.0000 |      3 |\n",
      "| sv         | alt_title | 0.8000 |     45 |\n",
      "| sv         | creator   | 0.8639 |     45 |\n",
      "| sv         | doi       | 1.0000 |     45 |\n",
      "| sv         | e-isbn    | 0.9333 |     45 |\n",
      "| sv         | e-issn    | 0.9556 |     45 |\n",
      "| sv         | language  | 1.0000 |     45 |\n",
      "| sv         | p-isbn    | 0.9111 |     45 |\n",
      "| sv         | p-issn    | 1.0000 |     45 |\n",
      "| sv         | publisher | 0.7556 |     45 |\n",
      "| sv         | title     | 0.7556 |     45 |\n",
      "| sv         | type_coar | 0.9333 |     45 |\n",
      "| sv         | year      | 0.8889 |     45 |\n",
      "CPU times: user 452 ms, sys: 70.5 ms, total: 522 ms\n",
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "resultfile = f\"../../eval/results-{MODEL_SHORT_NAME.replace('.','_')}.md\"\n",
    "\n",
    "# evaluate using the evaluate-model script, which needs venv with vLLM installed\n",
    "!../dspy/venv/bin/python evaluate-model.py out-{MODEL_SHORT_NAME}/merged axolotl-test.jsonl {resultfile}\n",
    "!cat {resultfile}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greylitlm-axolotl",
   "language": "python",
   "name": "greylitlm-axolotl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
