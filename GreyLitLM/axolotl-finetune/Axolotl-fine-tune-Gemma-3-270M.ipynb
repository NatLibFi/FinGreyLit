{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune Gemma-3-270M-it model using Axolotl framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n",
      "BF16 is supported? True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print('GPU available?', torch.cuda.is_available())\n",
    "print('BF16 is supported?', torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/appl/easybuild/opt/CUDA/12.6.0\n"
     ]
    }
   ],
   "source": [
    "!printenv CUDA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name etc.\n",
    "\n",
    "MODEL_NAME = \"google/gemma-3-270m-it\"\n",
    "MODEL_SHORT_NAME = MODEL_NAME.split('/')[-1]\n",
    "SUFFIX = \"FinGreyLit\"\n",
    "#SLICE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 640 train records\n",
      "Wrote 182 test records\n",
      "Wrote 32 eval records\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare fine-tuning dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of test set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "EVAL_SIZE = 32  # how many documents to evaluate (i.e. calculate loss) on during fine-tuning\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    output = json.dumps(sample[\"ground_truth\"])\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    # ShareGPT format\n",
    "    conversations = [\n",
    "        {'from': 'system', 'value': SYSTEM_PROMPT},\n",
    "        {'from': 'user', 'value': INSTRUCTION + \"\\n\\n\" + input_},\n",
    "        {'from': 'assistant', 'value': output}\n",
    "    ]\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "def write_jsonl(records, filename):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for record in records:\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "train_recs = dataset_to_records(train_files)\n",
    "random.shuffle(train_recs)\n",
    "write_jsonl(train_recs, \"axolotl-train.jsonl\")\n",
    "print(f\"Wrote {len(train_recs)} train records\")\n",
    "\n",
    "test_recs = dataset_to_records(test_files)\n",
    "write_jsonl(test_recs, \"axolotl-test.jsonl\")\n",
    "print(f\"Wrote {len(test_recs)} test records\")\n",
    "\n",
    "eval_recs = random.sample(test_recs, EVAL_SIZE)\n",
    "write_jsonl(eval_recs, \"axolotl-eval.jsonl\")\n",
    "print(f\"Wrote {len(eval_recs)} eval records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Axolotl configuration file\n",
    "\n",
    "CONFIG_FILE = f\"config-{MODEL_SHORT_NAME}.yml\"\n",
    "\n",
    "\n",
    "CONFIG = f\"\"\"\n",
    "base_model: {MODEL_NAME}\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: false\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: axolotl-train.jsonl\n",
    "    type: chat_template\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "\n",
    "test_datasets:\n",
    "  - path: axolotl-eval.jsonl\n",
    "    type: chat_template\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "\n",
    "output_dir: ./out-{MODEL_SHORT_NAME}\n",
    "\n",
    "chat_template: gemma3\n",
    "eot_tokens:\n",
    "  - <end_of_turn>\n",
    "\n",
    "peft_use_dora: true\n",
    "adapter: lora\n",
    "lora_r: 32\n",
    "lora_alpha: 16\n",
    "lora_dropout: 0.05\n",
    "lora_target_linear: true\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "eval_batch_size: 2\n",
    "num_epochs: 8\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: true\n",
    "fp16: false\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true  # true: saves VRAM but is slower to train\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 2\n",
    "eval_table_size:\n",
    "eval_table_max_new_tokens: 128\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as outfile:\n",
    "    print(CONFIG, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2025-10-07 09:16:25,295] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:3056496] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "[2025-10-07 09:16:25,296] [INFO] [axolotl.utils.schemas.config.hint_sample_packing_padding:539] [PID:3056496] [RANK:0] Setting `pad_to_sequence_len: true` to prevent memory leaks when sample_packing\u001b[39m\n",
      "\u001b[33m[2025-10-07 09:16:25,296] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:871] [PID:3056496] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2025-10-07 09:16:25,547] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:3056496] [RANK:0] cuda memory usage baseline: 0.000GB (+0.818GB misc)\u001b[39m\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-10-07 09:16:27,107] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:3056496] [RANK:0] Unable to find prepared dataset in last_run_prepared/9995208875383310c98f856a93500d35\u001b[39m\n",
      "[2025-10-07 09:16:27,107] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:3056496] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-10-07 09:16:27,107] [WARNING] [axolotl.utils.data.sft._load_raw_datasets:312] [PID:3056496] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\u001b[39m\n",
      "Generating train split: 640 examples [00:00, 18229.17 examples/s]\n",
      "[2025-10-07 09:16:27,685] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:3056496] [RANK:0] Loading dataset: axolotl-train.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
      "[2025-10-07 09:16:27,757] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:3056496] [RANK:0] Using chat template:\n",
      "---\n",
      "{{ bos_token }}\n",
      "{%- if messages[0]['role'] == 'system' -%}\n",
      "    {%- if messages[0]['content'] is string -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- else -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- endif -%}\n",
      "    {%- set loop_messages = messages[1:] -%}\n",
      "{%- else -%}\n",
      "    {%- set first_user_prefix = \"\" -%}\n",
      "    {%- set loop_messages = messages -%}\n",
      "{%- endif -%}\n",
      "{%- for message in loop_messages -%}\n",
      "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n",
      "        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
      "    {%- endif -%}\n",
      "    {%- if (message['role'] == 'assistant') -%}\n",
      "        {%- set role = \"model\" -%}\n",
      "    {%- else -%}\n",
      "        {%- set role = message['role'] -%}\n",
      "    {%- endif -%}\n",
      "    {{ '<start_of_turn>' + role + '\n",
      "' + (first_user_prefix if loop.first else \"\") }}\n",
      "    {%- if message['content'] is string -%}\n",
      "        {{ message['content'] | trim }}\n",
      "    {%- elif message['content'] is iterable -%}\n",
      "        {%- for item in message['content'] -%}\n",
      "            {%- if item['type'] == 'image' -%}\n",
      "                {{ '<start_of_image>' }}\n",
      "            {%- elif item['type'] == 'text' -%}\n",
      "                {{ item['text'] | trim }}\n",
      "            {%- endif -%}\n",
      "        {%- endfor -%}\n",
      "    {%- else -%}\n",
      "        {{ raise_exception(\"Invalid content type\") }}\n",
      "    {%- endif -%}\n",
      "    {{ '<end_of_turn>\n",
      "' }}\n",
      "{%- endfor -%}\n",
      "{%- if add_generation_prompt -%}\n",
      "    {{'<start_of_turn>model\n",
      "'}}\n",
      "{%- endif -%}\n",
      "\n",
      "---\u001b[39m\n",
      "Tokenizing Prompts (num_proc=32): 100%|█| 640/640 [00:11<00:00, 54.65 examples/s\n",
      "[2025-10-07 09:16:40,154] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:3056496] [RANK:0] min_input_len: 388\u001b[39m\n",
      "[2025-10-07 09:16:40,154] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:3056496] [RANK:0] max_input_len: 8994\u001b[39m\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 640/640 [00:00<00:00, 1662.22 exa\n",
      "\u001b[33m[2025-10-07 09:16:41,831] [WARNING] [axolotl.utils.data.utils.drop_long_seq_in_dataset:201] [PID:3056496] [RANK:0] Dropped 5 long samples from dataset\u001b[39m\n",
      "Drop Samples with Zero Trainable Tokens (num_proc=32): 100%|█| 635/635 [00:00<00\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 635/635 [00:00<00\n",
      "Saving the dataset (1/1 shards): 100%|█| 635/635 [00:00<00:00, 13067.52 examples\n",
      "[2025-10-07 09:16:44,678] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:3056496] [RANK:0] Unable to find prepared dataset in last_run_prepared/3e9c7502992f1e22c561f1905c168a52\u001b[39m\n",
      "[2025-10-07 09:16:44,678] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:3056496] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-10-07 09:16:44,678] [WARNING] [axolotl.utils.data.sft._load_raw_datasets:312] [PID:3056496] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\u001b[39m\n",
      "Generating train split: 32 examples [00:00, 2893.68 examples/s]\n",
      "[2025-10-07 09:16:45,138] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:3056496] [RANK:0] Loading dataset: axolotl-eval.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
      "[2025-10-07 09:16:45,205] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:3056496] [RANK:0] Using chat template:\n",
      "---\n",
      "{{ bos_token }}\n",
      "{%- if messages[0]['role'] == 'system' -%}\n",
      "    {%- if messages[0]['content'] is string -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- else -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- endif -%}\n",
      "    {%- set loop_messages = messages[1:] -%}\n",
      "{%- else -%}\n",
      "    {%- set first_user_prefix = \"\" -%}\n",
      "    {%- set loop_messages = messages -%}\n",
      "{%- endif -%}\n",
      "{%- for message in loop_messages -%}\n",
      "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n",
      "        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
      "    {%- endif -%}\n",
      "    {%- if (message['role'] == 'assistant') -%}\n",
      "        {%- set role = \"model\" -%}\n",
      "    {%- else -%}\n",
      "        {%- set role = message['role'] -%}\n",
      "    {%- endif -%}\n",
      "    {{ '<start_of_turn>' + role + '\n",
      "' + (first_user_prefix if loop.first else \"\") }}\n",
      "    {%- if message['content'] is string -%}\n",
      "        {{ message['content'] | trim }}\n",
      "    {%- elif message['content'] is iterable -%}\n",
      "        {%- for item in message['content'] -%}\n",
      "            {%- if item['type'] == 'image' -%}\n",
      "                {{ '<start_of_image>' }}\n",
      "            {%- elif item['type'] == 'text' -%}\n",
      "                {{ item['text'] | trim }}\n",
      "            {%- endif -%}\n",
      "        {%- endfor -%}\n",
      "    {%- else -%}\n",
      "        {{ raise_exception(\"Invalid content type\") }}\n",
      "    {%- endif -%}\n",
      "    {{ '<end_of_turn>\n",
      "' }}\n",
      "{%- endfor -%}\n",
      "{%- if add_generation_prompt -%}\n",
      "    {{'<start_of_turn>model\n",
      "'}}\n",
      "{%- endif -%}\n",
      "\n",
      "---\u001b[39m\n",
      "Tokenizing Prompts (num_proc=32): 100%|██| 32/32 [00:11<00:00,  2.83 examples/s]\n",
      "[2025-10-07 09:16:57,277] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:3056496] [RANK:0] min_input_len: 526\u001b[39m\n",
      "[2025-10-07 09:16:57,277] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:3056496] [RANK:0] max_input_len: 3316\u001b[39m\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 32/32 [00:00<00:00, 171.14 exampl\n",
      "Drop Samples with Zero Trainable Tokens (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "Saving the dataset (1/1 shards): 100%|█| 32/32 [00:00<00:00, 2280.06 examples/s]\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m[2025-10-07 09:18:03,381] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:3056496] [RANK:0] gather_len_batches: [200]\u001b[39m\n",
      "[2025-10-07 09:18:03,382] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:123] [PID:3056496] [RANK:0] Maximum number of steps set at 400\u001b[39m\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "[2025-10-07 09:18:12,046] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:308] [PID:3056496] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-10-07 09:18:12,104] [INFO] [axolotl.loaders.adapter.load_lora:82] [PID:3056496] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
      "[2025-10-07 09:18:12,104] [INFO] [axolotl.loaders.adapter.load_lora:99] [PID:3056496] [RANK:0] Initializing LoRA weights using dora. This might take longer.\u001b[39m\n",
      "trainable params: 7,718,400 || all params: 275,817,216 || trainable%: 2.7984\n",
      "[2025-10-07 09:18:16,503] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:3056496] [RANK:0] cuda memory usage after adapters: 0.000GB ()\u001b[39m\n",
      "[2025-10-07 09:18:20,669] [WARNING] [accelerate.utils.other.check_os_kernel:441] [PID:3056496] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n",
      "[2025-10-07 09:18:24,371] [INFO] [axolotl.train.save_initial_configs:403] [PID:3056496] [RANK:0] Pre-saving adapter config to ./out-gemma-3-270m-it...\u001b[39m\n",
      "[2025-10-07 09:18:24,372] [INFO] [axolotl.train.save_initial_configs:407] [PID:3056496] [RANK:0] Pre-saving tokenizer to ./out-gemma-3-270m-it...\u001b[39m\n",
      "[2025-10-07 09:18:24,701] [INFO] [axolotl.train.save_initial_configs:410] [PID:3056496] [RANK:0] Pre-saving model config to ./out-gemma-3-270m-it...\u001b[39m\n",
      "[2025-10-07 09:18:24,709] [INFO] [axolotl.train.execute_training:225] [PID:3056496] [RANK:0] Starting trainer...\u001b[39m\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m[2025-10-07 09:19:27,420] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:3056496] [RANK:0] gather_len_batches: [200]\u001b[39m\n",
      "  0%|                                                   | 0/400 [00:00<?, ?it/s]You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:00, 15.41it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  6.72it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  5.70it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  5.42it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  5.17it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  5.06it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.72it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.79it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.78it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.78it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.54it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.66it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  4.68it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.521451473236084, 'eval_runtime': 3.8008, 'eval_samples_per_second': 8.419, 'eval_steps_per_second': 4.21, 'epoch': 0}\n",
      "  0%|                                                   | 0/400 [00:03<?, ?it/s]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.82it/s]\u001b[A\n",
      "                                                                                \u001b[A\u001b[0m\u001b[0mIt is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `flash_attention_2`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n",
      "{'loss': 2.4122, 'grad_norm': 5.87448787689209, 'learning_rate': 0.0, 'epoch': 0.02}\n",
      "  0%|                                         | 1/400 [00:21<2:20:56, 21.20s/it][2025-10-07 09:19:51,142] [INFO] [axolotl.utils.callbacks.log_gpu_memory_usage:107] [PID:3056496] [RANK:0] cuda memory usage while training: 0.561GB (+28.660GB cache, +1.326GB misc)\u001b[39m\n",
      "{'loss': 2.1592, 'grad_norm': 5.155996322631836, 'learning_rate': 2e-05, 'epoch': 0.04}\n",
      "{'loss': 2.0193, 'grad_norm': 4.649717330932617, 'learning_rate': 4e-05, 'epoch': 0.06}\n",
      "{'loss': 2.5398, 'grad_norm': 5.143614292144775, 'learning_rate': 6e-05, 'epoch': 0.08}\n",
      "{'loss': 1.8483, 'grad_norm': 3.8261263370513916, 'learning_rate': 8e-05, 'epoch': 0.1}\n",
      "{'loss': 1.6106, 'grad_norm': 3.0719118118286133, 'learning_rate': 0.0001, 'epoch': 0.12}\n",
      "{'loss': 1.5599, 'grad_norm': 2.740431785583496, 'learning_rate': 0.00012, 'epoch': 0.14}\n",
      "{'loss': 1.4287, 'grad_norm': 2.0245981216430664, 'learning_rate': 0.00014, 'epoch': 0.16}\n",
      "{'loss': 1.3324, 'grad_norm': 1.6536413431167603, 'learning_rate': 0.00016, 'epoch': 0.18}\n",
      "{'loss': 1.1769, 'grad_norm': 1.7328206300735474, 'learning_rate': 0.00018, 'epoch': 0.2}\n",
      "{'loss': 0.9439, 'grad_norm': 1.3708906173706055, 'learning_rate': 0.0002, 'epoch': 0.22}\n",
      "{'loss': 1.0051, 'grad_norm': 1.4549943208694458, 'learning_rate': 0.0001999967555716528, 'epoch': 0.24}\n",
      "{'loss': 0.8703, 'grad_norm': 1.274669885635376, 'learning_rate': 0.00019998702249713748, 'epoch': 0.26}\n",
      "{'loss': 0.9219, 'grad_norm': 1.4755587577819824, 'learning_rate': 0.00019997080140801932, 'epoch': 0.28}\n",
      "{'loss': 0.8697, 'grad_norm': 1.399580717086792, 'learning_rate': 0.0001999480933568615, 'epoch': 0.3}\n",
      "{'loss': 0.841, 'grad_norm': 1.1113054752349854, 'learning_rate': 0.00019991889981715698, 'epoch': 0.32}\n",
      "{'loss': 0.6157, 'grad_norm': 1.0465810298919678, 'learning_rate': 0.00019988322268323268, 'epoch': 0.34}\n",
      "{'loss': 0.6842, 'grad_norm': 0.9840162992477417, 'learning_rate': 0.00019984106427012668, 'epoch': 0.36}\n",
      "{'loss': 0.66, 'grad_norm': 0.8761158585548401, 'learning_rate': 0.00019979242731343804, 'epoch': 0.38}\n",
      "{'loss': 0.494, 'grad_norm': 0.8823120594024658, 'learning_rate': 0.00019973731496914914, 'epoch': 0.4}\n",
      "{'loss': 0.492, 'grad_norm': 0.9126423001289368, 'learning_rate': 0.00019967573081342103, 'epoch': 0.42}\n",
      "{'loss': 0.4487, 'grad_norm': 0.9960971474647522, 'learning_rate': 0.0001996076788423613, 'epoch': 0.44}\n",
      "{'loss': 0.7354, 'grad_norm': 1.1519720554351807, 'learning_rate': 0.00019953316347176488, 'epoch': 0.46}\n",
      "{'loss': 0.5904, 'grad_norm': 0.9377411007881165, 'learning_rate': 0.00019945218953682734, 'epoch': 0.48}\n",
      "{'loss': 0.3899, 'grad_norm': 0.9594908356666565, 'learning_rate': 0.00019936476229183133, 'epoch': 0.5}\n",
      "  6%|██▋                                       | 25/400 [01:20<15:21,  2.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.83it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.5353316068649292, 'eval_runtime': 3.4747, 'eval_samples_per_second': 9.209, 'eval_steps_per_second': 4.605, 'epoch': 0.5}\n",
      "  6%|██▋                                       | 25/400 [01:23<15:21,  2.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "{'loss': 0.4634, 'grad_norm': 1.0240986347198486, 'learning_rate': 0.0001992708874098054, 'epoch': 0.52}\n",
      "{'loss': 0.4982, 'grad_norm': 1.0656381845474243, 'learning_rate': 0.0001991705709821562, 'epoch': 0.54}\n",
      "{'loss': 0.7022, 'grad_norm': 0.9359015226364136, 'learning_rate': 0.00019906381951827293, 'epoch': 0.56}\n",
      "{'loss': 0.3048, 'grad_norm': 0.8644123673439026, 'learning_rate': 0.0001989506399451051, 'epoch': 0.58}\n",
      "{'loss': 0.3715, 'grad_norm': 0.8615468740463257, 'learning_rate': 0.00019883103960671305, 'epoch': 0.6}\n",
      "{'loss': 0.3852, 'grad_norm': 0.7860567569732666, 'learning_rate': 0.00019870502626379127, 'epoch': 0.62}\n",
      "{'loss': 0.3542, 'grad_norm': 0.8460948467254639, 'learning_rate': 0.0001985726080931651, 'epoch': 0.64}\n",
      "{'loss': 0.4327, 'grad_norm': 0.8553018569946289, 'learning_rate': 0.00019843379368725977, 'epoch': 0.66}\n",
      "{'loss': 0.4227, 'grad_norm': 0.8828775882720947, 'learning_rate': 0.00019828859205354323, 'epoch': 0.68}\n",
      "{'loss': 0.3583, 'grad_norm': 0.6326623558998108, 'learning_rate': 0.00019813701261394136, 'epoch': 0.7}\n",
      "{'loss': 0.3428, 'grad_norm': 0.6130365133285522, 'learning_rate': 0.00019797906520422677, 'epoch': 0.72}\n",
      "{'loss': 0.346, 'grad_norm': 0.6798052191734314, 'learning_rate': 0.00019781476007338058, 'epoch': 0.74}\n",
      "{'loss': 0.3713, 'grad_norm': 0.8640207052230835, 'learning_rate': 0.00019764410788292722, 'epoch': 0.76}\n",
      "{'loss': 0.5578, 'grad_norm': 0.8771188855171204, 'learning_rate': 0.0001974671197062428, 'epoch': 0.78}\n",
      "{'loss': 0.3202, 'grad_norm': 0.713738203048706, 'learning_rate': 0.00019728380702783643, 'epoch': 0.8}\n",
      "{'loss': 0.3881, 'grad_norm': 0.72853684425354, 'learning_rate': 0.0001970941817426052, 'epoch': 0.82}\n",
      "{'loss': 0.2837, 'grad_norm': 0.7568292617797852, 'learning_rate': 0.00019689825615506207, 'epoch': 0.84}\n",
      "{'loss': 0.4536, 'grad_norm': 0.7798508405685425, 'learning_rate': 0.00019669604297853764, 'epoch': 0.86}\n",
      "{'loss': 0.3095, 'grad_norm': 0.6994364261627197, 'learning_rate': 0.00019648755533435518, 'epoch': 0.88}\n",
      "{'loss': 0.1858, 'grad_norm': 0.6136603951454163, 'learning_rate': 0.00019627280675097908, 'epoch': 0.9}\n",
      "{'loss': 0.4694, 'grad_norm': 0.7598215341567993, 'learning_rate': 0.00019605181116313724, 'epoch': 0.92}\n",
      "{'loss': 0.2251, 'grad_norm': 0.6915275454521179, 'learning_rate': 0.00019582458291091663, 'epoch': 0.94}\n",
      "{'loss': 0.2979, 'grad_norm': 0.7021480202674866, 'learning_rate': 0.0001955911367388329, 'epoch': 0.96}\n",
      "{'loss': 0.3888, 'grad_norm': 0.7228391766548157, 'learning_rate': 0.00019535148779487363, 'epoch': 0.98}\n",
      "{'loss': 0.5999, 'grad_norm': 0.9826788306236267, 'learning_rate': 0.00019510565162951537, 'epoch': 1.0}\n",
      " 12%|█████▎                                    | 50/400 [02:25<14:16,  2.45s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.84it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.12it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.03it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.83it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.65it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.33902397751808167, 'eval_runtime': 3.4759, 'eval_samples_per_second': 9.206, 'eval_steps_per_second': 4.603, 'epoch': 1.0}\n",
      " 12%|█████▎                                    | 50/400 [02:28<14:16,  2.45s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.80it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'loss': 0.4727, 'grad_norm': 0.7030892968177795, 'learning_rate': 0.00019485364419471454, 'epoch': 1.02}\n",
      "{'loss': 0.3295, 'grad_norm': 0.734971821308136, 'learning_rate': 0.00019459548184287253, 'epoch': 1.04}\n",
      "{'loss': 0.2841, 'grad_norm': 0.6435965299606323, 'learning_rate': 0.0001943311813257743, 'epoch': 1.06}\n",
      "{'loss': 0.2132, 'grad_norm': 0.5802095532417297, 'learning_rate': 0.00019406075979350174, 'epoch': 1.08}\n",
      "{'loss': 0.2867, 'grad_norm': 0.6593062877655029, 'learning_rate': 0.00019378423479332046, 'epoch': 1.1}\n",
      "{'loss': 0.2037, 'grad_norm': 0.45779159665107727, 'learning_rate': 0.0001935016242685415, 'epoch': 1.12}\n",
      "{'loss': 0.3072, 'grad_norm': 0.5062695741653442, 'learning_rate': 0.0001932129465573568, 'epoch': 1.14}\n",
      "{'loss': 0.1871, 'grad_norm': 0.4756486117839813, 'learning_rate': 0.00019291822039164933, 'epoch': 1.16}\n",
      "{'loss': 0.1724, 'grad_norm': 0.4838673174381256, 'learning_rate': 0.00019261746489577765, 'epoch': 1.18}\n",
      "{'loss': 0.205, 'grad_norm': 0.5561674237251282, 'learning_rate': 0.0001923106995853349, 'epoch': 1.2}\n",
      "{'loss': 0.3224, 'grad_norm': 0.634621262550354, 'learning_rate': 0.00019199794436588243, 'epoch': 1.22}\n",
      "{'loss': 0.1749, 'grad_norm': 0.41669559478759766, 'learning_rate': 0.00019167921953165825, 'epoch': 1.24}\n",
      "{'loss': 0.2435, 'grad_norm': 0.5458173751831055, 'learning_rate': 0.0001913545457642601, 'epoch': 1.26}\n",
      "{'loss': 0.2495, 'grad_norm': 0.5673225522041321, 'learning_rate': 0.00019102394413130346, 'epoch': 1.28}\n",
      "{'loss': 0.2079, 'grad_norm': 0.5533594489097595, 'learning_rate': 0.00019068743608505455, 'epoch': 1.3}\n",
      "{'loss': 0.2592, 'grad_norm': 0.5330437421798706, 'learning_rate': 0.00019034504346103823, 'epoch': 1.32}\n",
      "{'loss': 0.1832, 'grad_norm': 0.483379989862442, 'learning_rate': 0.0001899967884766212, 'epoch': 1.34}\n",
      "{'loss': 0.2827, 'grad_norm': 0.6330879330635071, 'learning_rate': 0.00018964269372957038, 'epoch': 1.36}\n",
      "{'loss': 0.2414, 'grad_norm': 0.6594528555870056, 'learning_rate': 0.00018928278219658643, 'epoch': 1.38}\n",
      "{'loss': 0.1992, 'grad_norm': 0.6448020935058594, 'learning_rate': 0.00018891707723181294, 'epoch': 1.4}\n",
      "{'loss': 0.2244, 'grad_norm': 0.4937573969364166, 'learning_rate': 0.000188545602565321, 'epoch': 1.42}\n",
      "{'loss': 0.2413, 'grad_norm': 0.5865885615348816, 'learning_rate': 0.00018816838230156942, 'epoch': 1.44}\n",
      "{'loss': 0.1685, 'grad_norm': 0.5673888325691223, 'learning_rate': 0.00018778544091784048, 'epoch': 1.46}\n",
      "{'loss': 0.2335, 'grad_norm': 0.5057591795921326, 'learning_rate': 0.0001873968032626518, 'epoch': 1.48}\n",
      "{'loss': 0.4138, 'grad_norm': 0.8412635922431946, 'learning_rate': 0.00018700249455414394, 'epoch': 1.5}\n",
      " 19%|███████▉                                  | 75/400 [03:45<13:19,  2.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.84it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.13it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.03it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.49it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.62it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.66it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.71it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.49it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.65it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.28590941429138184, 'eval_runtime': 3.4806, 'eval_samples_per_second': 9.194, 'eval_steps_per_second': 4.597, 'epoch': 1.5}\n",
      " 19%|███████▉                                  | 75/400 [03:48<13:19,  2.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "{'loss': 0.283, 'grad_norm': 0.5720861554145813, 'learning_rate': 0.00018660254037844388, 'epoch': 1.52}\n",
      "{'loss': 0.2705, 'grad_norm': 0.5433810353279114, 'learning_rate': 0.00018619696668800492, 'epoch': 1.54}\n",
      "{'loss': 0.3752, 'grad_norm': 0.5754126310348511, 'learning_rate': 0.00018578579979992266, 'epoch': 1.56}\n",
      "{'loss': 0.2058, 'grad_norm': 0.522150993347168, 'learning_rate': 0.00018536906639422725, 'epoch': 1.58}\n",
      "{'loss': 0.2026, 'grad_norm': 0.42929139733314514, 'learning_rate': 0.0001849467935121521, 'epoch': 1.6}\n",
      "{'loss': 0.1882, 'grad_norm': 0.47051212191581726, 'learning_rate': 0.0001845190085543795, 'epoch': 1.62}\n",
      "{'loss': 0.1715, 'grad_norm': 0.47208040952682495, 'learning_rate': 0.00018408573927926222, 'epoch': 1.64}\n",
      "{'loss': 0.1931, 'grad_norm': 0.5007612705230713, 'learning_rate': 0.00018364701380102266, 'epoch': 1.66}\n",
      "{'loss': 0.2714, 'grad_norm': 0.471420019865036, 'learning_rate': 0.00018320286058792843, 'epoch': 1.68}\n",
      "{'loss': 0.2979, 'grad_norm': 0.5867433547973633, 'learning_rate': 0.000182753308460445, 'epoch': 1.7}\n",
      "{'loss': 0.3225, 'grad_norm': 0.5757184028625488, 'learning_rate': 0.00018229838658936564, 'epoch': 1.72}\n",
      "{'loss': 0.0916, 'grad_norm': 0.4647989869117737, 'learning_rate': 0.0001818381244939187, 'epoch': 1.74}\n",
      "{'loss': 0.243, 'grad_norm': 0.5932144522666931, 'learning_rate': 0.00018137255203985197, 'epoch': 1.76}\n",
      "{'loss': 0.3063, 'grad_norm': 0.7183741331100464, 'learning_rate': 0.00018090169943749476, 'epoch': 1.78}\n",
      "{'loss': 0.205, 'grad_norm': 0.7389131188392639, 'learning_rate': 0.0001804255972397977, 'epoch': 1.8}\n",
      "{'loss': 0.1723, 'grad_norm': 0.7315937876701355, 'learning_rate': 0.00017994427634035015, 'epoch': 1.82}\n",
      "{'loss': 0.2153, 'grad_norm': 0.6531150341033936, 'learning_rate': 0.00017945776797137543, 'epoch': 1.84}\n",
      "{'loss': 0.1616, 'grad_norm': 0.5511686205863953, 'learning_rate': 0.0001789661037017045, 'epoch': 1.86}\n",
      "{'loss': 0.122, 'grad_norm': 0.5149949193000793, 'learning_rate': 0.0001784693154347272, 'epoch': 1.88}\n",
      "{'loss': 0.3449, 'grad_norm': 0.7577927708625793, 'learning_rate': 0.00017796743540632223, 'epoch': 1.9}\n",
      "{'loss': 0.181, 'grad_norm': 0.5774346590042114, 'learning_rate': 0.00017746049618276545, 'epoch': 1.92}\n",
      "{'loss': 0.2524, 'grad_norm': 0.8056231141090393, 'learning_rate': 0.00017694853065861662, 'epoch': 1.94}\n",
      "{'loss': 0.1765, 'grad_norm': 0.44470760226249695, 'learning_rate': 0.00017643157205458483, 'epoch': 1.96}\n",
      "{'loss': 0.2354, 'grad_norm': 0.6041816473007202, 'learning_rate': 0.00017590965391537316, 'epoch': 1.98}\n",
      "{'loss': 0.1371, 'grad_norm': 0.6643272042274475, 'learning_rate': 0.0001753828101075017, 'epoch': 2.0}\n",
      " 25%|██████████▎                              | 100/400 [04:50<12:12,  2.44s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.83it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.90it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.10it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.89it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.37it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.54it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.60it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.66it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.46it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.61it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.64it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.2505873441696167, 'eval_runtime': 3.5007, 'eval_samples_per_second': 9.141, 'eval_steps_per_second': 4.571, 'epoch': 2.0}\n",
      " 25%|██████████▎                              | 100/400 [04:53<12:12,  2.44s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.80it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'loss': 0.1544, 'grad_norm': 0.4363182485103607, 'learning_rate': 0.00017485107481711012, 'epoch': 2.02}\n",
      "{'loss': 0.1476, 'grad_norm': 0.4663909077644348, 'learning_rate': 0.00017431448254773944, 'epoch': 2.04}\n",
      "{'loss': 0.1552, 'grad_norm': 0.43054428696632385, 'learning_rate': 0.00017377306811809304, 'epoch': 2.06}\n",
      "{'loss': 0.1716, 'grad_norm': 0.5754823088645935, 'learning_rate': 0.00017322686665977737, 'epoch': 2.08}\n",
      "{'loss': 0.1403, 'grad_norm': 0.40682587027549744, 'learning_rate': 0.00017267591361502232, 'epoch': 2.1}\n",
      "{'loss': 0.2754, 'grad_norm': 0.6097861528396606, 'learning_rate': 0.00017212024473438147, 'epoch': 2.12}\n",
      "{'loss': 0.3266, 'grad_norm': 0.5666090250015259, 'learning_rate': 0.00017155989607441213, 'epoch': 2.14}\n",
      "{'loss': 0.1465, 'grad_norm': 0.38718944787979126, 'learning_rate': 0.00017099490399533583, 'epoch': 2.16}\n",
      "{'loss': 0.2014, 'grad_norm': 0.41397979855537415, 'learning_rate': 0.00017042530515867896, 'epoch': 2.18}\n",
      "{'loss': 0.1743, 'grad_norm': 0.38619691133499146, 'learning_rate': 0.00016985113652489374, 'epoch': 2.2}\n",
      "{'loss': 0.2348, 'grad_norm': 0.5244578719139099, 'learning_rate': 0.00016927243535095997, 'epoch': 2.22}\n",
      "{'loss': 0.1328, 'grad_norm': 0.5436574220657349, 'learning_rate': 0.00016868923918796753, 'epoch': 2.24}\n",
      "{'loss': 0.1983, 'grad_norm': 0.492654949426651, 'learning_rate': 0.00016810158587867973, 'epoch': 2.26}\n",
      "{'loss': 0.2912, 'grad_norm': 0.51939857006073, 'learning_rate': 0.00016750951355507763, 'epoch': 2.28}\n",
      "{'loss': 0.1611, 'grad_norm': 0.5465809106826782, 'learning_rate': 0.00016691306063588583, 'epoch': 2.3}\n",
      "{'loss': 0.0977, 'grad_norm': 0.41201427578926086, 'learning_rate': 0.00016631226582407952, 'epoch': 2.32}\n",
      "{'loss': 0.2345, 'grad_norm': 0.49226829409599304, 'learning_rate': 0.0001657071681043731, 'epoch': 2.34}\n",
      "{'loss': 0.3028, 'grad_norm': 0.7108384966850281, 'learning_rate': 0.0001650978067406904, 'epoch': 2.36}\n",
      "{'loss': 0.1119, 'grad_norm': 0.4155828058719635, 'learning_rate': 0.00016448422127361706, 'epoch': 2.38}\n",
      "{'loss': 0.1246, 'grad_norm': 0.419331431388855, 'learning_rate': 0.0001638664515178348, 'epoch': 2.4}\n",
      "{'loss': 0.1123, 'grad_norm': 0.5108972191810608, 'learning_rate': 0.00016324453755953773, 'epoch': 2.42}\n",
      "{'loss': 0.2093, 'grad_norm': 0.495066374540329, 'learning_rate': 0.00016261851975383137, 'epoch': 2.44}\n",
      "{'loss': 0.16, 'grad_norm': 0.6000941395759583, 'learning_rate': 0.00016198843872211404, 'epoch': 2.46}\n",
      "{'loss': 0.1555, 'grad_norm': 0.6085270047187805, 'learning_rate': 0.0001613543353494409, 'epoch': 2.48}\n",
      "{'loss': 0.1402, 'grad_norm': 0.4438289999961853, 'learning_rate': 0.00016071625078187114, 'epoch': 2.5}\n",
      " 31%|████████████▊                            | 125/400 [06:10<11:19,  2.47s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.76it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.85it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.92it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.03it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.91it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.84it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.55it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.66it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.69it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.51it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.64it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.23251593112945557, 'eval_runtime': 3.4711, 'eval_samples_per_second': 9.219, 'eval_steps_per_second': 4.609, 'epoch': 2.5}\n",
      " 31%|████████████▊                            | 125/400 [06:13<11:19,  2.47s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "{'loss': 0.0925, 'grad_norm': 0.43367138504981995, 'learning_rate': 0.0001600742264237979, 'epoch': 2.52}\n",
      "{'loss': 0.1181, 'grad_norm': 0.4130477011203766, 'learning_rate': 0.00015942830393526176, 'epoch': 2.54}\n",
      "{'loss': 0.1105, 'grad_norm': 0.43445494771003723, 'learning_rate': 0.00015877852522924732, 'epoch': 2.56}\n",
      "{'loss': 0.09, 'grad_norm': 0.4824370741844177, 'learning_rate': 0.00015812493246896366, 'epoch': 2.58}\n",
      "{'loss': 0.1928, 'grad_norm': 0.512090265750885, 'learning_rate': 0.00015746756806510838, 'epoch': 2.6}\n",
      "{'loss': 0.1518, 'grad_norm': 0.6051832437515259, 'learning_rate': 0.00015680647467311557, 'epoch': 2.62}\n",
      "{'loss': 0.0925, 'grad_norm': 0.46572789549827576, 'learning_rate': 0.0001561416951903881, 'epoch': 2.64}\n",
      "{'loss': 0.1442, 'grad_norm': 0.5389589667320251, 'learning_rate': 0.0001554732727535139, 'epoch': 2.66}\n",
      "{'loss': 0.0991, 'grad_norm': 0.5999234914779663, 'learning_rate': 0.00015480125073546704, 'epoch': 2.68}\n",
      "{'loss': 0.1814, 'grad_norm': 0.6706179976463318, 'learning_rate': 0.00015412567274279316, 'epoch': 2.7}\n",
      "{'loss': 0.1611, 'grad_norm': 0.785226047039032, 'learning_rate': 0.0001534465826127801, 'epoch': 2.72}\n",
      "{'loss': 0.1288, 'grad_norm': 0.4781976044178009, 'learning_rate': 0.0001527640244106133, 'epoch': 2.74}\n",
      "{'loss': 0.1961, 'grad_norm': 0.634552538394928, 'learning_rate': 0.00015207804242651626, 'epoch': 2.76}\n",
      "{'loss': 0.1873, 'grad_norm': 0.5323247909545898, 'learning_rate': 0.0001513886811728769, 'epoch': 2.78}\n",
      "{'loss': 0.1272, 'grad_norm': 0.5547800660133362, 'learning_rate': 0.00015069598538135906, 'epoch': 2.8}\n",
      "{'loss': 0.322, 'grad_norm': 0.5741224884986877, 'learning_rate': 0.00015000000000000001, 'epoch': 2.82}\n",
      "{'loss': 0.3794, 'grad_norm': 0.6940755844116211, 'learning_rate': 0.00014930077019029375, 'epoch': 2.84}\n",
      "{'loss': 0.1317, 'grad_norm': 0.44568541646003723, 'learning_rate': 0.0001485983413242606, 'epoch': 2.86}\n",
      "{'loss': 0.1269, 'grad_norm': 0.37207430601119995, 'learning_rate': 0.00014789275898150308, 'epoch': 2.88}\n",
      "{'loss': 0.1086, 'grad_norm': 0.49335598945617676, 'learning_rate': 0.0001471840689462482, 'epoch': 2.9}\n",
      "{'loss': 0.1312, 'grad_norm': 0.39309120178222656, 'learning_rate': 0.00014647231720437686, 'epoch': 2.92}\n",
      "{'loss': 0.0873, 'grad_norm': 0.4483436346054077, 'learning_rate': 0.00014575754994043956, 'epoch': 2.94}\n",
      "{'loss': 0.1936, 'grad_norm': 0.6028394103050232, 'learning_rate': 0.0001450398135346597, 'epoch': 2.96}\n",
      "{'loss': 0.1659, 'grad_norm': 0.45255863666534424, 'learning_rate': 0.00014431915455992414, 'epoch': 2.98}\n",
      "{'loss': 0.1272, 'grad_norm': 0.573324978351593, 'learning_rate': 0.00014359561977876102, 'epoch': 3.0}\n",
      " 38%|███████████████▍                         | 150/400 [07:15<10:11,  2.44s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.70it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.82it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.90it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.10it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.70it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.49it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.65it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.21661052107810974, 'eval_runtime': 3.4791, 'eval_samples_per_second': 9.198, 'eval_steps_per_second': 4.599, 'epoch': 3.0}\n",
      " 38%|███████████████▍                         | 150/400 [07:18<10:11,  2.44s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.80it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'loss': 0.1408, 'grad_norm': 0.4168042242527008, 'learning_rate': 0.00014286925614030542, 'epoch': 3.02}\n",
      "{'loss': 0.1698, 'grad_norm': 0.43367061018943787, 'learning_rate': 0.00014214011077725292, 'epoch': 3.04}\n",
      "{'loss': 0.0936, 'grad_norm': 0.38154318928718567, 'learning_rate': 0.0001414082310028012, 'epoch': 3.06}\n",
      "{'loss': 0.0547, 'grad_norm': 0.3663478493690491, 'learning_rate': 0.00014067366430758004, 'epoch': 3.08}\n",
      "{'loss': 0.1322, 'grad_norm': 0.4349450469017029, 'learning_rate': 0.00013993645835656953, 'epoch': 3.1}\n",
      "{'loss': 0.2175, 'grad_norm': 0.4319140613079071, 'learning_rate': 0.00013919666098600753, 'epoch': 3.12}\n",
      "{'loss': 0.1459, 'grad_norm': 0.3531001806259155, 'learning_rate': 0.0001384543202002851, 'epoch': 3.14}\n",
      "{'loss': 0.1537, 'grad_norm': 0.4219207465648651, 'learning_rate': 0.00013770948416883205, 'epoch': 3.16}\n",
      "{'loss': 0.121, 'grad_norm': 0.4811761975288391, 'learning_rate': 0.00013696220122299112, 'epoch': 3.18}\n",
      "{'loss': 0.0859, 'grad_norm': 0.37722212076187134, 'learning_rate': 0.0001362125198528817, 'epoch': 3.2}\n",
      "{'loss': 0.1727, 'grad_norm': 0.4302927851676941, 'learning_rate': 0.00013546048870425356, 'epoch': 3.22}\n",
      "{'loss': 0.09, 'grad_norm': 0.3785363435745239, 'learning_rate': 0.0001347061565753303, 'epoch': 3.24}\n",
      "{'loss': 0.101, 'grad_norm': 0.39317408204078674, 'learning_rate': 0.00013394957241364273, 'epoch': 3.26}\n",
      "{'loss': 0.0987, 'grad_norm': 0.4215620160102844, 'learning_rate': 0.00013319078531285285, 'epoch': 3.28}\n",
      "{'loss': 0.0572, 'grad_norm': 0.39045295119285583, 'learning_rate': 0.00013242984450956828, 'epoch': 3.3}\n",
      "{'loss': 0.1377, 'grad_norm': 0.6872321963310242, 'learning_rate': 0.00013166679938014726, 'epoch': 3.32}\n",
      "{'loss': 0.059, 'grad_norm': 0.332597553730011, 'learning_rate': 0.00013090169943749476, 'epoch': 3.34}\n",
      "{'loss': 0.0808, 'grad_norm': 0.43909138441085815, 'learning_rate': 0.00013013459432784961, 'epoch': 3.36}\n",
      "{'loss': 0.1919, 'grad_norm': 0.8273612260818481, 'learning_rate': 0.0001293655338275631, 'epoch': 3.38}\n",
      "{'loss': 0.1062, 'grad_norm': 0.5227341055870056, 'learning_rate': 0.00012859456783986893, 'epoch': 3.4}\n",
      "{'loss': 0.0555, 'grad_norm': 0.4041900038719177, 'learning_rate': 0.0001278217463916453, 'epoch': 3.42}\n",
      "{'loss': 0.1322, 'grad_norm': 0.5238372087478638, 'learning_rate': 0.0001270471196301684, 'epoch': 3.44}\n",
      "{'loss': 0.1088, 'grad_norm': 1.0355143547058105, 'learning_rate': 0.0001262707378198587, 'epoch': 3.46}\n",
      "{'loss': 0.094, 'grad_norm': 0.5233693718910217, 'learning_rate': 0.00012549265133901934, 'epoch': 3.48}\n",
      "{'loss': 0.116, 'grad_norm': 0.44207489490509033, 'learning_rate': 0.00012471291067656697, 'epoch': 3.5}\n",
      " 44%|█████████████████▉                       | 175/400 [08:35<09:13,  2.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.84it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.83it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.20846234261989594, 'eval_runtime': 3.4751, 'eval_samples_per_second': 9.208, 'eval_steps_per_second': 4.604, 'epoch': 3.5}\n",
      " 44%|█████████████████▉                       | 175/400 [08:39<09:13,  2.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "{'loss': 0.2299, 'grad_norm': 0.5934640765190125, 'learning_rate': 0.0001239315664287558, 'epoch': 3.52}\n",
      "{'loss': 0.0692, 'grad_norm': 0.45683470368385315, 'learning_rate': 0.00012314866929589432, 'epoch': 3.54}\n",
      "{'loss': 0.2187, 'grad_norm': 0.5420056581497192, 'learning_rate': 0.00012236427007905558, 'epoch': 3.56}\n",
      "{'loss': 0.1015, 'grad_norm': 0.6314148306846619, 'learning_rate': 0.00012157841967678063, 'epoch': 3.58}\n",
      "{'loss': 0.1372, 'grad_norm': 0.47032928466796875, 'learning_rate': 0.00012079116908177593, 'epoch': 3.6}\n",
      "{'loss': 0.1506, 'grad_norm': 0.549901008605957, 'learning_rate': 0.00012000256937760445, 'epoch': 3.62}\n",
      "{'loss': 0.1395, 'grad_norm': 0.4464922845363617, 'learning_rate': 0.00011921267173537086, 'epoch': 3.64}\n",
      "{'loss': 0.1367, 'grad_norm': 0.648892343044281, 'learning_rate': 0.00011842152741040116, 'epoch': 3.66}\n",
      "{'loss': 0.0823, 'grad_norm': 0.4328186810016632, 'learning_rate': 0.00011762918773891691, 'epoch': 3.68}\n",
      "{'loss': 0.1094, 'grad_norm': 0.40728041529655457, 'learning_rate': 0.00011683570413470383, 'epoch': 3.7}\n",
      "{'loss': 0.273, 'grad_norm': 0.5151470899581909, 'learning_rate': 0.00011604112808577603, 'epoch': 3.72}\n",
      "{'loss': 0.0771, 'grad_norm': 0.41477569937705994, 'learning_rate': 0.00011524551115103454, 'epoch': 3.74}\n",
      "{'loss': 0.11, 'grad_norm': 0.38658714294433594, 'learning_rate': 0.00011444890495692213, 'epoch': 3.76}\n",
      "{'loss': 0.092, 'grad_norm': 0.48261603713035583, 'learning_rate': 0.00011365136119407319, 'epoch': 3.78}\n",
      "{'loss': 0.1073, 'grad_norm': 0.7567941546440125, 'learning_rate': 0.00011285293161395946, 'epoch': 3.8}\n",
      "{'loss': 0.1146, 'grad_norm': 0.4463179409503937, 'learning_rate': 0.0001120536680255323, 'epoch': 3.82}\n",
      "{'loss': 0.1544, 'grad_norm': 0.47076740860939026, 'learning_rate': 0.00011125362229186057, 'epoch': 3.84}\n",
      "{'loss': 0.1188, 'grad_norm': 0.5302958488464355, 'learning_rate': 0.00011045284632676536, 'epoch': 3.86}\n",
      "{'loss': 0.17, 'grad_norm': 0.499560683965683, 'learning_rate': 0.00010965139209145152, 'epoch': 3.88}\n",
      "{'loss': 0.0966, 'grad_norm': 0.44566550850868225, 'learning_rate': 0.00010884931159113586, 'epoch': 3.9}\n",
      "{'loss': 0.0626, 'grad_norm': 0.378535658121109, 'learning_rate': 0.00010804665687167262, 'epoch': 3.92}\n",
      "{'loss': 0.2929, 'grad_norm': 0.6264580488204956, 'learning_rate': 0.00010724348001617625, 'epoch': 3.94}\n",
      "{'loss': 0.102, 'grad_norm': 0.450788676738739, 'learning_rate': 0.00010643983314164194, 'epoch': 3.96}\n",
      "{'loss': 0.08, 'grad_norm': 0.49662038683891296, 'learning_rate': 0.00010563576839556374, 'epoch': 3.98}\n",
      "{'loss': 0.0492, 'grad_norm': 0.4787982106208801, 'learning_rate': 0.00010483133795255071, 'epoch': 4.0}\n",
      " 50%|████████████████████▌                    | 200/400 [09:40<07:55,  2.38s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.83it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.89it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.21201381087303162, 'eval_runtime': 3.4772, 'eval_samples_per_second': 9.203, 'eval_steps_per_second': 4.601, 'epoch': 4.0}\n",
      " 50%|████████████████████▌                    | 200/400 [09:43<07:55,  2.38s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'loss': 0.1045, 'grad_norm': 0.32769834995269775, 'learning_rate': 0.00010402659401094152, 'epoch': 4.02}\n",
      "{'loss': 0.1173, 'grad_norm': 0.4385451674461365, 'learning_rate': 0.00010322158878941732, 'epoch': 4.04}\n",
      "{'loss': 0.1818, 'grad_norm': 0.4590665400028229, 'learning_rate': 0.00010241637452361323, 'epoch': 4.06}\n",
      "{'loss': 0.0849, 'grad_norm': 0.40228331089019775, 'learning_rate': 0.00010161100346272914, 'epoch': 4.08}\n",
      "{'loss': 0.0589, 'grad_norm': 0.280857115983963, 'learning_rate': 0.00010080552786613899, 'epoch': 4.1}\n",
      "{'loss': 0.0771, 'grad_norm': 0.43195751309394836, 'learning_rate': 0.0001, 'epoch': 4.12}\n",
      "{'loss': 0.111, 'grad_norm': 0.35630568861961365, 'learning_rate': 9.919447213386103e-05, 'epoch': 4.14}\n",
      "{'loss': 0.102, 'grad_norm': 0.39244896173477173, 'learning_rate': 9.838899653727088e-05, 'epoch': 4.16}\n",
      "{'loss': 0.2057, 'grad_norm': 0.5738720297813416, 'learning_rate': 9.75836254763868e-05, 'epoch': 4.18}\n",
      "{'loss': 0.0782, 'grad_norm': 0.5581870079040527, 'learning_rate': 9.677841121058273e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0888, 'grad_norm': 0.35280847549438477, 'learning_rate': 9.597340598905852e-05, 'epoch': 4.22}\n",
      "{'loss': 0.0647, 'grad_norm': 0.41044339537620544, 'learning_rate': 9.516866204744931e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0698, 'grad_norm': 0.42172905802726746, 'learning_rate': 9.436423160443625e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0851, 'grad_norm': 0.45974692702293396, 'learning_rate': 9.356016685835806e-05, 'epoch': 4.28}\n",
      "{'loss': 0.0856, 'grad_norm': 0.6153208613395691, 'learning_rate': 9.275651998382377e-05, 'epoch': 4.3}\n",
      "{'loss': 0.0981, 'grad_norm': 0.4970308244228363, 'learning_rate': 9.195334312832742e-05, 'epoch': 4.32}\n",
      "{'loss': 0.0465, 'grad_norm': 0.32407721877098083, 'learning_rate': 9.115068840886417e-05, 'epoch': 4.34}\n",
      "{'loss': 0.1063, 'grad_norm': 0.5318803787231445, 'learning_rate': 9.034860790854849e-05, 'epoch': 4.36}\n",
      "{'loss': 0.0972, 'grad_norm': 0.3531469702720642, 'learning_rate': 8.954715367323468e-05, 'epoch': 4.38}\n",
      "{'loss': 0.1196, 'grad_norm': 0.8016135692596436, 'learning_rate': 8.874637770813946e-05, 'epoch': 4.4}\n",
      "{'loss': 0.0513, 'grad_norm': 0.33979326486587524, 'learning_rate': 8.79463319744677e-05, 'epoch': 4.42}\n",
      "{'loss': 0.0793, 'grad_norm': 0.41235652565956116, 'learning_rate': 8.714706838604055e-05, 'epoch': 4.44}\n",
      "{'loss': 0.0558, 'grad_norm': 0.36907628178596497, 'learning_rate': 8.634863880592686e-05, 'epoch': 4.46}\n",
      "{'loss': 0.0967, 'grad_norm': 0.42394185066223145, 'learning_rate': 8.55510950430779e-05, 'epoch': 4.48}\n",
      "{'loss': 0.1321, 'grad_norm': 0.4438260495662689, 'learning_rate': 8.475448884896547e-05, 'epoch': 4.5}\n",
      " 56%|███████████████████████                  | 225/400 [11:00<07:10,  2.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.84it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.12it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.20952272415161133, 'eval_runtime': 3.4747, 'eval_samples_per_second': 9.209, 'eval_steps_per_second': 4.605, 'epoch': 4.5}\n",
      " 56%|███████████████████████                  | 225/400 [11:03<07:10,  2.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "{'loss': 0.0663, 'grad_norm': 0.44828832149505615, 'learning_rate': 8.395887191422397e-05, 'epoch': 4.52}\n",
      "{'loss': 0.1225, 'grad_norm': 0.5278084874153137, 'learning_rate': 8.316429586529615e-05, 'epoch': 4.54}\n",
      "{'loss': 0.0429, 'grad_norm': 0.34463798999786377, 'learning_rate': 8.237081226108311e-05, 'epoch': 4.56}\n",
      "{'loss': 0.1355, 'grad_norm': 0.4241845905780792, 'learning_rate': 8.157847258959885e-05, 'epoch': 4.58}\n",
      "{'loss': 0.1067, 'grad_norm': 0.399095743894577, 'learning_rate': 8.078732826462915e-05, 'epoch': 4.6}\n",
      "{'loss': 0.192, 'grad_norm': 0.6367175579071045, 'learning_rate': 7.999743062239557e-05, 'epoch': 4.62}\n",
      "{'loss': 0.1161, 'grad_norm': 0.43518495559692383, 'learning_rate': 7.920883091822408e-05, 'epoch': 4.64}\n",
      "{'loss': 0.1361, 'grad_norm': 0.5350768566131592, 'learning_rate': 7.84215803232194e-05, 'epoch': 4.66}\n",
      "{'loss': 0.046, 'grad_norm': 0.39296212792396545, 'learning_rate': 7.763572992094447e-05, 'epoch': 4.68}\n",
      "{'loss': 0.1118, 'grad_norm': 0.3995246887207031, 'learning_rate': 7.685133070410571e-05, 'epoch': 4.7}\n",
      "{'loss': 0.1924, 'grad_norm': 0.5622637271881104, 'learning_rate': 7.606843357124426e-05, 'epoch': 4.72}\n",
      "{'loss': 0.1597, 'grad_norm': 0.4881860613822937, 'learning_rate': 7.528708932343304e-05, 'epoch': 4.74}\n",
      "{'loss': 0.1117, 'grad_norm': 0.4909290373325348, 'learning_rate': 7.450734866098066e-05, 'epoch': 4.76}\n",
      "{'loss': 0.0805, 'grad_norm': 0.36455845832824707, 'learning_rate': 7.372926218014131e-05, 'epoch': 4.78}\n",
      "{'loss': 0.0743, 'grad_norm': 0.39560192823410034, 'learning_rate': 7.295288036983163e-05, 'epoch': 4.8}\n",
      "{'loss': 0.0287, 'grad_norm': 0.27760425209999084, 'learning_rate': 7.217825360835473e-05, 'epoch': 4.82}\n",
      "{'loss': 0.0739, 'grad_norm': 0.32903218269348145, 'learning_rate': 7.14054321601311e-05, 'epoch': 4.84}\n",
      "{'loss': 0.0521, 'grad_norm': 0.42648792266845703, 'learning_rate': 7.063446617243694e-05, 'epoch': 4.86}\n",
      "{'loss': 0.0404, 'grad_norm': 0.3351297974586487, 'learning_rate': 6.986540567215044e-05, 'epoch': 4.88}\n",
      "{'loss': 0.0701, 'grad_norm': 0.43283116817474365, 'learning_rate': 6.909830056250527e-05, 'epoch': 4.9}\n",
      "{'loss': 0.1089, 'grad_norm': 0.7134954333305359, 'learning_rate': 6.833320061985277e-05, 'epoch': 4.92}\n",
      "{'loss': 0.0365, 'grad_norm': 0.41375789046287537, 'learning_rate': 6.757015549043175e-05, 'epoch': 4.94}\n",
      "{'loss': 0.0945, 'grad_norm': 0.4155278205871582, 'learning_rate': 6.680921468714719e-05, 'epoch': 4.96}\n",
      "{'loss': 0.1248, 'grad_norm': 0.6720771789550781, 'learning_rate': 6.605042758635729e-05, 'epoch': 4.98}\n",
      "{'loss': 0.2073, 'grad_norm': 0.5644330978393555, 'learning_rate': 6.52938434246697e-05, 'epoch': 5.0}\n",
      " 62%|█████████████████████████▋               | 250/400 [12:05<06:07,  2.45s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.72it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.83it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  5.00it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.88it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.65it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.2020527422428131, 'eval_runtime': 3.4778, 'eval_samples_per_second': 9.201, 'eval_steps_per_second': 4.601, 'epoch': 5.0}\n",
      " 62%|█████████████████████████▋               | 250/400 [12:08<06:07,  2.45s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.80it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'loss': 0.0961, 'grad_norm': 0.4081760048866272, 'learning_rate': 6.453951129574644e-05, 'epoch': 5.02}\n",
      "{'loss': 0.0661, 'grad_norm': 0.2677020728588104, 'learning_rate': 6.378748014711834e-05, 'epoch': 5.04}\n",
      "{'loss': 0.1381, 'grad_norm': 0.4008996784687042, 'learning_rate': 6.30377987770089e-05, 'epoch': 5.06}\n",
      "{'loss': 0.0525, 'grad_norm': 0.34934258460998535, 'learning_rate': 6.229051583116796e-05, 'epoch': 5.08}\n",
      "{'loss': 0.125, 'grad_norm': 0.3558529317378998, 'learning_rate': 6.154567979971493e-05, 'epoch': 5.1}\n",
      "{'loss': 0.0439, 'grad_norm': 0.31691622734069824, 'learning_rate': 6.080333901399251e-05, 'epoch': 5.12}\n",
      "{'loss': 0.0638, 'grad_norm': 0.36730605363845825, 'learning_rate': 6.006354164343046e-05, 'epoch': 5.14}\n",
      "{'loss': 0.029, 'grad_norm': 0.30561351776123047, 'learning_rate': 5.9326335692419995e-05, 'epoch': 5.16}\n",
      "{'loss': 0.2033, 'grad_norm': 0.45254161953926086, 'learning_rate': 5.859176899719883e-05, 'epoch': 5.18}\n",
      "{'loss': 0.0899, 'grad_norm': 0.43033578991889954, 'learning_rate': 5.785988922274711e-05, 'epoch': 5.2}\n",
      "{'loss': 0.0801, 'grad_norm': 0.363307923078537, 'learning_rate': 5.713074385969457e-05, 'epoch': 5.22}\n",
      "{'loss': 0.1453, 'grad_norm': 0.38824906945228577, 'learning_rate': 5.6404380221238985e-05, 'epoch': 5.24}\n",
      "{'loss': 0.1379, 'grad_norm': 0.4719548523426056, 'learning_rate': 5.568084544007588e-05, 'epoch': 5.26}\n",
      "{'loss': 0.0609, 'grad_norm': 0.31259220838546753, 'learning_rate': 5.4960186465340316e-05, 'epoch': 5.28}\n",
      "{'loss': 0.0305, 'grad_norm': 0.28138071298599243, 'learning_rate': 5.424245005956048e-05, 'epoch': 5.3}\n",
      "{'loss': 0.0778, 'grad_norm': 0.31529703736305237, 'learning_rate': 5.3527682795623146e-05, 'epoch': 5.32}\n",
      "{'loss': 0.0613, 'grad_norm': 0.4376368522644043, 'learning_rate': 5.28159310537518e-05, 'epoch': 5.34}\n",
      "{'loss': 0.0431, 'grad_norm': 0.3700469732284546, 'learning_rate': 5.210724101849696e-05, 'epoch': 5.36}\n",
      "{'loss': 0.0402, 'grad_norm': 0.36897119879722595, 'learning_rate': 5.14016586757394e-05, 'epoch': 5.38}\n",
      "{'loss': 0.052, 'grad_norm': 0.2907363176345825, 'learning_rate': 5.069922980970626e-05, 'epoch': 5.4}\n",
      "{'loss': 0.0392, 'grad_norm': 0.28859394788742065, 'learning_rate': 5.000000000000002e-05, 'epoch': 5.42}\n",
      "{'loss': 0.1091, 'grad_norm': 0.4494079053401947, 'learning_rate': 4.9304014618640995e-05, 'epoch': 5.44}\n",
      "{'loss': 0.0823, 'grad_norm': 0.2883443534374237, 'learning_rate': 4.861131882712314e-05, 'epoch': 5.46}\n",
      "{'loss': 0.0711, 'grad_norm': 0.5859274864196777, 'learning_rate': 4.7921957573483754e-05, 'epoch': 5.48}\n",
      "{'loss': 0.1069, 'grad_norm': 0.4004884660243988, 'learning_rate': 4.723597558938672e-05, 'epoch': 5.5}\n",
      " 69%|████████████████████████████▏            | 275/400 [13:25<05:07,  2.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.58it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.74it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.82it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.05it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  4.99it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.85it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.77it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.48it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.59it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.62it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.67it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.45it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.58it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.60it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.21901366114616394, 'eval_runtime': 3.5196, 'eval_samples_per_second': 9.092, 'eval_steps_per_second': 4.546, 'epoch': 5.5}\n",
      " 69%|████████████████████████████▏            | 275/400 [13:29<05:07,  2.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.76it/s]\u001b[A\n",
      "{'loss': 0.1853, 'grad_norm': 0.5922706127166748, 'learning_rate': 4.6553417387219886e-05, 'epoch': 5.52}\n",
      "{'loss': 0.0832, 'grad_norm': 0.4647192060947418, 'learning_rate': 4.587432725720687e-05, 'epoch': 5.54}\n",
      "{'loss': 0.0376, 'grad_norm': 0.37604400515556335, 'learning_rate': 4.519874926453302e-05, 'epoch': 5.56}\n",
      "{'loss': 0.0293, 'grad_norm': 0.3091113567352295, 'learning_rate': 4.452672724648611e-05, 'epoch': 5.58}\n",
      "{'loss': 0.0406, 'grad_norm': 0.3698002099990845, 'learning_rate': 4.385830480961192e-05, 'epoch': 5.6}\n",
      "{'loss': 0.0431, 'grad_norm': 0.36042118072509766, 'learning_rate': 4.3193525326884435e-05, 'epoch': 5.62}\n",
      "{'loss': 0.0292, 'grad_norm': 0.2825547456741333, 'learning_rate': 4.253243193489165e-05, 'epoch': 5.64}\n",
      "{'loss': 0.0758, 'grad_norm': 0.3372112810611725, 'learning_rate': 4.1875067531036374e-05, 'epoch': 5.66}\n",
      "{'loss': 0.0433, 'grad_norm': 0.41653746366500854, 'learning_rate': 4.12214747707527e-05, 'epoch': 5.68}\n",
      "{'loss': 0.1446, 'grad_norm': 0.47047340869903564, 'learning_rate': 4.057169606473827e-05, 'epoch': 5.7}\n",
      "{'loss': 0.0671, 'grad_norm': 0.4052739143371582, 'learning_rate': 3.99257735762021e-05, 'epoch': 5.72}\n",
      "{'loss': 0.0376, 'grad_norm': 0.3856949210166931, 'learning_rate': 3.9283749218128885e-05, 'epoch': 5.74}\n",
      "{'loss': 0.0476, 'grad_norm': 0.3576034605503082, 'learning_rate': 3.864566465055912e-05, 'epoch': 5.76}\n",
      "{'loss': 0.0747, 'grad_norm': 0.8592492938041687, 'learning_rate': 3.8011561277885964e-05, 'epoch': 5.78}\n",
      "{'loss': 0.1297, 'grad_norm': 1.118322491645813, 'learning_rate': 3.738148024616863e-05, 'epoch': 5.8}\n",
      "{'loss': 0.0846, 'grad_norm': 0.4110085070133209, 'learning_rate': 3.675546244046228e-05, 'epoch': 5.82}\n",
      "{'loss': 0.127, 'grad_norm': 0.43087223172187805, 'learning_rate': 3.6133548482165225e-05, 'epoch': 5.84}\n",
      "{'loss': 0.0916, 'grad_norm': 0.4292435348033905, 'learning_rate': 3.5515778726382966e-05, 'epoch': 5.86}\n",
      "{'loss': 0.0791, 'grad_norm': 0.8591576814651489, 'learning_rate': 3.490219325930962e-05, 'epoch': 5.88}\n",
      "{'loss': 0.1486, 'grad_norm': 0.4366658627986908, 'learning_rate': 3.429283189562694e-05, 'epoch': 5.9}\n",
      "{'loss': 0.1, 'grad_norm': 0.329377144575119, 'learning_rate': 3.36877341759205e-05, 'epoch': 5.92}\n",
      "{'loss': 0.05, 'grad_norm': 0.4026828706264496, 'learning_rate': 3.308693936411421e-05, 'epoch': 5.94}\n",
      "{'loss': 0.0596, 'grad_norm': 0.4939657747745514, 'learning_rate': 3.24904864449224e-05, 'epoch': 5.96}\n",
      "{'loss': 0.0342, 'grad_norm': 0.33064723014831543, 'learning_rate': 3.1898414121320276e-05, 'epoch': 5.98}\n",
      "{'loss': 0.0548, 'grad_norm': 0.4491739869117737, 'learning_rate': 3.131076081203247e-05, 'epoch': 6.0}\n",
      " 75%|██████████████████████████████▊          | 300/400 [14:30<04:04,  2.44s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.84it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.20449626445770264, 'eval_runtime': 3.4771, 'eval_samples_per_second': 9.203, 'eval_steps_per_second': 4.601, 'epoch': 6.0}\n",
      " 75%|██████████████████████████████▊          | 300/400 [14:34<04:04,  2.44s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'loss': 0.0876, 'grad_norm': 0.317195862531662, 'learning_rate': 3.072756464904006e-05, 'epoch': 6.02}\n",
      "{'loss': 0.0674, 'grad_norm': 0.3407246172428131, 'learning_rate': 3.0148863475106314e-05, 'epoch': 6.04}\n",
      "{'loss': 0.043, 'grad_norm': 0.3409706950187683, 'learning_rate': 2.9574694841321082e-05, 'epoch': 6.06}\n",
      "{'loss': 0.0957, 'grad_norm': 0.33290690183639526, 'learning_rate': 2.9005096004664177e-05, 'epoch': 6.08}\n",
      "{'loss': 0.0591, 'grad_norm': 0.3185310959815979, 'learning_rate': 2.84401039255879e-05, 'epoch': 6.1}\n",
      "{'loss': 0.0518, 'grad_norm': 0.319232702255249, 'learning_rate': 2.7879755265618555e-05, 'epoch': 6.12}\n",
      "{'loss': 0.0526, 'grad_norm': 0.2950107753276825, 'learning_rate': 2.7324086384977698e-05, 'epoch': 6.14}\n",
      "{'loss': 0.0391, 'grad_norm': 0.331287145614624, 'learning_rate': 2.677313334022268e-05, 'epoch': 6.16}\n",
      "{'loss': 0.0637, 'grad_norm': 0.45839977264404297, 'learning_rate': 2.622693188190699e-05, 'epoch': 6.18}\n",
      "{'loss': 0.1267, 'grad_norm': 0.47432801127433777, 'learning_rate': 2.5685517452260567e-05, 'epoch': 6.2}\n",
      "{'loss': 0.0335, 'grad_norm': 0.36994266510009766, 'learning_rate': 2.514892518288988e-05, 'epoch': 6.22}\n",
      "{'loss': 0.0502, 'grad_norm': 0.27380967140197754, 'learning_rate': 2.4617189892498327e-05, 'epoch': 6.24}\n",
      "{'loss': 0.0352, 'grad_norm': 0.29994869232177734, 'learning_rate': 2.409034608462686e-05, 'epoch': 6.26}\n",
      "{'loss': 0.1493, 'grad_norm': 0.4152407646179199, 'learning_rate': 2.356842794541516e-05, 'epoch': 6.28}\n",
      "{'loss': 0.1219, 'grad_norm': 0.42236459255218506, 'learning_rate': 2.3051469341383402e-05, 'epoch': 6.3}\n",
      "{'loss': 0.1007, 'grad_norm': 0.4168317914009094, 'learning_rate': 2.2539503817234553e-05, 'epoch': 6.32}\n",
      "{'loss': 0.0363, 'grad_norm': 0.43412914872169495, 'learning_rate': 2.2032564593677774e-05, 'epoch': 6.34}\n",
      "{'loss': 0.1141, 'grad_norm': 0.39523324370384216, 'learning_rate': 2.153068456527283e-05, 'epoch': 6.36}\n",
      "{'loss': 0.0441, 'grad_norm': 0.374700129032135, 'learning_rate': 2.1033896298295508e-05, 'epoch': 6.38}\n",
      "{'loss': 0.1024, 'grad_norm': 0.4121944010257721, 'learning_rate': 2.0542232028624586e-05, 'epoch': 6.4}\n",
      "{'loss': 0.0377, 'grad_norm': 0.22557584941387177, 'learning_rate': 2.0055723659649904e-05, 'epoch': 6.42}\n",
      "{'loss': 0.0363, 'grad_norm': 0.35758113861083984, 'learning_rate': 1.9574402760202315e-05, 'epoch': 6.44}\n",
      "{'loss': 0.0791, 'grad_norm': 0.43639618158340454, 'learning_rate': 1.9098300562505266e-05, 'epoch': 6.46}\n",
      "{'loss': 0.0361, 'grad_norm': 0.2706812024116516, 'learning_rate': 1.8627447960148037e-05, 'epoch': 6.48}\n",
      "{'loss': 0.0801, 'grad_norm': 0.40473291277885437, 'learning_rate': 1.8161875506081293e-05, 'epoch': 6.5}\n",
      " 81%|█████████████████████████████████▎       | 325/400 [15:51<03:04,  2.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.84it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.92it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.12it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.03it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.82it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.65it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.20990462601184845, 'eval_runtime': 3.475, 'eval_samples_per_second': 9.209, 'eval_steps_per_second': 4.604, 'epoch': 6.5}\n",
      " 81%|█████████████████████████████████▎       | 325/400 [15:55<03:04,  2.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "{'loss': 0.0701, 'grad_norm': 0.3924380838871002, 'learning_rate': 1.7701613410634365e-05, 'epoch': 6.52}\n",
      "{'loss': 0.0454, 'grad_norm': 0.6718001365661621, 'learning_rate': 1.7246691539555028e-05, 'epoch': 6.54}\n",
      "{'loss': 0.0683, 'grad_norm': 0.44715964794158936, 'learning_rate': 1.6797139412071584e-05, 'epoch': 6.56}\n",
      "{'loss': 0.1198, 'grad_norm': 0.480172723531723, 'learning_rate': 1.6352986198977325e-05, 'epoch': 6.58}\n",
      "{'loss': 0.041, 'grad_norm': 0.3256594240665436, 'learning_rate': 1.5914260720737795e-05, 'epoch': 6.6}\n",
      "{'loss': 0.0641, 'grad_norm': 0.36148884892463684, 'learning_rate': 1.5480991445620542e-05, 'epoch': 6.62}\n",
      "{'loss': 0.1529, 'grad_norm': 0.424503892660141, 'learning_rate': 1.5053206487847914e-05, 'epoch': 6.64}\n",
      "{'loss': 0.0513, 'grad_norm': 0.38048359751701355, 'learning_rate': 1.4630933605772801e-05, 'epoch': 6.66}\n",
      "{'loss': 0.1003, 'grad_norm': 0.44985824823379517, 'learning_rate': 1.4214200200077343e-05, 'epoch': 6.68}\n",
      "{'loss': 0.0355, 'grad_norm': 0.337291419506073, 'learning_rate': 1.3803033311995072e-05, 'epoch': 6.7}\n",
      "{'loss': 0.0362, 'grad_norm': 0.455356627702713, 'learning_rate': 1.339745962155613e-05, 'epoch': 6.72}\n",
      "{'loss': 0.0423, 'grad_norm': 0.298045814037323, 'learning_rate': 1.2997505445856084e-05, 'epoch': 6.74}\n",
      "{'loss': 0.0552, 'grad_norm': 0.34743592143058777, 'learning_rate': 1.260319673734821e-05, 'epoch': 6.76}\n",
      "{'loss': 0.0325, 'grad_norm': 0.33502861857414246, 'learning_rate': 1.2214559082159537e-05, 'epoch': 6.78}\n",
      "{'loss': 0.0661, 'grad_norm': 0.38786929845809937, 'learning_rate': 1.1831617698430609e-05, 'epoch': 6.8}\n",
      "{'loss': 0.0382, 'grad_norm': 0.2817856967449188, 'learning_rate': 1.1454397434679021e-05, 'epoch': 6.82}\n",
      "{'loss': 0.0341, 'grad_norm': 0.3777707517147064, 'learning_rate': 1.10829227681871e-05, 'epoch': 6.84}\n",
      "{'loss': 0.0278, 'grad_norm': 0.2719218134880066, 'learning_rate': 1.0717217803413604e-05, 'epoch': 6.86}\n",
      "{'loss': 0.0245, 'grad_norm': 0.2945742607116699, 'learning_rate': 1.0357306270429624e-05, 'epoch': 6.88}\n",
      "{'loss': 0.1286, 'grad_norm': 0.3760562837123871, 'learning_rate': 1.0003211523378796e-05, 'epoch': 6.9}\n",
      "{'loss': 0.0365, 'grad_norm': 0.39979806542396545, 'learning_rate': 9.65495653896179e-06, 'epoch': 6.92}\n",
      "{'loss': 0.0542, 'grad_norm': 0.3339255452156067, 'learning_rate': 9.31256391494546e-06, 'epoch': 6.94}\n",
      "{'loss': 0.066, 'grad_norm': 0.453529953956604, 'learning_rate': 8.976055868696542e-06, 'epoch': 6.96}\n",
      "{'loss': 0.2521, 'grad_norm': 0.5722355842590332, 'learning_rate': 8.645454235739903e-06, 'epoch': 6.98}\n",
      "{'loss': 0.0285, 'grad_norm': 0.41058582067489624, 'learning_rate': 8.32078046834176e-06, 'epoch': 7.0}\n",
      " 88%|███████████████████████████████████▉     | 350/400 [16:56<02:02,  2.44s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.73it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.84it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.02it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.90it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.83it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.54it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.66it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.68it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.72it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.64it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.21131736040115356, 'eval_runtime': 3.4729, 'eval_samples_per_second': 9.214, 'eval_steps_per_second': 4.607, 'epoch': 7.0}\n",
      " 88%|███████████████████████████████████▉     | 350/400 [17:00<02:02,  2.44s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'loss': 0.0673, 'grad_norm': 0.33801576495170593, 'learning_rate': 8.002055634117578e-06, 'epoch': 7.02}\n",
      "{'loss': 0.0364, 'grad_norm': 0.32055944204330444, 'learning_rate': 7.689300414665124e-06, 'epoch': 7.04}\n",
      "{'loss': 0.054, 'grad_norm': 0.3150416910648346, 'learning_rate': 7.382535104222366e-06, 'epoch': 7.06}\n",
      "{'loss': 0.0279, 'grad_norm': 0.30286312103271484, 'learning_rate': 7.08177960835068e-06, 'epoch': 7.08}\n",
      "{'loss': 0.0685, 'grad_norm': 0.34543028473854065, 'learning_rate': 6.787053442643232e-06, 'epoch': 7.1}\n",
      "{'loss': 0.0892, 'grad_norm': 0.3244650363922119, 'learning_rate': 6.498375731458528e-06, 'epoch': 7.12}\n",
      "{'loss': 0.0548, 'grad_norm': 0.31594905257225037, 'learning_rate': 6.215765206679569e-06, 'epoch': 7.14}\n",
      "{'loss': 0.0527, 'grad_norm': 0.2975058853626251, 'learning_rate': 5.939240206498287e-06, 'epoch': 7.16}\n",
      "{'loss': 0.0254, 'grad_norm': 0.21800455451011658, 'learning_rate': 5.668818674225685e-06, 'epoch': 7.18}\n",
      "{'loss': 0.0315, 'grad_norm': 0.3006148636341095, 'learning_rate': 5.40451815712748e-06, 'epoch': 7.2}\n",
      "{'loss': 0.0511, 'grad_norm': 0.3940395414829254, 'learning_rate': 5.146355805285452e-06, 'epoch': 7.22}\n",
      "{'loss': 0.0409, 'grad_norm': 0.35553354024887085, 'learning_rate': 4.8943483704846475e-06, 'epoch': 7.24}\n",
      "{'loss': 0.0197, 'grad_norm': 0.23978134989738464, 'learning_rate': 4.648512205126376e-06, 'epoch': 7.26}\n",
      "{'loss': 0.0529, 'grad_norm': 0.36153531074523926, 'learning_rate': 4.408863261167096e-06, 'epoch': 7.28}\n",
      "{'loss': 0.0672, 'grad_norm': 0.37826433777809143, 'learning_rate': 4.175417089083378e-06, 'epoch': 7.3}\n",
      "{'loss': 0.0203, 'grad_norm': 0.2562366724014282, 'learning_rate': 3.948188836862776e-06, 'epoch': 7.32}\n",
      "{'loss': 0.0318, 'grad_norm': 0.3236604630947113, 'learning_rate': 3.7271932490209328e-06, 'epoch': 7.34}\n",
      "{'loss': 0.1414, 'grad_norm': 0.4582403302192688, 'learning_rate': 3.512444665644865e-06, 'epoch': 7.36}\n",
      "{'loss': 0.0825, 'grad_norm': 0.41544511914253235, 'learning_rate': 3.3039570214623782e-06, 'epoch': 7.38}\n",
      "{'loss': 0.1256, 'grad_norm': 0.4421073794364929, 'learning_rate': 3.1017438449379434e-06, 'epoch': 7.4}\n",
      "{'loss': 0.0732, 'grad_norm': 0.3551267981529236, 'learning_rate': 2.905818257394799e-06, 'epoch': 7.42}\n",
      "{'loss': 0.0396, 'grad_norm': 0.3074437081813812, 'learning_rate': 2.716192972163556e-06, 'epoch': 7.44}\n",
      "{'loss': 0.0267, 'grad_norm': 0.3189760446548462, 'learning_rate': 2.532880293757223e-06, 'epoch': 7.46}\n",
      "{'loss': 0.0947, 'grad_norm': 0.35963496565818787, 'learning_rate': 2.3558921170727888e-06, 'epoch': 7.48}\n",
      "{'loss': 0.0603, 'grad_norm': 0.38975322246551514, 'learning_rate': 2.1852399266194314e-06, 'epoch': 7.5}\n",
      " 94%|██████████████████████████████████████▍  | 375/400 [18:18<01:01,  2.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.75it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.85it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.92it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.12it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.03it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.91it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.83it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.54it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.66it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.69it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.73it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.50it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.64it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.21426567435264587, 'eval_runtime': 3.4692, 'eval_samples_per_second': 9.224, 'eval_steps_per_second': 4.612, 'epoch': 7.5}\n",
      " 94%|██████████████████████████████████████▍  | 375/400 [18:21<01:01,  2.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.81it/s]\u001b[A\n",
      "{'loss': 0.0354, 'grad_norm': 0.2689930498600006, 'learning_rate': 2.0209347957732328e-06, 'epoch': 7.52}\n",
      "{'loss': 0.0731, 'grad_norm': 0.37676697969436646, 'learning_rate': 1.8629873860586566e-06, 'epoch': 7.54}\n",
      "{'loss': 0.0683, 'grad_norm': 0.3746795952320099, 'learning_rate': 1.7114079464567888e-06, 'epoch': 7.56}\n",
      "{'loss': 0.035, 'grad_norm': 0.6359199285507202, 'learning_rate': 1.566206312740226e-06, 'epoch': 7.58}\n",
      "{'loss': 0.1359, 'grad_norm': 0.444001704454422, 'learning_rate': 1.4273919068349184e-06, 'epoch': 7.6}\n",
      "{'loss': 0.0749, 'grad_norm': 0.39133143424987793, 'learning_rate': 1.2949737362087156e-06, 'epoch': 7.62}\n",
      "{'loss': 0.0819, 'grad_norm': 0.4147777259349823, 'learning_rate': 1.1689603932869665e-06, 'epoch': 7.64}\n",
      "{'loss': 0.0264, 'grad_norm': 0.27041950821876526, 'learning_rate': 1.0493600548948878e-06, 'epoch': 7.66}\n",
      "{'loss': 0.0655, 'grad_norm': 0.3198292851448059, 'learning_rate': 9.36180481727067e-07, 'epoch': 7.68}\n",
      "{'loss': 0.0523, 'grad_norm': 0.2979887127876282, 'learning_rate': 8.294290178437969e-07, 'epoch': 7.7}\n",
      "{'loss': 0.0494, 'grad_norm': 0.26376065611839294, 'learning_rate': 7.291125901946027e-07, 'epoch': 7.72}\n",
      "{'loss': 0.0695, 'grad_norm': 0.6526001691818237, 'learning_rate': 6.352377081687011e-07, 'epoch': 7.74}\n",
      "{'loss': 0.0366, 'grad_norm': 0.2988506555557251, 'learning_rate': 5.478104631726711e-07, 'epoch': 7.76}\n",
      "{'loss': 0.0604, 'grad_norm': 0.34122830629348755, 'learning_rate': 4.668365282351372e-07, 'epoch': 7.78}\n",
      "{'loss': 0.0438, 'grad_norm': 0.346072256565094, 'learning_rate': 3.923211576387087e-07, 'epoch': 7.8}\n",
      "{'loss': 0.0579, 'grad_norm': 0.275515615940094, 'learning_rate': 3.2426918657900704e-07, 'epoch': 7.82}\n",
      "{'loss': 0.0636, 'grad_norm': 0.34655365347862244, 'learning_rate': 2.6268503085089547e-07, 'epoch': 7.84}\n",
      "{'loss': 0.0445, 'grad_norm': 0.29608607292175293, 'learning_rate': 2.0757268656198537e-07, 'epoch': 7.86}\n",
      "{'loss': 0.0948, 'grad_norm': 0.3808535933494568, 'learning_rate': 1.5893572987333293e-07, 'epoch': 7.88}\n",
      "{'loss': 0.1163, 'grad_norm': 0.4363033175468445, 'learning_rate': 1.1677731676733584e-07, 'epoch': 7.9}\n",
      "{'loss': 0.0697, 'grad_norm': 0.35206717252731323, 'learning_rate': 8.110018284304133e-08, 'epoch': 7.92}\n",
      "{'loss': 0.0778, 'grad_norm': 0.5459943413734436, 'learning_rate': 5.190664313851068e-08, 'epoch': 7.94}\n",
      "{'loss': 0.0699, 'grad_norm': 0.34840354323387146, 'learning_rate': 2.9198591980705848e-08, 'epoch': 7.96}\n",
      "{'loss': 0.213, 'grad_norm': 0.6242286562919617, 'learning_rate': 1.2977502862532297e-08, 'epoch': 7.98}\n",
      "{'loss': 0.1687, 'grad_norm': 0.603456974029541, 'learning_rate': 3.244428347204398e-09, 'epoch': 8.0}\n",
      "100%|█████████████████████████████████████████| 400/400 [19:23<00:00,  2.43s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  9.74it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:01,  6.85it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.92it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  5.12it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:01,  5.04it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:01,  4.91it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  4.84it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.54it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  4.67it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  4.70it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:02<00:00,  4.74it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:02<00:00,  4.51it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  4.64it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:03<00:00,  4.66it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.21331049501895905, 'eval_runtime': 3.4662, 'eval_samples_per_second': 9.232, 'eval_steps_per_second': 4.616, 'epoch': 8.0}\n",
      "100%|█████████████████████████████████████████| 400/400 [19:26<00:00,  2.43s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:03<00:00,  4.82it/s]\u001b[A\n",
      "                                                                                \u001b[A/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "{'train_runtime': 1167.9809, 'train_samples_per_second': 2.74, 'train_steps_per_second': 0.342, 'train_loss': 0.20156055052764713, 'epoch': 8.0}\n",
      "100%|█████████████████████████████████████████| 400/400 [19:28<00:00,  2.92s/it]\n",
      "[2025-10-07 09:38:55,521] [INFO] [axolotl.train.save_trained_model:244] [PID:3056496] [RANK:0] Training completed! Saving trained model to ./out-gemma-3-270m-it.\u001b[39m\n",
      "/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/axolotl-finetune/venv/lib/python3.12/site-packages/peft/utils/save_and_load.py:250: UserWarning: Setting `save_embedding_layers` to `True` as the embedding layer has been resized during finetuning.\n",
      "  warnings.warn(\n",
      "[2025-10-07 09:38:56,376] [INFO] [axolotl.train.save_trained_model:341] [PID:3056496] [RANK:0] Model successfully saved to ./out-gemma-3-270m-it\u001b[39m\n",
      "\u001b[0mCPU times: user 7.4 s, sys: 867 ms, total: 8.27 s\n",
      "Wall time: 22min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/accelerate launch -m axolotl.cli.train {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge the LoRA/DoRA into the base model (for inference & quantization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-10-07 09:39:04,303] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:3059674] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "[2025-10-07 09:39:04,303] [INFO] [axolotl.utils.schemas.config.hint_sample_packing_padding:539] [PID:3059674] [RANK:0] Setting `pad_to_sequence_len: true` to prevent memory leaks when sample_packing\u001b[39m\n",
      "\u001b[33m[2025-10-07 09:39:04,303] [WARNING] [axolotl.utils.schemas.config.check_sample_packing_wo_flash:482] [PID:3059674] [RANK:0] sample_packing without flash, sdp, xformers or flex attention does not handle cross sample decontamination.\u001b[39m\n",
      "\u001b[33m[2025-10-07 09:39:04,303] [WARNING] [axolotl.utils.schemas.config.hint_lora_8bit:871] [PID:3059674] [RANK:0] We recommend setting `load_in_8bit: true` for LORA finetuning\u001b[39m\n",
      "[2025-10-07 09:39:04,525] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:3059674] [RANK:0] cuda memory usage baseline: 0.000GB (+0.818GB misc)\u001b[39m\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-10-07 09:39:04,536] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:318] [PID:3059674] [RANK:0] loading tokenizer... google/gemma-3-270m-it\u001b[39m\n",
      "[2025-10-07 09:39:05,982] [INFO] [axolotl.cli.utils.load_model_and_tokenizer:321] [PID:3059674] [RANK:0] loading model...\u001b[39m\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "[2025-10-07 09:39:08,074] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:3059674] [RANK:0] cuda memory usage after model load: 0.499GB (+0.323GB cache, +1.225GB misc)\u001b[39m\n",
      "[2025-10-07 09:39:08,088] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:308] [PID:3059674] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-10-07 09:39:08,092] [INFO] [axolotl.loaders.adapter.load_lora:82] [PID:3059674] [RANK:0] found linear modules: ['down_proj', 'gate_proj', 'k_proj', 'o_proj', 'q_proj', 'up_proj', 'v_proj']\u001b[39m\n",
      "[2025-10-07 09:39:08,092] [INFO] [axolotl.loaders.adapter.load_lora:99] [PID:3059674] [RANK:0] Initializing LoRA weights using dora. This might take longer.\u001b[39m\n",
      "trainable params: 7,718,400 || all params: 275,817,216 || trainable%: 2.7984\n",
      "[2025-10-07 09:39:12,024] [INFO] [axolotl.loaders.model.log_gpu_memory_usage:107] [PID:3059674] [RANK:0] cuda memory usage after adapters: 0.537GB (+0.971GB cache, +1.317GB misc)\u001b[39m\n",
      "[2025-10-07 09:39:12,447] [INFO] [axolotl.cli.merge_lora.do_merge_lora:31] [PID:3059674] [RANK:0] Running merge of LoRA with base model...\u001b[39m\n",
      "Unloading and merging model: 100%|██████████| 440/440 [00:00<00:00, 4450.44it/s]\n",
      "[2025-10-07 09:39:12,552] [INFO] [axolotl.cli.merge_lora.do_merge_lora:44] [PID:3059674] [RANK:0] Saving merged model to: out-gemma-3-270m-it/merged...\u001b[39m\n",
      "\u001b[0mCPU times: user 165 ms, sys: 32.3 ms, total: 197 ms\n",
      "Wall time: 25.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/axolotl merge-lora {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the merged model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-07 09:39:44 [__init__.py:216] Automatically detected platform cuda.\n",
      "INFO 10-07 09:39:48 [utils.py:328] non-default args: {'max_model_len': 8192, 'disable_log_stats': True, 'model': 'out-gemma-3-270m-it/merged'}\n",
      "INFO 10-07 09:40:00 [__init__.py:742] Resolved architecture: Gemma3ForCausalLM\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "INFO 10-07 09:40:00 [__init__.py:1815] Using max model len 8192\n",
      "INFO 10-07 09:40:01 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:02 [core.py:654] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:02 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='out-gemma-3-270m-it/merged', speculative_config=None, tokenizer='out-gemma-3-270m-it/merged', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=out-gemma-3-270m-it/merged, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "[W1007 09:40:06.617120838 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:06 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m WARNING 10-07 09:40:06 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:06 [gpu_model_runner.py:2338] Starting to load model out-gemma-3-270m-it/merged...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:06 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:06 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.72it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:00<00:00,  6.71it/s]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m \n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:07 [default_loader.py:268] Loading weights took 0.16 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:07 [gpu_model_runner.py:2392] Model loading took 0.5334 GiB and 0.411216 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:13 [backends.py:539] Using cache directory: /home/oisuomin/.cache/vllm/torch_compile_cache/0e8477b7f0/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:13 [backends.py:550] Dynamo bytecode transform time: 6.17 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:36 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 22.538 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:37 [monitor.py:34] torch.compile takes 6.17 s in total\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:38 [gpu_worker.py:298] Available KV cache memory: 68.32 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:38 [kv_cache_utils.py:1028] GPU KV cache size: 3,980,048 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:38 [kv_cache_utils.py:1032] Maximum concurrency for 8,192 tokens per request: 485.06x\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|█| 67/67 [00:01<00\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:40 [gpu_model_runner.py:3118] Graph capturing finished in 2 secs, took 1.15 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:40 [gpu_worker.py:391] Free memory on device (78.7/79.18 GiB) on startup. Desired GPU memory utilization is (0.9, 71.27 GiB). Actual usage is 0.53 GiB for weight, 2.39 GiB for peak activation, 0.02 GiB for non-torch memory, and 1.15 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=71971944960` to fit into requested memory, or `--kv-cache-memory=79952755200` to fully utilize gpu memory. Current kv cache memory in use is 73360259584 bytes.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=3059841)\u001b[0;0m INFO 10-07 09:40:40 [core.py:218] init engine (profile, create kv cache, warmup model) took 32.98 seconds\n",
      "INFO 10-07 09:40:43 [llm.py:295] Supported_tasks: ['generate']\n",
      "INFO 10-07 09:40:43 [__init__.py:36] No IOProcessor plugins requested by the model\n",
      "Adding requests: 100%|███████████████████████| 182/182 [00:00<00:00, 456.12it/s]\n",
      "Processed prompts: 100%|█| 182/182 [00:09<00:00, 18.91it/s, est. speed input: 46\n",
      "ERROR 10-07 09:40:55 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.\n",
      "| language   | field     |   mean |   size |\n",
      "|------------|-----------|--------|--------|\n",
      "| en         | alt_title | 0.7049 |     61 |\n",
      "| en         | creator   | 0.5423 |     61 |\n",
      "| en         | doi       | 0.8689 |     61 |\n",
      "| en         | e-isbn    | 0.7869 |     61 |\n",
      "| en         | e-issn    | 0.8525 |     61 |\n",
      "| en         | language  | 0.8197 |     61 |\n",
      "| en         | p-isbn    | 0.7705 |     61 |\n",
      "| en         | p-issn    | 0.8361 |     61 |\n",
      "| en         | publisher | 0.4372 |     61 |\n",
      "| en         | title     | 0.6066 |     61 |\n",
      "| en         | type_coar | 0.6557 |     61 |\n",
      "| en         | year      | 0.7869 |     61 |\n",
      "| fi         | alt_title | 0.5890 |     73 |\n",
      "| fi         | creator   | 0.5342 |     73 |\n",
      "| fi         | doi       | 1.0000 |     73 |\n",
      "| fi         | e-isbn    | 0.9863 |     73 |\n",
      "| fi         | e-issn    | 0.9452 |     73 |\n",
      "| fi         | language  | 0.9589 |     73 |\n",
      "| fi         | p-isbn    | 0.9315 |     73 |\n",
      "| fi         | p-issn    | 0.9178 |     73 |\n",
      "| fi         | publisher | 0.6164 |     73 |\n",
      "| fi         | title     | 0.4521 |     73 |\n",
      "| fi         | type_coar | 0.7945 |     73 |\n",
      "| fi         | year      | 0.8082 |     73 |\n",
      "| se         | alt_title | 0.6667 |      3 |\n",
      "| se         | creator   | 0.3333 |      3 |\n",
      "| se         | doi       | 1.0000 |      3 |\n",
      "| se         | e-isbn    | 1.0000 |      3 |\n",
      "| se         | e-issn    | 1.0000 |      3 |\n",
      "| se         | language  | 0.6667 |      3 |\n",
      "| se         | p-isbn    | 1.0000 |      3 |\n",
      "| se         | p-issn    | 1.0000 |      3 |\n",
      "| se         | publisher | 0.0000 |      3 |\n",
      "| se         | title     | 0.0000 |      3 |\n",
      "| se         | type_coar | 0.0000 |      3 |\n",
      "| se         | year      | 0.0000 |      3 |\n",
      "| sv         | alt_title | 0.7111 |     45 |\n",
      "| sv         | creator   | 0.5711 |     45 |\n",
      "| sv         | doi       | 0.9778 |     45 |\n",
      "| sv         | e-isbn    | 0.8222 |     45 |\n",
      "| sv         | e-issn    | 0.8222 |     45 |\n",
      "| sv         | language  | 0.8889 |     45 |\n",
      "| sv         | p-isbn    | 0.8222 |     45 |\n",
      "| sv         | p-issn    | 0.9333 |     45 |\n",
      "| sv         | publisher | 0.4444 |     45 |\n",
      "| sv         | title     | 0.2889 |     45 |\n",
      "| sv         | type_coar | 0.7778 |     45 |\n",
      "| sv         | year      | 0.6222 |     45 |\n",
      "CPU times: user 513 ms, sys: 73.3 ms, total: 586 ms\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# evaluate using the evaluate-model script, which needs venv with vLLM installed\n",
    "!../dspy/venv/bin/python evaluate-model.py out-{MODEL_SHORT_NAME}/merged axolotl-test.jsonl results-{MODEL_SHORT_NAME}.md\n",
    "!cat results-{MODEL_SHORT_NAME}.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greylitlm-axolotl",
   "language": "python",
   "name": "greylitlm-axolotl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
