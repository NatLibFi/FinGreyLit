{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tune Gemma-3-270M-it model using Axolotl framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available? True\n",
      "BF16 is supported? True\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "import torch\n",
    "print('GPU available?', torch.cuda.is_available())\n",
    "print('BF16 is supported?', torch.cuda.is_bf16_supported())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/appl/easybuild/opt/CUDA/12.6.0\n"
     ]
    }
   ],
   "source": [
    "!printenv CUDA_HOME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set model name etc.\n",
    "\n",
    "MODEL_NAME = \"google/gemma-3-270m-it\"\n",
    "MODEL_SHORT_NAME = MODEL_NAME.split('/')[-1]\n",
    "SUFFIX = \"FinGreyLit\"\n",
    "#SLICE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1224 train records\n",
      "Wrote 377 test records\n",
      "Wrote 32 eval records\n"
     ]
    }
   ],
   "source": [
    "# Load and prepare fine-tuning dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of test set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "EVAL_SIZE = 32  # how many documents to evaluate (i.e. calculate loss) on during fine-tuning\n",
    "SYSTEM_PROMPT = \"You are a skilled librarian specialized in meticulous cataloguing of digital documents.\"\n",
    "INSTRUCTION = \"Extract metadata from this document. Return as JSON.\"\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    output = json.dumps(sample[\"ground_truth\"])\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    # ShareGPT format\n",
    "    conversations = [\n",
    "        {'from': 'system', 'value': SYSTEM_PROMPT},\n",
    "        {'from': 'user', 'value': INSTRUCTION + \"\\n\\n\" + input_},\n",
    "        {'from': 'assistant', 'value': output}\n",
    "    ]\n",
    "    return {\"conversations\": conversations}\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "def write_jsonl(records, filename):\n",
    "    with open(filename, \"w\") as outfile:\n",
    "        for record in records:\n",
    "            json.dump(record, outfile)\n",
    "            outfile.write(\"\\n\")\n",
    "\n",
    "train_recs = dataset_to_records(train_files)\n",
    "random.shuffle(train_recs)\n",
    "write_jsonl(train_recs, \"axolotl-train.jsonl\")\n",
    "print(f\"Wrote {len(train_recs)} train records\")\n",
    "\n",
    "test_recs = dataset_to_records(test_files)\n",
    "write_jsonl(test_recs, \"axolotl-test.jsonl\")\n",
    "print(f\"Wrote {len(test_recs)} test records\")\n",
    "\n",
    "eval_recs = random.sample(test_recs, EVAL_SIZE)\n",
    "write_jsonl(eval_recs, \"axolotl-eval.jsonl\")\n",
    "print(f\"Wrote {len(eval_recs)} eval records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Axolotl configuration file\n",
    "\n",
    "CONFIG_FILE = f\"config-{MODEL_SHORT_NAME}.yml\"\n",
    "\n",
    "\n",
    "CONFIG = f\"\"\"\n",
    "base_model: {MODEL_NAME}\n",
    "model_type: AutoModelForCausalLM\n",
    "tokenizer_type: AutoTokenizer\n",
    "\n",
    "load_in_8bit: false\n",
    "load_in_4bit: false\n",
    "strict: false\n",
    "\n",
    "datasets:\n",
    "  - path: axolotl-train.jsonl\n",
    "    type: chat_template\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "\n",
    "test_datasets:\n",
    "  - path: axolotl-eval.jsonl\n",
    "    type: chat_template\n",
    "    ds_type: json\n",
    "    split: train\n",
    "    field_messages: conversations\n",
    "    message_property_mappings:\n",
    "      role: from\n",
    "      content: value\n",
    "\n",
    "output_dir: ./out-{MODEL_SHORT_NAME}\n",
    "\n",
    "chat_template: gemma3\n",
    "eot_tokens:\n",
    "  - <end_of_turn>\n",
    "\n",
    "#peft_use_dora: true\n",
    "#adapter: lora\n",
    "#lora_r: 32\n",
    "#lora_alpha: 16\n",
    "#lora_dropout: 0.05\n",
    "#lora_target_linear: true\n",
    "\n",
    "sequence_len: 4096\n",
    "sample_packing: true\n",
    "eval_sample_packing: false\n",
    "\n",
    "wandb_project:\n",
    "wandb_entity:\n",
    "wandb_watch:\n",
    "wandb_name:\n",
    "wandb_log_model:\n",
    "\n",
    "gradient_accumulation_steps: 4\n",
    "micro_batch_size: 2\n",
    "eval_batch_size: 2\n",
    "num_epochs: 5\n",
    "optimizer: adamw_bnb_8bit\n",
    "lr_scheduler: cosine\n",
    "learning_rate: 0.0002\n",
    "\n",
    "train_on_inputs: false\n",
    "group_by_length: false\n",
    "bf16: true\n",
    "fp16: false\n",
    "tf32: false\n",
    "\n",
    "gradient_checkpointing: true  # true: saves VRAM but is slower to train\n",
    "early_stopping_patience:\n",
    "resume_from_checkpoint:\n",
    "local_rank:\n",
    "logging_steps: 1\n",
    "xformers_attention:\n",
    "flash_attention: true\n",
    "\n",
    "warmup_steps: 10\n",
    "evals_per_epoch: 2\n",
    "eval_table_size:\n",
    "eval_table_max_new_tokens: 128\n",
    "saves_per_epoch: 1\n",
    "debug:\n",
    "weight_decay: 0.0\n",
    "fsdp:\n",
    "fsdp_config:\n",
    "\n",
    "\n",
    "\"\"\".strip()\n",
    "\n",
    "with open(CONFIG_FILE, 'w') as outfile:\n",
    "    print(CONFIG, file=outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following values were not passed to `accelerate launch` and had defaults used instead:\n",
      "\t`--num_processes` was set to a value of `1`\n",
      "\t`--num_machines` was set to a value of `1`\n",
      "\t`--mixed_precision` was set to a value of `'no'`\n",
      "\t`--dynamo_backend` was set to a value of `'no'`\n",
      "To avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\n",
      "[2025-10-10 12:10:23,367] [INFO] [axolotl.utils.schemas.config.check_eval_packing:756] [PID:4133512] [RANK:0] setting `remove_unused_columns: false` for when sample_packing and eval_sample_packing don't match\u001b[39m\n",
      "[2025-10-10 12:10:23,367] [INFO] [axolotl.utils.schemas.config.hint_sample_packing_padding:539] [PID:4133512] [RANK:0] Setting `pad_to_sequence_len: true` to prevent memory leaks when sample_packing\u001b[39m\n",
      "[2025-10-10 12:10:23,676] [INFO] [axolotl.utils.config.log_gpu_memory_usage:107] [PID:4133512] [RANK:0] cuda memory usage baseline: 0.000GB (+73.021GB misc)\u001b[39m\n",
      "\n",
      "     #@@ #@@      @@# @@#\n",
      "    @@  @@          @@  @@           =@@#                               @@                 #@    =@@#.\n",
      "    @@    #@@@@@@@@@    @@           #@#@=                              @@                 #@     .=@@\n",
      "      #@@@@@@@@@@@@@@@@@            =@# @#     ##=     ##    =####=+    @@      =#####+  =#@@###.   @@\n",
      "    @@@@@@@@@@/  +@@/  +@@          #@  =@=     #@=   @@   =@#+  +#@#   @@    =@#+  +#@#   #@.      @@\n",
      "    @@@@@@@@@@  ##@@  ##@@         =@#   @#      =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "     @@@@@@@@@@@@@@@@@@@@          #@=+++#@=      =@@#     @@      @@   @@    @@      #@   #@       @@\n",
      "                                  =@#=====@@     =@# @#    @@      @@   @@    @@      #@   #@       @@\n",
      "    @@@@@@@@@@@@@@@@  @@@@        #@      #@=   #@=  +@@   #@#    =@#   @@.   =@#    =@#   #@.      @@\n",
      "                                 =@#       @#  #@=     #@   =#@@@@#=    +#@@=  +#@@@@#=    .##@@+   @@\n",
      "    @@@@  @@@@@@@@@@@@@@@@\n",
      "\n",
      "[2025-10-10 12:10:25,671] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:4133512] [RANK:0] Unable to find prepared dataset in last_run_prepared/9995208875383310c98f856a93500d35\u001b[39m\n",
      "[2025-10-10 12:10:25,672] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:4133512] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-10-10 12:10:25,672] [WARNING] [axolotl.utils.data.sft._load_raw_datasets:312] [PID:4133512] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\u001b[39m\n",
      "Generating train split: 1224 examples [00:00, 37494.27 examples/s]\n",
      "[2025-10-10 12:10:26,143] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:4133512] [RANK:0] Loading dataset: axolotl-train.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
      "[2025-10-10 12:10:26,206] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:4133512] [RANK:0] Using chat template:\n",
      "---\n",
      "{{ bos_token }}\n",
      "{%- if messages[0]['role'] == 'system' -%}\n",
      "    {%- if messages[0]['content'] is string -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- else -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- endif -%}\n",
      "    {%- set loop_messages = messages[1:] -%}\n",
      "{%- else -%}\n",
      "    {%- set first_user_prefix = \"\" -%}\n",
      "    {%- set loop_messages = messages -%}\n",
      "{%- endif -%}\n",
      "{%- for message in loop_messages -%}\n",
      "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n",
      "        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
      "    {%- endif -%}\n",
      "    {%- if (message['role'] == 'assistant') -%}\n",
      "        {%- set role = \"model\" -%}\n",
      "    {%- else -%}\n",
      "        {%- set role = message['role'] -%}\n",
      "    {%- endif -%}\n",
      "    {{ '<start_of_turn>' + role + '\n",
      "' + (first_user_prefix if loop.first else \"\") }}\n",
      "    {%- if message['content'] is string -%}\n",
      "        {{ message['content'] | trim }}\n",
      "    {%- elif message['content'] is iterable -%}\n",
      "        {%- for item in message['content'] -%}\n",
      "            {%- if item['type'] == 'image' -%}\n",
      "                {{ '<start_of_image>' }}\n",
      "            {%- elif item['type'] == 'text' -%}\n",
      "                {{ item['text'] | trim }}\n",
      "            {%- endif -%}\n",
      "        {%- endfor -%}\n",
      "    {%- else -%}\n",
      "        {{ raise_exception(\"Invalid content type\") }}\n",
      "    {%- endif -%}\n",
      "    {{ '<end_of_turn>\n",
      "' }}\n",
      "{%- endfor -%}\n",
      "{%- if add_generation_prompt -%}\n",
      "    {{'<start_of_turn>model\n",
      "'}}\n",
      "{%- endif -%}\n",
      "\n",
      "---\u001b[39m\n",
      "Tokenizing Prompts (num_proc=32): 100%|█| 1224/1224 [00:13<00:00, 88.94 examples\n",
      "[2025-10-10 12:10:40,810] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:4133512] [RANK:0] min_input_len: 160\u001b[39m\n",
      "[2025-10-10 12:10:40,810] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:4133512] [RANK:0] max_input_len: 12150\u001b[39m\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 1224/1224 [00:00<00:00, 2793.18 e\n",
      "\u001b[33m[2025-10-10 12:10:42,648] [WARNING] [axolotl.utils.data.utils.drop_long_seq_in_dataset:201] [PID:4133512] [RANK:0] Dropped 10 long samples from dataset\u001b[39m\n",
      "Drop Samples with Zero Trainable Tokens (num_proc=32): 100%|█| 1214/1214 [00:00<\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 1214/1214 [00:00<\n",
      "Saving the dataset (1/1 shards): 100%|█| 1214/1214 [00:00<00:00, 9426.22 example\n",
      "[2025-10-10 12:10:46,093] [INFO] [axolotl.utils.data.shared.load_preprocessed_dataset:467] [PID:4133512] [RANK:0] Unable to find prepared dataset in last_run_prepared/3e9c7502992f1e22c561f1905c168a52\u001b[39m\n",
      "[2025-10-10 12:10:46,094] [INFO] [axolotl.utils.data.sft._load_raw_datasets:310] [PID:4133512] [RANK:0] Loading raw datasets...\u001b[39m\n",
      "\u001b[33m[2025-10-10 12:10:46,094] [WARNING] [axolotl.utils.data.sft._load_raw_datasets:312] [PID:4133512] [RANK:0] Processing datasets during training can lead to VRAM instability. Please pre-process your dataset using `axolotl preprocess path/to/config.yml`.\u001b[39m\n",
      "Generating train split: 32 examples [00:00, 7571.80 examples/s]\n",
      "[2025-10-10 12:10:46,505] [INFO] [axolotl.utils.data.wrappers.get_dataset_wrapper:88] [PID:4133512] [RANK:0] Loading dataset: axolotl-eval.jsonl with base_type: chat_template and prompt_style: None\u001b[39m\n",
      "[2025-10-10 12:10:46,570] [INFO] [axolotl.prompt_strategies.chat_template.__call__:941] [PID:4133512] [RANK:0] Using chat template:\n",
      "---\n",
      "{{ bos_token }}\n",
      "{%- if messages[0]['role'] == 'system' -%}\n",
      "    {%- if messages[0]['content'] is string -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- else -%}\n",
      "        {%- set first_user_prefix = messages[0]['content'][0]['text'] + '\n",
      "\n",
      "' -%}\n",
      "    {%- endif -%}\n",
      "    {%- set loop_messages = messages[1:] -%}\n",
      "{%- else -%}\n",
      "    {%- set first_user_prefix = \"\" -%}\n",
      "    {%- set loop_messages = messages -%}\n",
      "{%- endif -%}\n",
      "{%- for message in loop_messages -%}\n",
      "    {%- if (message['role'] == 'user') != (loop.index0 % 2 == 0) -%}\n",
      "        {{ raise_exception(\"Conversation roles must alternate user/assistant/user/assistant/...\") }}\n",
      "    {%- endif -%}\n",
      "    {%- if (message['role'] == 'assistant') -%}\n",
      "        {%- set role = \"model\" -%}\n",
      "    {%- else -%}\n",
      "        {%- set role = message['role'] -%}\n",
      "    {%- endif -%}\n",
      "    {{ '<start_of_turn>' + role + '\n",
      "' + (first_user_prefix if loop.first else \"\") }}\n",
      "    {%- if message['content'] is string -%}\n",
      "        {{ message['content'] | trim }}\n",
      "    {%- elif message['content'] is iterable -%}\n",
      "        {%- for item in message['content'] -%}\n",
      "            {%- if item['type'] == 'image' -%}\n",
      "                {{ '<start_of_image>' }}\n",
      "            {%- elif item['type'] == 'text' -%}\n",
      "                {{ item['text'] | trim }}\n",
      "            {%- endif -%}\n",
      "        {%- endfor -%}\n",
      "    {%- else -%}\n",
      "        {{ raise_exception(\"Invalid content type\") }}\n",
      "    {%- endif -%}\n",
      "    {{ '<end_of_turn>\n",
      "' }}\n",
      "{%- endfor -%}\n",
      "{%- if add_generation_prompt -%}\n",
      "    {{'<start_of_turn>model\n",
      "'}}\n",
      "{%- endif -%}\n",
      "\n",
      "---\u001b[39m\n",
      "Tokenizing Prompts (num_proc=32): 100%|██| 32/32 [00:12<00:00,  2.64 examples/s]\n",
      "[2025-10-10 12:10:59,598] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:177] [PID:4133512] [RANK:0] min_input_len: 386\u001b[39m\n",
      "[2025-10-10 12:10:59,598] [INFO] [axolotl.utils.data.utils.drop_long_seq_in_dataset:179] [PID:4133512] [RANK:0] max_input_len: 3380\u001b[39m\n",
      "Dropping Long Sequences (num_proc=32): 100%|█| 32/32 [00:00<00:00, 159.00 exampl\n",
      "Drop Samples with Zero Trainable Tokens (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "Add position_id column (Sample Packing) (num_proc=32): 100%|█| 32/32 [00:00<00:0\n",
      "Saving the dataset (1/1 shards): 100%|██| 32/32 [00:00<00:00, 934.44 examples/s]\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m[2025-10-10 12:12:20,093] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:4133512] [RANK:0] gather_len_batches: [390]\u001b[39m\n",
      "[2025-10-10 12:12:20,094] [INFO] [axolotl.utils.data.sft._prepare_standard_dataset:123] [PID:4133512] [RANK:0] Maximum number of steps set at 485\u001b[39m\n",
      "You are attempting to use Flash Attention 2.0 with a model not initialized on GPU. Make sure to move the model to GPU after initializing it on CPU with `model.to('cuda')`.\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['cache_implementation']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "[2025-10-10 12:12:34,366] [INFO] [axolotl.loaders.model._configure_embedding_dtypes:308] [PID:4133512] [RANK:0] Converting modules to torch.bfloat16\u001b[39m\n",
      "[2025-10-10 12:12:37,305] [WARNING] [accelerate.utils.other.check_os_kernel:441] [PID:4133512] Detected kernel version 4.18.0, which is below the recommended minimum of 5.5.0; this can cause the process to hang. It is recommended to upgrade the kernel to the minimum version or higher.\n",
      "[2025-10-10 12:12:42,955] [INFO] [axolotl.train.save_initial_configs:407] [PID:4133512] [RANK:0] Pre-saving tokenizer to ./out-gemma-3-270m-it...\u001b[39m\n",
      "[2025-10-10 12:12:43,470] [INFO] [axolotl.train.save_initial_configs:410] [PID:4133512] [RANK:0] Pre-saving model config to ./out-gemma-3-270m-it...\u001b[39m\n",
      "[2025-10-10 12:12:43,481] [INFO] [axolotl.train.execute_training:225] [PID:4133512] [RANK:0] Starting trainer...\u001b[39m\n",
      "\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m\u001b[0m[2025-10-10 12:14:03,105] [INFO] [axolotl.utils.samplers.multipack.calc_min_len:431] [PID:4133512] [RANK:0] gather_len_batches: [389]\u001b[39m\n",
      "  0%|                                                   | 0/485 [00:00<?, ?it/s]You're using a GemmaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:00, 14.35it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  9.13it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  8.38it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  7.83it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:00<00:01,  7.47it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  4.94it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:01,  5.39it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  5.73it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  5.99it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.00it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:02<00:00,  6.25it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.38it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 2.317384719848633, 'eval_runtime': 3.2052, 'eval_samples_per_second': 9.984, 'eval_steps_per_second': 4.992, 'epoch': 0}\n",
      "  0%|                                                   | 0/485 [00:03<?, ?it/s]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.62it/s]\u001b[A\n",
      "                                                                                \u001b[A\u001b[0m\u001b[0mIt is strongly recommended to train Gemma3 models with the `eager` attention implementation instead of `flash_attention_2`. Use `eager` with `AutoModelForCausalLM.from_pretrained('<path-to-checkpoint>', attn_implementation='eager')`.\n",
      "{'loss': 2.9833, 'grad_norm': 98.5, 'learning_rate': 0.0, 'epoch': 0.01}        \n",
      "  0%|                                         | 1/485 [00:20<2:45:56, 20.57s/it][2025-10-10 12:14:25,252] [INFO] [axolotl.utils.callbacks.log_gpu_memory_usage:107] [PID:4133512] [RANK:0] cuda memory usage while training: 1.963GB (+26.977GB cache, +1.265GB misc)\u001b[39m\n",
      "{'loss': 2.4776, 'grad_norm': 96.5, 'learning_rate': 2e-05, 'epoch': 0.02}      \n",
      "{'loss': 1.692, 'grad_norm': 34.5, 'learning_rate': 4e-05, 'epoch': 0.03}       \n",
      "{'loss': 1.2895, 'grad_norm': 31.625, 'learning_rate': 6e-05, 'epoch': 0.04}    \n",
      "{'loss': 0.8101, 'grad_norm': 20.0, 'learning_rate': 8e-05, 'epoch': 0.05}      \n",
      "{'loss': 0.6413, 'grad_norm': 13.5, 'learning_rate': 0.0001, 'epoch': 0.06}     \n",
      "{'loss': 0.9578, 'grad_norm': 18.375, 'learning_rate': 0.00012, 'epoch': 0.07}  \n",
      "{'loss': 0.8897, 'grad_norm': 24.625, 'learning_rate': 0.00014, 'epoch': 0.08}  \n",
      "{'loss': 0.5893, 'grad_norm': 20.125, 'learning_rate': 0.00016, 'epoch': 0.09}  \n",
      "{'loss': 0.5836, 'grad_norm': 9.75, 'learning_rate': 0.00018, 'epoch': 0.1}     \n",
      "{'loss': 0.7378, 'grad_norm': 30.75, 'learning_rate': 0.0002, 'epoch': 0.11}    \n",
      "{'loss': 0.676, 'grad_norm': 22.375, 'learning_rate': 0.0001999978128380225, 'epoch': 0.12}\n",
      "{'loss': 0.5878, 'grad_norm': 10.5625, 'learning_rate': 0.0001999912514477634, 'epoch': 0.13}\n",
      "{'loss': 0.5511, 'grad_norm': 10.1875, 'learning_rate': 0.0001999803161162393, 'epoch': 0.14}\n",
      "{'loss': 0.4523, 'grad_norm': 8.0, 'learning_rate': 0.00019996500732179695, 'epoch': 0.15}\n",
      "{'loss': 0.3454, 'grad_norm': 8.4375, 'learning_rate': 0.00019994532573409262, 'epoch': 0.16}\n",
      "{'loss': 0.3132, 'grad_norm': 6.90625, 'learning_rate': 0.00019992127221406275, 'epoch': 0.17}\n",
      "{'loss': 0.4364, 'grad_norm': 13.625, 'learning_rate': 0.00019989284781388617, 'epoch': 0.19}\n",
      "{'loss': 0.5865, 'grad_norm': 9.9375, 'learning_rate': 0.00019986005377693825, 'epoch': 0.2}\n",
      "{'loss': 0.4844, 'grad_norm': 8.625, 'learning_rate': 0.00019982289153773646, 'epoch': 0.21}\n",
      "{'loss': 0.4241, 'grad_norm': 7.40625, 'learning_rate': 0.00019978136272187747, 'epoch': 0.22}\n",
      "{'loss': 0.4637, 'grad_norm': 8.0625, 'learning_rate': 0.00019973546914596623, 'epoch': 0.23}\n",
      "{'loss': 0.4837, 'grad_norm': 8.1875, 'learning_rate': 0.00019968521281753642, 'epoch': 0.24}\n",
      "{'loss': 0.3965, 'grad_norm': 4.9375, 'learning_rate': 0.00019963059593496268, 'epoch': 0.25}\n",
      "{'loss': 0.3302, 'grad_norm': 5.90625, 'learning_rate': 0.0001995716208873644, 'epoch': 0.26}\n",
      "{'loss': 0.4909, 'grad_norm': 7.96875, 'learning_rate': 0.00019950829025450114, 'epoch': 0.27}\n",
      "{'loss': 0.3287, 'grad_norm': 5.5, 'learning_rate': 0.00019944060680666002, 'epoch': 0.28}\n",
      "{'loss': 0.5358, 'grad_norm': 7.8125, 'learning_rate': 0.0001993685735045343, 'epoch': 0.29}\n",
      "{'loss': 0.3701, 'grad_norm': 6.75, 'learning_rate': 0.00019929219349909392, 'epoch': 0.3}\n",
      "{'loss': 0.3801, 'grad_norm': 5.625, 'learning_rate': 0.0001992114701314478, 'epoch': 0.31}\n",
      "{'loss': 0.4806, 'grad_norm': 6.34375, 'learning_rate': 0.00019912640693269752, 'epoch': 0.32}\n",
      "{'loss': 0.4997, 'grad_norm': 5.6875, 'learning_rate': 0.000199037007623783, 'epoch': 0.33}\n",
      "{'loss': 0.4263, 'grad_norm': 7.375, 'learning_rate': 0.0001989432761153196, 'epoch': 0.34}\n",
      "{'loss': 0.3, 'grad_norm': 6.21875, 'learning_rate': 0.00019884521650742715, 'epoch': 0.35}\n",
      "{'loss': 0.4013, 'grad_norm': 6.03125, 'learning_rate': 0.00019874283308955057, 'epoch': 0.36}\n",
      "{'loss': 0.3642, 'grad_norm': 6.46875, 'learning_rate': 0.00019863613034027224, 'epoch': 0.37}\n",
      "{'loss': 0.2529, 'grad_norm': 4.0625, 'learning_rate': 0.00019852511292711608, 'epoch': 0.38}\n",
      "{'loss': 0.3735, 'grad_norm': 5.0, 'learning_rate': 0.0001984097857063434, 'epoch': 0.39}\n",
      "{'loss': 0.8095, 'grad_norm': 6.875, 'learning_rate': 0.00019829015372274038, 'epoch': 0.4}\n",
      "{'loss': 0.7231, 'grad_norm': 6.3125, 'learning_rate': 0.0001981662222093976, 'epoch': 0.41}\n",
      "{'loss': 0.3376, 'grad_norm': 6.1875, 'learning_rate': 0.00019803799658748094, 'epoch': 0.42}\n",
      "{'loss': 0.3707, 'grad_norm': 4.1875, 'learning_rate': 0.00019790548246599447, 'epoch': 0.43}\n",
      "{'loss': 0.387, 'grad_norm': 4.96875, 'learning_rate': 0.00019776868564153516, 'epoch': 0.44}\n",
      "{'loss': 0.2271, 'grad_norm': 4.1875, 'learning_rate': 0.00019762761209803927, 'epoch': 0.45}\n",
      "{'loss': 0.2286, 'grad_norm': 4.53125, 'learning_rate': 0.0001974822680065206, 'epoch': 0.46}\n",
      "{'loss': 0.4689, 'grad_norm': 5.5625, 'learning_rate': 0.0001973326597248006, 'epoch': 0.47}\n",
      "{'loss': 0.2759, 'grad_norm': 4.1875, 'learning_rate': 0.00019717879379723012, 'epoch': 0.48}\n",
      "{'loss': 0.4263, 'grad_norm': 5.34375, 'learning_rate': 0.00019702067695440332, 'epoch': 0.49}\n",
      "{'loss': 0.2474, 'grad_norm': 3.640625, 'learning_rate': 0.0001968583161128631, 'epoch': 0.5}\n",
      " 10%|████▏                                     | 49/485 [01:35<11:23,  1.57s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.99it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:01,  8.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:01,  7.90it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:00<00:01,  7.53it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:00<00:01,  7.26it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:01,  7.09it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:01<00:01,  6.72it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:01<00:00,  6.78it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:01<00:00,  6.54it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:01<00:00,  6.63it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:02<00:00,  6.65it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.33112066984176636, 'eval_runtime': 2.4703, 'eval_samples_per_second': 12.954, 'eval_steps_per_second': 6.477, 'epoch': 0.5}\n",
      " 10%|████▏                                     | 49/485 [01:38<11:23,  1.57s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:02<00:00,  6.82it/s]\u001b[A\n",
      "{'loss': 0.3985, 'grad_norm': 5.21875, 'learning_rate': 0.00019669171837479873, 'epoch': 0.51}\n",
      "{'loss': 0.3192, 'grad_norm': 5.3125, 'learning_rate': 0.00019652089102773488, 'epoch': 0.52}\n",
      "{'loss': 0.2486, 'grad_norm': 3.875, 'learning_rate': 0.00019634584154421317, 'epoch': 0.53}\n",
      "{'loss': 0.2138, 'grad_norm': 4.125, 'learning_rate': 0.00019616657758146503, 'epoch': 0.54}\n",
      "{'loss': 0.1723, 'grad_norm': 4.6875, 'learning_rate': 0.00019598310698107702, 'epoch': 0.56}\n",
      "{'loss': 0.3318, 'grad_norm': 3.40625, 'learning_rate': 0.0001957954377686475, 'epoch': 0.57}\n",
      "{'loss': 0.2987, 'grad_norm': 8.75, 'learning_rate': 0.00019560357815343577, 'epoch': 0.58}\n",
      "{'loss': 0.3163, 'grad_norm': 4.53125, 'learning_rate': 0.000195407536528003, 'epoch': 0.59}\n",
      "{'loss': 0.4809, 'grad_norm': 6.625, 'learning_rate': 0.00019520732146784491, 'epoch': 0.6}\n",
      "{'loss': 0.2143, 'grad_norm': 3.609375, 'learning_rate': 0.00019500294173101687, 'epoch': 0.61}\n",
      "{'loss': 0.4431, 'grad_norm': 6.15625, 'learning_rate': 0.0001947944062577507, 'epoch': 0.62}\n",
      "{'loss': 0.4646, 'grad_norm': 5.0625, 'learning_rate': 0.00019458172417006347, 'epoch': 0.63}\n",
      "{'loss': 0.3605, 'grad_norm': 3.78125, 'learning_rate': 0.00019436490477135878, 'epoch': 0.64}\n",
      "{'loss': 0.2493, 'grad_norm': 3.765625, 'learning_rate': 0.00019414395754601947, 'epoch': 0.65}\n",
      "{'loss': 0.2777, 'grad_norm': 4.0625, 'learning_rate': 0.00019391889215899299, 'epoch': 0.66}\n",
      "{'loss': 0.4059, 'grad_norm': 6.46875, 'learning_rate': 0.00019368971845536845, 'epoch': 0.67}\n",
      "{'loss': 0.2621, 'grad_norm': 3.8125, 'learning_rate': 0.0001934564464599461, 'epoch': 0.68}\n",
      "{'loss': 0.2803, 'grad_norm': 3.734375, 'learning_rate': 0.00019321908637679865, 'epoch': 0.69}\n",
      "{'loss': 0.4353, 'grad_norm': 5.375, 'learning_rate': 0.00019297764858882514, 'epoch': 0.7}\n",
      "{'loss': 0.259, 'grad_norm': 3.734375, 'learning_rate': 0.00019273214365729655, 'epoch': 0.71}\n",
      "{'loss': 0.2605, 'grad_norm': 4.9375, 'learning_rate': 0.00019248258232139388, 'epoch': 0.72}\n",
      "{'loss': 0.558, 'grad_norm': 4.78125, 'learning_rate': 0.00019222897549773848, 'epoch': 0.73}\n",
      "{'loss': 0.3485, 'grad_norm': 4.125, 'learning_rate': 0.00019197133427991436, 'epoch': 0.74}\n",
      "{'loss': 0.1642, 'grad_norm': 2.65625, 'learning_rate': 0.000191709669937983, 'epoch': 0.75}\n",
      "{'loss': 0.3, 'grad_norm': 4.8125, 'learning_rate': 0.00019144399391799043, 'epoch': 0.76}\n",
      "{'loss': 0.5263, 'grad_norm': 7.84375, 'learning_rate': 0.00019117431784146645, 'epoch': 0.77}\n",
      "{'loss': 0.3251, 'grad_norm': 4.90625, 'learning_rate': 0.00019090065350491626, 'epoch': 0.78}\n",
      "{'loss': 0.2019, 'grad_norm': 3.546875, 'learning_rate': 0.00019062301287930446, 'epoch': 0.79}\n",
      "{'loss': 0.4709, 'grad_norm': 5.25, 'learning_rate': 0.0001903414081095315, 'epoch': 0.8}\n",
      "{'loss': 0.2416, 'grad_norm': 4.3125, 'learning_rate': 0.00019005585151390223, 'epoch': 0.81}\n",
      "{'loss': 0.4135, 'grad_norm': 4.5625, 'learning_rate': 0.00018976635558358722, 'epoch': 0.82}\n",
      "{'loss': 0.2922, 'grad_norm': 3.640625, 'learning_rate': 0.00018947293298207635, 'epoch': 0.83}\n",
      "{'loss': 0.1794, 'grad_norm': 3.578125, 'learning_rate': 0.00018917559654462474, 'epoch': 0.84}\n",
      "{'loss': 0.2614, 'grad_norm': 3.125, 'learning_rate': 0.00018887435927769137, 'epoch': 0.85}\n",
      "{'loss': 0.2294, 'grad_norm': 3.65625, 'learning_rate': 0.00018856923435837022, 'epoch': 0.86}\n",
      "{'loss': 0.5951, 'grad_norm': 6.21875, 'learning_rate': 0.0001882602351338137, 'epoch': 0.87}\n",
      "{'loss': 0.2928, 'grad_norm': 4.59375, 'learning_rate': 0.0001879473751206489, 'epoch': 0.88}\n",
      "{'loss': 0.3526, 'grad_norm': 5.25, 'learning_rate': 0.00018763066800438636, 'epoch': 0.89}\n",
      "{'loss': 0.2012, 'grad_norm': 3.796875, 'learning_rate': 0.00018731012763882133, 'epoch': 0.9}\n",
      "{'loss': 0.5746, 'grad_norm': 10.5625, 'learning_rate': 0.00018698576804542777, 'epoch': 0.92}\n",
      "{'loss': 0.3044, 'grad_norm': 4.375, 'learning_rate': 0.00018665760341274505, 'epoch': 0.93}\n",
      "{'loss': 0.3772, 'grad_norm': 8.375, 'learning_rate': 0.00018632564809575742, 'epoch': 0.94}\n",
      "{'loss': 0.4361, 'grad_norm': 5.21875, 'learning_rate': 0.00018598991661526572, 'epoch': 0.95}\n",
      "{'loss': 0.2933, 'grad_norm': 2.96875, 'learning_rate': 0.00018565042365725258, 'epoch': 0.96}\n",
      "{'loss': 0.6561, 'grad_norm': 6.6875, 'learning_rate': 0.00018530718407223974, 'epoch': 0.97}\n",
      "{'loss': 0.2416, 'grad_norm': 3.09375, 'learning_rate': 0.0001849602128746387, 'epoch': 0.98}\n",
      "{'loss': 0.2701, 'grad_norm': 4.125, 'learning_rate': 0.00018460952524209355, 'epoch': 0.99}\n",
      "{'loss': 0.1275, 'grad_norm': 4.03125, 'learning_rate': 0.00018425513651481747, 'epoch': 1.0}\n",
      "{'loss': 0.7281, 'grad_norm': 10.3125, 'learning_rate': 0.00018389706219492147, 'epoch': 1.0}\n",
      " 20%|████████▍                                 | 98/485 [03:08<21:58,  3.41s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:02,  6.93it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:02,  6.39it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.21it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:01<00:02,  4.05it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  3.71it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.60it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:02,  3.62it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:02,  3.37it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.25it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  3.35it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.48it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:00,  3.28it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:03<00:00,  3.24it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  3.33it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.27604013681411743, 'eval_runtime': 4.7013, 'eval_samples_per_second': 6.807, 'eval_steps_per_second': 3.403, 'epoch': 1.0}\n",
      " 20%|████████▍                                 | 98/485 [03:13<21:58,  3.41s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.48it/s]\u001b[A\n",
      "{'loss': 0.2928, 'grad_norm': 3.40625, 'learning_rate': 0.00018353531794573625, 'epoch': 1.01}\n",
      "{'loss': 0.4295, 'grad_norm': 2.71875, 'learning_rate': 0.00018316991959112716, 'epoch': 1.02}\n",
      "{'loss': 0.2059, 'grad_norm': 2.65625, 'learning_rate': 0.00018280088311480201, 'epoch': 1.03}\n",
      "{'loss': 0.4482, 'grad_norm': 3.109375, 'learning_rate': 0.00018242822465961176, 'epoch': 1.04}\n",
      "{'loss': 0.4286, 'grad_norm': 3.34375, 'learning_rate': 0.00018205196052684445, 'epoch': 1.05}\n",
      "{'loss': 0.4797, 'grad_norm': 2.9375, 'learning_rate': 0.00018167210717551224, 'epoch': 1.06}\n",
      "{'loss': 0.1725, 'grad_norm': 2.328125, 'learning_rate': 0.00018128868122163123, 'epoch': 1.07}\n",
      "{'loss': 0.2009, 'grad_norm': 3.90625, 'learning_rate': 0.00018090169943749476, 'epoch': 1.08}\n",
      "{'loss': 0.2641, 'grad_norm': 3.140625, 'learning_rate': 0.00018051117875093976, 'epoch': 1.09}\n",
      "{'loss': 0.4158, 'grad_norm': 3.484375, 'learning_rate': 0.00018011713624460608, 'epoch': 1.1}\n",
      "{'loss': 0.1195, 'grad_norm': 2.15625, 'learning_rate': 0.0001797195891551896, 'epoch': 1.11}\n",
      "{'loss': 0.2835, 'grad_norm': 3.875, 'learning_rate': 0.00017931855487268782, 'epoch': 1.12}\n",
      "{'loss': 0.2284, 'grad_norm': 3.234375, 'learning_rate': 0.00017891405093963938, 'epoch': 1.13}\n",
      "{'loss': 0.123, 'grad_norm': 2.96875, 'learning_rate': 0.0001785060950503568, 'epoch': 1.14}\n",
      "{'loss': 0.1547, 'grad_norm': 2.75, 'learning_rate': 0.0001780947050501522, 'epoch': 1.15}\n",
      "{'loss': 0.1627, 'grad_norm': 2.8125, 'learning_rate': 0.00017767989893455698, 'epoch': 1.16}\n",
      "{'loss': 0.2177, 'grad_norm': 3.5625, 'learning_rate': 0.00017726169484853438, 'epoch': 1.17}\n",
      "{'loss': 0.1894, 'grad_norm': 3.046875, 'learning_rate': 0.00017684011108568592, 'epoch': 1.19}\n",
      "{'loss': 0.1619, 'grad_norm': 4.8125, 'learning_rate': 0.00017641516608745114, 'epoch': 1.2}\n",
      "{'loss': 0.1556, 'grad_norm': 2.59375, 'learning_rate': 0.00017598687844230088, 'epoch': 1.21}\n",
      "{'loss': 0.1233, 'grad_norm': 3.015625, 'learning_rate': 0.0001755552668849242, 'epoch': 1.22}\n",
      "{'loss': 0.1265, 'grad_norm': 2.234375, 'learning_rate': 0.00017512035029540885, 'epoch': 1.23}\n",
      "{'loss': 0.1111, 'grad_norm': 4.8125, 'learning_rate': 0.0001746821476984154, 'epoch': 1.24}\n",
      "{'loss': 0.2639, 'grad_norm': 3.734375, 'learning_rate': 0.000174240678262345, 'epoch': 1.25}\n",
      "{'loss': 0.1655, 'grad_norm': 3.40625, 'learning_rate': 0.00017379596129850098, 'epoch': 1.26}\n",
      "{'loss': 0.338, 'grad_norm': 3.546875, 'learning_rate': 0.000173348016260244, 'epoch': 1.27}\n",
      "{'loss': 0.246, 'grad_norm': 2.875, 'learning_rate': 0.00017289686274214118, 'epoch': 1.28}\n",
      "{'loss': 0.1628, 'grad_norm': 3.359375, 'learning_rate': 0.00017244252047910892, 'epoch': 1.29}\n",
      "{'loss': 0.1512, 'grad_norm': 2.53125, 'learning_rate': 0.00017198500934554966, 'epoch': 1.3}\n",
      "{'loss': 0.1583, 'grad_norm': 2.9375, 'learning_rate': 0.00017152434935448256, 'epoch': 1.31}\n",
      "{'loss': 0.2007, 'grad_norm': 2.703125, 'learning_rate': 0.00017106056065666793, 'epoch': 1.32}\n",
      "{'loss': 0.1311, 'grad_norm': 2.46875, 'learning_rate': 0.0001705936635397259, 'epoch': 1.33}\n",
      "{'loss': 0.1866, 'grad_norm': 4.125, 'learning_rate': 0.00017012367842724887, 'epoch': 1.34}\n",
      "{'loss': 0.1438, 'grad_norm': 2.703125, 'learning_rate': 0.00016965062587790823, 'epoch': 1.35}\n",
      "{'loss': 0.2406, 'grad_norm': 4.03125, 'learning_rate': 0.00016917452658455495, 'epoch': 1.36}\n",
      "{'loss': 0.1329, 'grad_norm': 2.75, 'learning_rate': 0.00016869540137331445, 'epoch': 1.37}\n",
      "{'loss': 0.1046, 'grad_norm': 2.234375, 'learning_rate': 0.00016821327120267567, 'epoch': 1.38}\n",
      "{'loss': 0.2222, 'grad_norm': 3.28125, 'learning_rate': 0.00016772815716257412, 'epoch': 1.39}\n",
      "{'loss': 0.0928, 'grad_norm': 1.8046875, 'learning_rate': 0.00016724008047346947, 'epoch': 1.4}\n",
      "{'loss': 0.0798, 'grad_norm': 1.8515625, 'learning_rate': 0.00016674906248541726, 'epoch': 1.41}\n",
      "{'loss': 0.1599, 'grad_norm': 2.96875, 'learning_rate': 0.000166255124677135, 'epoch': 1.42}\n",
      "{'loss': 0.2255, 'grad_norm': 3.296875, 'learning_rate': 0.00016575828865506245, 'epoch': 1.43}\n",
      "{'loss': 0.1821, 'grad_norm': 2.796875, 'learning_rate': 0.00016525857615241687, 'epoch': 1.44}\n",
      "{'loss': 0.2329, 'grad_norm': 3.375, 'learning_rate': 0.0001647560090282419, 'epoch': 1.45}\n",
      "{'loss': 0.1331, 'grad_norm': 2.453125, 'learning_rate': 0.00016425060926645167, 'epoch': 1.46}\n",
      "{'loss': 0.1432, 'grad_norm': 2.59375, 'learning_rate': 0.000163742398974869, 'epoch': 1.47}\n",
      "{'loss': 0.1535, 'grad_norm': 3.21875, 'learning_rate': 0.00016323140038425842, 'epoch': 1.48}\n",
      "{'loss': 0.2317, 'grad_norm': 3.453125, 'learning_rate': 0.0001627176358473537, 'epoch': 1.49}\n",
      "{'loss': 0.103, 'grad_norm': 1.984375, 'learning_rate': 0.0001622011278378801, 'epoch': 1.5}\n",
      " 30%|████████████▍                            | 147/485 [06:21<19:28,  3.46s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:02,  6.48it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:02,  6.03it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.30it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:01<00:03,  2.89it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:03,  3.05it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.02it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:02<00:02,  3.05it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:02,  3.13it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.07it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:03<00:01,  3.09it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.17it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:00,  3.25it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:04<00:00,  3.06it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  3.07it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.21465131640434265, 'eval_runtime': 5.0685, 'eval_samples_per_second': 6.314, 'eval_steps_per_second': 3.157, 'epoch': 1.5}\n",
      " 30%|████████████▍                            | 147/485 [06:26<19:28,  3.46s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.41it/s]\u001b[A\n",
      "{'loss': 0.1253, 'grad_norm': 3.578125, 'learning_rate': 0.0001616818989495711, 'epoch': 1.51}\n",
      "{'loss': 0.1637, 'grad_norm': 2.484375, 'learning_rate': 0.00016115997189518043, 'epoch': 1.52}\n",
      "{'loss': 0.0852, 'grad_norm': 1.8203125, 'learning_rate': 0.00016063536950548826, 'epoch': 1.53}\n",
      "{'loss': 0.1395, 'grad_norm': 2.515625, 'learning_rate': 0.00016010811472830252, 'epoch': 1.54}\n",
      "{'loss': 0.1103, 'grad_norm': 2.53125, 'learning_rate': 0.0001595782306274553, 'epoch': 1.56}\n",
      "{'loss': 0.1197, 'grad_norm': 3.640625, 'learning_rate': 0.0001590457403817937, 'epoch': 1.57}\n",
      "{'loss': 0.1625, 'grad_norm': 3.0, 'learning_rate': 0.00015851066728416618, 'epoch': 1.58}\n",
      "{'loss': 0.159, 'grad_norm': 3.9375, 'learning_rate': 0.00015797303474040332, 'epoch': 1.59}\n",
      "{'loss': 0.2225, 'grad_norm': 3.734375, 'learning_rate': 0.00015743286626829437, 'epoch': 1.6}\n",
      "{'loss': 0.1551, 'grad_norm': 2.609375, 'learning_rate': 0.00015689018549655813, 'epoch': 1.61}\n",
      "{'loss': 0.1136, 'grad_norm': 2.5625, 'learning_rate': 0.00015634501616380967, 'epoch': 1.62}\n",
      "{'loss': 0.3401, 'grad_norm': 4.65625, 'learning_rate': 0.00015579738211752165, 'epoch': 1.63}\n",
      "{'loss': 0.1996, 'grad_norm': 2.984375, 'learning_rate': 0.00015524730731298134, 'epoch': 1.64}\n",
      "{'loss': 0.1324, 'grad_norm': 1.9296875, 'learning_rate': 0.00015469481581224272, 'epoch': 1.65}\n",
      "{'loss': 0.1468, 'grad_norm': 3.0625, 'learning_rate': 0.0001541399317830738, 'epoch': 1.66}\n",
      "{'loss': 0.0871, 'grad_norm': 1.8125, 'learning_rate': 0.00015358267949789966, 'epoch': 1.67}\n",
      "{'loss': 0.1831, 'grad_norm': 2.59375, 'learning_rate': 0.0001530230833327405, 'epoch': 1.68}\n",
      "{'loss': 0.1241, 'grad_norm': 2.71875, 'learning_rate': 0.00015246116776614538, 'epoch': 1.69}\n",
      "{'loss': 0.2031, 'grad_norm': 2.96875, 'learning_rate': 0.00015189695737812152, 'epoch': 1.7}\n",
      "{'loss': 0.1871, 'grad_norm': 2.875, 'learning_rate': 0.00015133047684905916, 'epoch': 1.71}\n",
      "{'loss': 0.2292, 'grad_norm': 2.453125, 'learning_rate': 0.0001507617509586517, 'epoch': 1.72}\n",
      "{'loss': 0.138, 'grad_norm': 3.140625, 'learning_rate': 0.00015019080458481202, 'epoch': 1.73}\n",
      "{'loss': 0.1457, 'grad_norm': 2.03125, 'learning_rate': 0.00014961766270258422, 'epoch': 1.74}\n",
      "{'loss': 0.1587, 'grad_norm': 3.203125, 'learning_rate': 0.00014904235038305083, 'epoch': 1.75}\n",
      "{'loss': 0.1332, 'grad_norm': 1.96875, 'learning_rate': 0.00014846489279223652, 'epoch': 1.76}\n",
      "{'loss': 0.1987, 'grad_norm': 3.15625, 'learning_rate': 0.00014788531519000696, 'epoch': 1.77}\n",
      "{'loss': 0.1281, 'grad_norm': 2.03125, 'learning_rate': 0.0001473036429289641, 'epoch': 1.78}\n",
      "{'loss': 0.159, 'grad_norm': 3.0625, 'learning_rate': 0.00014671990145333696, 'epoch': 1.79}\n",
      "{'loss': 0.0903, 'grad_norm': 1.9375, 'learning_rate': 0.0001461341162978688, 'epoch': 1.8}\n",
      "{'loss': 0.2013, 'grad_norm': 4.3125, 'learning_rate': 0.00014554631308669994, 'epoch': 1.81}\n",
      "{'loss': 0.2112, 'grad_norm': 2.8125, 'learning_rate': 0.00014495651753224705, 'epoch': 1.82}\n",
      "{'loss': 0.152, 'grad_norm': 2.578125, 'learning_rate': 0.00014436475543407843, 'epoch': 1.83}\n",
      "{'loss': 0.419, 'grad_norm': 4.46875, 'learning_rate': 0.00014377105267778518, 'epoch': 1.84}\n",
      "{'loss': 0.364, 'grad_norm': 3.984375, 'learning_rate': 0.00014317543523384928, 'epoch': 1.85}\n",
      "{'loss': 0.1527, 'grad_norm': 3.078125, 'learning_rate': 0.00014257792915650728, 'epoch': 1.86}\n",
      "{'loss': 0.1053, 'grad_norm': 2.578125, 'learning_rate': 0.0001419785605826106, 'epoch': 1.87}\n",
      "{'loss': 0.1887, 'grad_norm': 3.34375, 'learning_rate': 0.00014137735573048233, 'epoch': 1.88}\n",
      "{'loss': 0.1778, 'grad_norm': 3.46875, 'learning_rate': 0.00014077434089877037, 'epoch': 1.89}\n",
      "{'loss': 0.1254, 'grad_norm': 2.4375, 'learning_rate': 0.00014016954246529696, 'epoch': 1.9}\n",
      "{'loss': 0.298, 'grad_norm': 3.78125, 'learning_rate': 0.00013956298688590484, 'epoch': 1.92}\n",
      "{'loss': 0.3409, 'grad_norm': 3.46875, 'learning_rate': 0.00013895470069330004, 'epoch': 1.93}\n",
      "{'loss': 0.1906, 'grad_norm': 2.625, 'learning_rate': 0.00013834471049589117, 'epoch': 1.94}\n",
      "{'loss': 0.2023, 'grad_norm': 2.21875, 'learning_rate': 0.00013773304297662559, 'epoch': 1.95}\n",
      "{'loss': 0.1212, 'grad_norm': 2.03125, 'learning_rate': 0.00013711972489182208, 'epoch': 1.96}\n",
      "{'loss': 0.1139, 'grad_norm': 2.5625, 'learning_rate': 0.00013650478307000057, 'epoch': 1.97}\n",
      "{'loss': 0.1005, 'grad_norm': 1.9453125, 'learning_rate': 0.00013588824441070852, 'epoch': 1.98}\n",
      "{'loss': 0.1501, 'grad_norm': 2.375, 'learning_rate': 0.00013527013588334415, 'epoch': 1.99}\n",
      "{'loss': 0.1977, 'grad_norm': 3.5, 'learning_rate': 0.00013465048452597682, 'epoch': 2.0}\n",
      "{'loss': 0.0609, 'grad_norm': 3.796875, 'learning_rate': 0.00013402931744416433, 'epoch': 2.0}\n",
      " 40%|████████████████▌                        | 196/485 [09:17<15:56,  3.31s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:02,  6.16it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:02,  4.43it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:03,  3.96it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:01<00:02,  3.77it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  3.43it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.29it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:02<00:02,  3.51it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:01,  3.90it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.88it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  3.54it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.39it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:01,  2.56it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:04<00:00,  2.69it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  2.93it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1943311095237732, 'eval_runtime': 5.0987, 'eval_samples_per_second': 6.276, 'eval_steps_per_second': 3.138, 'epoch': 2.0}\n",
      " 40%|████████████████▌                        | 196/485 [09:22<15:56,  3.31s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.01it/s]\u001b[A\n",
      "{'loss': 0.274, 'grad_norm': 2.4375, 'learning_rate': 0.00013340666180976712, 'epoch': 2.01}\n",
      "{'loss': 0.2891, 'grad_norm': 2.65625, 'learning_rate': 0.00013278254485975976, 'epoch': 2.02}\n",
      "{'loss': 0.1469, 'grad_norm': 2.0625, 'learning_rate': 0.00013215699389503954, 'epoch': 2.03}\n",
      "{'loss': 0.2705, 'grad_norm': 3.015625, 'learning_rate': 0.00013153003627923218, 'epoch': 2.04}\n",
      "{'loss': 0.1659, 'grad_norm': 1.765625, 'learning_rate': 0.00013090169943749476, 'epoch': 2.05}\n",
      "{'loss': 0.0587, 'grad_norm': 1.4140625, 'learning_rate': 0.00013027201085531634, 'epoch': 2.06}\n",
      "{'loss': 0.1518, 'grad_norm': 2.390625, 'learning_rate': 0.0001296409980773154, 'epoch': 2.07}\n",
      "{'loss': 0.1269, 'grad_norm': 2.578125, 'learning_rate': 0.00012900868870603503, 'epoch': 2.08}\n",
      "{'loss': 0.1689, 'grad_norm': 2.75, 'learning_rate': 0.0001283751104007355, 'epoch': 2.09}\n",
      "{'loss': 0.1196, 'grad_norm': 2.53125, 'learning_rate': 0.00012774029087618446, 'epoch': 2.1}\n",
      "{'loss': 0.0802, 'grad_norm': 2.21875, 'learning_rate': 0.00012710425790144446, 'epoch': 2.11}\n",
      "{'loss': 0.0682, 'grad_norm': 2.671875, 'learning_rate': 0.00012646703929865817, 'epoch': 2.12}\n",
      "{'loss': 0.0888, 'grad_norm': 2.46875, 'learning_rate': 0.00012582866294183167, 'epoch': 2.13}\n",
      "{'loss': 0.0886, 'grad_norm': 1.7734375, 'learning_rate': 0.00012518915675561483, 'epoch': 2.14}\n",
      "{'loss': 0.1234, 'grad_norm': 2.578125, 'learning_rate': 0.00012454854871407994, 'epoch': 2.15}\n",
      "{'loss': 0.0466, 'grad_norm': 1.125, 'learning_rate': 0.00012390686683949798, 'epoch': 2.16}\n",
      "{'loss': 0.0607, 'grad_norm': 1.765625, 'learning_rate': 0.00012326413920111303, 'epoch': 2.17}\n",
      "{'loss': 0.0484, 'grad_norm': 1.4921875, 'learning_rate': 0.00012262039391391404, 'epoch': 2.19}\n",
      "{'loss': 0.1288, 'grad_norm': 2.578125, 'learning_rate': 0.00012197565913740531, 'epoch': 2.2}\n",
      "{'loss': 0.0456, 'grad_norm': 1.75, 'learning_rate': 0.0001213299630743747, 'epoch': 2.21}\n",
      "{'loss': 0.1057, 'grad_norm': 2.015625, 'learning_rate': 0.00012068333396965968, 'epoch': 2.22}\n",
      "{'loss': 0.0316, 'grad_norm': 1.28125, 'learning_rate': 0.00012003580010891213, 'epoch': 2.23}\n",
      "{'loss': 0.1885, 'grad_norm': 3.6875, 'learning_rate': 0.00011938738981736085, 'epoch': 2.24}\n",
      "{'loss': 0.0602, 'grad_norm': 1.6171875, 'learning_rate': 0.00011873813145857249, 'epoch': 2.25}\n",
      "{'loss': 0.0723, 'grad_norm': 2.265625, 'learning_rate': 0.000118088053433211, 'epoch': 2.26}\n",
      "{'loss': 0.0331, 'grad_norm': 1.3125, 'learning_rate': 0.00011743718417779517, 'epoch': 2.27}\n",
      "{'loss': 0.0398, 'grad_norm': 1.5078125, 'learning_rate': 0.00011678555216345477, 'epoch': 2.28}\n",
      "{'loss': 0.0551, 'grad_norm': 1.5234375, 'learning_rate': 0.00011613318589468511, 'epoch': 2.29}\n",
      "{'loss': 0.0837, 'grad_norm': 2.03125, 'learning_rate': 0.00011548011390810017, 'epoch': 2.3}\n",
      "{'loss': 0.0804, 'grad_norm': 1.7109375, 'learning_rate': 0.0001148263647711842, 'epoch': 2.31}\n",
      "{'loss': 0.0957, 'grad_norm': 2.4375, 'learning_rate': 0.00011417196708104243, 'epoch': 2.32}\n",
      "{'loss': 0.0634, 'grad_norm': 1.421875, 'learning_rate': 0.0001135169494631497, 'epoch': 2.33}\n",
      "{'loss': 0.074, 'grad_norm': 2.671875, 'learning_rate': 0.00011286134057009863, 'epoch': 2.34}\n",
      "{'loss': 0.105, 'grad_norm': 2.46875, 'learning_rate': 0.00011220516908034601, 'epoch': 2.35}\n",
      "{'loss': 0.2092, 'grad_norm': 3.328125, 'learning_rate': 0.00011154846369695863, 'epoch': 2.36}\n",
      "{'loss': 0.1095, 'grad_norm': 2.234375, 'learning_rate': 0.00011089125314635726, 'epoch': 2.37}\n",
      "{'loss': 0.0318, 'grad_norm': 0.90625, 'learning_rate': 0.00011023356617706052, 'epoch': 2.38}\n",
      "{'loss': 0.0874, 'grad_norm': 2.15625, 'learning_rate': 0.00010957543155842702, 'epoch': 2.39}\n",
      "{'loss': 0.1126, 'grad_norm': 2.234375, 'learning_rate': 0.00010891687807939707, 'epoch': 2.4}\n",
      "{'loss': 0.0551, 'grad_norm': 1.5078125, 'learning_rate': 0.00010825793454723325, 'epoch': 2.41}\n",
      "{'loss': 0.0419, 'grad_norm': 1.1875, 'learning_rate': 0.00010759862978626031, 'epoch': 2.42}\n",
      "{'loss': 0.0639, 'grad_norm': 1.90625, 'learning_rate': 0.00010693899263660441, 'epoch': 2.43}\n",
      "{'loss': 0.1888, 'grad_norm': 2.890625, 'learning_rate': 0.00010627905195293135, 'epoch': 2.44}\n",
      "{'loss': 0.1183, 'grad_norm': 1.953125, 'learning_rate': 0.00010561883660318455, 'epoch': 2.45}\n",
      "{'loss': 0.1078, 'grad_norm': 3.6875, 'learning_rate': 0.00010495837546732224, 'epoch': 2.46}\n",
      "{'loss': 0.0912, 'grad_norm': 2.21875, 'learning_rate': 0.00010429769743605407, 'epoch': 2.47}\n",
      "{'loss': 0.074, 'grad_norm': 1.640625, 'learning_rate': 0.00010363683140957745, 'epoch': 2.48}\n",
      "{'loss': 0.0602, 'grad_norm': 1.390625, 'learning_rate': 0.00010297580629631325, 'epoch': 2.49}\n",
      "{'loss': 0.108, 'grad_norm': 1.8515625, 'learning_rate': 0.00010231465101164139, 'epoch': 2.5}\n",
      " 51%|████████████████████▋                    | 245/485 [12:09<13:57,  3.49s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  7.53it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:02,  4.63it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:03,  3.94it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:01<00:03,  3.66it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  3.66it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.33it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:02<00:02,  3.24it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:02,  3.23it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.18it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:03<00:01,  3.16it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.14it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:00,  3.02it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:04<00:00,  3.07it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  3.12it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.19583556056022644, 'eval_runtime': 5.0891, 'eval_samples_per_second': 6.288, 'eval_steps_per_second': 3.144, 'epoch': 2.5}\n",
      " 51%|████████████████████▋                    | 245/485 [12:14<13:57,  3.49s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.20it/s]\u001b[A\n",
      "{'loss': 0.0905, 'grad_norm': 1.6171875, 'learning_rate': 0.00010165339447663587, 'epoch': 2.51}\n",
      "{'loss': 0.1092, 'grad_norm': 2.0625, 'learning_rate': 0.00010099206561679963, 'epoch': 2.52}\n",
      "{'loss': 0.0984, 'grad_norm': 2.578125, 'learning_rate': 0.00010033069336079952, 'epoch': 2.53}\n",
      "{'loss': 0.1329, 'grad_norm': 2.296875, 'learning_rate': 9.966930663920049e-05, 'epoch': 2.54}\n",
      "{'loss': 0.1006, 'grad_norm': 2.75, 'learning_rate': 9.900793438320037e-05, 'epoch': 2.56}\n",
      "{'loss': 0.0538, 'grad_norm': 1.609375, 'learning_rate': 9.834660552336415e-05, 'epoch': 2.57}\n",
      "{'loss': 0.1119, 'grad_norm': 2.34375, 'learning_rate': 9.768534898835862e-05, 'epoch': 2.58}\n",
      "{'loss': 0.0399, 'grad_norm': 2.171875, 'learning_rate': 9.702419370368676e-05, 'epoch': 2.59}\n",
      "{'loss': 0.0373, 'grad_norm': 1.2890625, 'learning_rate': 9.636316859042259e-05, 'epoch': 2.6}\n",
      "{'loss': 0.0614, 'grad_norm': 1.4140625, 'learning_rate': 9.570230256394596e-05, 'epoch': 2.61}\n",
      "{'loss': 0.0966, 'grad_norm': 1.78125, 'learning_rate': 9.504162453267777e-05, 'epoch': 2.62}\n",
      "{'loss': 0.0538, 'grad_norm': 1.59375, 'learning_rate': 9.438116339681545e-05, 'epoch': 2.63}\n",
      "{'loss': 0.081, 'grad_norm': 1.828125, 'learning_rate': 9.372094804706867e-05, 'epoch': 2.64}\n",
      "{'loss': 0.0677, 'grad_norm': 1.796875, 'learning_rate': 9.30610073633956e-05, 'epoch': 2.65}\n",
      "{'loss': 0.0444, 'grad_norm': 1.3671875, 'learning_rate': 9.24013702137397e-05, 'epoch': 2.66}\n",
      "{'loss': 0.0642, 'grad_norm': 1.625, 'learning_rate': 9.174206545276677e-05, 'epoch': 2.67}\n",
      "{'loss': 0.0805, 'grad_norm': 1.65625, 'learning_rate': 9.108312192060298e-05, 'epoch': 2.68}\n",
      "{'loss': 0.0308, 'grad_norm': 1.5390625, 'learning_rate': 9.042456844157299e-05, 'epoch': 2.69}\n",
      "{'loss': 0.0801, 'grad_norm': 1.3984375, 'learning_rate': 8.97664338229395e-05, 'epoch': 2.7}\n",
      "{'loss': 0.0358, 'grad_norm': 1.0703125, 'learning_rate': 8.910874685364275e-05, 'epoch': 2.71}\n",
      "{'loss': 0.0598, 'grad_norm': 1.828125, 'learning_rate': 8.845153630304139e-05, 'epoch': 2.72}\n",
      "{'loss': 0.0648, 'grad_norm': 2.140625, 'learning_rate': 8.7794830919654e-05, 'epoch': 2.73}\n",
      "{'loss': 0.1068, 'grad_norm': 1.671875, 'learning_rate': 8.713865942990141e-05, 'epoch': 2.74}\n",
      "{'loss': 0.0672, 'grad_norm': 1.71875, 'learning_rate': 8.648305053685034e-05, 'epoch': 2.75}\n",
      "{'loss': 0.0488, 'grad_norm': 1.5859375, 'learning_rate': 8.582803291895758e-05, 'epoch': 2.76}\n",
      "{'loss': 0.1046, 'grad_norm': 1.7265625, 'learning_rate': 8.517363522881579e-05, 'epoch': 2.77}\n",
      "{'loss': 0.0889, 'grad_norm': 1.4921875, 'learning_rate': 8.451988609189987e-05, 'epoch': 2.78}\n",
      "{'loss': 0.0409, 'grad_norm': 1.2734375, 'learning_rate': 8.386681410531491e-05, 'epoch': 2.79}\n",
      "{'loss': 0.0907, 'grad_norm': 1.5234375, 'learning_rate': 8.321444783654524e-05, 'epoch': 2.8}\n",
      "{'loss': 0.075, 'grad_norm': 1.484375, 'learning_rate': 8.256281582220485e-05, 'epoch': 2.81}\n",
      "{'loss': 0.0334, 'grad_norm': 1.1640625, 'learning_rate': 8.191194656678904e-05, 'epoch': 2.82}\n",
      "{'loss': 0.0667, 'grad_norm': 1.6171875, 'learning_rate': 8.126186854142752e-05, 'epoch': 2.83}\n",
      "{'loss': 0.0721, 'grad_norm': 1.4921875, 'learning_rate': 8.061261018263919e-05, 'epoch': 2.84}\n",
      "{'loss': 0.141, 'grad_norm': 2.28125, 'learning_rate': 7.996419989108789e-05, 'epoch': 2.85}\n",
      "{'loss': 0.0544, 'grad_norm': 1.34375, 'learning_rate': 7.931666603034033e-05, 'epoch': 2.86}\n",
      "{'loss': 0.0388, 'grad_norm': 1.2578125, 'learning_rate': 7.867003692562534e-05, 'epoch': 2.87}\n",
      "{'loss': 0.047, 'grad_norm': 1.4375, 'learning_rate': 7.80243408625947e-05, 'epoch': 2.88}\n",
      "{'loss': 0.106, 'grad_norm': 1.7734375, 'learning_rate': 7.7379606086086e-05, 'epoch': 2.89}\n",
      "{'loss': 0.0415, 'grad_norm': 1.3671875, 'learning_rate': 7.673586079888698e-05, 'epoch': 2.9}\n",
      "{'loss': 0.1118, 'grad_norm': 1.7109375, 'learning_rate': 7.6093133160502e-05, 'epoch': 2.92}\n",
      "{'loss': 0.1106, 'grad_norm': 3.28125, 'learning_rate': 7.54514512859201e-05, 'epoch': 2.93}\n",
      "{'loss': 0.04, 'grad_norm': 1.4765625, 'learning_rate': 7.48108432443852e-05, 'epoch': 2.94}\n",
      "{'loss': 0.0556, 'grad_norm': 1.609375, 'learning_rate': 7.417133705816837e-05, 'epoch': 2.95}\n",
      "{'loss': 0.022, 'grad_norm': 1.09375, 'learning_rate': 7.353296070134186e-05, 'epoch': 2.96}\n",
      "{'loss': 0.0799, 'grad_norm': 1.890625, 'learning_rate': 7.289574209855559e-05, 'epoch': 2.97}\n",
      "{'loss': 0.047, 'grad_norm': 1.7578125, 'learning_rate': 7.225970912381556e-05, 'epoch': 2.98}\n",
      "{'loss': 0.0556, 'grad_norm': 1.5859375, 'learning_rate': 7.16248895992645e-05, 'epoch': 2.99}\n",
      "{'loss': 0.0939, 'grad_norm': 2.609375, 'learning_rate': 7.099131129396501e-05, 'epoch': 3.0}\n",
      "{'loss': 0.2193, 'grad_norm': 4.90625, 'learning_rate': 7.035900192268464e-05, 'epoch': 3.0}\n",
      " 61%|████████████████████████▊                | 294/485 [15:06<10:14,  3.22s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01,  7.95it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:02,  4.68it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:03,  3.90it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:01<00:02,  3.67it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  3.63it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.29it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:02<00:02,  3.22it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:02,  3.23it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.16it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:03<00:01,  3.12it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.22it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:00,  3.25it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:04<00:00,  3.07it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  3.02it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1706729382276535, 'eval_runtime': 4.8453, 'eval_samples_per_second': 6.604, 'eval_steps_per_second': 3.302, 'epoch': 3.0}\n",
      " 61%|████████████████████████▊                | 294/485 [15:10<10:14,  3.22s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.50it/s]\u001b[A\n",
      "{'loss': 0.0607, 'grad_norm': 1.2578125, 'learning_rate': 6.972798914468369e-05, 'epoch': 3.01}\n",
      "{'loss': 0.1301, 'grad_norm': 2.140625, 'learning_rate': 6.909830056250527e-05, 'epoch': 3.02}\n",
      "{'loss': 0.084, 'grad_norm': 1.3359375, 'learning_rate': 6.846996372076786e-05, 'epoch': 3.03}\n",
      "{'loss': 0.0748, 'grad_norm': 1.1015625, 'learning_rate': 6.784300610496048e-05, 'epoch': 3.04}\n",
      "{'loss': 0.1301, 'grad_norm': 1.4765625, 'learning_rate': 6.721745514024022e-05, 'epoch': 3.05}\n",
      "{'loss': 0.0923, 'grad_norm': 1.328125, 'learning_rate': 6.65933381902329e-05, 'epoch': 3.06}\n",
      "{'loss': 0.0218, 'grad_norm': 0.6640625, 'learning_rate': 6.59706825558357e-05, 'epoch': 3.07}\n",
      "{'loss': 0.0237, 'grad_norm': 1.1015625, 'learning_rate': 6.534951547402322e-05, 'epoch': 3.08}\n",
      "{'loss': 0.062, 'grad_norm': 2.53125, 'learning_rate': 6.47298641166559e-05, 'epoch': 3.09}\n",
      "{'loss': 0.0221, 'grad_norm': 1.5625, 'learning_rate': 6.411175558929152e-05, 'epoch': 3.1}\n",
      "{'loss': 0.052, 'grad_norm': 1.609375, 'learning_rate': 6.349521692999945e-05, 'epoch': 3.11}\n",
      "{'loss': 0.0385, 'grad_norm': 1.1328125, 'learning_rate': 6.28802751081779e-05, 'epoch': 3.12}\n",
      "{'loss': 0.0273, 'grad_norm': 0.85546875, 'learning_rate': 6.226695702337442e-05, 'epoch': 3.13}\n",
      "{'loss': 0.0131, 'grad_norm': 1.296875, 'learning_rate': 6.165528950410884e-05, 'epoch': 3.14}\n",
      "{'loss': 0.0394, 'grad_norm': 1.34375, 'learning_rate': 6.10452993067e-05, 'epoch': 3.15}\n",
      "{'loss': 0.0303, 'grad_norm': 1.0625, 'learning_rate': 6.0437013114095195e-05, 'epoch': 3.16}\n",
      "{'loss': 0.0286, 'grad_norm': 0.77734375, 'learning_rate': 5.983045753470308e-05, 'epoch': 3.17}\n",
      "{'loss': 0.0192, 'grad_norm': 0.828125, 'learning_rate': 5.922565910122967e-05, 'epoch': 3.19}\n",
      "{'loss': 0.0435, 'grad_norm': 1.171875, 'learning_rate': 5.862264426951768e-05, 'epoch': 3.2}\n",
      "{'loss': 0.0346, 'grad_norm': 1.0625, 'learning_rate': 5.8021439417389444e-05, 'epoch': 3.21}\n",
      "{'loss': 0.0165, 'grad_norm': 1.3671875, 'learning_rate': 5.7422070843492734e-05, 'epoch': 3.22}\n",
      "{'loss': 0.0585, 'grad_norm': 1.609375, 'learning_rate': 5.6824564766150726e-05, 'epoch': 3.23}\n",
      "{'loss': 0.0602, 'grad_norm': 1.828125, 'learning_rate': 5.622894732221482e-05, 'epoch': 3.24}\n",
      "{'loss': 0.022, 'grad_norm': 1.140625, 'learning_rate': 5.563524456592163e-05, 'epoch': 3.25}\n",
      "{'loss': 0.0509, 'grad_norm': 1.0703125, 'learning_rate': 5.504348246775299e-05, 'epoch': 3.26}\n",
      "{'loss': 0.0241, 'grad_norm': 0.76953125, 'learning_rate': 5.4453686913300074e-05, 'epoch': 3.27}\n",
      "{'loss': 0.032, 'grad_norm': 0.9453125, 'learning_rate': 5.386588370213124e-05, 'epoch': 3.28}\n",
      "{'loss': 0.0488, 'grad_norm': 1.6015625, 'learning_rate': 5.328009854666303e-05, 'epoch': 3.29}\n",
      "{'loss': 0.0254, 'grad_norm': 1.3515625, 'learning_rate': 5.269635707103593e-05, 'epoch': 3.3}\n",
      "{'loss': 0.0392, 'grad_norm': 0.984375, 'learning_rate': 5.2114684809993044e-05, 'epoch': 3.31}\n",
      "{'loss': 0.02, 'grad_norm': 0.84765625, 'learning_rate': 5.1535107207763534e-05, 'epoch': 3.32}\n",
      "{'loss': 0.0342, 'grad_norm': 0.89453125, 'learning_rate': 5.095764961694922e-05, 'epoch': 3.33}\n",
      "{'loss': 0.0847, 'grad_norm': 1.875, 'learning_rate': 5.0382337297415773e-05, 'epoch': 3.34}\n",
      "{'loss': 0.0182, 'grad_norm': 1.375, 'learning_rate': 4.980919541518796e-05, 'epoch': 3.35}\n",
      "{'loss': 0.0308, 'grad_norm': 0.9609375, 'learning_rate': 4.923824904134829e-05, 'epoch': 3.36}\n",
      "{'loss': 0.0217, 'grad_norm': 0.69921875, 'learning_rate': 4.866952315094088e-05, 'epoch': 3.37}\n",
      "{'loss': 0.0103, 'grad_norm': 0.53515625, 'learning_rate': 4.810304262187852e-05, 'epoch': 3.38}\n",
      "{'loss': 0.0307, 'grad_norm': 1.2578125, 'learning_rate': 4.753883223385467e-05, 'epoch': 3.39}\n",
      "{'loss': 0.0252, 'grad_norm': 1.0859375, 'learning_rate': 4.697691666725955e-05, 'epoch': 3.4}\n",
      "{'loss': 0.0245, 'grad_norm': 0.9609375, 'learning_rate': 4.6417320502100316e-05, 'epoch': 3.41}\n",
      "{'loss': 0.0434, 'grad_norm': 0.90234375, 'learning_rate': 4.58600682169262e-05, 'epoch': 3.42}\n",
      "{'loss': 0.0322, 'grad_norm': 0.984375, 'learning_rate': 4.530518418775733e-05, 'epoch': 3.43}\n",
      "{'loss': 0.0313, 'grad_norm': 1.4140625, 'learning_rate': 4.475269268701868e-05, 'epoch': 3.44}\n",
      "{'loss': 0.0276, 'grad_norm': 1.109375, 'learning_rate': 4.4202617882478405e-05, 'epoch': 3.45}\n",
      "{'loss': 0.0304, 'grad_norm': 0.77734375, 'learning_rate': 4.365498383619036e-05, 'epoch': 3.46}\n",
      "{'loss': 0.0156, 'grad_norm': 0.96875, 'learning_rate': 4.310981450344189e-05, 'epoch': 3.47}\n",
      "{'loss': 0.0445, 'grad_norm': 2.84375, 'learning_rate': 4.256713373170564e-05, 'epoch': 3.48}\n",
      "{'loss': 0.012, 'grad_norm': 1.046875, 'learning_rate': 4.2026965259596666e-05, 'epoch': 3.49}\n",
      "{'loss': 0.0215, 'grad_norm': 1.0625, 'learning_rate': 4.148933271583385e-05, 'epoch': 3.5}\n",
      " 71%|████████████████████████████▉            | 343/485 [17:57<07:14,  3.06s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:01, 13.23it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  4.94it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:01<00:02,  4.11it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  3.87it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.83it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:02,  3.53it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:02,  3.36it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.42it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  3.52it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.28it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:00,  3.16it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:03<00:00,  3.30it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  3.27it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.1903466284275055, 'eval_runtime': 4.7, 'eval_samples_per_second': 6.808, 'eval_steps_per_second': 3.404, 'epoch': 3.5}\n",
      " 71%|████████████████████████████▉            | 343/485 [18:02<07:14,  3.06s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.29it/s]\u001b[A\n",
      "{'loss': 0.0096, 'grad_norm': 0.41015625, 'learning_rate': 4.0954259618206295e-05, 'epoch': 3.51}\n",
      "{'loss': 0.031, 'grad_norm': 1.125, 'learning_rate': 4.0421769372544736e-05, 'epoch': 3.52}\n",
      "{'loss': 0.031, 'grad_norm': 1.8984375, 'learning_rate': 3.9891885271697496e-05, 'epoch': 3.53}\n",
      "{'loss': 0.0221, 'grad_norm': 0.9453125, 'learning_rate': 3.936463049451179e-05, 'epoch': 3.54}\n",
      "{'loss': 0.025, 'grad_norm': 0.95703125, 'learning_rate': 3.884002810481958e-05, 'epoch': 3.56}\n",
      "{'loss': 0.0296, 'grad_norm': 0.91015625, 'learning_rate': 3.8318101050428904e-05, 'epoch': 3.57}\n",
      "{'loss': 0.0268, 'grad_norm': 1.7421875, 'learning_rate': 3.779887216211995e-05, 'epoch': 3.58}\n",
      "{'loss': 0.0386, 'grad_norm': 0.88671875, 'learning_rate': 3.7282364152646297e-05, 'epoch': 3.59}\n",
      "{'loss': 0.0205, 'grad_norm': 0.85546875, 'learning_rate': 3.676859961574162e-05, 'epoch': 3.6}\n",
      "{'loss': 0.016, 'grad_norm': 0.69921875, 'learning_rate': 3.6257601025131026e-05, 'epoch': 3.61}\n",
      "{'loss': 0.0423, 'grad_norm': 1.1328125, 'learning_rate': 3.574939073354838e-05, 'epoch': 3.62}\n",
      "{'loss': 0.0168, 'grad_norm': 0.8203125, 'learning_rate': 3.5243990971758125e-05, 'epoch': 3.63}\n",
      "{'loss': 0.0254, 'grad_norm': 1.25, 'learning_rate': 3.4741423847583134e-05, 'epoch': 3.64}\n",
      "{'loss': 0.017, 'grad_norm': 0.83984375, 'learning_rate': 3.424171134493756e-05, 'epoch': 3.65}\n",
      "{'loss': 0.0215, 'grad_norm': 1.1953125, 'learning_rate': 3.3744875322865034e-05, 'epoch': 3.66}\n",
      "{'loss': 0.0271, 'grad_norm': 2.265625, 'learning_rate': 3.325093751458276e-05, 'epoch': 3.67}\n",
      "{'loss': 0.0133, 'grad_norm': 0.83984375, 'learning_rate': 3.275991952653054e-05, 'epoch': 3.68}\n",
      "{'loss': 0.0392, 'grad_norm': 1.171875, 'learning_rate': 3.227184283742591e-05, 'epoch': 3.69}\n",
      "{'loss': 0.0455, 'grad_norm': 1.5390625, 'learning_rate': 3.178672879732435e-05, 'epoch': 3.7}\n",
      "{'loss': 0.0492, 'grad_norm': 1.1328125, 'learning_rate': 3.1304598626685545e-05, 'epoch': 3.71}\n",
      "{'loss': 0.0207, 'grad_norm': 0.98828125, 'learning_rate': 3.0825473415445074e-05, 'epoch': 3.72}\n",
      "{'loss': 0.0168, 'grad_norm': 0.8203125, 'learning_rate': 3.034937412209178e-05, 'epoch': 3.73}\n",
      "{'loss': 0.0185, 'grad_norm': 1.1796875, 'learning_rate': 2.9876321572751144e-05, 'epoch': 3.74}\n",
      "{'loss': 0.0201, 'grad_norm': 1.2421875, 'learning_rate': 2.940633646027414e-05, 'epoch': 3.75}\n",
      "{'loss': 0.0225, 'grad_norm': 0.62109375, 'learning_rate': 2.8939439343332086e-05, 'epoch': 3.76}\n",
      "{'loss': 0.0285, 'grad_norm': 2.3125, 'learning_rate': 2.8475650645517472e-05, 'epoch': 3.77}\n",
      "{'loss': 0.0099, 'grad_norm': 1.125, 'learning_rate': 2.8014990654450325e-05, 'epoch': 3.78}\n",
      "{'loss': 0.0179, 'grad_norm': 0.77734375, 'learning_rate': 2.7557479520891104e-05, 'epoch': 3.79}\n",
      "{'loss': 0.029, 'grad_norm': 1.1484375, 'learning_rate': 2.7103137257858868e-05, 'epoch': 3.8}\n",
      "{'loss': 0.0126, 'grad_norm': 0.6171875, 'learning_rate': 2.6651983739756026e-05, 'epoch': 3.81}\n",
      "{'loss': 0.0112, 'grad_norm': 0.484375, 'learning_rate': 2.6204038701499056e-05, 'epoch': 3.82}\n",
      "{'loss': 0.0212, 'grad_norm': 0.875, 'learning_rate': 2.5759321737655017e-05, 'epoch': 3.83}\n",
      "{'loss': 0.0186, 'grad_norm': 0.96484375, 'learning_rate': 2.5317852301584643e-05, 'epoch': 3.84}\n",
      "{'loss': 0.0648, 'grad_norm': 1.6796875, 'learning_rate': 2.487964970459118e-05, 'epoch': 3.85}\n",
      "{'loss': 0.0231, 'grad_norm': 1.0703125, 'learning_rate': 2.4444733115075823e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0307, 'grad_norm': 1.1171875, 'learning_rate': 2.4013121557699157e-05, 'epoch': 3.87}\n",
      "{'loss': 0.0186, 'grad_norm': 1.8515625, 'learning_rate': 2.3584833912548888e-05, 'epoch': 3.88}\n",
      "{'loss': 0.0127, 'grad_norm': 0.8125, 'learning_rate': 2.315988891431412e-05, 'epoch': 3.89}\n",
      "{'loss': 0.01, 'grad_norm': 0.6796875, 'learning_rate': 2.2738305151465645e-05, 'epoch': 3.9}\n",
      "{'loss': 0.0138, 'grad_norm': 0.60546875, 'learning_rate': 2.2320101065443056e-05, 'epoch': 3.92}\n",
      "{'loss': 0.0113, 'grad_norm': 0.58984375, 'learning_rate': 2.190529494984782e-05, 'epoch': 3.93}\n",
      "{'loss': 0.0154, 'grad_norm': 0.97265625, 'learning_rate': 2.149390494964323e-05, 'epoch': 3.94}\n",
      "{'loss': 0.0125, 'grad_norm': 0.64453125, 'learning_rate': 2.1085949060360654e-05, 'epoch': 3.95}\n",
      "{'loss': 0.042, 'grad_norm': 1.1953125, 'learning_rate': 2.0681445127312214e-05, 'epoch': 3.96}\n",
      "{'loss': 0.0349, 'grad_norm': 1.1796875, 'learning_rate': 2.0280410844810428e-05, 'epoch': 3.97}\n",
      "{'loss': 0.0099, 'grad_norm': 0.546875, 'learning_rate': 1.988286375539391e-05, 'epoch': 3.98}\n",
      "{'loss': 0.0239, 'grad_norm': 0.76953125, 'learning_rate': 1.9488821249060297e-05, 'epoch': 3.99}\n",
      "{'loss': 0.056, 'grad_norm': 2.96875, 'learning_rate': 1.9098300562505266e-05, 'epoch': 4.0}\n",
      "{'loss': 0.0448, 'grad_norm': 1.703125, 'learning_rate': 1.871131877836879e-05, 'epoch': 4.0}\n",
      " 81%|█████████████████████████████████▏       | 392/485 [20:50<04:48,  3.10s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:02,  5.92it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:03,  4.33it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:03,  3.91it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:01<00:02,  3.70it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:03,  3.30it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.20it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:02<00:02,  3.58it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:01,  3.62it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.43it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:03<00:01,  3.34it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.40it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:00,  3.41it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:04<00:00,  3.17it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  3.15it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17470110952854156, 'eval_runtime': 4.8968, 'eval_samples_per_second': 6.535, 'eval_steps_per_second': 3.267, 'epoch': 4.0}\n",
      " 81%|█████████████████████████████████▏       | 392/485 [20:55<04:48,  3.10s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.29it/s]\u001b[A\n",
      "{'loss': 0.0758, 'grad_norm': 1.21875, 'learning_rate': 1.8327892824487792e-05, 'epoch': 4.01}\n",
      "{'loss': 0.0207, 'grad_norm': 0.57421875, 'learning_rate': 1.7948039473155554e-05, 'epoch': 4.02}\n",
      "{'loss': 0.0764, 'grad_norm': 1.265625, 'learning_rate': 1.7571775340388276e-05, 'epoch': 4.03}\n",
      "{'loss': 0.0198, 'grad_norm': 0.7421875, 'learning_rate': 1.7199116885197995e-05, 'epoch': 4.04}\n",
      "{'loss': 0.0211, 'grad_norm': 0.6953125, 'learning_rate': 1.683008040887285e-05, 'epoch': 4.05}\n",
      "{'loss': 0.0271, 'grad_norm': 1.015625, 'learning_rate': 1.646468205426377e-05, 'epoch': 4.06}\n",
      "{'loss': 0.0296, 'grad_norm': 0.88671875, 'learning_rate': 1.6102937805078544e-05, 'epoch': 4.07}\n",
      "{'loss': 0.0079, 'grad_norm': 0.267578125, 'learning_rate': 1.5744863485182537e-05, 'epoch': 4.08}\n",
      "{'loss': 0.0168, 'grad_norm': 0.5390625, 'learning_rate': 1.5390474757906446e-05, 'epoch': 4.09}\n",
      "{'loss': 0.007, 'grad_norm': 0.427734375, 'learning_rate': 1.5039787125361326e-05, 'epoch': 4.1}\n",
      "{'loss': 0.0061, 'grad_norm': 0.34765625, 'learning_rate': 1.4692815927760273e-05, 'epoch': 4.11}\n",
      "{'loss': 0.0195, 'grad_norm': 0.65625, 'learning_rate': 1.4349576342747462e-05, 'epoch': 4.12}\n",
      "{'loss': 0.0159, 'grad_norm': 0.484375, 'learning_rate': 1.4010083384734308e-05, 'epoch': 4.13}\n",
      "{'loss': 0.0137, 'grad_norm': 0.439453125, 'learning_rate': 1.3674351904242611e-05, 'epoch': 4.14}\n",
      "{'loss': 0.0129, 'grad_norm': 1.0859375, 'learning_rate': 1.3342396587254958e-05, 'epoch': 4.15}\n",
      "{'loss': 0.014, 'grad_norm': 0.451171875, 'learning_rate': 1.3014231954572287e-05, 'epoch': 4.16}\n",
      "{'loss': 0.0097, 'grad_norm': 0.5703125, 'learning_rate': 1.2689872361178701e-05, 'epoch': 4.17}\n",
      "{'loss': 0.0132, 'grad_norm': 0.64453125, 'learning_rate': 1.2369331995613665e-05, 'epoch': 4.19}\n",
      "{'loss': 0.0167, 'grad_norm': 0.52734375, 'learning_rate': 1.2052624879351104e-05, 'epoch': 4.2}\n",
      "{'loss': 0.0041, 'grad_norm': 0.279296875, 'learning_rate': 1.173976486618631e-05, 'epoch': 4.21}\n",
      "{'loss': 0.0246, 'grad_norm': 0.5390625, 'learning_rate': 1.143076564162977e-05, 'epoch': 4.22}\n",
      "{'loss': 0.006, 'grad_norm': 0.326171875, 'learning_rate': 1.1125640722308628e-05, 'epoch': 4.23}\n",
      "{'loss': 0.0026, 'grad_norm': 0.228515625, 'learning_rate': 1.0824403455375288e-05, 'epoch': 4.24}\n",
      "{'loss': 0.0036, 'grad_norm': 0.2080078125, 'learning_rate': 1.0527067017923654e-05, 'epoch': 4.25}\n",
      "{'loss': 0.0124, 'grad_norm': 0.8359375, 'learning_rate': 1.0233644416412791e-05, 'epoch': 4.26}\n",
      "{'loss': 0.0084, 'grad_norm': 0.390625, 'learning_rate': 9.944148486097793e-06, 'epoch': 4.27}\n",
      "{'loss': 0.0165, 'grad_norm': 0.51953125, 'learning_rate': 9.658591890468515e-06, 'epoch': 4.28}\n",
      "{'loss': 0.0081, 'grad_norm': 0.435546875, 'learning_rate': 9.376987120695545e-06, 'epoch': 4.29}\n",
      "{'loss': 0.0058, 'grad_norm': 0.361328125, 'learning_rate': 9.09934649508375e-06, 'epoch': 4.3}\n",
      "{'loss': 0.0086, 'grad_norm': 0.5390625, 'learning_rate': 8.825682158533554e-06, 'epoch': 4.31}\n",
      "{'loss': 0.0146, 'grad_norm': 0.53515625, 'learning_rate': 8.55600608200956e-06, 'epoch': 4.32}\n",
      "{'loss': 0.0064, 'grad_norm': 0.5078125, 'learning_rate': 8.290330062017016e-06, 'epoch': 4.33}\n",
      "{'loss': 0.0036, 'grad_norm': 0.220703125, 'learning_rate': 8.02866572008566e-06, 'epoch': 4.34}\n",
      "{'loss': 0.008, 'grad_norm': 0.46484375, 'learning_rate': 7.771024502261526e-06, 'epoch': 4.35}\n",
      "{'loss': 0.019, 'grad_norm': 0.625, 'learning_rate': 7.51741767860612e-06, 'epoch': 4.36}\n",
      "{'loss': 0.0046, 'grad_norm': 0.30078125, 'learning_rate': 7.267856342703461e-06, 'epoch': 4.37}\n",
      "{'loss': 0.0039, 'grad_norm': 0.287109375, 'learning_rate': 7.022351411174866e-06, 'epoch': 4.38}\n",
      "{'loss': 0.0191, 'grad_norm': 0.54296875, 'learning_rate': 6.780913623201346e-06, 'epoch': 4.39}\n",
      "{'loss': 0.0019, 'grad_norm': 0.171875, 'learning_rate': 6.543553540053926e-06, 'epoch': 4.4}\n",
      "{'loss': 0.0156, 'grad_norm': 0.59765625, 'learning_rate': 6.310281544631546e-06, 'epoch': 4.41}\n",
      "{'loss': 0.0046, 'grad_norm': 0.36328125, 'learning_rate': 6.081107841007006e-06, 'epoch': 4.42}\n",
      "{'loss': 0.0057, 'grad_norm': 0.39453125, 'learning_rate': 5.856042453980526e-06, 'epoch': 4.43}\n",
      "{'loss': 0.0131, 'grad_norm': 0.392578125, 'learning_rate': 5.63509522864123e-06, 'epoch': 4.44}\n",
      "{'loss': 0.0051, 'grad_norm': 0.310546875, 'learning_rate': 5.418275829936537e-06, 'epoch': 4.45}\n",
      "{'loss': 0.0144, 'grad_norm': 0.546875, 'learning_rate': 5.205593742249326e-06, 'epoch': 4.46}\n",
      "{'loss': 0.0133, 'grad_norm': 0.51953125, 'learning_rate': 4.997058268983135e-06, 'epoch': 4.47}\n",
      "{'loss': 0.0274, 'grad_norm': 1.03125, 'learning_rate': 4.792678532155115e-06, 'epoch': 4.48}\n",
      "{'loss': 0.0079, 'grad_norm': 0.373046875, 'learning_rate': 4.592463471997022e-06, 'epoch': 4.49}\n",
      "{'loss': 0.0107, 'grad_norm': 0.462890625, 'learning_rate': 4.3964218465642355e-06, 'epoch': 4.5}\n",
      " 91%|█████████████████████████████████████▎   | 441/485 [24:04<02:38,  3.61s/it]\n",
      "  0%|                                                    | 0/16 [00:00<?, ?it/s]\u001b[A\n",
      " 12%|█████▌                                      | 2/16 [00:00<00:02,  6.32it/s]\u001b[A\n",
      " 19%|████████▎                                   | 3/16 [00:00<00:02,  5.24it/s]\u001b[A\n",
      " 25%|███████████                                 | 4/16 [00:00<00:02,  5.47it/s]\u001b[A\n",
      " 31%|█████████████▊                              | 5/16 [00:00<00:02,  4.64it/s]\u001b[A\n",
      " 38%|████████████████▌                           | 6/16 [00:01<00:02,  3.92it/s]\u001b[A\n",
      " 44%|███████████████████▎                        | 7/16 [00:01<00:02,  3.59it/s]\u001b[A\n",
      " 50%|██████████████████████                      | 8/16 [00:01<00:02,  3.58it/s]\u001b[A\n",
      " 56%|████████████████████████▊                   | 9/16 [00:02<00:01,  3.53it/s]\u001b[A\n",
      " 62%|██████████████████████████▉                | 10/16 [00:02<00:01,  3.30it/s]\u001b[A\n",
      " 69%|█████████████████████████████▌             | 11/16 [00:02<00:01,  3.31it/s]\u001b[A\n",
      " 75%|████████████████████████████████▎          | 12/16 [00:03<00:01,  3.42it/s]\u001b[A\n",
      " 81%|██████████████████████████████████▉        | 13/16 [00:03<00:00,  3.30it/s]\u001b[A\n",
      " 88%|█████████████████████████████████████▋     | 14/16 [00:03<00:00,  3.19it/s]\u001b[A\n",
      " 94%|████████████████████████████████████████▎  | 15/16 [00:04<00:00,  3.16it/s]\u001b[A\n",
      "                                                                                \u001b[A\n",
      "\u001b[A{'eval_loss': 0.17837972939014435, 'eval_runtime': 4.7107, 'eval_samples_per_second': 6.793, 'eval_steps_per_second': 3.397, 'epoch': 4.5}\n",
      " 91%|█████████████████████████████████████▎   | 441/485 [24:09<02:38,  3.61s/it]\n",
      "100%|███████████████████████████████████████████| 16/16 [00:04<00:00,  3.37it/s]\u001b[A\n",
      "{'loss': 0.0087, 'grad_norm': 0.322265625, 'learning_rate': 4.204562231352516e-06, 'epoch': 4.51}\n",
      "{'loss': 0.0158, 'grad_norm': 0.4375, 'learning_rate': 4.016893018922996e-06, 'epoch': 4.52}\n",
      "{'loss': 0.0295, 'grad_norm': 0.9765625, 'learning_rate': 3.83342241853496e-06, 'epoch': 4.53}\n",
      "{'loss': 0.0088, 'grad_norm': 0.37890625, 'learning_rate': 3.6541584557868604e-06, 'epoch': 4.54}\n",
      "{'loss': 0.0056, 'grad_norm': 0.482421875, 'learning_rate': 3.4791089722651436e-06, 'epoch': 4.56}\n",
      "{'loss': 0.026, 'grad_norm': 0.68359375, 'learning_rate': 3.3082816252012926e-06, 'epoch': 4.57}\n",
      "{'loss': 0.0052, 'grad_norm': 0.375, 'learning_rate': 3.1416838871368924e-06, 'epoch': 4.58}\n",
      "{'loss': 0.0146, 'grad_norm': 0.578125, 'learning_rate': 2.9793230455966937e-06, 'epoch': 4.59}\n",
      "{'loss': 0.016, 'grad_norm': 0.6171875, 'learning_rate': 2.821206202769899e-06, 'epoch': 4.6}\n",
      "{'loss': 0.0039, 'grad_norm': 0.271484375, 'learning_rate': 2.667340275199426e-06, 'epoch': 4.61}\n",
      "{'loss': 0.0078, 'grad_norm': 0.5390625, 'learning_rate': 2.5177319934794e-06, 'epoch': 4.62}\n",
      "{'loss': 0.0046, 'grad_norm': 0.275390625, 'learning_rate': 2.3723879019607374e-06, 'epoch': 4.63}\n",
      "{'loss': 0.0069, 'grad_norm': 0.375, 'learning_rate': 2.2313143584648423e-06, 'epoch': 4.64}\n",
      "{'loss': 0.0137, 'grad_norm': 0.65625, 'learning_rate': 2.0945175340055357e-06, 'epoch': 4.65}\n",
      "{'loss': 0.0299, 'grad_norm': 0.8515625, 'learning_rate': 1.9620034125190644e-06, 'epoch': 4.66}\n",
      "{'loss': 0.0249, 'grad_norm': 0.671875, 'learning_rate': 1.8337777906023978e-06, 'epoch': 4.67}\n",
      "{'loss': 0.0103, 'grad_norm': 0.349609375, 'learning_rate': 1.7098462772596302e-06, 'epoch': 4.68}\n",
      "{'loss': 0.0202, 'grad_norm': 0.58984375, 'learning_rate': 1.5902142936566334e-06, 'epoch': 4.69}\n",
      "{'loss': 0.0206, 'grad_norm': 0.79296875, 'learning_rate': 1.4748870728839347e-06, 'epoch': 4.7}\n",
      "{'loss': 0.0127, 'grad_norm': 0.5390625, 'learning_rate': 1.3638696597277679e-06, 'epoch': 4.71}\n",
      "{'loss': 0.0146, 'grad_norm': 0.859375, 'learning_rate': 1.2571669104494256e-06, 'epoch': 4.72}\n",
      "{'loss': 0.0079, 'grad_norm': 0.58203125, 'learning_rate': 1.1547834925728528e-06, 'epoch': 4.73}\n",
      "{'loss': 0.0151, 'grad_norm': 0.412109375, 'learning_rate': 1.0567238846803996e-06, 'epoch': 4.74}\n",
      "{'loss': 0.0047, 'grad_norm': 0.28125, 'learning_rate': 9.62992376217009e-07, 'epoch': 4.75}\n",
      "{'loss': 0.0079, 'grad_norm': 0.49609375, 'learning_rate': 8.735930673024806e-07, 'epoch': 4.76}\n",
      "{'loss': 0.006, 'grad_norm': 0.54296875, 'learning_rate': 7.885298685522235e-07, 'epoch': 4.77}\n",
      "{'loss': 0.012, 'grad_norm': 0.51171875, 'learning_rate': 7.078065009060941e-07, 'epoch': 4.78}\n",
      "{'loss': 0.0102, 'grad_norm': 0.90234375, 'learning_rate': 6.314264954657256e-07, 'epoch': 4.79}\n",
      "{'loss': 0.0081, 'grad_norm': 0.453125, 'learning_rate': 5.593931933399854e-07, 'epoch': 4.8}\n",
      "{'loss': 0.0096, 'grad_norm': 0.59765625, 'learning_rate': 4.917097454988584e-07, 'epoch': 4.81}\n",
      "{'loss': 0.0034, 'grad_norm': 0.23828125, 'learning_rate': 4.2837911263562404e-07, 'epoch': 4.82}\n",
      "{'loss': 0.0166, 'grad_norm': 0.4375, 'learning_rate': 3.694040650373154e-07, 'epoch': 4.83}\n",
      "{'loss': 0.0135, 'grad_norm': 0.828125, 'learning_rate': 3.1478718246357173e-07, 'epoch': 4.84}\n",
      "{'loss': 0.0123, 'grad_norm': 0.578125, 'learning_rate': 2.645308540337843e-07, 'epoch': 4.85}\n",
      "{'loss': 0.0285, 'grad_norm': 0.7578125, 'learning_rate': 2.1863727812254653e-07, 'epoch': 4.86}\n",
      "{'loss': 0.028, 'grad_norm': 0.69140625, 'learning_rate': 1.7710846226355328e-07, 'epoch': 4.87}\n",
      "{'loss': 0.0228, 'grad_norm': 0.71875, 'learning_rate': 1.3994622306173765e-07, 'epoch': 4.88}\n",
      "{'loss': 0.0105, 'grad_norm': 0.474609375, 'learning_rate': 1.0715218611384581e-07, 'epoch': 4.89}\n",
      "{'loss': 0.0075, 'grad_norm': 0.4375, 'learning_rate': 7.872778593728258e-08, 'epoch': 4.9}\n",
      "{'loss': 0.008, 'grad_norm': 0.41796875, 'learning_rate': 5.467426590739511e-08, 'epoch': 4.92}\n",
      "{'loss': 0.004, 'grad_norm': 0.2392578125, 'learning_rate': 3.499267820307184e-08, 'epoch': 4.93}\n",
      "{'loss': 0.016, 'grad_norm': 0.71484375, 'learning_rate': 1.9683883760723832e-08, 'epoch': 4.94}\n",
      "{'loss': 0.0104, 'grad_norm': 0.494140625, 'learning_rate': 8.748552236603757e-09, 'epoch': 4.95}\n",
      "{'loss': 0.0137, 'grad_norm': 0.49609375, 'learning_rate': 2.187161977540431e-09, 'epoch': 4.96}\n",
      "{'train_runtime': 1583.2368, 'train_samples_per_second': 2.451, 'train_steps_per_second': 0.306, 'train_loss': 0.161400637163579, 'epoch': 4.96}\n",
      "100%|█████████████████████████████████████████| 485/485 [26:23<00:00,  3.26s/it]\n",
      "[2025-10-10 12:40:26,420] [INFO] [axolotl.train.save_trained_model:244] [PID:4133512] [RANK:0] Training completed! Saving trained model to ./out-gemma-3-270m-it.\u001b[39m\n",
      "[2025-10-10 12:40:27,184] [INFO] [axolotl.train.save_trained_model:341] [PID:4133512] [RANK:0] Model successfully saved to ./out-gemma-3-270m-it\u001b[39m\n",
      "\u001b[0mCPU times: user 9.92 s, sys: 2.06 s, total: 12 s\n",
      "Wall time: 30min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "!venv/bin/accelerate launch -m axolotl.cli.train {CONFIG_FILE}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 10-10 13:21:41 [__init__.py:216] Automatically detected platform cuda.\n",
      "INFO 10-10 13:21:45 [utils.py:328] non-default args: {'max_model_len': 8192, 'disable_log_stats': True, 'model': 'out-gemma-3-270m-it'}\n",
      "INFO 10-10 13:21:58 [__init__.py:742] Resolved architecture: Gemma3ForCausalLM\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "INFO 10-10 13:21:58 [__init__.py:1815] Using max model len 8192\n",
      "INFO 10-10 13:21:59 [scheduler.py:222] Chunked prefill is enabled with max_num_batched_tokens=8192.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:00 [core.py:654] Waiting for init message from front-end.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:00 [core.py:76] Initializing a V1 LLM engine (v0.10.2) with config: model='out-gemma-3-270m-it', speculative_config=None, tokenizer='out-gemma-3-270m-it', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.bfloat16, max_seq_len=8192, download_dir=None, load_format=auto, tensor_parallel_size=1, pipeline_parallel_size=1, data_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, device_config=cuda, decoding_config=DecodingConfig(backend='auto', disable_fallback=False, disable_any_whitespace=False, disable_additional_properties=False, reasoning_backend=''), observability_config=ObservabilityConfig(show_hidden_metrics_for_version=None, otlp_traces_endpoint=None, collect_detailed_traces=None), seed=0, served_model_name=out-gemma-3-270m-it, enable_prefix_caching=True, chunked_prefill_enabled=True, use_async_output_proc=True, pooler_config=None, compilation_config={\"level\":3,\"debug_dump_path\":\"\",\"cache_dir\":\"\",\"backend\":\"\",\"custom_ops\":[],\"splitting_ops\":[\"vllm.unified_attention\",\"vllm.unified_attention_with_output\",\"vllm.mamba_mixer2\",\"vllm.mamba_mixer\",\"vllm.short_conv\",\"vllm.linear_attention\",\"vllm.plamo2_mamba_mixer\",\"vllm.gdn_attention\"],\"use_inductor\":true,\"compile_sizes\":[],\"inductor_compile_config\":{\"enable_auto_functionalized_v2\":false},\"inductor_passes\":{},\"cudagraph_mode\":1,\"use_cudagraph\":true,\"cudagraph_num_of_warmups\":1,\"cudagraph_capture_sizes\":[512,504,496,488,480,472,464,456,448,440,432,424,416,408,400,392,384,376,368,360,352,344,336,328,320,312,304,296,288,280,272,264,256,248,240,232,224,216,208,200,192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"cudagraph_copy_inputs\":false,\"full_cuda_graph\":false,\"pass_config\":{},\"max_capture_size\":512,\"local_cache_dir\":null}\n",
      "[W1010 13:22:04.509646388 ProcessGroupNCCL.cpp:981] Warning: TORCH_NCCL_AVOID_RECORD_STREAMS is the default now, this environment variable is thus deprecated. (function operator())\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "[Gloo] Rank 0 is connected to 0 peer ranks. Expected number of connected peer ranks is : 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:04 [parallel_state.py:1165] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0, EP rank 0\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m WARNING 10-10 13:22:04 [topk_topp_sampler.py:69] FlashInfer is not available. Falling back to the PyTorch-native implementation of top-p & top-k sampling. For the best performance, please install FlashInfer.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:04 [gpu_model_runner.py:2338] Starting to load model out-gemma-3-270m-it...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:04 [gpu_model_runner.py:2370] Loading model from scratch...\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:05 [cuda.py:362] Using Flash Attention backend on V1 engine.\n",
      "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.16s/it]\n",
      "Loading safetensors checkpoint shards: 100% Completed | 1/1 [00:01<00:00,  1.16s/it]\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m \n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:06 [default_loader.py:268] Loading weights took 1.17 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:06 [gpu_model_runner.py:2392] Model loading took 0.5334 GiB and 1.441661 seconds\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:13 [backends.py:539] Using cache directory: /home/oisuomin/.cache/vllm/torch_compile_cache/d786bb4ef6/rank_0_0/backbone for vLLM's torch.compile\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:13 [backends.py:550] Dynamo bytecode transform time: 6.86 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:43 [backends.py:161] Directly load the compiled graph(s) for dynamic shape from the cache, took 29.126 s\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:47 [monitor.py:34] torch.compile takes 6.86 s in total\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:47 [gpu_worker.py:298] Available KV cache memory: 68.38 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:48 [kv_cache_utils.py:1028] GPU KV cache size: 3,983,376 tokens\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:48 [kv_cache_utils.py:1032] Maximum concurrency for 8,192 tokens per request: 485.46x\n",
      "Capturing CUDA graphs (mixed prefill-decode, PIECEWISE): 100%|█| 67/67 [00:01<00\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:49 [gpu_model_runner.py:3118] Graph capturing finished in 2 secs, took 0.29 GiB\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:49 [gpu_worker.py:391] Free memory on device (78.76/79.25 GiB) on startup. Desired GPU memory utilization is (0.9, 71.33 GiB). Actual usage is 0.53 GiB for weight, 2.39 GiB for peak activation, 0.02 GiB for non-torch memory, and 0.29 GiB for CUDAGraph memory. Replace gpu_memory_utilization config with `--kv-cache-memory=72954139545` to fit into requested memory, or `--kv-cache-memory=80937105920` to fully utilize gpu memory. Current kv cache memory in use is 73421804441 bytes.\n",
      "\u001b[1;36m(EngineCore_DP0 pid=4143065)\u001b[0;0m INFO 10-10 13:22:50 [core.py:218] init engine (profile, create kv cache, warmup model) took 43.34 seconds\n",
      "INFO 10-10 13:22:53 [llm.py:295] Supported_tasks: ['generate']\n",
      "INFO 10-10 13:22:53 [__init__.py:36] No IOProcessor plugins requested by the model\n",
      "Adding requests: 100%|███████████████████████| 377/377 [00:00<00:00, 462.47it/s]\n",
      "Processed prompts: 100%|█| 377/377 [00:12<00:00, 29.17it/s, est. speed input: 73\n",
      "Errors: 7 out of 377 records (1.86%)\n",
      "ERROR 10-10 13:23:08 [core_client.py:564] Engine core proc EngineCore_DP0 died unexpectedly, shutting down client.\n",
      "| language   | field     |   mean |   size |\n",
      "|------------|-----------|--------|--------|\n",
      "| en         | alt_title | 0.8444 |    135 |\n",
      "| en         | creator   | 0.6115 |    135 |\n",
      "| en         | doi       | 0.9630 |    135 |\n",
      "| en         | e-isbn    | 0.8272 |    135 |\n",
      "| en         | e-issn    | 0.9259 |    135 |\n",
      "| en         | language  | 0.9556 |    135 |\n",
      "| en         | p-isbn    | 0.8963 |    135 |\n",
      "| en         | p-issn    | 0.9481 |    135 |\n",
      "| en         | publisher | 0.6420 |    135 |\n",
      "| en         | title     | 0.6296 |    135 |\n",
      "| en         | type_coar | 0.8000 |    135 |\n",
      "| en         | year      | 0.8741 |    135 |\n",
      "| fi         | alt_title | 0.8508 |    181 |\n",
      "| fi         | creator   | 0.5732 |    181 |\n",
      "| fi         | doi       | 1.0000 |    181 |\n",
      "| fi         | e-isbn    | 0.9061 |    181 |\n",
      "| fi         | e-issn    | 0.9171 |    181 |\n",
      "| fi         | language  | 0.9724 |    181 |\n",
      "| fi         | p-isbn    | 0.9613 |    181 |\n",
      "| fi         | p-issn    | 0.9613 |    181 |\n",
      "| fi         | publisher | 0.6888 |    181 |\n",
      "| fi         | title     | 0.5249 |    181 |\n",
      "| fi         | type_coar | 0.7072 |    181 |\n",
      "| fi         | year      | 0.8066 |    181 |\n",
      "| se         | alt_title | 1.0000 |      3 |\n",
      "| se         | creator   | 0.3333 |      3 |\n",
      "| se         | doi       | 1.0000 |      3 |\n",
      "| se         | e-isbn    | 1.0000 |      3 |\n",
      "| se         | e-issn    | 1.0000 |      3 |\n",
      "| se         | language  | 1.0000 |      3 |\n",
      "| se         | p-isbn    | 1.0000 |      3 |\n",
      "| se         | p-issn    | 1.0000 |      3 |\n",
      "| se         | publisher | 0.0000 |      3 |\n",
      "| se         | title     | 0.3333 |      3 |\n",
      "| se         | type_coar | 0.3333 |      3 |\n",
      "| se         | year      | 0.6667 |      3 |\n",
      "| sv         | alt_title | 0.7241 |     58 |\n",
      "| sv         | creator   | 0.6770 |     58 |\n",
      "| sv         | doi       | 0.9828 |     58 |\n",
      "| sv         | e-isbn    | 0.8966 |     58 |\n",
      "| sv         | e-issn    | 0.9828 |     58 |\n",
      "| sv         | language  | 0.9483 |     58 |\n",
      "| sv         | p-isbn    | 0.8793 |     58 |\n",
      "| sv         | p-issn    | 0.9655 |     58 |\n",
      "| sv         | publisher | 0.7414 |     58 |\n",
      "| sv         | title     | 0.4828 |     58 |\n",
      "| sv         | type_coar | 0.7759 |     58 |\n",
      "| sv         | year      | 0.8966 |     58 |\n",
      "CPU times: user 522 ms, sys: 128 ms, total: 650 ms\n",
      "Wall time: 1min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# evaluate using the evaluate-model script, which needs venv with vLLM installed\n",
    "!../dspy/venv/bin/python evaluate-model.py out-{MODEL_SHORT_NAME} axolotl-test.jsonl ../../eval/results-{MODEL_SHORT_NAME}.md\n",
    "!cat ../../eval/results-{MODEL_SHORT_NAME}.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "greylitlm-axolotl",
   "language": "python",
   "name": "greylitlm-axolotl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
