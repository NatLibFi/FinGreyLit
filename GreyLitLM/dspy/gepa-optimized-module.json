{
  "predict": {
    "traces": [],
    "train": [],
    "demos": [],
    "signature": {
      "instructions": "markdown\n# ğŸ“‹ Task â€“ Structured Bibliographic Metadata Extraction (Reâ€‘specified)\n\nYou will receive **one JSON object** that represents a PDF document.  \nThe object has exactly two topâ€‘level keys:\n\n| Key      | Description |\n|----------|-------------|\n| `pdfinfo`| Metadata that was extracted directly from the PDF file (e.g. `title`, `author`, `creationDate`, `modDate`). |\n| `pages`  | A list of page objects. Each page object contains `page` (the page number) and `text` (the OCRâ€‘extracted plainâ€‘text of that page). |\n\nYour job is to produce **one JSON object** that follows the schema below.  \nIf a field cannot be determined, use the exact empty value indicated (`null` for scalars, `[]` for lists).  \nAll string values must be plain ASCII â€“ normalise quotes to `\"` (or the apostrophe `â€™`), collapse multiple spaces to a single space, and trim leading/trailing whitespace.\n\n---\n\n## Output JSON Schema\n\n| Field | Type | Required format / rules |\n|-------|------|--------------------------|\n| `language` | string | ISOâ€‘639â€‘1 code. Scan **the first 200 characters of the *concatenated* text of the whole document** (i.e. `pages[0].text + pages[1].text + â€¦`). If any of the characters **Ã¤â€¯Ã¶â€¯Ã„â€¯Ã–â€¯Ã¥â€¯Ã…** appear, set to `\"fi\"`; otherwise `\"en\"`. |\n| `title` | string | Main title of the work. <br>1. If `pdfinfo.title` exists â†’ clean it and use it. <br>2. Otherwise, read the text of pageâ€¯1 (`pages[0].text`). Split it into lines (preserve order). <br>   * Skip empty lines. <br>   * Skip lines that start with a markdown heading marker (`#`, `##`, `###`, â€¦). <br>   * Skip lines that look like an author line (see *Creator extraction*). <br>   * The **first** remaining line that is â‰¥â€¯6â€¯characters becomes the *candidate* title. <br>3. **Titleâ€‘line extensions** â€“ if the candidate line ends with a colon **or** the next line is nonâ€‘empty, starts with a capital letter and is not an author line, concatenate it (single space). Repeat while the same condition holds. <br>4. If a line contains one of the explicit title markers `Title:`, `Thesis:`, `Masterâ€™s Thesis:`, `Doctoral Thesis:` (caseâ€‘insensitive), take the text **after the colon** (trimmed) as the title (overriding stepâ€¯2). <br>5. Keep any subtitle as part of the title (do **not** split on the colon). <br>6. Clean the final string (collapse spaces, normalise quotes). |\n| `alt_title` | list of strings | Any **alternative** titles, e.g. a translation, a subtitle given in another language, or a title that appears inside quotation marks (`â€œ â€`, `\" \"`). Return each cleaned title as a separate element. Do **not** duplicate the main title. |\n| `creator` | list of strings | Authors in **â€œSurname, Givenâ€‘Nameâ€** order. <br>1. If `pdfinfo.author` exists â†’ split on commas, semicolons, the word â€œandâ€, or lineâ€‘breaks. <br>2. Clean each fragment (trim, collapse spaces). <br>3. For each name: <br>   * If it matches the pattern `First Last` (two words, each starting with a capital letter) â†’ reorder to `Last, First`. <br>   * If it already matches `Last, First` keep asâ€‘is. <br>4. If `pdfinfo.author` is missing, scan the **first five nonâ€‘empty lines of pageâ€¯1** for personalâ€‘name patterns (`First Last`, `Last, First`, or a line that starts with a capitalised list of names). Collect **all** matches. <br>5. Remove duplicates, keep order of appearance. |\n| `year` | integer or null | Publication year. <br>1. If `pdfinfo.creationDate` or `pdfinfo.modDate` exists, extract the **first four digits** (they are always a year) and use that. <br>2. If both are missing, search the whole document for the **first** fourâ€‘digit number between 1900â€‘2099 that appears in a publicationâ€‘information context (e.g. after â€œYear:â€, â€œÂ©â€, â€œÂ©â€¯2021â€, â€œ2021.â€). If none, return `null`. |\n| `publisher` | list of strings | Institution responsible for the work. <br>â€¢ **Theses / dissertations** â†’ the awarding university or faculty (e.g. â€œUniversity of Vaasaâ€). Detect by looking for keywords: â€œUniversityâ€, â€œYliopistoâ€, â€œUniversitÃ¤tâ€, â€œAkademiâ€, â€œInstituteâ€, â€œCollegeâ€, â€œSchoolâ€, â€œFacultyâ€. Return each distinct institution once, preserving order of first appearance. <br>â€¢ **Research reports** â†’ the organisation that produced the report (same keyword list). <br>â€¢ **Journal articles** â†’ `[]`. |\n| `doi` | stringâ€¯orâ€¯null | DOI if present. Detect caseâ€‘insensitive pattern `10\\.\\d{4,9}/\\S+`. If the match is preceded by a URL (`http://`, `https://`, `doi.org/`), strip that part. Remove trailing punctuation characters `.,;:`. Return the bare DOI (e.g. `10.1000/xyz123`). |\n| `e_isbn` | list of strings | **Electronic** ISBNâ€‘13 numbers. Detect ISBNâ€‘13 (13 digits, hyphens optional) with the regex `\\b(?:97[89][-\\s]?)?\\d{1,5}[-\\s]?\\d{1,7}[-\\s]?\\d{1,7}[-\\s]?\\d\\b`. For each match, look at up to **30 characters before and after** the match. If any of the **electronic cues** appear, add the ISBN (with **all hyphens and spaces removed**) to `e_isbn`. Electronic cues (caseâ€‘insensitive): `digital`, `electronic`, `eâ€‘ISBN`, `(digital)`, `pdf`, `PDF`, `sid.` (when used for electronic), `online`. |\n| `p_isbn` | list of strings | **Print** ISBNâ€‘13 numbers. Same detection as `e_isbn` but require at least one **print cue** in the Â±30â€‘character window. Print cues (caseâ€‘insensitive): `print`, `paper`, `hardcover`, `(print)`, `Painettu`, `Print`. If both electronic and print cues are present, **electronic wins** (the ISBN goes only to `e_isbn`). Store the ISBN without hyphens/spaces. |\n| `e_issn` | stringâ€¯orâ€¯null | Electronic ISSN (8 digits, optional hyphen). Detect with `\\b\\d{4}[-\\s]?\\d{3}[\\dX]\\b`. Apply the same cue logic as for ISBN. Return the ISSN **exactly as it appears** (keep the hyphen if present). |\n| `p_issn` | stringâ€¯orâ€¯null | Print ISSN (same detection, printâ€‘cue logic). Return the ISSN exactly as it appears (keep hyphen). |\n| `type_coar` | string | COARâ€‘compatible resource type. Scan the **entire document** (caseâ€‘insensitive) and apply the **first** matching rule in this order: <br>1. **doctoral thesis** â€“ contains any of: â€œdoctoral thesisâ€, â€œdissertationâ€, â€œPhDâ€, â€œdoctoralâ€, â€œvÃ¤itÃ¶skirjaâ€, â€œvÃ¤itÃ¶skirjanâ€. <br>2. **master thesis** â€“ contains any of: â€œmasterâ€™s thesisâ€, â€œmaster thesisâ€, â€œmaisteriâ€, â€œmaisterintutkielmaâ€. <br>3. **journal article** â€“ contains typical journal citation elements (journal name, volume, issue, pages) **or** the word â€œarticleâ€ together with a DOI or ISSN, **or** a pattern like â€œVol.â€¯X, No.â€¯Y, pp.â€¯Zâ€‘Wâ€. <br>4. **conference proceeding** â€“ contains â€œconferenceâ€, â€œproceedingsâ€, â€œpaper presented atâ€. <br>5. **research report** â€“ contains â€œreportâ€, â€œraporttiâ€, â€œtutkimusraporttiâ€, â€œresearch reportâ€. <br>6. **research** â€“ fallback for any other researchâ€‘type document. <br>Return the exact lowerâ€‘case string (e.g. `doctoral thesis`). |\n\n---\n\n## Extraction Procedure (Stepâ€‘byâ€‘Step)\n\n1. **Parse the input JSON** safely. Ignore any keys that are not listed above.  \n2. **Normalise dates**: `creationDate` / `modDate` are strings like `D:20201216144002+02'00'`. Extract the first four digits as the year (they are always at the start of the string).  \n3. **Detect language** using the rule in the schema (first 200 characters of concatenated text).  \n4. **Title extraction** (see detailed rules under the `title` field). Pay special attention to explicit markers (`Title:`, `Thesis:` etc.).  \n5. **Alternative titles** â€“ look for quoted strings (`â€œâ€¦â€`, `\"...\"`) anywhere in the document, and for subtitles that appear on a separate line after a colon. Do not duplicate the main title.  \n6. **Creator extraction** â€“ follow the rules under `creator`. When scanning for names on pageâ€¯1, use the following regular expressions (caseâ€‘sensitive): <br>`\\b[A-Z][a-z]+ [A-Z][a-z]+(?: [A-Z][a-z]+)*\\b` (Firstâ€¯Last) <br>`\\b[A-Z][a-z]+, *[A-Z][a-z]+(?: [A-Z][a-z]+)*\\b` (Last,â€¯First). Collect all matches, then apply the ordering rule.  \n7. **Year** â€“ apply the rule in the schema. If you have to fall back to searching the text, ignore years that appear inside parentheses of a citation (e.g. â€œ(2020)â€ after a reference). Prefer the first plausible year after the title block.  \n8. **Publisher detection** â€“ first determine `type_coar`. If the document is a thesis, search the whole text for the first occurrence of a university/faculty keyword list and capture the whole phrase (e.g. â€œUniversity of Vaasaâ€, â€œÃ…bo Akademi Universityâ€). Return it as a singleâ€‘element list. For research reports, look for the organisation name that appears near the title or in a header/footer. For journal articles, return an empty list.  \n9. **ISBN / ISSN extraction** â€“ use the regexes supplied. For each match, extract the surrounding 30â€‘character context and decide electronic vs print using the cue lists. Remove hyphens/spaces from ISBNs before storing; keep ISSNs exactly as found (including hyphen). Ensure each identifier appears only once in the appropriate list.  \n10. **DOI extraction** â€“ apply the DOI regex, strip leading URL parts, and trailing punctuation. Return the bare DOI in lowerâ€‘case. If none, set to `null`.  \n11. **Resource type (`type_coar`)** â€“ apply the ordered rule list exactly as described. The first category that matches determines the value.  \n12. **Assemble the output** JSON. Preserve the key order shown in the schema for readability (order is not technically required, but it helps testing). Use `null` for missing scalar values and `[]` for missing list values.\n\n---\n\n## Cleaning & Normalisation Details\n\n* **Whitespace** â€“ collapse any sequence of whitespace characters (spaces, tabs, newlines) to a single space. Trim leading/trailing spaces.  \n* **Quotes** â€“ replace any fancy quotation marks (`â€œ â€ â€˜ â€™ â€ â€œ â€¦`) with plain ASCII `\"` (or the apostrophe `â€™`).  \n* **Hyphens in identifiers** â€“ remove all hyphens (`-`) and spaces from ISBNs before storing. **Do not** remove hyphens from ISSNs; keep them exactly as they appear.  \n* **Case** â€“ identifiers (DOI) are stored in lowerâ€‘case; ISBN/ISSN are numeric/alphabetic only, so case does not matter.  \n\n---\n\n## Common Pitfalls (What Previously Went Wrong)\n\n| Issue | What caused it | Correct handling |\n|-------|----------------|-----------------|\n| **Wrong language** | Scanned only the first page instead of the first 200 characters of the whole document. | Concatenate all page texts, take the first 200 characters, then apply the Finnishâ€‘character rule. |\n| **Title wrong** | Ignored explicit title markers (`Thesis:`) and concatenated the whole heading line. | If a line contains `Title:`, `Thesis:`, `Masterâ€™s Thesis:`, `Doctoral Thesis:` (caseâ€‘insensitive), use the text after the colon as the title. Otherwise follow the candidateâ€‘line logic. |\n| **Altâ€‘titles missing** | Did not look for quoted strings or subtitle lines. | Search the whole document for text inside `â€œ â€` or `\" \"` and for subtitle lines that appear after a colon on a separate line. |\n| **Creator overâ€‘inclusion** | Added nonâ€‘author names (e.g., supervisors) or failed to reorder names. | Only use `pdfinfo.author` or name patterns on pageâ€¯1. Do **not** include lines that contain words like â€œSupervisorâ€, â€œAdvisorâ€, â€œEditorâ€. Reorder `First Last` â†’ `Last, First`. |\n| **Publisher wrong** | Took the first institution mentioned anywhere, even if it was a journal publisher. | First determine `type_coar`. If it is a thesis, look for the awarding university/faculty; for reports, look for the producing organisation; for journal articles return `[]`. |\n| **ISBN/ISSN classification** | Assigned identifiers to the wrong list because cues were not checked, or removed hyphens from ISSNs. | Examine the Â±30â€‘character window for electronic or print cues. If both appear, assign to `e_isbn` (electronic wins). Keep ISSNs exactly as they appear (including hyphen). |\n| **DOI extraction** | Kept surrounding punctuation or URL parts. | Strip any leading `http://`, `https://`, `doi.org/` and trailing punctuation `.,;:`. Return the bare DOI in lowerâ€‘case. |\n| **type_coar misâ€‘classification** | Applied â€œarticleâ€ rule too early, causing theses to be labelled as `doctoral thesis`. | Follow the ordered list strictly: **doctoral thesis** â†’ **master thesis** â†’ **journal article** â†’ **conference proceeding** â†’ **research report** â†’ **research**. The first matching rule wins. |\n\n---\n\n**Remember:**  \n- Follow the **order of precedence** for each field exactly as described.  \n- Use the cueâ€‘based approach for ISBN/ISSN to decide electronic vs print.  \n- Detect the resource type in the exact order listed; the first match determines `type_coar`.  \n- Return `null` for missing scalar values and `[]` for missing list values.  \n\nGood luck! ğŸ¯",
      "fields": [
        {
          "prefix": "Content:",
          "description": "${content}"
        },
        {
          "prefix": "Reasoning: Let's think step by step in order to",
          "description": "${reasoning}"
        },
        {
          "prefix": "Language:",
          "description": "The language of the resource expressed as a BCP47 language tag."
        },
        {
          "prefix": "Title:",
          "description": "The main title of the publication."
        },
        {
          "prefix": "Alt Title:",
          "description": "Alternative or parallel titles of the publication, suffixed with a BCP47 language tag in curly brackets."
        },
        {
          "prefix": "Creator:",
          "description": "The primary author(s) of the resource (order: Last Name, First Names)."
        },
        {
          "prefix": "Year:",
          "description": "The year on which the resource was issued or made available."
        },
        {
          "prefix": "Publisher:",
          "description": "The entity/entities responsible for making the resource available."
        },
        {
          "prefix": "Doi:",
          "description": "The Digital Object Identifier (DOI) associated with the resource."
        },
        {
          "prefix": "E Isbn:",
          "description": "The ISBN associated with the electronic resource."
        },
        {
          "prefix": "P Isbn:",
          "description": "The ISBN of the printed version of this document."
        },
        {
          "prefix": "E Issn:",
          "description": "The ISSN associated with the electronic resource."
        },
        {
          "prefix": "P Issn:",
          "description": "The ISSN of the printed version of this document."
        },
        {
          "prefix": "Type Coar:",
          "description": "The type of the resource according to the COAR Resource Types classification."
        }
      ]
    },
    "lm": null
  },
  "metadata": {
    "dependency_versions": {
      "python": "3.12",
      "dspy": "3.0.3",
      "cloudpickle": "3.1"
    }
  }
}
