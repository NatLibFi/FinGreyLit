{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73c40ed4-71a7-409b-a8d5-b3a00084799a",
   "metadata": {},
   "source": [
    "# Metadata extraction using DSPy and a local LLM using GEPA optimization\n",
    "\n",
    "To run this, you first need to start two local vLLM servers in the backround. These commands are tested on a single A100 80GB in non-exclusive mode (e.g. Turso oversub GPU). The GPT-OSS 120B model has to be partially offloaded to CPU to preserve VRAM.\n",
    "\n",
    "For the main extractor model:\n",
    "\n",
    "    vllm serve google/gemma-3-4b-it --port 7987 --max-model-len 16384 --gpu-memory-utilization 0.25\n",
    "\n",
    "For the reflection model:\n",
    "    \n",
    "    llama-server -hf ggml-org/gpt-oss-120b-GGUF --host 0.0.0.0 --port 7988 --ctx-size 0 --jinja -ub 2048 -b 2048 --n-cpu-moe 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5209ed6-b8db-4c6b-9030-b995851f8c41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm Gemma, a large language model created by the Gemma team at Google DeepMind. I’m an open-weights model, which means I’m widely available for public use! \\n\\nI can take text and images as inputs and generate text-based responses. \\n\\nYou can learn more about me on the Gemma project page: [https://ai.google.dev/gemma](https://ai.google.dev/gemma)\"]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dspy\n",
    "\n",
    "MODEL_ID = \"google/gemma-3-4b-it\"  # should match the model vLLM is running (does it matter??)\n",
    "PORT = 7987  # should match the port where vLLM is running\n",
    "MAX_TOKENS = 2048  # limit on how many new tokens to generate (default: 4000)\n",
    "TEMPERATURE = 0.7\n",
    "\n",
    "lm = dspy.LM(\"openai/\" + MODEL_ID,\n",
    "             api_base=f\"http://localhost:{PORT}/v1\",  # ensure this points to your port\n",
    "             api_key=\"local\", model_type=\"chat\", max_tokens=MAX_TOKENS, temperature=TEMPERATURE)\n",
    "dspy.configure(lm=lm)\n",
    "\n",
    "# test the connection to the LLM\n",
    "lm(\"Who are you?\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "678b2403-0239-4b0c-9bc4-e58caefe2be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I’m ChatGPT\\u202f—\\u202fa large language model created by OpenAI. I’ve been trained on a wide variety of text up through June\\u202f2024, which lets me help with things like answering questions, brainstorming ideas, explaining concepts, drafting or editing writing, solving problems, and much more. I don’t have personal experiences or consciousness, and I can’t browse the web in real time, but I can draw on the information I was trained on to generate useful, context‑aware responses.  \\n\\nIf there’s anything specific you’d like to know or discuss, just let me know!']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "REFLECTION_MODEL_ID = \"ggml-org/gpt-oss-120b-GGUF\"\n",
    "REFLECTION_PORT = PORT + 1\n",
    "REFLECTION_MAX_TOKENS = 16384\n",
    "\n",
    "reflection_lm = dspy.LM(\"openai/\" + REFLECTION_MODEL_ID,\n",
    "             api_base=f\"http://localhost:{REFLECTION_PORT}/v1\",  # ensure this points to your port\n",
    "             api_key=\"local\", model_type=\"chat\", max_tokens=REFLECTION_MAX_TOKENS, temperature=TEMPERATURE)\n",
    "\n",
    "# test the connection to the LLM\n",
    "reflection_lm(\"Who are you?\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "875a6803-72a9-43a2-8cf9-f27be5322401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(576, 64, 182)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and prepare dataset\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "random.seed(42)  # for deterministic sampling of validation set\n",
    "\n",
    "train_files = glob.glob(\"../../llm-dataset/*-train.jsonl\")\n",
    "test_files = glob.glob(\"../../llm-dataset/*-test.jsonl\")\n",
    "\n",
    "VAL_SIZE = 64  # how many documents to validate on during optimization\n",
    "\n",
    "def preprocess_sample(sample):\n",
    "    # fix some bad field names\n",
    "    ground_truth = { fld.replace('-', '_'): val for fld, val in sample[\"ground_truth\"].items() }\n",
    "    output = json.dumps(ground_truth)\n",
    "    input_ = json.dumps(sample[\"content\"])\n",
    "    return dspy.Example({\"content\": input_, \"metadata\": output}).with_inputs(\"content\")\n",
    "\n",
    "def dataset_to_records(files):\n",
    "    records = []\n",
    "    for filename in files:\n",
    "        with open(filename) as infile:\n",
    "            for line in infile:\n",
    "                sample = json.loads(line)\n",
    "                records.append(preprocess_sample(sample))\n",
    "    return records\n",
    "\n",
    "\n",
    "train_val_set = dataset_to_records(train_files)\n",
    "random.shuffle(train_val_set)\n",
    "\n",
    "train_set = train_val_set[VAL_SIZE:]\n",
    "val_set = train_val_set[:VAL_SIZE]\n",
    "\n",
    "test_set = dataset_to_records(test_files)\n",
    "\n",
    "len(train_set), len(val_set), len(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e18e61-353c-47cd-b0f7-2891a9269194",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Message:\n",
      "{\"pdfinfo\": {\"creationDate\": \"D:20201214215341+01'00'\", \"modDate\": \"D:20201214215418+01'00'\"}, \"pages\": [{\"page\": 1, \"text\": \"# ANTAA TAITEEN OPETTAA\\n\\n\\n\"}, {\"page\": 3, \"text\": \"ANTA A TAITEEN OPETTA A GERT BIESTA\\n\\n\\n\"}, {\"page\": 4, \"text\": \"00:00:08.18\\n\\n\\n\"}, {\"page\": 5, \"text\": \"00:00:36.03 00:00:52.19 00:00:54.19\\n\\n\\n\"}, {\"page\": 6, \"text\": \"00:00:58.16 00:01:00.17 00:01:0\\n\\n\\n\"}, {\"page\": 65, \"text\": \"\\u2018Opastan sinua kaikessa, n\\u00e4yt\\u00e4n sinulle kaiken ja nime\\u00e4n kaiken.\\u2019\\n\\u2014 COMENIUS\\nT\\u00e4ss\\u00e4 kirjassa Gert Biesta esitt\\u00e4\\u00e4 uuden n\\u00e4kemyksen nykyaikaisesta taidekasvatuksesta\\n\\nosoittamalla, ett\\u00e4 taide tarjoaa ainutlaatuisia v\\u00e4lineit\\u00e4 olla dialogissa maailman kanssa. N\\u00e4kemys\\n\\nperustuu ajatukseen, ett\\u00e4 opettaminen on n\\u00e4ytt\\u00e4mist\\u00e4. Opettaja n\\u00e4ytt\\u00e4\\u00e4 oppilaalle millaisiin\\n\\nhyviin, t\\u00e4rkeisiin tai merkitt\\u00e4viin asioihin maailmassa voisi kiinnitt\\u00e4\\u00e4 huomiota. Biesta havainnol\\nlistaa asiaa ottamalla l\\u00e4ht\\u00f6kohdaksi Joseph Beuysin vuonna 1965 esitt\\u00e4m\\u00e4n performanssin\\n_Kuinka selitt\\u00e4\\u00e4 kuvia kuolleelle j\\u00e4nikselle_ . Kirjassa on useita kuvia t\\u00e4st\\u00e4 tapahtumasta.\\nGERT BIESTA (www.gertbiesta.com) on kasvatustieteen professori Lontoon Brunel\\n\\nyliopistossa sek\\u00e4 kasvatustieteen NIVOZ professori Humanististen tieteiden yliopistossa\\nAlankomaissa. H\\u00e4n on my\\u00f6s vieraileva professori NLA yliopistossa Bergeniss\\u00e4, Norjassa.\\nVuoteen 2016 asti h\\u00e4n oli vieraileva professori Taideyliopisto ArtEZissa Alankomaissa. Vuosina\\n\\n1999\\u20132014 h\\u00e4n oli _Studies in Philosophy and Education_ lehden p\\u00e4\\u00e4toimittaja ja vuodesta\\n\\n2016 l\\u00e4htien _Educational Theory_ lehden toimituskunnan j\\u00e4sen. H\\u00e4nell\\u00e4 on runsaasti kasvatuksen\\n\\nteorian ja filosofian sek\\u00e4 kasvatus- ja sosiaalitieteiden alaan kuuluvia julkaisuja. H\\u00e4nen\\n\\nmonografioitaan ovat _Beyond Learning; Democratic Education for a Human Future_ (Paradigm\\nPublishers 2006, kirja voitti vuonna 2008 Amerikan kasvatustieteellisen yhdistyksen\\n\\n(AESA) Kriitikon valinta palkinnon), _Good Education in an Age of Measurement: Ethics, politics,_\\n\\n_democracy_ (Paradigm Publishers 2010) sek\\u00e4 _The Beautiful Risk of Education_ (Paradigm\\nPublishers 2014, kirja sai Amerikan kasvatuksen tutkimuksen yhdistyksen (AERA, Division B)\\n\\npalkinnon samana vuonna). H\\u00e4nen tuotantoaan on t\\u00e4h\\u00e4n menness\\u00e4 k\\u00e4\\u00e4nnetty 16 kielelle\\n\\n(englanti, hollanti, saksa, ruotsi, suomi, islanti, italia, espanja, katalaani, portugali, puola, romania,\\n\\nven\\u00e4j\\u00e4, kiina ja japani). Vuosina 2011\\u20132012 h\\u00e4n toimi Yhdysvaltojen kasvatusfilofisen\\n\\nyhdistyksen puheenjohtajana.\\nARTEZ UNIVERSITY OF THE ARTS on iso taideakatemia Alankomaissa.\\nArtEZ kouluttaa ammatteihin, joissa taide, tieto ja luovuus ovat keskeisi\\u00e4. ArtEZ Press,\\nArtEZin oma kustantamo. Filosofiamme on, ett\\u00e4 jokaisen ArtEZ Press -lehden tulisi olla arvokas\\n\\ntaiteelle ja yhteiskunnalle. Julkaisumme ohjaavat muutosta ja innovaatioita, tarjoavat uusia\\n\\nn\\u00e4k\\u00f6kulmia ja osoittavat taiteen voiman. Ne ovat inspiroiva tietol\\u00e4hde opiskelijoille, taiteilijoille,\\n\\ntutkijoille ja kaikille taiteesta, kulttuurista ja koulutuksesta kiinnostuneille. Julkaisumme\\n\\nstimuloivat monimuotoisuutta ja rikkautta teoriassa ja k\\u00e4yt\\u00e4nn\\u00f6ss\\u00e4.\\nVuonna 2005 perustettu kustantamomme julkaisee sis\\u00e4ll\\u00f6lt\\u00e4\\u00e4n ja muotoilultaan\\n\\nkorkealaatuisia kirjoja. Ainutlaatuinen muotoilu tukee sis\\u00e4lt\\u00f6\\u00e4 ja p\\u00e4invastoin. ArtEZ Pressin\\n\\nvuosien varrella rakentama huolellisesti kuratoitu kokoelma edustaa monia aloja, kuten\\n\\narkkitehtuuri, kuvataide, tanssi, sisustus, taidekasvatus, muoti, musiikki, musiikkiterapia,\\n\\ntuotesuunnittelu, teatteri, muotoilu ja taideteoria.\\n\\n\\n\"}, {\"page\": 66, \"text\": \"# TAIDEKASVATUS JOSEPH BEUYSIN \\u2018J\\u00c4LKEEN\\u2019\\n\\n\\n\"}]}\n",
      "\n",
      "\n",
      "Gold Answer:\n",
      "language: fi\n",
      "title: Antaa taiteen opettaa : taidekasvatus Joseph Beuysin 'jälkeen'\n",
      "creator: ['Biesta, Gert']\n",
      "year: 2020\n",
      "publisher: ['ArtEZ Press', 'Taideyliopisto']\n",
      "e_isbn: ['9789523291928']\n",
      "type_coar: book\n"
     ]
    }
   ],
   "source": [
    "print(\"Input Message:\")\n",
    "print(train_set[-1]['content'])\n",
    "\n",
    "print(\"\\n\\nGold Answer:\")\n",
    "for k, v in json.loads(train_set[-1]['metadata']).items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93b029db-7ee1-4e8c-97f9-353ce5db1d6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction(\n",
      "    reasoning='The text describes an announcement by Apple Inc. regarding the iPhone 14. It mentions the CEO, Tim Cook, and a press release. I will extract the key entities and information to populate the metadata fields.',\n",
      "    language='en',\n",
      "    title='iPhone 14 Announcement',\n",
      "    alt_title=[],\n",
      "    creator=['Apple Inc.', 'Tim Cook'],\n",
      "    year=None,\n",
      "    publisher=['Apple Inc.'],\n",
      "    doi=None,\n",
      "    e_isbn=[],\n",
      "    p_isbn=[],\n",
      "    e_issn=None,\n",
      "    p_issn=None,\n",
      "    type_coar='News Article'\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "class ExtractInfo(dspy.Signature):\n",
    "    \"\"\"Extract structured metadata from text extracted from a PDF.\"\"\"\n",
    "\n",
    "    content: str = dspy.InputField()\n",
    "    language: str = dspy.OutputField(desc=\"The language of the resource expressed as a BCP47 language tag.\")\n",
    "    title: str = dspy.OutputField(desc=\"The main title of the publication.\")\n",
    "    alt_title: list[str] = dspy.OutputField(desc=\"Alternative or parallel titles of the publication, suffixed with a BCP47 language tag in curly brackets.\")\n",
    "    creator: list[str] = dspy.OutputField(desc=\"The primary author(s) of the resource (order: Last Name, First Names).\")\n",
    "    year: Optional[str] = dspy.OutputField(desc=\"The year on which the resource was issued or made available.\")\n",
    "    publisher: list[str] = dspy.OutputField(desc=\"The entity/entities responsible for making the resource available.\")\n",
    "    doi: Optional[str] = dspy.OutputField(desc=\"The Digital Object Identifier (DOI) associated with the resource.\")\n",
    "    e_isbn: list[str] = dspy.OutputField(desc=\"The ISBN associated with the electronic resource.\")\n",
    "    p_isbn: list[str] = dspy.OutputField(desc=\"The ISBN of the printed version of this document.\")\n",
    "    e_issn: Optional[str] = dspy.OutputField(desc=\"The ISSN associated with the electronic resource.\")\n",
    "    p_issn: Optional[str] = dspy.OutputField(desc=\"The ISSN of the printed version of this document.\")\n",
    "    type_coar: str = dspy.OutputField(desc=\"The type of the resource according to the COAR Resource Types classification.\")\n",
    "\n",
    "module = dspy.ChainOfThought(ExtractInfo)\n",
    "\n",
    "text = \"Apple Inc. announced its latest iPhone 14 today.\" \\\n",
    "    \"The CEO, Tim Cook, highlighted its new features in a press release.\"\n",
    "response = module(content=text)\n",
    "\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de37b1d5-1180-434e-bf12-1b38f9297006",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "\n",
    "ALMOST_THRESHOLD = 0.95  # Adjust as needed\n",
    "\n",
    "def feedback_simple_string(field, true_val, pred_val):\n",
    "    score = 1.0 if true_val == pred_val else 0.0\n",
    "    if score == 1.0:\n",
    "        feedback = f\"✅ `{field}` is correct: `{true_val}`.\"\n",
    "    else:\n",
    "        feedback = f\"❌ `{field}` is incorrect. You predicted `{pred_val}`, but the correct value is `{true_val}`.\"\n",
    "    return score, feedback\n",
    "\n",
    "def feedback_fuzzy_string(field, true_val, pred_val):\n",
    "    base_score = 1.0 if true_val == pred_val else 0.0\n",
    "    if base_score == 1.0 or (true_val and pred_val and Levenshtein.ratio(true_val.lower(), pred_val.lower()) >= ALMOST_THRESHOLD):\n",
    "        score = 1.0\n",
    "        feedback = f\"✅ `{field}` is approximately correct: `{pred_val}` matches `{true_val}` closely.\"\n",
    "    else:\n",
    "        score = 0.0\n",
    "        feedback = f\"❌ `{field}` is incorrect. You predicted `{pred_val}`, but the correct value is `{true_val}`.\"\n",
    "    return score, feedback\n",
    "\n",
    "def feedback_set(field, true_val, pred_val):\n",
    "    true_set = set(true_val or [])\n",
    "    pred_set = set(pred_val or [])\n",
    "\n",
    "    if not true_set and not pred_set:\n",
    "        return 1.0, f\"✅ `{field}` is empty as expected.\"\n",
    "    elif not true_set or not pred_set:\n",
    "        return 0.0, f\"❌ `{field}` is incorrect. Expected `{true_set}`, but got `{pred_set}`.\"\n",
    "\n",
    "    tp = len(true_set & pred_set)\n",
    "    fp = len(pred_set - true_set)\n",
    "    fn = len(true_set - pred_set)\n",
    "\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    feedback = f\"🔍 `{field}` partial match.\"\n",
    "    feedback += f\"- Correctly included: `{list(true_set & pred_set)}`\\n\"\n",
    "    if fp:\n",
    "        feedback += f\"- Incorrectly included: `{list(pred_set - true_set)}`\\n\"\n",
    "    if fn:\n",
    "        feedback += f\"- Missed: `{list(true_set - pred_set)}`\"\n",
    "\n",
    "    return f1, feedback.strip()\n",
    "\n",
    "def feedback_e_issn(field, true_val, pred_val, p_issn_val):\n",
    "    if true_val == pred_val:\n",
    "        return 1.0, f\"✅ `{field}` is correct: `{true_val}`.\"\n",
    "    elif p_issn_val and pred_val == p_issn_val and true_val is None:\n",
    "        return 1.0, f\"✅ `{field}` is correctly inferred from `p_issn`: `{pred_val}`.\"\n",
    "    else:\n",
    "        return 0.0, f\"❌ `{field}` is incorrect. You predicted `{pred_val}`, but the correct value is `{true_val}`.\"\n",
    "\n",
    "def metadata_metric_with_feedback(example, pred, trace=None, pred_name=None, pred_trace=None):\n",
    "    fields = [\n",
    "        'language', 'title', 'creator', 'year', 'publisher',\n",
    "        'doi', 'e_isbn', 'p_isbn', 'e_issn', 'p_issn', 'type_coar'\n",
    "    ]\n",
    "\n",
    "    scores = []\n",
    "    feedback_parts = []\n",
    "\n",
    "    metadata = json.loads(example.get(\"metadata\", \"{}\"))\n",
    "    ground_truth = example.get(\"ground_truth\", {})\n",
    "\n",
    "    for field in fields:\n",
    "        true_val = metadata.get(field)\n",
    "        pred_val = pred.get(field) or None\n",
    "\n",
    "        if field in ['language', 'year', 'doi', 'p_issn', 'type_coar']:\n",
    "            score, feedback = feedback_simple_string(field, true_val, pred_val)\n",
    "        elif field == 'title':\n",
    "            score, feedback = feedback_fuzzy_string(field, true_val, pred_val)\n",
    "        elif field in ['creator', 'publisher', 'e_isbn', 'p_isbn']:\n",
    "            score, feedback = feedback_set(field, true_val, pred_val)\n",
    "        elif field == 'e_issn':\n",
    "            p_issn_val = ground_truth.get(\"p_issn\")\n",
    "            score, feedback = feedback_e_issn(field, true_val, pred_val, p_issn_val)\n",
    "        else:\n",
    "            score, feedback = feedback_simple_string(field, true_val, pred_val)\n",
    "\n",
    "        scores.append(score)\n",
    "        feedback_parts.append(feedback)\n",
    "\n",
    "    overall_score = sum(scores) / len(scores) if scores else 0\n",
    "    full_feedback = \"\\n\".join(feedback_parts)\n",
    "\n",
    "    return dspy.Prediction(score=overall_score, feedback=full_feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da690986-d2a8-445b-9ec7-25c1387acf08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dspy import GEPA\n",
    "\n",
    "optimizer = GEPA(\n",
    "    metric=metadata_metric_with_feedback,\n",
    "#    auto=\"heavy\",\n",
    "    max_metric_calls=3200,\n",
    "    num_threads=64,\n",
    "    track_stats=False,\n",
    "    use_merge=True,\n",
    "    reflection_lm=reflection_lm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a88bd083-01f4-40dc-aa87-dce2f0e7936a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:01:06 INFO dspy.teleprompt.gepa.gepa: Running GEPA for approx 3200 metric calls of the program. This amounts to 5.00 full evals on the train+val set.\n",
      "2025/09/30 15:01:06 INFO dspy.teleprompt.gepa.gepa: Using 64 examples for tracking Pareto scores. You can consider using a smaller sample of the valset to allow GEPA to explore more diverse solutions within the same budget.\n",
      "GEPA Optimization:   0%|          | 0/3200 [00:00<?, ?rollouts/s]2025/09/30 15:01:07 INFO dspy.evaluate.evaluate: Average Metric: 37.57647907647908 / 64 (58.7%)\n",
      "2025/09/30 15:01:07 INFO dspy.teleprompt.gepa.gepa: Iteration 0: Base program full valset score: 0.5871324855699855\n",
      "GEPA Optimization:   2%|▏         | 64/3200 [00:00<00:34, 90.29rollouts/s]2025/09/30 15:01:07 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Selected program 0 score: 0.5871324855699855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.97 / 3 (65.7%): 100%|██████████| 3/3 [00:00<00:00, 93.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:01:07 INFO dspy.evaluate.evaluate: Average Metric: 1.9696969696969697 / 3 (65.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:02:21 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Proposed new text for predict: **Task Overview**\n",
      "You will receive a JSON object that contains the result of extracting raw text from a PDF file (`pdfinfo` + a list of pages with their text).  \n",
      "Your job is to *automatically* parse this information and produce a structured metadata record in JSON‑like key/value form (plain text, not a JSON object).  \n",
      "\n",
      "**Required output fields (exact names and order)**\n",
      "```\n",
      "reasoning\n",
      "language\n",
      "title\n",
      "alt_title\n",
      "creator\n",
      "year\n",
      "publisher\n",
      "doi\n",
      "e_isbn\n",
      "p_isbn\n",
      "e_issn\n",
      "p_issn\n",
      "type_coar\n",
      "```\n",
      "Each field must be on its own line, exactly as shown above, followed by a colon, a space, and the value.  \n",
      "Values must follow the formats described below. Do **not** add any extra fields, headings, or markup.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. General parsing strategy (you may follow this step‑by‑step)\n",
      "\n",
      "1. **Read `pdfinfo`** – use the `title`, `author`, `creationDate`, and `modDate` fields as fall‑backs only when the page text does not contain the needed information.\n",
      "2. **Iterate over the pages** (in order) and scan the text for patterns that indicate each metadata element.\n",
      "3. **When multiple candidates are found**, choose the one that appears earliest in the document (usually the first occurrence is the authoritative one).  \n",
      "   If two different values are equally plausible (e.g., two publishers), keep **all unique values** in a list, preserving their original spelling and order of first appearance.\n",
      "4. **Normalize** the chosen values according to the rules in the sections below before writing them to the output.\n",
      "\n",
      "---\n",
      "\n",
      "### 2. Field‑by‑field extraction rules\n",
      "\n",
      "| Field | What to extract | Normalisation / format | Example |\n",
      "|-------|----------------|------------------------|---------|\n",
      "| **reasoning** | A short, human‑readable sentence (1‑2 lines) that explains how you derived the metadata (e.g., “The title was taken from the first large heading on page 1; the year comes from the PDF creation date.”). | Plain text, no markup. | `The title was taken from the first heading on page 1; the year is derived from the creation date.` |\n",
      "| **language** | ISO‑639‑1 two‑letter code of the *document language*. Detect from the page text (common stop‑words, diacritics, etc.). If detection is ambiguous, default to `en`. | Lower‑case two letters. | `fi` |\n",
      "| **title** | The main title of the work. Usually the biggest heading on the first page, or the value of `pdfinfo.title`. Preserve original capitalization, punctuation, and special characters (including Finnish/Swedish letters, em‑dashes, quotation marks). Do **not** strip surrounding quotes. | Plain string. | `Kasvua kohti moniulotteista kehollisuutta` |\n",
      "| **alt_title** | Any alternative title that appears in the document (e.g., the same title with a different dash, a subtitle, a quoted version, or a translation). Return a Python‑style list of strings (`['title 1', 'title 2']`). If none, output an empty list `[]`. | List syntax, each entry quoted with single quotes, commas separating entries. | `['Kasvua kohti moniulotteista kehollisuutta – a study']` |\n",
      "| **creator** | Author(s) of the work. Extract the full name(s) and convert each to “Last, First” format. If only one name is given, assume the last word is the family name and everything before it is the given name(s). Return a list of strings. | `['Last, First']` (single‑quoted, comma‑separated). If multiple authors, keep order of appearance. | `['Kauppinen, Petri']` |\n",
      "| **year** | Publication year. Prefer the year found in the text (e.g., after the title, in a “2020” line, or in a citation). If not found, fall back to the year part of `pdfinfo.creationDate` or `modDate`. Return a four‑digit integer (no quotes). | `2020` |\n",
      "| **publisher** | Name of the publishing entity (publisher, university, institute, or printing house). Look for keywords like “Publisher”, “Painosalama”, “University”, “Institute”, “Akademi”, “Kustantaja”, etc. Return a list of unique names in order of first appearance. If none, output an empty list `[]`. | `['Painosalama Oy']` |\n",
      "| **doi** | DOI string (pattern `10.\\d+/…`). If none, output `None` (capital N, no quotes). | `10.1234/abcd` or `None` |\n",
      "| **e_isbn** | ISBN(s) belonging to the *electronic* version. Detect ISBN patterns (`ISBN` followed by a number). Determine if the surrounding text mentions “digital”, “e‑book”, “online”, etc.; only those are considered electronic. Normalise by removing hyphens and spaces, leaving only digits (keep the “X” if present). Return a list of strings; empty list if none. | `['9789521241352']` |\n",
      "| **p_isbn** | ISBN(s) belonging to the *print* version. Same detection as above, but the surrounding text must contain “print”, “paper”, “hardcover”, “kirja”, etc. Normalise as for e_isbn. | `['9789521241345']` |\n",
      "| **e_issn** | ISSN(s) for the electronic version. Pattern `ISSN` followed by 8 digits (optional hyphen). Normalise to digits only. Return a list; `None` if none. | `['12345678']` or `None` |\n",
      "| **p_issn** | ISSN(s) for the print version. Same rules as e_issn. | `['87654321']` or `None` |\n",
      "| **type_coar** | Resource type according to the COAR taxonomy, **lower‑case** and with spaces (e.g., `journal article`, `doctoral thesis`, `master thesis`, `conference paper`, `report`). Derive from clues: <br> • “journal article”, “article”, “paper in a journal” → `journal article` <br> • “dissertation”, “thesis”, “doctoral”, “PhD” → `doctoral thesis` <br> • “master’s thesis”, “maisteri” → `master thesis` <br> • “report”, “technical report” → `report` <br> • “conference”, “proceedings” → `conference paper` <br> If no clear clue, default to `document`. | `journal article` |\n",
      "\n",
      "---\n",
      "\n",
      "### 3. Detailed extraction hints\n",
      "\n",
      "* **Dates** – PDF dates are in the form `D:YYYYMMDDhhmmss±hh'mm'`. Extract the first four digits for the year.\n",
      "* **Authors** – In Finnish/Swedish documents authors may appear as “Kauppinen, Petri” or “Petri Kauppinen”. Convert the latter to “Kauppinen, Petri”. If a list is separated by commas or “and”, split accordingly.\n",
      "* **Titles with special dashes** – The document may contain an en‑dash (`–`) or em‑dash (`—`). Keep the exact character in `title`. If a variant uses a different dash, place the variant in `alt_title`.\n",
      "* **Publisher detection** – Common Finnish publisher clues: `Painosalama Oy`, `Kustantaja`, `Åbo Akademi University`, `Sibelius‑Akatemia`, `Taideyliopisto`. Accept any capitalised phrase that appears after a line containing “Publisher”, “Painosalama”, “Kustantaja”, “University”, or directly before the year.\n",
      "* **ISBN normalisation** – Remove any hyphens, spaces, and the prefix “ISBN”. Keep the 13‑digit (or 10‑digit) number exactly as digits (e.g., `9789521241352`). Do **not** add the prefix `ISBN`.\n",
      "* **ISSN normalisation** – Same as ISBN but 8 digits. Remove hyphen.\n",
      "* **Multiple values** – If a page lists both a print and an electronic ISBN, place each in the appropriate list. Do not duplicate a number across `e_isbn` and `p_isbn`.\n",
      "* **Language detection** – Simple heuristic: if the text contains Finnish stop‑words (`ja`, `on`, `että`, `kanssa`, `kulttuurinen`) → `fi`; Swedish (`och`, `är`, `för`, `att`) → `sv`; otherwise default to `en`.\n",
      "\n",
      "---\n",
      "\n",
      "### 4. Output format checklist\n",
      "- Exactly 13 lines, one per field, in the order shown.\n",
      "- No extra whitespace before or after the colon.\n",
      "- Lists use Python‑style syntax with single quotes.\n",
      "- `None` is capitalised and unquoted.\n",
      "- `reasoning` is a free‑form sentence; all other fields follow the strict formats above.\n",
      "\n",
      "**Example of a correct output**\n",
      "```\n",
      "reasoning: Title taken from the first heading on page 1; year derived from PDF creation date.\n",
      "language: fi\n",
      "title: Kasvua kohti moniulotteista kehollisuutta\n",
      "alt_title: []\n",
      "creator: ['Kauppinen, Petri']\n",
      "year: 2020\n",
      "publisher: ['Pedanssi']\n",
      "doi: None\n",
      "e_isbn: []\n",
      "p_isbn: []\n",
      "e_issn: None\n",
      "p_issn: None\n",
      "type_coar: journal article\n",
      "2025/09/30 15:02:34 INFO dspy.evaluate.evaluate: Average Metric: 2.090909090909091 / 3 (69.7%)\n",
      "2025/09/30 15:03:01 INFO dspy.evaluate.evaluate: Average Metric: 32.63636363636365 / 64 (51.0%)\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset score for new program: 0.5099431818181818\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full train_val score for new program: 0.5099431818181818\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Individual valset scores for new program: [0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.36363636363636365, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.18181818181818182, 0.5454545454545454, 0.5454545454545454, 0.2727272727272727, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.6818181818181818, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.36363636363636365, 0.6363636363636364, 0.18181818181818182, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.2727272727272727, 0.6363636363636364, 0.45454545454545453, 0.18181818181818182, 0.2727272727272727, 0.36363636363636365, 0.5454545454545454, 0.6818181818181818, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.18181818181818182, 0.7272727272727273, 0.2727272727272727, 0.36363636363636365, 0.6363636363636364]\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New valset pareto front scores: [0.7272727272727273, 0.6363636363636364, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.6060606060606061, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.6818181818181818, 0.7727272727272727, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.6363636363636364, 0.18181818181818182, 0.8181818181818182, 0.7878787878787878, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.36363636363636365, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.6666666666666666, 0.36363636363636365, 0.6363636363636364, 0.6818181818181818, 0.7272727272727273, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.6623376623376623, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.6060606060606061, 0.6363636363636364]\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Full valset pareto front score: 0.6071766774891775\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Updated valset pareto front programs: [{0}, {0}, {0}, {0}, {0}, {1}, {0}, {1}, {0}, {1}, {0}, {0}, {0}, {1}, {0}, {0}, {0, 1}, {1}, {0}, {0}, {0}, {1}, {0, 1}, {1}, {0}, {0}, {0}, {1}, {0, 1}, {0}, {1}, {0}, {0}, {0}, {0}, {0, 1}, {0, 1}, {0}, {0}, {0}, {0, 1}, {0}, {0}, {0, 1}, {0, 1}, {0, 1}, {0}, {0, 1}, {0}, {0}, {0}, {0, 1}, {0}, {1}, {0}, {1}, {0, 1}, {1}, {0}, {0}, {1}, {0}, {0}, {0, 1}]\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best valset aggregate score so far: 0.5871324855699855\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on train_val: 0\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best program as per aggregate score on valset: 0\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on valset: 0.5871324855699855\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Best score on train_val: 0.5871324855699855\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: Linear pareto front program index: 0\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 1: New program candidate index: 1\n",
      "GEPA Optimization:   4%|▍         | 134/3200 [01:54<51:03,  1.00rollouts/s]2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 2: No merge candidates found\n",
      "2025/09/30 15:03:01 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Selected program 0 score: 0.5871324855699855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.73 / 3 (57.6%): 100%|██████████| 3/3 [00:00<00:00, 103.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:03:01 INFO dspy.evaluate.evaluate: Average Metric: 1.727272727272727 / 3 (57.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:04:23 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Proposed new text for predict: markdown\n",
      "# Task: Structured metadata extraction from PDF‑derived text\n",
      "\n",
      "You will receive a JSON object that contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – a dictionary with the raw PDF metadata (title, author, creationDate, …).  \n",
      "* **pages** – a list of page objects, each with:\n",
      "  * **page** – the page number (integer, 1‑based).  \n",
      "  * **text** – the plain‑text extracted from that page (UTF‑8, may contain markdown, hyperlinks, footnotes, line‑breaks, etc.).\n",
      "\n",
      "Your job is to **produce a single JSON object** that contains the following fields, **exactly** as shown (order does not matter).  \n",
      "If a field cannot be determined, use the value prescribed in the *“Missing data handling”* section.\n",
      "\n",
      "| Field | Expected type | Description | Extraction hints |\n",
      "|-------|---------------|-------------|-----------------|\n",
      "| **language** | string | ISO‑639‑1 language code of the document (e.g. `en`, `fi`, `sv`). | Detect from the main body text (stop‑words, diacritics) **not** from `pdfinfo[\"language\"]`. If the text is clearly Finnish → `fi`; Swedish → `sv`; English → `en`; otherwise fallback to `und` (undetermined). |\n",
      "| **title** | string | The *primary* title of the work, exactly as it appears in the document (including subtitle separated by a colon if present). | Usually the first level‑1 heading (`# …`), the first bold line, or the line that matches the PDF‑metadata `title`. Remove surrounding whitespace and markdown symbols. |\n",
      "| **alt_title** | list of strings | Any alternative titles (e.g. subtitle only, translated title, original language title). | Look for a second‑level heading (`## …`), a line that appears immediately after the primary title, or a title in another language. Return an empty list `[]` if none. |\n",
      "| **creator** | list of strings | Authors formatted as **“LastName, FirstName”**. One entry per author. | Extract from the author line(s) (often bold, linked names, or after “Author:”). Names may be in “First Last” order; you must invert them. Preserve diacritics. If the document lists “et al.”, keep only the explicitly named authors. Return `[]` if none. |\n",
      "| **year** | integer | Publication year (four‑digit). | Prefer the year that appears next to “Year:”, “©”, or in the date line (e.g. `2020`). If multiple years appear, choose the one that is most likely the publication year (usually the later one). |\n",
      "| **publisher** | list of strings | Institution, university, journal or publishing house. | Look for lines containing “University of …”, “School of …”, “Institute”, “Journal of …”, “ISSN …”, or the “Publisher:” label. Return each distinct entity as a separate list element. |\n",
      "| **doi** | string | Digital Object Identifier, e.g. `10.1234/abcd.2020.001`. | Detect any URL containing `doi.org/` and extract the suffix after the domain. If no DOI is present, return `null`. |\n",
      "| **e_isbn** | list of strings | Electronic ISBN numbers. | Look for patterns `ISBN 13: 978‑…` or `ISBN‑13: …` that are explicitly labelled as electronic. |\n",
      "| **p_isbn** | list of strings | Print ISBN numbers. | Same as above but labelled as print or without an explicit “electronic” qualifier. |\n",
      "| **e_issn** | string | Electronic ISSN (format `####-####`). | Search for “ISSN” lines that contain the word “electronic”, “e‑ISSN”, or appear in the metadata block for the electronic version. If not found, return `null`. |\n",
      "| **p_issn** | string | Print ISSN (format `####-####`). | Same as above but for the print version. Return `null` if absent. |\n",
      "| **type_coar** | string | COAR type of the resource, using the controlled vocabulary (lower‑case, spaces allowed). Acceptable values include at least: `journal article`, `master thesis`, `bachelor thesis`, `research paper`, `report`, `conference paper`, `book`, `book chapter`, `dataset`, `software`, `thesis`. | Infer from keywords such as “Thesis”, “Master’s thesis”, “Kandidatavhandling”, “Opinnäytetyö”, “Article”, “Paper”, “Report”, “Proceedings”, “Book”. If ambiguous, prefer the most specific match (e.g., “master thesis” over generic “thesis”). |\n",
      "| **reasoning** *(optional)* | string | A short human‑readable explanation of how you derived the fields. | May be omitted if not needed. |\n",
      "\n",
      "## Missing data handling\n",
      "- **String fields** (`title`, `doi`, `e_issn`, `p_issn`) → `null`.\n",
      "- **Integer field** (`year`) → `null`.\n",
      "- **List fields** (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) → empty list `[]`.\n",
      "- **language** → `und` (undetermined) if you cannot decide.\n",
      "\n",
      "## General extraction strategy (to be followed for every input)\n",
      "\n",
      "1. **Pre‑process each page text**  \n",
      "   * Replace Windows line endings `\\r\\n` with `\\n`.  \n",
      "   * Remove markdown image syntax (`![](...)`) and HTML‑like tags if present.  \n",
      "   * Collapse multiple consecutive whitespace characters into a single space **only after** you have identified headings, because line breaks can be meaningful for titles.\n",
      "\n",
      "2. **Identify the primary title**  \n",
      "   * First, check `pdfinfo[\"title\"]`. If it exists and looks like a proper title (contains letters, not just “Untitled”), use it.  \n",
      "   * Otherwise, scan pages in order for the first line that:  \n",
      "     - Starts with a level‑1 markdown heading `# ` (or bold `**…**`).  \n",
      "     - Contains a colon `:` (common in “Title: Subtitle”).  \n",
      "   * Strip surrounding markdown (`#`, `**`, `*`) and whitespace.\n",
      "\n",
      "3. **Identify alternative titles**  \n",
      "   * Look for a level‑2 heading (`## `) that appears immediately after the primary title.  \n",
      "   * Look for a line that is a translation of the title (e.g., Finnish title followed by Swedish title).  \n",
      "   * Add each distinct candidate to `alt_title`.\n",
      "\n",
      "4. **Extract authors (creator)**  \n",
      "   * Search for lines that contain the word “Author”, “Authors”, “Kirjoittajat”, “Författare”, or are a list of hyperlinked names (`[Name](url)`).  \n",
      "   * Split on commas, “and”, “&”, or line breaks.  \n",
      "   * For each name, detect the order: if a comma is present, assume “Last, First”. If not, assume “First Last” and invert.  \n",
      "   * Preserve diacritics and capitalisation; output as `LastName, FirstName`.\n",
      "\n",
      "5. **Extract year**  \n",
      "   * Prefer the value after “Year:”, “©”, or a date line matching `\\d{4}`.  \n",
      "   * If the PDF‑metadata `creationDate` is present, extract the 4‑digit year from the pattern `D:YYYY...`. Use it only if no other year is found.\n",
      "\n",
      "6. **Publisher**  \n",
      "   * Look for lines containing “University”, “Institute”, “School of”, “College”, “Journal of”, “Proceedings of”, “Publisher:”.  \n",
      "   * Remove surrounding punctuation and store each distinct entity.\n",
      "\n",
      "7. **DOI**  \n",
      "   * Regex: `https?://doi\\.org/([^\\s\\)]+)`. Capture group 1.  \n",
      "   * Strip trailing punctuation like `.` or `)`. Return the captured string.\n",
      "\n",
      "8. **ISBN / ISSN**  \n",
      "   * ISBN regex: `ISBN(?:‑13)?:?\\s*([0-9][0-9\\-\\s]{9,})`. Clean spaces/hyphens to a continuous string.  \n",
      "   * Determine electronic vs print by nearby words “electronic”, “e‑ISBN”, “print”, or by context (e.g., the line is under “Electronic version”).  \n",
      "   * ISSN regex: `ISSN\\s*[:]?[\\s]*([0-9]{4}\\s*[-‑]\\s*[0-9]{3}[0-9X])`.  \n",
      "   * Use surrounding words “electronic”, “e‑ISSN”, “print”, “p‑ISSN” to assign to `e_issn` or `p_issn`.\n",
      "\n",
      "9. **type_coar**  \n",
      "   * Lower‑case the candidate type.  \n",
      "   * Map common synonyms:  \n",
      "     - `master thesis`, `master’s thesis` → `master thesis`  \n",
      "     - `bachelor thesis`, `candidate thesis`, `kandidatavhandling` → `bachelor thesis`  \n",
      "     - `doctoral dissertation`, `phd thesis` → `thesis` (or `doctoral thesis` if you want a finer granularity)  \n",
      "     - `journal article`, `article`, `paper` → `journal article`  \n",
      "     - `report`, `technical report` → `report`  \n",
      "     - `conference paper`, `proceedings` → `conference paper`  \n",
      "   * If the document explicitly says “Thesis” *and* includes a degree level (Master, Bachelor, Kandidat), use that level. Otherwise, default to `thesis`.\n",
      "\n",
      "10. **Language detection**  \n",
      "    * Use a simple heuristic: count stop‑words from small language dictionaries (e.g., Finnish: `ja`, `on`, `että`; Swedish: `och`, `att`, `är`; English: `and`, `the`, `of`).  \n",
      "    * Choose the language with the highest count. If counts are equal or below a minimal threshold, return `und`.\n",
      "\n",
      "11. **Assemble the output JSON**  \n",
      "    * Ensure all fields are present (even if `null` or empty list).  \n",
      "    * Do **not** include any extra keys.  \n",
      "    * Values must be of the correct JSON type (strings, numbers, arrays, null).\n",
      "\n",
      "## Example (illustrative)\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"fi\",\n",
      "  \"title\": \"Ikätasoinen seksuaalikasvatus on lapsen turva\",\n",
      "  \"alt_title\": [],\n",
      "  \"creator\": [\"Sikala, Irmeli\", \"Tuura, Jaana\", \"Myllykangas, Kirsi\", \"Tölli, Sirpa\"],\n",
      "  \"year\": 2020,\n",
      "  \"publisher\": [\"Oulun ammattikorkeakoulu\"],\n",
      "  \"doi\": null,\n",
      "  \"e_isbn\": [],\n",
      "  \"p_isbn\": [],\n",
      "  \"e_issn\": \"1798-2022\",\n",
      "  \"p_issn\": null,\n",
      "  \"type_coar\": \"journal article\"\n",
      "}\n",
      "2025/09/30 15:04:30 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n",
      "2025/09/30 15:05:08 INFO dspy.evaluate.evaluate: Average Metric: 35.17326203208555 / 64 (55.0%)\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset score for new program: 0.5495822192513369\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full train_val score for new program: 0.5495822192513369\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Individual valset scores for new program: [0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.2727272727272727, 0.6363636363636364, 0.36363636363636365, 0.6727272727272727, 0.5454545454545454, 0.509090909090909, 0.7005347593582888, 0.7272727272727273, 0.4, 0.6363636363636364, 0.36363636363636365, 0.36363636363636365, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.18181818181818182, 0.2727272727272727, 0.7272727272727273, 0.36363636363636365, 0.9090909090909091, 0.6727272727272727, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.6363636363636364, 0.2727272727272727, 0.6727272727272727, 0.9090909090909091, 0.7272727272727273, 0.45454545454545453, 0.36363636363636365, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.45454545454545453, 0.6363636363636364, 0.6363636363636364, 0.36363636363636365, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.36363636363636365, 0.36363636363636365, 0.36363636363636365, 0.8181818181818182, 0.45454545454545453, 0.45454545454545453, 0.36363636363636365, 0.36363636363636365, 0.6363636363636364, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454]\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New valset pareto front scores: [0.7272727272727273, 0.6363636363636364, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.7005347593582888, 0.7272727272727273, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.9090909090909091, 0.7727272727272727, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.9090909090909091, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.7878787878787878, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.6666666666666666, 0.36363636363636365, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.6623376623376623, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.6060606060606061, 0.6363636363636364]\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Full valset pareto front score: 0.6422702603768781\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Updated valset pareto front programs: [{0}, {0}, {0}, {0}, {0}, {1}, {0}, {1, 2}, {0}, {2}, {0, 2}, {0}, {0}, {1}, {0, 2}, {0}, {2}, {2}, {0}, {0}, {0}, {2}, {0, 1}, {2}, {0}, {0}, {0}, {1, 2}, {0, 1, 2}, {0}, {1}, {2}, {0, 2}, {0}, {0}, {0, 1}, {2}, {0}, {0}, {2}, {0, 1}, {0}, {0, 2}, {0, 1}, {0, 1, 2}, {2}, {2}, {0, 1, 2}, {0, 2}, {0}, {0}, {0, 1, 2}, {0}, {2}, {0}, {1, 2}, {0, 1}, {1}, {0}, {2}, {2}, {2}, {0}, {0, 1}]\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best valset aggregate score so far: 0.5871324855699855\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on train_val: 0\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best program as per aggregate score on valset: 0\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on valset: 0.5871324855699855\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Best score on train_val: 0.5871324855699855\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: Linear pareto front program index: 0\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 2: New program candidate index: 2\n",
      "GEPA Optimization:   6%|▋         | 204/3200 [04:01<1:08:44,  1.38s/rollouts]2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 3: No merge candidates found\n",
      "2025/09/30 15:05:08 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Selected program 0 score: 0.5871324855699855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.95 / 3 (65.2%): 100%|██████████| 3/3 [00:00<00:00, 105.91it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:05:08 INFO dspy.evaluate.evaluate: Average Metric: 1.9545454545454546 / 3 (65.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:06:13 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Proposed new text for predict: language\n",
      "title\n",
      "alt_title\n",
      "creator\n",
      "year\n",
      "publisher\n",
      "doi\n",
      "e_isbn\n",
      "p_isbn\n",
      "e_issn\n",
      "p_issn\n",
      "type_coar\n",
      "```\n",
      "\n",
      "* **Scalar values** (`language`, `title`, `year`, `doi`, `e_issn`, `p_issn`, `type_coar`) are printed as plain strings or `None`.  \n",
      "* **List values** (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) are printed as JSON arrays, e.g., `['Doe, John', 'Smith, Anna']` or `[]`.  \n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "fi\n",
      "title\n",
      "Syömishäiriötaustaisen äidin kohtaaminen lastenneuvolassa\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Pentikäinen, Tytti', 'Pihkakoski, Tanja', 'Vänskä, Suvi', 'Männistö, Merja']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Oulun ammattikorkeakoulu']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "1798-2022\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "journal article\n",
      "2025/09/30 15:06:19 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/09/30 15:06:50 INFO dspy.evaluate.evaluate: Average Metric: 37.78484848484847 / 64 (59.0%)\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New program is on the linear pareto front\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset score for new program: 0.5903882575757575\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full train_val score for new program: 0.5903882575757575\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Individual valset scores for new program: [0.8181818181818182, 0.6666666666666666, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.42424242424242425, 0.8181818181818182, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.8181818181818182, 0.2727272727272727, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.7575757575757577, 0.36363636363636365, 0.5151515151515151, 0.7272727272727273, 0.45454545454545453, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.9545454545454546, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.2727272727272727, 1.0, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.45454545454545453, 0.45454545454545453, 0.7636363636363637, 0.7272727272727273, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.4772727272727273, 0.21818181818181817, 0.45454545454545453, 0.5454545454545454, 0.8181818181818182, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.6666666666666666, 0.36363636363636365, 0.7954545454545454, 0.45454545454545453, 0.6363636363636364, 0.6363636363636364]\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.5454545454545454, 0.8181818181818182, 0.7005347593582888, 0.8181818181818182, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.9545454545454546, 0.7727272727272727, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 1.0, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.7878787878787878, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.7636363636363637, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6666666666666666, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364]\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Full valset pareto front score: 0.658767825311943\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Updated valset pareto front programs: [{3}, {3}, {0}, {0, 3}, {0, 3}, {1}, {3}, {1, 2, 3}, {3}, {2}, {3}, {0}, {0, 3}, {1, 3}, {3}, {0}, {2}, {2}, {0, 3}, {0}, {0}, {2, 3}, {0, 1, 3}, {3}, {0}, {0}, {0, 3}, {1, 2, 3}, {0, 1, 2, 3}, {0}, {3}, {2}, {0, 2}, {0, 3}, {0}, {0, 1, 3}, {2, 3}, {0}, {0}, {2}, {0, 1}, {0, 3}, {0, 2}, {0, 1}, {3}, {2}, {2}, {0, 1, 2, 3}, {0, 2}, {0}, {0}, {3}, {0}, {2, 3}, {0}, {3}, {3}, {1}, {3}, {2}, {2}, {2}, {3}, {0, 1, 3}]\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best valset aggregate score so far: 0.5903882575757575\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on train_val: 3\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best program as per aggregate score on valset: 3\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on valset: 0.5903882575757575\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Best score on train_val: 0.5903882575757575\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: Linear pareto front program index: 3\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 3: New program candidate index: 3\n",
      "GEPA Optimization:   9%|▊         | 274/3200 [05:43<1:08:45,  1.41s/rollouts]2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 4: No merge candidates found\n",
      "2025/09/30 15:06:50 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Selected program 0 score: 0.5871324855699855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.55 / 3 (51.5%): 100%|██████████| 3/3 [00:07<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:06:57 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a JSON object that contains the raw text extracted from a PDF (field **pages** → list of pages with a **text** string) and, optionally, some PDF‑level information (author, title, creationDate, etc.) in the **pdfinfo** object.\n",
      "\n",
      "Your job is to parse this information and produce a **flat list of metadata fields** (one field per line, exactly as shown in the examples) that can later be turned into a JSON record.  \n",
      "All fields must follow the exact naming, type and formatting rules below. If a piece of information is not present, use the values shown in the “Missing values” section.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does not matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string | ISO‑639‑1 language code of the document (e.g. `fi`, `en`, `sv`). Detect from the *content language*, **not** from the PDF metadata. |\n",
      "| **title** | string | Full title **exactly as it appears** in the PDF (including subtitle, colon, punctuation, and original language). Do **not** truncate or translate. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that appear (e.g. an English translation of a Finnish title). If none, output an empty list `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"`. If the PDF metadata provides a single string like `\"Samuli Virtanen\"` you must split it into last‑ and first‑name. Preserve the order “LastName, FirstName”. If multiple creators are present, list each as a separate element. |\n",
      "| **year** | integer | Publication year. Prefer the year that appears in the title page, copyright line, or the PDF’s creation/modification date. |\n",
      "| **publisher** | list of strings | The publishing institution **exactly as it appears** (do not translate). If the publisher is a university department, include the full name (e.g. `\"Lappeenranta‑Lahti University of Technology LUT\"`). |\n",
      "| **doi** | string or `None` | DOI if present (e.g. `10.1234/abcd`). If absent, output `None`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Return the numeric string **without hyphens or spaces** (e.g. `9789523359369`). If none, output an empty list `[]`. |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalized the same way as `e_isbn`. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalized (remove hyphens). If absent, output `None`. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| **type_coar** | string | COAR type of the resource. Use one of the following exact values (lower‑case where shown):  <br>• `master thesis`  <br>• `doctoral thesis`  <br>• `book`  <br>• `article`  <br>• `report`  <br>• `conference paper`  <br>Determine the type from clues such as “Thesis”, “Dissertation”, “Väitöskirja”, “Pro gradu”, “Kirja”, “Artikkeli”, etc. Do **not** output generic terms like “Thesis”. |\n",
      "| **reasoning** (optional) | free text | A short paragraph explaining how you derived the values (not required for scoring). |\n",
      "\n",
      "*All list values must be formatted exactly as Python‑style lists, e.g. `['value1', 'value2']`.*\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation rules\n",
      "\n",
      "1. **ISBN / ISSN**  \n",
      "   - Strip all hyphens, spaces, and surrounding parentheses.  \n",
      "   - Keep only the digits (ISBN‑13) or the 8‑digit ISSN.  \n",
      "   - Example: `ISBN 978-952-335-936-9 (PDF)` → `9789523359369` and placed in `e_isbn`.  \n",
      "   - If the same ISBN appears with both “Print” and “PDF” qualifiers, put it in the corresponding list(s).\n",
      "\n",
      "2. **Creator name splitting**  \n",
      "   - If the name is a single string “First Last”, split on the last space: `Last, First`.  \n",
      "   - For names already in “Last, First” order, keep them unchanged.  \n",
      "   - Preserve diacritics and case.  \n",
      "   - Example: `\"Samuli Virtanen\"` → `[\"Virtanen, Samuli\"]`.  \n",
      "   - If multiple authors are separated by commas, semicolons, or “and”, treat each separately.\n",
      "\n",
      "3. **Publisher**  \n",
      "   - Use the exact wording that appears on the title page or in the imprint line.  \n",
      "   - Do **not** translate university names; keep the original language (e.g. `Vaasan yliopisto`, not `University of Vaasa`).  \n",
      "\n",
      "4. **Language detection**  \n",
      "   - Look at the majority of the visible text. If the document contains Finnish words (e.g., “käsittely”, “tutkimus”), output `fi`.  \n",
      "   - If the text is English, output `en`.  \n",
      "   - Use the most reliable indicator; ignore any language code that might be present in the PDF metadata if it conflicts with the actual content.\n",
      "\n",
      "5. **Title extraction**  \n",
      "   - Prefer the largest heading on the title page (usually the first line of text).  \n",
      "   - Include any subtitle after a colon or line break that belongs to the same logical title.  \n",
      "   - Do **not** truncate at page numbers or section headings.  \n",
      "\n",
      "6. **Alt title**  \n",
      "   - If an English (or otherwise different‑language) version of the title appears, capture it as a separate string in the list.  \n",
      "   - Do not include the main title again.\n",
      "\n",
      "7. **Year**  \n",
      "   - First look for a 4‑digit year on the title page (e.g., “2020”, “2022”).  \n",
      "   - If not found, fall back to the PDF creation/modification date (`creationDate` or `modDate`).  \n",
      "   - The year must be an integer, not a string.\n",
      "\n",
      "8. **DOI**  \n",
      "   - Detect patterns that start with `10.` followed by a slash and characters, possibly prefixed by “doi:” or “DOI”.  \n",
      "   - Return the raw DOI string without the prefix.\n",
      "\n",
      "9. **COAR type mapping**  \n",
      "   - **master thesis** → documents labeled “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”.  \n",
      "   - **doctoral thesis** → documents labeled “Dissertation”, “Väitöskirja”, “Doctoral thesis”.  \n",
      "   - **book** → monographs, series volumes, publications with ISBN but no thesis wording.  \n",
      "   - **article** → journal articles, conference proceedings with ISSN but no book‑style imprint.  \n",
      "   - **report** → technical or research reports, often with “Report” in the title.  \n",
      "   - **conference paper** → papers that mention a conference name or “Proceedings”.  \n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` (but this should rarely happen) |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Example output (illustrative)\n",
      "\n",
      "```\n",
      "language\n",
      "fi\n",
      "title\n",
      "Liikearvon alaskirjaukset tuloksenjärjestelykeinona : tarkastelussa Helsingin pörssiin listatut yritykset\n",
      "alt_title\n",
      "['Impairment of Goodwill as a Measure of Profitability']\n",
      "creator\n",
      "['Virtanen, Samuli']\n",
      "year\n",
      "2020\n",
      "publisher\n",
      "['Vaasan yliopisto']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "2025/09/30 15:08:12 INFO dspy.evaluate.evaluate: Average Metric: 2.1515151515151514 / 3 (71.7%)\n",
      "2025/09/30 15:08:46 INFO dspy.evaluate.evaluate: Average Metric: 37.21212121212122 / 64 (58.1%)\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset score for new program: 0.5814393939393939\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full train_val score for new program: 0.5814393939393939\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Individual valset scores for new program: [0.5454545454545454, 0.45454545454545453, 0.696969696969697, 0.2727272727272727, 0.7272727272727273, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.36363636363636365, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.5909090909090909, 0.6363636363636364, 0.9090909090909091, 0.45454545454545453, 0.45454545454545453, 0.9090909090909091, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365, 0.36363636363636365, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.6363636363636364, 0.6060606060606061, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.36363636363636365, 0.45454545454545453, 0.5909090909090909, 0.5454545454545454, 0.36363636363636365, 0.45454545454545453, 0.36363636363636365, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.36363636363636365, 0.7272727272727273]\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.9545454545454546, 0.7727272727272727, 0.9090909090909091, 0.5454545454545454, 0.45454545454545453, 0.9090909090909091, 0.45454545454545453, 1.0, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.7878787878787878, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.6060606060606061, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6666666666666666, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273]\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Full valset pareto front score: 0.678030303030303\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Updated valset pareto front programs: [{3}, {3}, {0}, {0, 3}, {0, 3, 4}, {1, 4}, {3}, {4}, {3}, {4}, {3, 4}, {0}, {0, 3, 4}, {4}, {3, 4}, {0}, {2}, {2, 4}, {0, 3}, {0}, {0}, {2, 3}, {0, 1, 3, 4}, {3}, {0}, {4}, {0, 3}, {1, 2, 3, 4}, {4}, {0}, {3}, {2}, {0, 2, 4}, {0, 3}, {0}, {0, 1, 3, 4}, {4}, {0, 4}, {0}, {2, 4}, {0, 1, 4}, {4}, {0, 2, 4}, {0, 1}, {4}, {2}, {4}, {0, 1, 2, 3}, {4}, {0, 4}, {0}, {3}, {0}, {2, 3}, {0}, {3}, {3}, {1}, {3}, {2}, {2}, {2, 4}, {3}, {4}]\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best valset aggregate score so far: 0.5903882575757575\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on train_val: 3\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best program as per aggregate score on valset: 3\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on valset: 0.5903882575757575\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Best score on train_val: 0.5903882575757575\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: Linear pareto front program index: 3\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 4: New program candidate index: 4\n",
      "GEPA Optimization:  11%|█         | 344/3200 [07:39<1:11:23,  1.50s/rollouts]2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 5: No merge candidates found\n",
      "2025/09/30 15:08:46 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Selected program 3 score: 0.5903882575757575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.09 / 2 (54.5%):  67%|██████▋   | 2/3 [00:05<00:02,  2.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:09:12 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:09:12 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.73 / 3 (57.6%): 100%|██████████| 3/3 [00:28<00:00,  9.51s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:09:15 INFO dspy.evaluate.evaluate: Average Metric: 1.7272727272727273 / 3 (57.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:10:32 INFO dspy.teleprompt.gepa.gepa: Iteration 5: Proposed new text for predict: markdown\n",
      "**Task Overview**\n",
      "\n",
      "You are given a JSON object that contains two top‑level keys:\n",
      "\n",
      "* `pdfinfo` – metadata extracted from the PDF (e.g. `title`, `author`, `creationDate`, `modDate`).\n",
      "* `pages` – an ordered list of pages, each with a `page` number and the plain‑text extracted from that page.\n",
      "\n",
      "From this information you must produce a flat list of **13 fields** in the exact order shown below.  \n",
      "Each field name is printed on its own line, immediately followed by its value on the next line.\n",
      "\n",
      "```\n",
      "language\n",
      "<title value>\n",
      "alt_title\n",
      "<list value>\n",
      "creator\n",
      "<list value>\n",
      "year\n",
      "<scalar value>\n",
      "publisher\n",
      "<list value>\n",
      "doi\n",
      "<scalar value>\n",
      "e_isbn\n",
      "<list value>\n",
      "p_isbn\n",
      "<list value>\n",
      "e_issn\n",
      "<scalar value>\n",
      "p_issn\n",
      "<scalar value>\n",
      "type_coar\n",
      "<scalar value>\n",
      "```\n",
      "\n",
      "*Scalar values* (`language`, `title`, `year`, `doi`, `e_issn`, `p_issn`, `type_coar`) must be printed **as plain strings** or the literal word `None` when the information is not available.  \n",
      "\n",
      "*List values* (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) must be printed as a JSON‑style Python list using **single quotes** and a space after each comma, e.g.:\n",
      "\n",
      "```\n",
      "['Doe, John', 'Smith, Anna']\n",
      "```\n",
      "\n",
      "If a list is empty, print `[]`.\n",
      "\n",
      "---\n",
      "\n",
      "## Detailed Extraction Rules\n",
      "\n",
      "### 1. Language (`language`)\n",
      "1. Look for an explicit language indicator in the text (e.g. `Språk:`, `Language:`) or in the PDF metadata.  \n",
      "2. If none is found, **detect the predominant language** of the title and the first few paragraphs:\n",
      "   * If the majority of words are English → `en`\n",
      "   * Finnish → `fi`\n",
      "   * Swedish → `sv`\n",
      "   * Otherwise use the ISO‑639‑1 code that best matches the detected language.\n",
      "3. Return the two‑letter code (e.g. `en`).  \n",
      "\n",
      "### 2. Title (`title`)\n",
      "* Prefer `pdfinfo.title` if it exists.  \n",
      "* If not, take the first line that looks like a main heading (all words capitalised, often preceded by `#` or displayed in a larger font).  \n",
      "* Preserve the exact capitalization and any subtitle (text after a colon `:`) as part of the title.  \n",
      "* Do **not** split subtitle into `alt_title`.\n",
      "\n",
      "### 3. Alternative Title (`alt_title`)\n",
      "* Populate only when the document explicitly provides a separate “alternative title” or “also known as” line.  \n",
      "* Otherwise return an empty list `[]`.\n",
      "\n",
      "### 4. Creator (`creator`)\n",
      "* Primary authors only – **do not** include supervisors, reviewers, examiners, or committee members.  \n",
      "* Extraction order:\n",
      "  1. Use `pdfinfo.author` if present; split on commas, semicolons, “and”, or line breaks.  \n",
      "  2. If not available, locate the author line(s) immediately under the title (often prefixed with “Author:”, “Authors:”, or just a name on its own line).  \n",
      "* Normalise each name to the form **`Surname, Given`** (retain all given‑name parts).  \n",
      "  * Example: “Chethan Parthasarathy” → `Parthasarathy, Chethan`.  \n",
      "* Preserve the order in which authors appear in the source.  \n",
      "* Return the list of normalized names; if none can be identified, return `[]`.\n",
      "\n",
      "### 5. Year (`year`)\n",
      "* Extract the four‑digit year from `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYY…`).  \n",
      "* If those are missing, look for a year on the title page or in a line like `2023:` or `2021` near the top of the document.  \n",
      "* Return the year as a string (e.g. `2023`).  \n",
      "\n",
      "### 6. Publisher (`publisher`)\n",
      "* Identify the institution, university, or organisation that issued the work.  \n",
      "* Typical cues: “University of …”, “Institute of …”, “Högskolan på …”, “Åland University of Applied Sciences”, etc.  \n",
      "* Do **not** include journal publishers or conference organisers unless the whole document is a report published by them.  \n",
      "* Return a list containing the publisher name(s); if none is found, return `[]`.\n",
      "\n",
      "### 7. DOI (`doi`)\n",
      "* Search the full text for patterns `doi:` or `DOI:` followed by a DOI string (e.g. `10.1109/IEECON.2018.8712263`).  \n",
      "* If found, return the DOI exactly as it appears (without the leading `doi:`).  \n",
      "* If no DOI is present, return `None`.\n",
      "\n",
      "### 8. Electronic ISBN (`e_isbn`) and Print ISBN (`p_isbn`)\n",
      "* Locate all ISBN strings (13‑digit numbers, sometimes hyphenated).  \n",
      "* Determine their type by the surrounding label:\n",
      "  * `ISBN … (online)` → electronic ISBN → add to `e_isbn`.\n",
      "  * `ISBN … (print)` → print ISBN → add to `p_isbn`.\n",
      "* If the label does not specify, treat it as **print** ISBN.  \n",
      "* Return each list with the raw numeric string **without hyphens** (e.g. `9789523950900`).  \n",
      "* If none are found, return an empty list `[]`.\n",
      "\n",
      "### 9. Electronic ISSN (`e_issn`) and Print ISSN (`p_issn`)\n",
      "* Locate ISSN strings (format `NNNN‑NNNN`).  \n",
      "* Use surrounding words to decide:\n",
      "  * `ISSN … (online)` → electronic → value for `e_issn`.\n",
      "  * `ISSN … (print)` → print → value for `p_issn`.\n",
      "* If no qualifier is present, assume **print** ISSN.  \n",
      "* Return the ISSN exactly as it appears (including the hyphen).  \n",
      "* If not found, return `None`.\n",
      "\n",
      "### 10. COAR Type (`type_coar`)\n",
      "Map the document to the appropriate COAR taxonomy term using these heuristics:\n",
      "\n",
      "| Cue in document                               | COAR term to output                |\n",
      "|----------------------------------------------|------------------------------------|\n",
      "| Contains “doctoral dissertation”, “PhD thesis”, “Doctoral thesis” | `doctoral thesis` |\n",
      "| Contains “bachelor thesis”, “examensarbete” (Swedish) | `bachelor thesis` |\n",
      "| Contains “master’s thesis”, “master thesis”, “opinnäytetyö” | `master's thesis` |\n",
      "| Contains “journal article”, DOI, ISSN, and typical journal layout | `journal article` |\n",
      "| Contains newspaper name or “article” with a newspaper citation (e.g., “Svängrum”) | `newspaper article` |\n",
      "| Contains “conference paper”, “proceedings”, or conference name | `conference paper` |\n",
      "| Otherwise, if it is a report or monograph without the above cues → `report` |\n",
      "| If none of the above apply, default to `other` |\n",
      "\n",
      "Return the term exactly as shown (all lower‑case, spaces where indicated).\n",
      "\n",
      "---\n",
      "\n",
      "## Output Formatting Checklist\n",
      "\n",
      "1. **Order** – fields must appear in the exact order listed at the top of this instruction.  \n",
      "2. **Line breaks** – each field name on its own line, followed by its value on the next line, with **no extra blank lines**.  \n",
      "3. **Quotes** – list items use single quotes (`'`) and a space after each comma.  \n",
      "4. **None** – use the literal word `None` (capital N, no quotes) for missing scalar values.  \n",
      "5. **No trailing spaces** – ensure lines end directly after the last character.\n",
      "\n",
      "---\n",
      "\n",
      "**Example of correct final output**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Accurate Battery Modelling for Control Design and Economic Analysis of Lithium-ion Battery Energy Storage Systems in Smart Grid\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Parthasarathy, Chethan']\n",
      "year\n",
      "2023\n",
      "publisher\n",
      "['University of Vaasa']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "['9789523950900']\n",
      "p_isbn\n",
      "['9789523950894']\n",
      "e_issn\n",
      "2323-9123\n",
      "p_issn\n",
      "0355-2667\n",
      "type_coar\n",
      "doctoral thesis\n",
      "2025/09/30 15:10:39 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n",
      "2025/09/30 15:10:39 INFO dspy.teleprompt.gepa.gepa: Iteration 5: New subsample score is not better, skipping\n",
      "GEPA Optimization:  11%|█         | 350/3200 [09:32<1:46:19,  2.24s/rollouts]2025/09/30 15:10:39 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Selected program 2 score: 0.5495822192513369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.09 / 3 (36.4%): 100%|██████████| 3/3 [00:07<00:00,  2.49s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:10:47 INFO dspy.evaluate.evaluate: Average Metric: 1.0909090909090908 / 3 (36.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:12:14 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Proposed new text for predict: markdown\n",
      "# Task: Precise Metadata Extraction from PDF‑derived Text\n",
      "\n",
      "You will be given a **single JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – a dictionary containing the raw PDF metadata (e.g. `title`, `author`, `creationDate`, …).  \n",
      "* **pages** – an ordered list of page objects, each with:\n",
      "  * **page** – the page number (integer, 1‑based).  \n",
      "  * **text** – the plain‑text extracted from that page (UTF‑8, may contain markdown headings, bold/italic markup, hyperlinks, footnotes, line‑breaks, etc.).\n",
      "\n",
      "Your job is to **produce ONE JSON object** that contains **exactly** the fields listed in the table below (order does not matter).  \n",
      "If a field cannot be determined, use the value prescribed in the *Missing‑Data Handling* section.\n",
      "\n",
      "| Field | Type | Description | Extraction Details |\n",
      "|-------|------|-------------|--------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language (`en`, `fi`, `sv`). | Detect **from the body text**, **not** from `pdfinfo[\"language\"]`. Use a simple stop‑word count (see below). If no language reaches the required threshold, return `und`. |\n",
      "| **title** | string | Primary title, exactly as it appears in the document (including subtitle after a colon, if present). | 1. Prefer a **level‑1 markdown heading** (`# …`).<br>2. If none, look for the **first bold line** (`**…**` or `*…*`).<br>3. If still none, fall back to `pdfinfo[\"title\"]` **only if** it looks like a real title (contains letters and spaces, not “Untitled”).<br>4. Titles may be split over several consecutive lines – treat them as a single title if they appear directly one after another **without an empty line** between them.<br>5. Strip all markdown symbols (`#`, `*`, `**`, leading/trailing whitespace). |\n",
      "| **alt_title** | list of strings | Any alternative titles (subtitle only, translation, or a second‑level heading that follows the primary title). | Look for a **level‑2 heading** (`## …`) that appears **immediately after** the primary title (no intervening non‑heading text). Also accept a line that is a **translation** of the primary title (e.g. Finnish title followed by Swedish title). Return distinct values, order as found. |\n",
      "| **creator** | list of strings | Authors, each formatted as `\"LastName, FirstName\"`. One entry per author. | Search for lines containing any of the following keywords (case‑insensitive): `author`, `authors`, `tekijä`, `kirjoittaja`, `kirjoittajat`, `author(s)`, `author:`. Also check `pdfinfo[\"author\"]`. <br> • Split the line on commas, semicolons, the word “and”, “&”, or line breaks.<br> • For each name:<br>   – If a comma is present, assume it is already “Last, First”.<br>   – Otherwise assume “First Last” and **invert** to “Last, First”.<br>   – Preserve diacritics and capitalisation.<br> • Discard generic placeholders like “et al.”, keep only explicitly named persons.<br> • Return an empty list `[]` if no author can be identified. |\n",
      "| **year** | integer | Publication year (four‑digit). | 1. Look for a four‑digit number (1900‑2099) that appears next to any of these cues (case‑insensitive): `Year:`, `©`, `©`, `©`, `2021`, `2022` etc., or in a line that looks like a date line (e.g. `Karelia‑ammattikorkeakoulu 2021`).<br>2. If multiple candidates are found, **choose the latest year** (the most recent).<br>3. If still none, extract the year from `pdfinfo[\"creationDate\"]` (pattern `D:YYYY…`).<br>4. If no year can be found, return `null`. |\n",
      "| **publisher** | list of strings | Institution, university, journal, or publishing house. | Scan for lines containing any of these keywords (case‑insensitive): `university`, `universitet`, `university of`, `college`, `institute`, `school of`, `journal of`, `publisher:`, `published by`, `Karelia‑ammattikorkeakoulu`, `Hansaprint Oy`, etc. Extract the **full entity name** (trim surrounding punctuation). Return each distinct entity once, preserving order of appearance. |\n",
      "| **doi** | string | Digital Object Identifier (without the `doi.org/` prefix). | Find any URL matching `https?://doi\\.org/([^\\s\\)]+)`. Capture the part after the domain, strip trailing punctuation (`.`, `)`, `]`). If none, return `null`. |\n",
      "| **e_isbn** | list of strings | Electronic ISBN numbers (cleaned, digits only, keep the 13‑digit prefix). | Regex: `ISBN(?:‑13)?:?\\s*([0-9][0-9\\-\\s]{9,})`. After extracting, **remove spaces and hyphens** to get a continuous string (e.g. `9789523950313`). Classify as electronic **only if** the surrounding line (or the same line) contains any of: `online`, `electronic`, `verkkojulkaisu`, `e‑isbn`, `e‑ISBN`. |\n",
      "| **p_isbn** | list of strings | Print ISBN numbers (cleaned, digits only). | Same regex as above, but classify as print when the line contains any of: `print`, `painettu`, `p‑isbn`, `p‑ISBN`, or when **no electronic cue** is present. |\n",
      "| **e_issn** | string | Electronic ISSN (`####-####`). | Regex: `ISSN\\s*[:]?[\\s]*([0-9]{4}\\s*[-‑]\\s*[0-9]{3}[0-9X])`. Classify as electronic when the line also contains `electronic`, `e‑issn`, `verkkojulkaisu`, `online`. Return `null` if none. |\n",
      "| **p_issn** | string | Print ISSN (`####-####`). | Same regex, classified as print when the line contains `print`, `painettu`, `p‑issn`, or when no electronic cue is present. Return `null` if none. |\n",
      "| **type_coar** | string | COAR type (lower‑case, spaces allowed). | Map Finnish/Swedish/English keywords to COAR terms (see table below). Choose the **most specific** term when several match. |\n",
      "| **reasoning** *(optional)* | string | Short human‑readable explanation of how each field was derived. | May be omitted. |\n",
      "\n",
      "### COAR Mapping Table\n",
      "| Detected keyword(s) (case‑insensitive) | COAR type |\n",
      "|----------------------------------------|-----------|\n",
      "| `master’s thesis`, `master thesis`, `kandidaatintutkielma`, `master thesis` | `master thesis` |\n",
      "| `bachelor thesis`, `bachelor’s thesis`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| `doctoral thesis`, `phd thesis`, `väitöskirja`, `dissertation` | `thesis` (or `doctoral thesis` if you want finer granularity; `thesis` is acceptable) |\n",
      "| `report`, `technical report`, `research report`, `tutkimusraportti` | `research report` |\n",
      "| `journal article`, `article`, `paper`, `artikkeli` | `journal article` |\n",
      "| `conference paper`, `proceedings`, `konferenssijulkaisu` | `conference paper` |\n",
      "| `book`, `book chapter`, `chapter` | `book` / `book chapter` as appropriate |\n",
      "| `dataset`, `software` | same term |\n",
      "| If none of the above match, default to `report`. |\n",
      "\n",
      "### Language Detection (stop‑word lists)\n",
      "* **Finnish (`fi`)** – count occurrences of any of: `ja`, `on`, `että`, `tämä`, `niin`, `mutta`, `tai`, `kun`, `että`, `se`, `niin`, `kanssa`.\n",
      "* **Swedish (`sv`)** – count any of: `och`, `att`, `är`, `det`, `så`, `men`, `eller`, `men`, `som`, `på`.\n",
      "* **English (`en`)** – count any of: `and`, `the`, `of`, `in`, `to`, `for`, `with`, `that`, `by`, `as`, `is`, `on`.\n",
      "* Tokenise on whitespace, ignore case and punctuation.  \n",
      "* If the highest count belongs to one language **and** the count is at least **3**, use that language code. Otherwise return `und`.\n",
      "\n",
      "### General Pre‑processing (apply to every page before any extraction)\n",
      "1. Replace Windows line endings `\\r\\n` with `\\n`.  \n",
      "2. Remove markdown image syntax `![](...)` and any HTML‑like tags `<...>`.  \n",
      "3. Preserve line breaks while scanning for headings; **only collapse multiple spaces into a single space after headings have been identified** (so titles that span lines are not merged prematurely).  \n",
      "4. Trim trailing/leading whitespace from each line.\n",
      "\n",
      "### Missing‑Data Handling\n",
      "| Field type | Value to use when missing |\n",
      "|------------|--------------------------|\n",
      "| String (`title`, `doi`, `e_issn`, `p_issn`) | `null` |\n",
      "| Integer (`year`) | `null` |\n",
      "| List (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) | `[]` |\n",
      "| `language` | `und` |\n",
      "| `type_coar` | `null` (but this should almost never happen if any keyword is found) |\n",
      "\n",
      "### Output Requirements\n",
      "* Produce **one** valid JSON object containing **exactly** the keys listed in the table (including `reasoning` only if you choose to provide it).  \n",
      "* Do **not** add any extra keys.  \n",
      "* Ensure each value conforms to the required JSON type (string, number, array, or null).  \n",
      "* ISBN/ISSN values must be **strings** in the exact format shown (e.g., `9789523950313` for ISBN, `0355-2667` for ISSN).  \n",
      "* Lists must contain **unique** items (no duplicates).  \n",
      "\n",
      "### Example Output (illustrative only)\n",
      "```json\n",
      "{\n",
      "  \"language\": \"fi\",\n",
      "  \"title\": \"Ison Someronjärven (Parkano) fysikaalis‑kemiallisen nykytilan selvitys kunnostussuunnittelun perustaksi\",\n",
      "  \"alt_title\": [],\n",
      "  \"creator\": [\"Tossavainen, Tarmo\"],\n",
      "  \"year\": 2021,\n",
      "  \"publisher\": [\"Karelia‑ammattikorkeakoulu\"],\n",
      "  \"doi\": null,\n",
      "  \"e_isbn\": [\"9789522753311\"],\n",
      "  \"p_isbn\": [],\n",
      "  \"e_issn\": \"2323-6914\",\n",
      "  \"p_issn\": null,\n",
      "  \"type_coar\": \"research report\",\n",
      "  \"reasoning\": \"Title taken from first level‑1 heading; author line contains 'Tekijä'...\"\n",
      "}\n",
      "2025/09/30 15:12:20 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n",
      "2025/09/30 15:13:00 INFO dspy.evaluate.evaluate: Average Metric: 29.185204991087346 / 64 (45.6%)\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full valset score for new program: 0.4560188279857397\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full train_val score for new program: 0.4560188279857397\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Individual valset scores for new program: [0.45454545454545453, 0.36363636363636365, 0.2727272727272727, 0.18181818181818182, 0.45454545454545453, 0.36363636363636365, 0.45454545454545453, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.5454545454545454, 0.36363636363636365, 0.45454545454545453, 0.36363636363636365, 0.45454545454545453, 0.45454545454545453, 0.2727272727272727, 0.7272727272727273, 0.6363636363636364, 0.2727272727272727, 0.36363636363636365, 0.36363636363636365, 0.45454545454545453, 0.6818181818181818, 0.36363636363636365, 0.5454545454545454, 0.36363636363636365, 0.506060606060606, 0.5454545454545454, 0.3333333333333333, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5, 0.2727272727272727, 0.7878787878787878, 0.6363636363636364, 0.42424242424242425, 0.5454545454545454, 0.6363636363636364, 0.2727272727272727, 0.6363636363636364, 0.45454545454545453, 0.2727272727272727, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.2727272727272727, 0.45454545454545453, 0.2727272727272727, 0.36363636363636365, 0.5454545454545454, 0.36363636363636365, 0.18181818181818182, 0.3333333333333333, 0.36363636363636365, 0.40641711229946526, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5151515151515151, 0.5151515151515151]\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.9545454545454546, 0.7727272727272727, 0.9090909090909091, 0.5454545454545454, 0.506060606060606, 0.9090909090909091, 0.45454545454545453, 1.0, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.7878787878787878, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.6060606060606061, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6666666666666666, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273]\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Full valset pareto front score: 0.682623106060606\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Updated valset pareto front programs: [{3}, {3}, {0}, {0, 3}, {0, 3, 4}, {1, 4}, {3}, {4}, {3}, {4}, {3, 4}, {0}, {0, 3, 4}, {4}, {3, 4, 5}, {0}, {2}, {2, 4, 5}, {0, 3}, {0}, {0}, {2, 3}, {0, 1, 3, 4}, {3}, {0}, {4}, {0, 3}, {5}, {4}, {0}, {3}, {2}, {0, 2, 4}, {0, 3}, {0}, {5}, {5}, {0, 4}, {0}, {2, 4}, {0, 1, 4}, {4}, {0, 2, 4}, {0, 1}, {4}, {2}, {4}, {0, 1, 2, 3}, {4, 5}, {0, 4}, {0}, {3}, {0}, {2, 3}, {0}, {3}, {3}, {1}, {3}, {2}, {2}, {2, 4}, {3}, {4}]\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best valset aggregate score so far: 0.5903882575757575\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best program as per aggregate score on train_val: 3\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best program as per aggregate score on valset: 3\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best score on valset: 0.5903882575757575\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Best score on train_val: 0.5903882575757575\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: Linear pareto front program index: 3\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 6: New program candidate index: 5\n",
      "GEPA Optimization:  13%|█▎        | 420/3200 [11:53<1:39:11,  2.14s/rollouts]2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 7: No merge candidates found\n",
      "2025/09/30 15:13:00 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Selected program 0 score: 0.5871324855699855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.64 / 3 (54.5%): 100%|██████████| 3/3 [00:08<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:13:08 INFO dspy.evaluate.evaluate: Average Metric: 1.6363636363636362 / 3 (54.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:14:47 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Proposed new text for predict: markdown\n",
      "# Task Overview\n",
      "You are given a JSON object that contains the raw text extracted from a PDF file (`pages` → list of `{page, text}`) together with the PDF‑metadata (`pdfinfo`).  \n",
      "Your job is to **extract structured bibliographic metadata** and return it as a single JSON object that follows the exact schema described below.\n",
      "\n",
      "The evaluation of your answer is strict: every field must be present, data must be in the required format, and only the values that are explicitly present in the source text may be returned.  \n",
      "Below you will find detailed rules, normalization conventions, and examples of how to handle edge‑cases that appeared in the training data.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output Schema\n",
      "\n",
      "| Field | Type | Description | Required? |\n",
      "|-------|------|-------------|-----------|\n",
      "| `language` | string | ISO‑639‑2 three‑letter code (`fi`, `sv`, `en`, …). Detect the primary language of the document from the visible text (titles, headings, “Language:” lines, etc.). | Yes |\n",
      "| `title` | string | The **main title** of the work, exactly as it appears in the document (preserve capitalization, punctuation, but strip surrounding whitespace). | Yes |\n",
      "| `alt_title` | list of strings | Any alternative titles that appear in other languages or as subtitle lines. Keep each alternative title as a separate string, in the order they appear. If none, return an empty list `[]`. | Yes |\n",
      "| `creator` | list of strings | Names of the **primary authors** of the work, **not** supervisors, editors, translators, or other contributors. Each name must be formatted as `\"Surname, First\"` (first name may contain multiple parts). The order should follow the order in the source. If no author is identifiable, return an empty list. | Yes |\n",
      "| `year` | integer | Publication year (four‑digit). Prefer the year that appears in a copyright line, imprint line, or the `creationDate`/`modDate` if it matches the publication year. | Yes |\n",
      "| `publisher` | list of strings | The institution or organisation that issued the publication (e.g., “Tilastokeskus”, “University of Turku”, “Arcada University of Applied Sciences”). Do **not** include series titles, imprint locations, or printing houses. If multiple publishers are listed, include them all in order; otherwise return a single‑element list. | Yes |\n",
      "| `doi` | string | Digital Object Identifier, exactly as it appears (e.g., `10.1007/xyz`). If none, return `null`. | Yes |\n",
      "| `e_isbn` | list of strings | ISBNs that refer to the **electronic** (PDF/online) version. Strip all hyphens and spaces; keep only the 13‑digit (or 10‑digit) number, e.g. `\"9789512986873\"`. Return an empty list if none. | Yes |\n",
      "| `p_isbn` | list of strings | ISBNs that refer to the **print** version. Same normalization as `e_isbn`. | Yes |\n",
      "| `e_issn` | list of strings or `null` | ISSN for the electronic version, normalized to digits only (e.g., `\"23433167\"`). Return `null` if not present. | Yes |\n",
      "| `p_issn` | list of strings or `null` | ISSN for the print version, normalized similarly. Return `null` if not present. | Yes |\n",
      "| `type_coar` | string | COAR‑compatible resource type. Use one of the following exact values (case‑sensitive):  \n",
      "\n",
      "  - `book`  \n",
      "  - `bachelor thesis`  \n",
      "  - `doctoral thesis`  \n",
      "  - `statistical report`  \n",
      "\n",
      "  Choose the most specific type that can be inferred from the document (see rules below). | Yes |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. General Extraction Strategy\n",
      "\n",
      "1. **Concatenate all page texts** in the order given (page 1 → last) into a single searchable string. Preserve line breaks because many patterns rely on them.\n",
      "\n",
      "2. **Detect language**  \n",
      "   - Look for language‑specific headings:  \n",
      "     - Finnish: “YHTEISTIEDOT”, “Kansikuva”, “ISBN”, “Julkaisun”.  \n",
      "     - Swedish: “Författare”, “Utgivare”, “ISBN”, “Utgivningsår”.  \n",
      "     - English: “Author”, “Publisher”, “ISBN”, “Abstract”.  \n",
      "   - If a language line such as “Språk: svenska” appears, use that directly.  \n",
      "   - Default to the language of the title if ambiguous.\n",
      "\n",
      "3. **Extract the main title**  \n",
      "   - Prefer the first line that is rendered as a heading (`#`, `##`, `###`, uppercase, or centered).  \n",
      "   - Remove any surrounding markdown symbols (`#`, `**`, etc.) and trim whitespace.  \n",
      "   - If the title appears twice (e.g., on cover and inside), keep the first occurrence.\n",
      "\n",
      "4. **Collect alternative titles**  \n",
      "   - Look for additional title lines that are not the main title but appear in a different language or as a subtitle (e.g., a line starting with `##` after the main title, or a line that contains a colon separating two language versions).  \n",
      "   - Add each distinct line to `alt_title` preserving its exact text (minus markdown symbols).\n",
      "\n",
      "5. **Identify primary authors**  \n",
      "   - Search for language‑specific author markers:  \n",
      "     - Finnish: `Tekijä:`, `Kirjoittaja:`, `Toim.` (editor) – **ignore editors**.  \n",
      "     - Swedish: `Författare:`, `Författare` – use the names after this label.  \n",
      "     - English: `Author:`, `Authors:`.  \n",
      "   - Names are usually separated by commas, semicolons, or the word “and”.  \n",
      "   - **Do not** include supervisors, advisors, or commission‑agents (e.g., “Handledare”, “Supervisor”, “Commissioned by”).  \n",
      "   - For each name, split into parts, assume the last word is the surname, and re‑format as `\"Surname, First\"` (preserve middle names).  \n",
      "   - If the name already appears as “Surname, First”, keep it unchanged.  \n",
      "   - Return an empty list if no clear primary author line is found.\n",
      "\n",
      "6. **Determine the publication year**  \n",
      "   - Look for a 4‑digit year preceded by `©`, `Copyright`, `Julkaisuvuosi`, `Publication year`, `Date of acceptance`, or inside an imprint line like `Helsinki – Helsingfors 2015`.  \n",
      "   - If multiple years appear, choose the one that is closest to the publisher/ISBN block.  \n",
      "   - As a fallback, use the year part of `creationDate` or `modDate` from `pdfinfo` if it matches the pattern `D:YYYY...`.\n",
      "\n",
      "7. **Extract publisher**  \n",
      "   - Search for lines containing words like `Kustantaja`, `Publisher`, `Utgivare`, `Julkaisija`, `Tilastokeskus`, `University of …`.  \n",
      "   - Discard location information (city, country) and series titles.  \n",
      "   - Keep the exact organisation name as it appears (e.g., “Tilastokeskus”, “University of Turku”, “Arcada University of Applied Sciences”).  \n",
      "   - If more than one distinct publisher is present, list them in order.\n",
      "\n",
      "8. **DOI**  \n",
      "   - Regex pattern: `10\\.\\d{4,9}/\\S+`. Return the first match or `null`.\n",
      "\n",
      "9. **ISBN extraction**  \n",
      "   - Regex: `ISBN\\s*[:]?[\\s]*([0-9Xx-]+)\\s*\\((PRINT|PDF|E‑BOOK|ONLINE|PDF)\\)`.  \n",
      "   - Capture the number and the version keyword.  \n",
      "   - Normalize by removing all hyphens and spaces (e.g., `978-952-244-542-1` → `9789522445421`).  \n",
      "   - Append to `p_isbn` if the version keyword contains `PRINT`; otherwise to `e_isbn`.  \n",
      "   - If the version keyword is missing, infer: numbers appearing after “(PDF)” or “(e‑book)” → electronic; after “(PRINT)” → print. If still ambiguous, place in both lists.\n",
      "\n",
      "10. **ISSN extraction**  \n",
      "    - Regex: `ISSN\\s*[:]?[\\s]*([0-9Xx-]+)\\s*\\((PRINT|ONLINE|E‑ISSN|P‑ISSN)\\)`.  \n",
      "    - Normalize like ISBN (remove hyphens).  \n",
      "    - Assign to `p_issn` for `PRINT`, to `e_issn` for `ONLINE`/`E‑ISSN`.  \n",
      "    - If the qualifier is absent, treat as print.\n",
      "\n",
      "11. **Determine `type_coar`**  \n",
      "    - **bachelor thesis** → presence of Swedish “Examensarbete”, Finnish “Kandidaatintyö”, or English “Bachelor thesis”.  \n",
      "    - **doctoral thesis** → presence of “Doctoral dissertation”, “Doctoral thesis”, “PhD thesis”, “Licentiate” etc.  \n",
      "    - **statistical report** → presence of “Report”, “Raportti”, “Statistical Report”, or the publisher being a statistics agency (e.g., Tilastokeskus) **and** the document is not a book or thesis.  \n",
      "    - **book** → any other monograph, especially when ISBNs for both print and electronic are present and no thesis‑specific keywords are found.  \n",
      "    - Choose the most specific match; if multiple apply, follow the priority order above (bachelor → doctoral → statistical → book).\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Normalisation Details\n",
      "\n",
      "| Item | How to normalise |\n",
      "|------|-----------------|\n",
      "| ISBN / ISSN | Remove **all** hyphens (`-`), spaces, and line‑breaks. Keep the raw digit string (13‑digit ISBN‑13 or 10‑digit ISBN‑10). |\n",
      "| Author names | Trim whitespace, remove titles (`Prof.`, `Dr.`, `Mr.`, `Ms.`). Preserve diacritics. Convert “First Middle Last” → `\"Last, First Middle\"`. |\n",
      "| Publisher | Keep exactly as it appears, but trim surrounding punctuation and whitespace. |\n",
      "| Year | Return as an integer (e.g., `2021`). |\n",
      "| Language | Use lower‑case ISO‑639‑2 codes (`fi`, `sv`, `en`). |\n",
      "| Type_coar | Use the exact strings listed in the table above. |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Edge Cases & Common Pitfalls (learned from feedback)\n",
      "\n",
      "| Issue | What caused it | Correct handling |\n",
      "|-------|----------------|-----------------|\n",
      "| **Hyphenated ISBNs** were returned with hyphens. | Not stripping hyphens. | Always strip hyphens and spaces. |\n",
      "| **Missing author** – returned editors or supervisors. | Using any name after “Toim.” or “Handledare”. | Only use the line explicitly labelled as author/författare/author. |\n",
      "| **Publisher over‑specific** (included series or imprint). | Taking the whole copyright line. | Extract only the institution name (e.g., “Tilastokeskus”, “University of Turku”). |\n",
      "| **Incorrect `type_coar`** (book vs statistical report). | Assuming any monograph is a book. | Follow the priority rules; use “statistical report” when the publisher is a statistics agency and no thesis markers are present. |\n",
      "| **Language detection** – returned Finnish for English text. | Relying only on `pdfinfo`. | Detect language from visible headings or explicit “Language:” lines. |\n",
      "| **Alt‑title handling** – empty or duplicated. | Ignoring subtitle lines. | Capture any additional title‑like lines that are not the main title. |\n",
      "| **ISSN assignment** – swapped print/e‑online. | Ignoring qualifier in parentheses. | Use the qualifier (`PRINT`, `ONLINE`) to decide which field to fill. |\n",
      "| **Creator order** – wrong order or missing commas. | Splitting on commas blindly. | Preserve the original order; split on semicolons or the word “and” when commas are part of the name. |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Expected JSON Example\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"sv\",\n",
      "  \"title\": \"Temadag om återupplivning för högstadieelever\",\n",
      "  \"alt_title\": [\n",
      "    \"Microsoft Word - Examensarbete Aöterupplivningstemadag Sirvio Wickström FINAL - KORRIGERING 2.3\",\n",
      "    \"Elvytyskoulutusteemapäivä ylästeen oppilaille\"\n",
      "  ],\n",
      "  \"creator\": [\"Sirviö, Birger\", \"Wickström, Jens\"],\n",
      "  \"year\": 2021,\n",
      "  \"publisher\": [\"Yrkeshögskolan Arcada\"],\n",
      "  \"doi\": null,\n",
      "  \"e_isbn\": [],\n",
      "  \"p_isbn\": [],\n",
      "  \"e_issn\": null,\n",
      "  \"p_issn\": null,\n",
      "  \"type_coar\": \"bachelor thesis\"\n",
      "}\n",
      "2025/09/30 15:14:56 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n",
      "2025/09/30 15:15:35 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 15:15:40 ERROR dspy.utils.parallelizer: Error for Example({'content': '{\"pdfinfo\": {\"creationDate\": \"D:20210323194007+02\\'00\\'\", \"modDate\": \"D:20210324090452+02\\'00\\'\"}, \"pages\": [{\"page\": 1, \"text\": \"## **B**\\\\nAntti Alam\\\\u00e4ki, Elina Nevala, Juha Jalovaara,\\\\nJohn Barton, Joan Condell, Karla Mu\\\\u00f1oz Esquivel,\\\\nAnna Nordstr\\\\u00f6m, Daniel Kelly, David Heaney, James Gillespie\\\\n\\\\n### **HANDBOOK II**\\\\n**Guidelines on the use of wearable sensor**\\\\n**systems in-home rehabilitation combined**\\\\n**with remote connections**\\\\n**Flowchart and Practice guideline**\\\\n\\\\n\\\\n\"}, {\"page\": 2, \"text\": \"Publications of Karelia University of Applied Sciences\\\\nB, Handbooks and Article collections: 68\\\\n\\\\n#### **Guidelines on the use of** **wearable sensor systems** **in-home rehabilitation** **combined with remote** **connections**\\\\nFlowchart and Practice guideline\\\\n**HANDBOOK II**\\\\nKarelia University of Applied Sciences\\\\nJoensuu 2021\\\\n\\\\n\\\\n\"}, {\"page\": 3, \"text\": \"_Publication series:_ B, Handbooks and Article collections: 68\\\\n_Layout:_ Pasi Tikka, Osuuskunta Mekastamo\\\\n_Authors:_ Alam\\\\u00e4ki, Antti (MSc)\\\\u00b9; Nevala, Elina (MHc)\\\\u00b9;\\\\nJalovaara, Juha (PT)\\\\u00b9; Barton, John (Industry\\\\nProjects Team Leader, Wireless Sensor\\\\nNetwork Group)\\\\u00b2; Prof. Condell, Joan\\\\u00b3;\\\\nDr. Mu\\\\u00f1oz Esquivel, Karla\\\\u00b3; Prof. Nordstr\\\\u00f6m,\\\\nAnna [4] ; Dr. Kelly, Daniel\\\\u00b3; Dr. Heaney David\\\\u00b3;\\\\nGillespie, James (MSc)\\\\u00b3\\\\n\\\\n\\\\n\\\\u00b9 Karelia University of Applied Sciences, Finland, Reasearch,\\\\nDevelopment and Innovation activities (RDI) & Physiotherapy Education\\\\n\\\\u00b2 Tyndall National Institute, University College Cork, Ireland\\\\n\\\\u00b3 Magee Campus, Ulster University, UK\\\\n4 Department of Public Health and Clinical Medicine, Ume\\\\u00e5 University, Sweden\\\\nand School of Sport Sciences, The Arctic University of Norway, Troms\\\\u00f8, Norway\\\\n\\\\n\\\\n\\\\u00a9 Authors and Karelia University of Applied Sciences\\\\nISBN 978-952-275-322-9\\\\nISSN-L 2323-6914\\\\nISSN 2323-6914\\\\nJoensuu, Finland, 2021\\\\n\\\\n\\\\n\"}, {\"page\": 5, \"text\": \"**FLOWCHART depicting the use of wearable sensor systems**\\\\n**in-home rehabilitation with remote connections**\\\\n**CONTACT TO SOCIAL AND HEALTH CARE / REHABILIATION BECAUSE**\\\\n**Worries about decreased functional capacity (ICF) or risk of it**\\\\n\\\\n\\\\n**evaluation of the functional capacity**\\\\n**Interact with rehabilitees \\\\u2013 involve her/him**\\\\n\\\\n**in the screening** **or rehabilitation process**\\\\nLegislation and\\\\nregulations\\\\nin different\\\\ncountries: who,\\\\nwhen, how\\\\nCheck and\\\\nconfirm\\\\nlegislation\\\\nand directions\\\\n\\\\nof different\\\\n\\\\ncountries for\\\\napproved\\\\nremote rehab\\\\n\\\\nactivities\\\\nA; B; C level\\\\nLegislation\\\\nand directions\\\\n\\\\nin different\\\\n\\\\ncountries\\\\n**Screening**\\\\n**Rehabilitation**\\\\nOther options\\\\nof screening\\\\nand rehab\\\\n**Agree the suitable/ best screening or rehabilitation**\\\\n**service model for the person**\\\\n**IF**\\\\n**At home with remote connections and wearable sensors**\\\\n**Select Suitable:**\\\\n\\\\n**rehabilitee & check**\\\\n\\\\n**environment**\\\\n**Select Suitable**\\\\n**professional**\\\\n**Select key aspects and parameters of functional**\\\\n**capacity and risks of decreasing FC**\\\\n**Select accurate and easy to use sensor system**\\\\n**INTERVENTION**\\\\n**EVALUATE BOTH FUNCTIONAL CAPACITY AND**\\\\n**REHABILITATION PROCESS SUITABILITY**\\\\nCheck\\\\n\\\\nconnections\\\\nand security\\\\ndemands\\\\nTake care\\\\n\\\\nof user\\\\nguidance\\\\n\\\\n\\\\n\"}, {\"page\": 6, \"text\": \"##### **1 Introduction**\\\\nThis Handbook Part II was developed to assist and orientate rehabilitation staff and organisations who are planning to start remote home rehabilitation activities, particularly with\\\\nthe older persons. The ideas and suggestions for the remote rehabilitation process in this\\\\ndocument can be easily adopted to any kind of functional capacity problem in rehabilitation. The Handbook Part II focuses on the attributes and aspects that you must consider\\\\nwhen you start a remote rehabilitation process with remote connections and wearable\\\\nsensor systems.\\\\nThis Handbook Part II is a continuation from the [HANDBOOK of Wearable Technology](https://www.theseus.fi/handle/10024/260641)\\\\n[Supported Home Rehabilitation Services in Rural Areas \\\\u2013 Emphasis on Monitoring Struc-](https://www.theseus.fi/handle/10024/260641)\\\\ntures and Activities of Functional Capacity, launched in 2019.\\\\n\\\\n\\\\n**5** | HANDBOOK II\\\\n\\\\n\\\\n\"}, {\"page\": 42, \"text\": \"J Med Internet Res 2020;22(5):e18378 DOI: 10.2196/18378\\\\nSl\\\\u00e1intecare Action Plan 2019. Https://www.gov.ie/en/publication/109e2b-slaintecare-actionplan-2019/\\\\nSoangra et al. (2018) Inertial Sensor-Based Variables Are Indicators of Frailty and Adverse PostOperative Outcomes in Cardiovascular Disease Patients PMID: 29865245 PMCID: PMC6021795 DOI:\\\\n10.3390/s18061792\\\\nTelehealth resource document. Https://www.aoti.ie/covid/telehealth-resource-document\\\\nTerveysportti. Kaatumisten ja kaatumisvammojen ehk\\\\u00e4isyn fysioterapiasuositus. (Fall).\\\\nhttps://www.terveysportti.fi/dtk/sfs/avaa?p_artikkeli=sfs00003\\\\nTerveysportti. Polven ja lonkan nivelrikon fysioterapiasuositus. (Arthrosis of hip and knee)\\\\nhttps://www.terveysportti.fi/dtk/sfs/avaa?p_artikkeli=sfs00001\\\\nTerveysportti. TOIMIA-tietokanta. (ICF based measures) https://www.terveysportti.fi/dtk/tmi/koti\\\\nTerveysportti. Sepelvaltimotautipotilaan liikunnallinen kuntoutus. (Cardiac).\\\\nhttps://www.terveysportti.fi/dtk/sfs/avaa?p_artikkeli=sfs00002\\\\nInternet Res. 2015 Mar; 17(3): e83. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4397389/\\\\nOutcomes of Two Simultaneously Body-Worn Motion Sensor Approaches and a Self-Estimation.\\\\nhttps://www.mdpi.com/1424-8220/20/7/1877/htm\\\\nValvira. Potilaille annettavat terveydenhuollon et\\\\u00e4palvelut. https://www.valvira.fi/terveydenhuolto/\\\\nyksityisen_terveydenhuollon_luvat/potilaille-annettavat-terveydenhuollon-etapalvelut\\\\n\\\\n\\\\nvan Egmond et al (2018). Effectiveness of physiotherapy with telerehabilitation in surgical patients: a\\\\nsystematic review and meta-analysis.\\\\nWherton, J., Shaw, S., Papoutsi, C., Seuren, L., Greenhalgh, T. (2020). Guidance on the introduction and\\\\nuse of video consultations during COVID-19: important lessons from qualitative research. https://\\\\nbmjleader.bmj.com/content/leader/4/3/120.full.pdf\\\\n\\\\n\\\\n**41** | HANDBOOK II\\\\n\\\\n\\\\n\"}, {\"page\": 43, \"text\": \"**Publications of Karelia University of Applied Sciences**\\\\n**B, Handbooks and Article collections: 68**\\\\nISBN 978-952-275-322-9\\\\nISSN-L 2323-6914\\\\nISSN 2323-6914\\\\n\\\\n\\\\n\"}]}', 'metadata': '{\"language\": \"en\", \"title\": \"Guidelines on the use of wearable sensor systems in-home rehabilitation combined with remote connections - Flowchart and Practice guideline : Handbook II\", \"creator\": [\"Alam\\\\u00e4ki, Antti\", \"Nevala, Elina\", \"Jalovaara, Juha\", \"Barton, John\", \"Condell, Joan\", \"Mu\\\\u00f1oz Esquivel, Karla\", \"Nordstr\\\\u00f6m, Anna\", \"Kelly, Daniel\", \"Heaney, David\", \"Gillespie, James\"], \"year\": \"2021\", \"publisher\": [\"Karelia University of Applied Sciences\"], \"e_isbn\": [\"9789522753229\"], \"e_issn\": \"2323-6914\", \"type_coar\": \"book\"}'}) (input_keys={'content'}): Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\\\"o} \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "Actual output fields parsed from the LM response: [] \n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 188, in parse\n",
      "    fields[k] = parse_value(v, signature.output_fields[k].annotation)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/utils.py\", line 173, in parse_value\n",
      "    return TypeAdapter(annotation).validate_python(candidate)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/pydantic/type_adapter.py\", line 421, in validate_python\n",
      "    return self.validator.validate_python(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "pydantic_core._pydantic_core.ValidationError: 2 validation errors for list[str]\n",
      "0\n",
      "  Input should be a valid string [type=string_type, input_value=['Microsoft Word - Examen...INAL - KORRIGERING 2.3'], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "1\n",
      "  Input should be a valid string [type=string_type, input_value=['Elvytyskoulutusteemapä... ylästeen oppilaille'], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 128, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 89, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 190, in parse\n",
      "    raise AdapterParseError(\n",
      "dspy.utils.exceptions.AdapterParseError: Failed to parse field alt_title with value [['Microsoft Word - Examensarbete Aöterupplivningstemadag Sirvio Wickström FINAL - KORRIGERING 2.3'], ['Elvytyskoulutusteemapäivä ylästeen oppilaille']] from the LM response. Error message: 2 validation errors for list[str]\n",
      "0\n",
      "  Input should be a valid string [type=string_type, input_value=['Microsoft Word - Examen...INAL - KORRIGERING 2.3'], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "1\n",
      "  Input should be a valid string [type=string_type, input_value=['Elvytyskoulutusteemapä... ylästeen oppilaille'], input_type=list]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "\n",
      "Adapter ChatAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: [[ ## reasoning ## ]]\n",
      "The document is a handbook about remote home rehabilitation. The main title is \"Temadag om återupplivning för högstadieelever\". The authors are Sirviö, Birger and Wickström, Jens. The publication year is 2021. The publisher is Karelia University of Applied Sciences. The document describes the use of wearable sensor systems in home rehabilitation. The type of resource is a bachelor thesis. The DOI is not available. The ISBNs are 978-952-275-322-9 and 2323-6914. The e_issn and p_issn are not available. The language is Swedish.\n",
      "[[ ## language ## ]]\n",
      "sv\n",
      "[[ ## title ## ]]\n",
      "Temadag om återupplivning för högstadieelever\n",
      "[[ ## alt_title ## ]]\n",
      "[['Microsoft Word - Examensarbete Aöterupplivningstemadag Sirvio Wickström FINAL - KORRIGERING 2.3'], ['Elvytyskoulutusteemapäivä ylästeen oppilaille']]\n",
      "[[ ## creator ## ]]\n",
      "[['Sirviö, Birger'], ['Wickström, Jens']]\n",
      "[[ ## year ## ]]\n",
      "2021\n",
      "[[ ## publisher ## ]]\n",
      "[['Karelia University of Applied Sciences']]\n",
      "[[ ## doi ## ]]\n",
      "null\n",
      "[[ ## e_isbn ## ]]\n",
      "[]\n",
      "[[ ## p_isbn ## ]]\n",
      "[]\n",
      "[[ ## e_issn ## ]]\n",
      "null\n",
      "[[ ## p_issn ## ]]\n",
      "null\n",
      "[[ ## type_coar ## ]]\n",
      "bachelor thesis\n",
      "[[ ## completed ## ]] \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 78, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n",
      "    raise e\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 128, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 89, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 172, in parse\n",
      "    raise AdapterParseError(\n",
      "dspy.utils.exceptions.AdapterParseError: Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\\\"o} \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "Actual output fields parsed from the LM response: [] \n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py\", line 55, in safe_func\n",
      "    return user_function(item)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/evaluate/evaluate.py\", line 158, in process_item\n",
      "    prediction = program(**example.inputs())\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/primitives/module.py\", line 78, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/chain_of_thought.py\", line 37, in forward\n",
      "    return self.predict(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/predict.py\", line 103, in __call__\n",
      "    return super().__call__(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/primitives/module.py\", line 78, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/predict.py\", line 192, in forward\n",
      "    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n",
      "    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n",
      "    raise e\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 128, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 89, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 172, in parse\n",
      "    raise AdapterParseError(\n",
      "dspy.utils.exceptions.AdapterParseError: Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\\\"o} \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "Actual output fields parsed from the LM response: [] \n",
      "\n",
      "\n",
      "\n",
      "2025/09/30 15:15:46 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:15:47 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:15:47 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:15:51 INFO dspy.evaluate.evaluate: Average Metric: 35.78787878787878 / 64 (55.9%)\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full valset score for new program: 0.5591856060606061\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full train_val score for new program: 0.5591856060606061\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.36363636363636365, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.36363636363636365, 0.696969696969697, 0.6363636363636364, 0.5454545454545454, 0.7878787878787878, 0.5454545454545454, 0.36363636363636365, 0.36363636363636365, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.2727272727272727, 0.0, 0.5454545454545454, 0.45454545454545453, 0.696969696969697, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.2727272727272727, 0.2727272727272727, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.45454545454545453, 0.36363636363636365, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.8181818181818182, 0.45454545454545453, 0.45454545454545453, 0.7878787878787878]\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.45454545454545453, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.7878787878787878, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.9545454545454546, 0.7727272727272727, 0.9090909090909091, 0.5454545454545454, 0.506060606060606, 0.9090909090909091, 0.45454545454545453, 1.0, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.7878787878787878, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.6060606060606061, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6666666666666666, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878]\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Full valset pareto front score: 0.688778409090909\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Updated valset pareto front programs: [{3, 6}, {3}, {0}, {0, 3}, {6}, {1, 4}, {3}, {4}, {3}, {4}, {3, 4}, {6}, {0, 3, 4, 6}, {4, 6}, {3, 4, 5}, {0}, {6}, {2, 4, 5}, {6}, {0}, {0}, {2, 3}, {0, 1, 3, 4, 6}, {3}, {0}, {4}, {0, 3}, {5}, {4}, {0, 6}, {3}, {2, 6}, {0, 2, 4, 6}, {0, 3, 6}, {0}, {5}, {5}, {0, 4, 6}, {0}, {2, 4}, {0, 1, 4}, {4}, {0, 2, 4, 6}, {0, 1}, {4}, {2, 6}, {4}, {0, 1, 2, 3, 6}, {4, 5}, {0, 4}, {0}, {3, 6}, {0}, {2, 3}, {0}, {3, 6}, {3}, {1}, {3}, {2}, {2}, {2, 4}, {3}, {6}]\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best valset aggregate score so far: 0.5903882575757575\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best program as per aggregate score on train_val: 3\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best program as per aggregate score on valset: 3\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best score on valset: 0.5903882575757575\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Best score on train_val: 0.5903882575757575\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: Linear pareto front program index: 3\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 7: New program candidate index: 6\n",
      "GEPA Optimization:  15%|█▌        | 490/3200 [14:44<1:41:54,  2.26s/rollouts]2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 8: No merge candidates found\n",
      "2025/09/30 15:15:51 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Selected program 4 score: 0.5814393939393939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.06 / 3 (35.4%): 100%|██████████| 3/3 [00:07<00:00,  2.38s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:15:58 INFO dspy.evaluate.evaluate: Average Metric: 1.0606060606060606 / 3 (35.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:17:22 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a JSON object with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata such as `title`, `author`, `creationDate`, `modDate`, etc.\n",
      "* **pages** – a list of page objects, each with a `page` number and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your task is to **scan the entire document** (all pages) and produce a **flat list of metadata fields**.  \n",
      "Each field is written on its own line, followed by the value on the next line, exactly as shown in the examples below.  \n",
      "The order of the fields is irrelevant, but the **field names and value formats must match the specification**.\n",
      "\n",
      "If a piece of information cannot be found, output the *missing‑value placeholder* described in section 3.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field name | Type | Description & formatting rules |\n",
      "|------------|------|--------------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the *document language* (`fi`, `en`, `sv`, …). Detect from the **majority of visible words** in the pages, not from PDF metadata. If the language cannot be determined, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (including subtitle, colon, punctuation, line‑breaks that belong to the same logical title). Do **not** truncate. If no title can be identified, output `None`. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a different language (e.g. an English version of a Finnish title). Do **not** repeat the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"`. Split a single‑string name on the **last space** (`\"First Middle Last\"` → `\"Last, First Middle\"`). Preserve diacritics and order. If the PDF metadata already supplies `\"Last, First\"` keep it unchanged. Separate multiple authors using commas, semicolons, or the word “and”. If none, output `[]`. |\n",
      "| **year** | integer | Publication year. Prefer a 4‑digit year found on the title page, copyright line, or imprint. If not present, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. If still missing, output `None`. |\n",
      "| **publisher** | list of strings | Publishing institution(s) **exactly as they appear** (do not translate). May be multiple (e.g. university + department). If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI string **without** any leading `doi:`, `DOI`, or URL prefix. Detect patterns beginning with `10.`. If absent, output `None`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Strip all hyphens, spaces, parentheses and keep only the digits (13‑digit ISBN). If the qualifier (e.g. “PDF”, “pdf”, “(PDF)”, “(electronic)”, “(sid.)”) is present, treat it as electronic. If the qualifier is missing, **do not guess** – place the ISBN only if the qualifier is explicit. If none, output `[]`. |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalized the same way as `e_isbn`. Qualifiers such as “Print”, “PRINT”, “(Print)”, “(painettu)”, “(sid.)” indicate print. If none, output `[]`. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalized (remove hyphens). Detect qualifiers “Online”, “PDF”, “(Online)”, “(pdf)”. If absent, output `None`. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalized. Detect qualifiers “Print”, “(Print)”, “(painettu)”. If absent, output `None`. |\n",
      "| **type_coar** | string | COAR type of the resource. Must be one of the exact lower‑case values: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `conference paper`, **`research report`**. Determine from wording on the title page or imprint (e.g. “Väitöskirja”, “Dissertation”, “Pro gradu”, “Report”, “Proceedings”). If none match, output `None`. |\n",
      "| **reasoning** (optional) | free text | A short paragraph (one or two sentences) explaining how the values were derived. This field is **optional** and does not affect scoring. |\n",
      "\n",
      "*All list values must be written as valid Python‑style lists, e.g. `['value1', 'value2']`.*\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "* Count the frequency of language‑specific stop‑words or diacritics.\n",
      "* Finnish → `fi`, English → `en`, Swedish → `sv`.  \n",
      "*If the detection is ambiguous, return `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page(s) containing the largest centered heading(s).  \n",
      "2. Capture the **entire heading line(s)** that together form the title, including any subtitle separated by a colon (`:`) or a line break that is visually part of the same block.  \n",
      "3. Preserve original capitalization, punctuation, and diacritics.  \n",
      "4. Do **not** include page numbers, section headings, or catalogue numbers.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "*Search for a title in a different language (most often English) that appears immediately below or beside the main title, or in a separate “English title” field. Add each distinct string to `alt_title`. Do not duplicate the main title.*\n",
      "\n",
      "### 2.4 Creator name handling\n",
      "* Split on the **last space** only (to keep possible middle names together).  \n",
      "* Trim surrounding whitespace.  \n",
      "* Preserve order “LastName, FirstName”.  \n",
      "* If the name already contains a comma, keep it unchanged.  \n",
      "* Example: `\"Samuli Virtanen\"` → `\"Virtanen, Samuli\"`; `\"Müller, Anna\"` → `\"Müller, Anna\"`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "* Search for a 4‑digit number (≥1900 and ≤ current year + 1) on the title page, copyright line, or imprint.  \n",
      "* If multiple candidates exist, prefer the one closest to the title.  \n",
      "* If none are found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`). Extract the `YYYY` part.  \n",
      "* Return as an integer.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "* Take the exact string(s) that appear in the imprint line, e.g. “Turun yliopisto”, “Vaasan yliopisto”, “Asumispalvelusäätiö ASPA”.  \n",
      "* If more than one institution is listed (e.g. university + department), include each as a separate element in the list, preserving the order they appear.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Look for patterns: `10.<digits>/<any non‑space characters>` possibly preceded by `doi:`, `DOI`, `https://doi.org/`, or enclosed in brackets.  \n",
      "* Return the raw DOI **without** any prefix or surrounding punctuation.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "* Identify each ISBN/ISSN line.  \n",
      "* Normalise by removing hyphens, spaces, parentheses, and any leading “ISBN” / “ISSN”.  \n",
      "* Determine the **format** (electronic vs print) from the qualifier that appears **in the same line**:  \n",
      "  * Electronic qualifiers: `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sid.” = “sähköinen”), `online`.  \n",
      "  * Print qualifiers: `Print`, `PRINT`, `painettu`, `sid.` (when paired with “Print”), `paper`.  \n",
      "* If a line contains **both** qualifiers (e.g. “ISBN 978‑... (Print) (PDF)”), add the number to **both** `e_isbn` and `p_isbn`.  \n",
      "* If no qualifier is present, **do not** add the number to any list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "| Indicator in document | COAR type to output |\n",
      "|-----------------------|--------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Contains ISBN(s) **and** no thesis wording, looks like a monograph | `book` |\n",
      "| Contains ISSN(s) and journal‑style headings, no ISBN | `article` |\n",
      "| Contains the word “Report”, “Technical report”, “Research report” | `report` (or `research report` if the word “research” is explicitly present) |\n",
      "| Mentions a conference name, “Proceedings”, “Conference paper” | `conference paper` |\n",
      "| If none of the above apply, output `None`. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line by itself, then the value on the next line, e.g.:\n",
      "\n",
      "```\n",
      "language\n",
      "fi\n",
      "title\n",
      "Elämää henkimaailman, uskonnon ja yhteiskunnan rajoilla: Etnografinen tutkimus kanavoinnista, tiedosta ja uushenkisestä yrittäjyydestä Suomessa\n",
      "alt_title\n",
      "['Life on the Boundaries of the Spirit World, Religion and Society']\n",
      "creator\n",
      "['Hulkkonen, Katriina']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Turun yliopisto']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "['9789512983735']\n",
      "p_isbn\n",
      "['9789512983728']\n",
      "e_issn\n",
      "2343191\n",
      "p_issn\n",
      "00826987\n",
      "type_coar\n",
      "doctoral thesis\n",
      "2025/09/30 15:17:30 INFO dspy.evaluate.evaluate: Average Metric: 1.7272727272727273 / 3 (57.6%)\n",
      "2025/09/30 15:18:09 INFO dspy.evaluate.evaluate: Average Metric: 23.96536796536796 / 64 (37.4%)\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Full valset score for new program: 0.37445887445887444\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Full train_val score for new program: 0.37445887445887444\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Individual valset scores for new program: [0.18181818181818182, 0.36363636363636365, 0.2424242424242424, 0.2727272727272727, 0.6363636363636364, 0.3333333333333333, 0.2727272727272727, 0.45454545454545453, 0.36363636363636365, 0.3333333333333333, 0.4090909090909091, 0.45454545454545453, 0.2727272727272727, 0.18181818181818182, 0.6363636363636364, 0.2727272727272727, 0.18181818181818182, 0.3896103896103896, 0.45454545454545453, 0.36363636363636365, 0.36363636363636365, 0.2424242424242424, 0.6363636363636364, 0.4090909090909091, 0.22727272727272727, 0.36363636363636365, 0.36363636363636365, 0.36363636363636365, 0.5454545454545454, 0.09090909090909091, 0.45454545454545453, 0.5454545454545454, 0.36363636363636365, 0.36363636363636365, 0.09090909090909091, 0.5454545454545454, 0.2727272727272727, 0.36363636363636365, 0.36363636363636365, 0.36363636363636365, 0.2424242424242424, 0.45454545454545453, 0.2727272727272727, 0.2727272727272727, 0.36363636363636365, 0.3181818181818182, 0.8181818181818182, 0.2727272727272727, 0.45454545454545453, 0.6363636363636364, 0.6363636363636364, 0.18181818181818182, 0.09090909090909091, 0.2727272727272727, 0.2727272727272727, 0.18181818181818182, 0.36363636363636365, 0.45454545454545453, 0.18181818181818182, 0.7272727272727273, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.2727272727272727]\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.45454545454545453, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.7878787878787878, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.7727272727272727, 0.9090909090909091, 0.5454545454545454, 0.506060606060606, 0.9090909090909091, 0.45454545454545453, 1.0, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.7878787878787878, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6666666666666666, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.7878787878787878]\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Full valset pareto front score: 0.7020359848484848\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Updated valset pareto front programs: [{3, 6}, {3}, {0}, {0, 3}, {6}, {1, 4}, {3}, {4}, {3}, {4}, {3, 4}, {6}, {0, 3, 4, 6}, {4, 6}, {7}, {0}, {6}, {2, 4, 5}, {6}, {0}, {0}, {2, 3}, {7}, {3}, {0}, {4}, {0, 3}, {5}, {4}, {0, 6}, {3}, {2, 6}, {0, 2, 4, 6}, {0, 3, 6}, {0}, {5}, {5}, {0, 4, 6}, {0}, {2, 4}, {0, 1, 4}, {4}, {0, 2, 4, 6}, {0, 1}, {4}, {2, 6}, {7}, {0, 1, 2, 3, 6}, {4, 5}, {0, 4, 7}, {0}, {3, 6}, {0}, {2, 3}, {0}, {3, 6}, {3}, {1}, {3}, {7}, {2}, {7}, {7}, {6}]\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best valset aggregate score so far: 0.5903882575757575\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best program as per aggregate score on train_val: 3\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best program as per aggregate score on valset: 3\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best score on valset: 0.5903882575757575\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Best score on train_val: 0.5903882575757575\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: Linear pareto front program index: 3\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 8: New program candidate index: 7\n",
      "GEPA Optimization:  18%|█▊        | 560/3200 [17:02<1:34:54,  2.16s/rollouts]2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 9: No merge candidates found\n",
      "2025/09/30 15:18:09 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Selected program 3 score: 0.5903882575757575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.23 / 3 (74.2%): 100%|██████████| 3/3 [00:06<00:00,  2.27s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:18:16 INFO dspy.evaluate.evaluate: Average Metric: 2.2272727272727275 / 3 (74.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:19:31 INFO dspy.teleprompt.gepa.gepa: Iteration 9: Proposed new text for predict: text\n",
      "**Task Overview**\n",
      "\n",
      "You are given a JSON representation of a PDF document.  \n",
      "The JSON has two top‑level keys:\n",
      "\n",
      "* `pdfinfo` – contains metadata such as `author`, `creationDate`, `modDate`.\n",
      "* `pages` – a list of page objects, each with `page` (number) and `text` (the OCR‑extracted plain text of that page).\n",
      "\n",
      "From this information you must extract a fixed set of bibliographic fields and output them **exactly** in the order and format shown in the examples:\n",
      "\n",
      "```\n",
      "language\n",
      "<value>\n",
      "title\n",
      "<value>\n",
      "alt_title\n",
      "<value>\n",
      "creator\n",
      "<value>\n",
      "year\n",
      "<value>\n",
      "publisher\n",
      "<value>\n",
      "doi\n",
      "<value>\n",
      "e_isbn\n",
      "<value>\n",
      "p_isbn\n",
      "<value>\n",
      "e_issn\n",
      "<value>\n",
      "p_issn\n",
      "<value>\n",
      "type_coar\n",
      "<value>\n",
      "2025/09/30 15:19:37 INFO dspy.evaluate.evaluate: Average Metric: 1.909090909090909 / 3 (63.6%)\n",
      "2025/09/30 15:19:37 INFO dspy.teleprompt.gepa.gepa: Iteration 9: New subsample score is not better, skipping\n",
      "GEPA Optimization:  18%|█▊        | 566/3200 [18:30<1:57:10,  2.67s/rollouts]2025/09/30 15:19:37 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Selected program 4 score: 0.5814393939393939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.73 / 3 (57.6%): 100%|██████████| 3/3 [00:05<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:19:43 INFO dspy.evaluate.evaluate: Average Metric: 1.7272727272727275 / 3 (57.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:21:02 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a **single JSON object** that contains:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).\n",
      "* **pages** – list of page objects, each with a `page` number and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your task is to **parse this information and output a flat list of metadata fields** (one field per line, exactly as shown in the examples). The output must be ready to be turned into a JSON record later.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the majority of visible words, not from PDF metadata. |\n",
      "| **title** | string or `None` | Full title exactly as it appears on the title page (including subtitle, colon, line‑breaks that belong to the same logical title). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"`. Split single‑string names on the **last** space; keep already‑comma‑separated names unchanged. Separate multiple authors by commas, semicolons, ampersand (`&`), or the word “and”. Preserve the order they appear. |\n",
      "| **year** | integer or `None` | Publication year. Prefer a 4‑digit year found on the title page, copyright line, or in the PDF’s `creationDate`/`modDate`. |\n",
      "| **publisher** | list of strings | Publishing institution exactly as it appears (do **not** translate). If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI without any prefix (`10.` …). Detect patterns like `doi:10.xxxx/…`, `DOI 10.xxxx/…`, or URLs such as `https://doi.org/10.xxxx/…`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing all hyphens, spaces and surrounding parentheses**; keep only the digit string (13‑digit for ISBN‑13, 10‑digit for ISBN‑10). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. |\n",
      "| **type_coar** | string or `None` | COAR resource type. Use **exactly one** of the following lower‑case values: `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book review`, `article`, `report`, `conference paper`. Determine from explicit wording on the title page or elsewhere (see mapping rules below). |\n",
      "| **reasoning** *(optional)* | free text | A short paragraph (one or two sentences) explaining how you derived the values. This field is optional and does not affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Every field name appears on its own line, **exactly** as shown above.\n",
      "* The value appears on the next line.\n",
      "* Python‑style list syntax must be used, e.g. `['value1', 'value2']`.\n",
      "* `None` is written literally (no quotes).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan all `pages[*].text`. Count occurrences of language‑specific stop‑words:\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, etc.\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, etc.\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, etc.\n",
      "2. Choose the language with the highest count. If counts are tied or no clear majority, fall back to `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **first page that contains a line in ALL CAPS or a line with a much larger font hint (e.g., surrounded by `#` or `##` in the extracted text).  \n",
      "2. Take that line and, if the next line(s) are part of the same logical heading (e.g., a subtitle after a colon or a line break without a blank line), concatenate them with a space.\n",
      "3. Preserve punctuation, diacritics, and original language exactly as they appear.\n",
      "4. Do **not** include page numbers, section headings, or footers.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* If the document contains a second title in a different language (often labelled “Title (English)”, “English title”, “Original title”, etc.), capture it as a separate string in `alt_title`.\n",
      "* Do not duplicate the main `title`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "* Identify author lines: look for keywords `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:` , `Authors:` , `Tekijät:`, `Opiskelijat`, etc.\n",
      "* Split multiple authors using any of the delimiters: `,`, `;`, `&`, `and`.\n",
      "* For each name:\n",
      "  * If it already contains a comma, keep as‑is (assumed `Last, First`).\n",
      "  * Otherwise split on the **last** space: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "* Preserve diacritics and original case.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Search the title page (first 2 pages) for a 4‑digit number that looks like a year (1900‑2100).  \n",
      "2. If none, look for a line containing `©` or `Copyright` followed by a year.  \n",
      "3. If still not found, use `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`). Extract the `YYYY` part.  \n",
      "4. Return as an integer; if no year can be found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "* Look for lines containing words like `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Julkaisija`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, etc.\n",
      "* Capture the **full phrase** exactly as it appears (including abbreviations, hyphens, and diacritics).  \n",
      "* If more than one distinct publisher appears, list them all in order of appearance.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Regex pattern: `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`\n",
      "* Return only the captured DOI (without surrounding whitespace or punctuation).\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "* Search for patterns containing `ISBN` or `ISSN`.  \n",
      "* Determine the qualifier:\n",
      "  * `(PDF)`, `e‑ISBN`, `Electronic`, `Online` → **electronic** (`e_isbn` or `e_issn`).  \n",
      "  * `Print`, `Hardcover`, `Paperback`, `Print version` → **print** (`p_isbn` or `p_issn`).  \n",
      "  * If no qualifier, place the ISBN/ISSN in **both** lists.\n",
      "* Normalise by stripping everything except digits (for ISBN) or digits (for ISSN, exactly 8 digits).  \n",
      "* Return as strings without hyphens.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "| Keyword(s) found in document | `type_coar` value |\n",
      "|------------------------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, plus a publisher that is a book‑publisher | `book` |\n",
      "| “Book review”, “Recension”, “Review of” (and a DOI that resolves to a journal) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| If none of the above apply, output `None`. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "2025/09/30 15:21:08 INFO dspy.evaluate.evaluate: Average Metric: 2.2727272727272725 / 3 (75.8%)\n",
      "2025/09/30 15:21:41 INFO dspy.evaluate.evaluate: Average Metric: 41.350937950937954 / 64 (64.6%)\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New program is on the linear pareto front\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset score for new program: 0.6461084054834055\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full train_val score for new program: 0.6461084054834055\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.7792207792207791, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7727272727272727, 0.8181818181818182, 0.9090909090909091, 0.36363636363636365, 0.5363636363636364, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.9090909090909091, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.45454545454545453, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.36363636363636365, 0.45454545454545453, 0.36363636363636365, 0.7272727272727273, 0.6363636363636364, 0.7171717171717172, 0.45454545454545453, 0.5454545454545454, 0.8181818181818182]\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.7878787878787878, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.5363636363636364, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Full valset pareto front score: 0.7278409090909091\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Updated valset pareto front programs: [{8, 3, 6}, {3}, {0}, {8}, {6}, {8, 1, 4}, {8, 3}, {8}, {3}, {4}, {8, 3, 4}, {8}, {8}, {8, 4, 6}, {7}, {0, 8}, {8, 6}, {2, 4, 5}, {6}, {0}, {0}, {2, 3}, {8, 7}, {3}, {8}, {8, 4}, {0, 3}, {8}, {8, 4}, {8}, {3}, {2, 6}, {8}, {8}, {8}, {5}, {5}, {8}, {0}, {2, 4}, {8}, {8, 4}, {0, 2, 4, 6, 8}, {8}, {4}, {2, 6}, {7}, {0, 1, 2, 3, 6, 8}, {8, 4, 5}, {8}, {0}, {3, 6}, {0}, {2, 3}, {8}, {3, 6}, {3}, {1}, {8}, {7}, {2}, {7}, {7}, {8}]\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best valset aggregate score so far: 0.6461084054834055\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on train_val: 8\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best program as per aggregate score on valset: 8\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on valset: 0.6461084054834055\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Best score on train_val: 0.6461084054834055\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: Linear pareto front program index: 8\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 10: New program candidate index: 8\n",
      "GEPA Optimization:  20%|█▉        | 636/3200 [20:35<1:38:34,  2.31s/rollouts]2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 11: No merge candidates found\n",
      "2025/09/30 15:21:41 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Selected program 8 score: 0.6461084054834055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:21:47 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:23:28 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line). The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | string or `None` | Full main title exactly as it appears on the title page, including subtitle(s) that belong to the same logical heading. |\n",
      "| `alt_title` | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | integer or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | list of strings | Publishing institution(s) exactly as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version, normalized to a plain digit string (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | string or `None` | COAR resource type, one of the **lower‑case** values listed in **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The value on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes) for missing values.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use the following small seed lists (feel free to extend them if needed):\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`.\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`.\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`.\n",
      "2. If any page contains an explicit language line such as `Kieli: suomi`, `Language: English`, `Språk: svenska`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv` respectively) **overriding** the stop‑word count.\n",
      "3. Choose the language with the highest count. If there is a tie or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – usually the first page that contains a line in **ALL CAPS** or a line that is surrounded by markdown heading markers (`#`, `##`, `###`).  \n",
      "   * In OCR output, headings are often preceded/followed by blank lines; treat a line that is the **only non‑blank line** on the page (or the first non‑blank line) and is in all caps as the title line.\n",
      "2. **Capture the full logical title**:\n",
      "   * If the next line(s) are a subtitle (no blank line between them, or the subtitle follows a colon), concatenate them with a single space.\n",
      "   * Preserve all original punctuation, diacritics, and case.\n",
      "3. **Do not** include page numbers, section headings, footers, or any surrounding markers (`#`, `##`). Strip surrounding whitespace only.\n",
      "4. If the document contains a *second* title in another language (often labelled “Title (English)”, “English title”, “Original title”, etc.), capture that in `alt_title` (see 2.3).\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier (e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”).  \n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.  \n",
      "* Do **not** duplicate the main `title`. If multiple alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "     * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the first two pages for a four‑digit number between 1900 and 2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing the word `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, etc.\n",
      "3. If still not found, fall back to the PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an integer; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, `Routledge`, `Springer`, etc.\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation).  \n",
      "   * Example: `Publisher: Routledge` → `Routledge`.\n",
      "   * Example: `Metropolia Ammattikorkeakoulu` (appears alone) → `Metropolia Ammattikorkeakoulu`.\n",
      "3. If more than one distinct publisher appears, list them in order of appearance.\n",
      "4. If no publisher can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Use the regex (case‑insensitive):  \n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "* Capture group 1 is the DOI. Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Extract the numeric identifier that follows, which may be surrounded by hyphens, spaces, or parentheses, e.g. `ISBN 978‑952‑302‑949‑1`, `(ISBN: 978 952 302 949 1)`, `URN:ISBN:978-952-302-949-1`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * Electronic indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * Print indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "   * If no qualifier is present, **add the identifier to both** `e_isbn` (or `e_issn`) **and** `p_isbn` (or `p_issn`).\n",
      "4. **Normalisation**:  \n",
      "   * For ISBN – keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * For ISSN – keep exactly 8 digits (remove hyphens).  \n",
      "5. Return each list with unique values (order of first appearance). If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Detect the resource type by searching for the following keywords (case‑insensitive) **anywhere** in the document. Use the **first matching row** in the table below (top‑to‑bottom priority). If multiple match, the earliest in the list wins.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and contains a journal identifier) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., `doi.org/10.1007/…` with a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "```\n",
      "\n",
      "If you want to include a short explanation, add a `reasoning` field after the last required field:\n",
      "\n",
      "```\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "2025/09/30 15:23:34 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n",
      "2025/09/30 15:24:08 INFO dspy.evaluate.evaluate: Average Metric: 40.783333333333324 / 64 (63.7%)\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Full valset score for new program: 0.6372395833333333\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Full train_val score for new program: 0.6372395833333333\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Individual valset scores for new program: [0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.6818181818181818, 0.7272727272727273, 0.7272727272727273, 0.45454545454545453, 0.6090909090909091, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.9090909090909091, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.45454545454545453, 0.9090909090909091, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.36363636363636365, 0.5454545454545454, 0.5151515151515151, 0.5454545454545454, 0.6363636363636364, 0.7045454545454546, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182]\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Full valset pareto front score: 0.7294507575757576\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Updated valset pareto front programs: [{8, 3, 6}, {3}, {0}, {8}, {6}, {8, 1, 4}, {8, 3}, {8, 9}, {3}, {4}, {8, 9, 3, 4}, {8}, {8}, {8, 9, 4, 6}, {9, 7}, {0, 8, 9}, {8, 6}, {2, 4, 5}, {9}, {0}, {0}, {2, 3}, {8, 7}, {3}, {8}, {8, 4}, {0, 3}, {9}, {8, 4}, {8}, {3}, {9, 2, 6}, {8, 9}, {8}, {8}, {5}, {5}, {8, 9}, {0}, {2, 4}, {8, 9}, {8, 9, 4}, {0, 2, 4, 6, 8, 9}, {8}, {9, 4}, {2, 6}, {7}, {0, 1, 2, 3, 6, 8, 9}, {8, 9, 4, 5}, {8}, {0}, {9, 3, 6}, {0}, {2, 3}, {8, 9}, {3, 6}, {9, 3}, {1}, {8}, {7}, {2}, {7}, {7}, {8, 9}]\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best valset aggregate score so far: 0.6461084054834055\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best program as per aggregate score on train_val: 8\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best program as per aggregate score on valset: 8\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best score on valset: 0.6461084054834055\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Best score on train_val: 0.6461084054834055\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: Linear pareto front program index: 8\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 11: New program candidate index: 9\n",
      "GEPA Optimization:  22%|██▏       | 706/3200 [23:01<1:32:42,  2.23s/rollouts]2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 12: No merge candidates found\n",
      "2025/09/30 15:24:08 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Selected program 9 score: 0.6372395833333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.15 / 3 (71.7%): 100%|██████████| 3/3 [00:08<00:00,  2.86s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:24:17 INFO dspy.evaluate.evaluate: Average Metric: 2.1515151515151514 / 3 (71.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:25:46 INFO dspy.teleprompt.gepa.gepa: Iteration 12: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"pdfinfo\": {               // optional, may be missing or empty\n",
      "    \"author\": \"...\",\n",
      "    \"title\": \"...\",\n",
      "    \"creationDate\": \"D:YYYYMMDD…\",\n",
      "    \"modDate\": \"D:YYYYMMDD…\",\n",
      "    ...\n",
      "  },\n",
      "  \"pages\": [\n",
      "    {\"page\": 1, \"text\": \"...\"},\n",
      "    {\"page\": 2, \"text\": \"...\"},\n",
      "    ...\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "`pages[*].text` contains the raw OCR / clipboard text of each page (line breaks are preserved).  \n",
      "Your job is to **produce a flat list of metadata fields** (one field name on a line, its value on the next line) that can later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Missing‑value placeholder |\n",
      "|------------|------|---------------------------|\n",
      "| `language` | `str` or `None` | `None` |\n",
      "| `title` | `str` or `None` | `None` |\n",
      "| `alt_title` | `list[str]` | `[]` |\n",
      "| `creator` | `list[str]` | `[]` |\n",
      "| `year` | `int` or `None` | `None` |\n",
      "| `publisher` | `list[str]` | `[]` |\n",
      "| `doi` | `str` or `None` | `None` |\n",
      "| `e_isbn` | `list[str]` | `[]` |\n",
      "| `p_isbn` | `list[str]` | `[]` |\n",
      "| `e_issn` | `str` or `None` | `None` |\n",
      "| `p_issn` | `str` or `None` | `None` |\n",
      "| `type_coar` | `str` or `None` | `None` |\n",
      "| `reasoning` *(optional)* | `str` | – |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name **exactly** as shown (e.g. `language`).\n",
      "* Value on the next line.\n",
      "* Python‑style list syntax, e.g. `['First', 'Second']`.\n",
      "* Use the literal `None` (no quotes) for missing values.\n",
      "* Do **not** add extra whitespace before/after values except inside strings/lists where it belongs.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & Normalisation Rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** pages for an explicit language line:\n",
      "   * `Kieli: suomi` → `fi`\n",
      "   * `Language: English` → `en`\n",
      "   * `Språk: svenska` → `sv`\n",
      "   * Any of the three patterns overrides everything else.\n",
      "2. If no explicit line, count occurrences of the stop‑word seeds (case‑insensitive):\n",
      "\n",
      "| ISO‑code | Seed words (case‑insensitive) |\n",
      "|----------|--------------------------------|\n",
      "| `fi` | käsittely, tutkimus, opinnäytetyö, väitöskirja, kieli, julkaistu |\n",
      "| `sv` | och, för, av, liv, historien, språk |\n",
      "| `en` | the, and, of, method, introduction, chapter |\n",
      "\n",
      "3. Choose the language with the highest count. If there is a tie or no hits → `None`.\n",
      "\n",
      "### 2.2 Title extraction (main title)\n",
      "1. **Identify the title page** – the first page that satisfies **any** of the following:\n",
      "   * Contains a line **in ALL CAPS** (ignore surrounding whitespace).  \n",
      "   * Starts with a Markdown heading marker (`#`, `##`, `###`).  \n",
      "   * Consists of a single non‑blank line (or the first non‑blank line) that is in all caps.\n",
      "2. **Capture the full logical title**:\n",
      "   * If the line(s) immediately **below** the title line (no blank line between them) look like a subtitle (e.g. start after a colon, or are shorter), concatenate them with a single space.  \n",
      "   * Preserve original punctuation, diacritics, and case.\n",
      "3. Strip any surrounding heading markers (`#`, `##`, `###`) and surrounding whitespace **only**.\n",
      "4. Do **not** include page numbers, footers, or surrounding section headings.\n",
      "5. If no title can be found → `None`.\n",
      "\n",
      "### 2.3 Alternate title(s)\n",
      "1. Look for lines containing a language qualifier such as:\n",
      "   * `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Title (Finnish)`, etc.\n",
      "2. The actual title text follows the qualifier on the same line **or** on the next line (again, no blank line in between). Apply the same concatenation rule as in 2.2.\n",
      "3. Do **not** duplicate the main `title`. If several alternate titles exist, list them all in a Python list.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. Search for lines containing any of these keywords (case‑insensitive):\n",
      "   * `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. The line may contain a list of names separated by **any** of:\n",
      "   `, ; & and ja och` (the word `and` may be surrounded by spaces).  \n",
      "   Example delimiters: `;`, `,`, `&`, `and`, `ja`, `och`.\n",
      "3. For each name:\n",
      "   * If it already contains a comma, assume it is in `Last, First` order → keep unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list. If no author line is found → `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **pages 1‑2** for a four‑digit number between 1900‑2100.\n",
      "2. Prefer a number that appears on a line containing any of these keywords (case‑insensitive):\n",
      "   `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`.\n",
      "3. If still not found, fall back to PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract `YYYY`.\n",
      "4. Return the year as an integer; if none → `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of these keywords (case‑insensitive):\n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus known publisher names (e.g. `Routledge`, `Springer`, `Cambridge`, `Elsevier`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as `.` `,` `;`).\n",
      "   * If the line consists *only* of a proper name (e.g. `Metropolia Ammattikorkeakoulu`) without a preceding keyword, treat it as a publisher.\n",
      "3. Keep each distinct publisher in order of first appearance. Return a list; if none → `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex:\n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1.\n",
      "* Strip surrounding whitespace, commas, periods, parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL).  \n",
      "* If none found → `None`.\n",
      "\n",
      "### 2.8 ISBN & ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. After each occurrence, extract the numeric identifier that follows, allowing hyphens, spaces, or parentheses.  \n",
      "   Example patterns: `ISBN 978‑952‑302‑949‑1`, `(ISBN: 978 952 302 949 1)`, `URN:ISBN:978-952-302-949-1`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * Electronic indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * Print indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "   * If a qualifier is present, add the identifier **only** to the corresponding list.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn` and `p_isbn` (or both ISSN lists).\n",
      "4. **Normalisation**  \n",
      "   * **ISBN**: keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN**: keep exactly 8 digits (remove hyphens).  \n",
      "5. Return each list with **unique** values preserving first‑appearance order. If none → `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (including metadata) for the keywords below (case‑insensitive). Use the **first matching row** in the table (top‑to‑bottom priority). If multiple rows match, the earliest row wins.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI contains a journal prefix) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (publisher is a book‑publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly the placeholder shown in the table of §1 (e.g. `None` or `[]`).\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Towards academic publishing in medias res\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Elo, Mika']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Vita e Pensiero']\n",
      "doi\n",
      "10.26350/001200_000107\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "1827-7969\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "article\n",
      "reasoning\n",
      "Language was taken from the explicit line “Kieli: suomi” → fi, but stop‑words gave en, so we kept en. The title was the all‑caps line on page 1. Author line gave “Elo, Mika”. Year came from © 2021 on page 1. Publisher was the line containing “Vita e Pensiero”. DOI was extracted with the regex. ISSN was found after “_ISSN_ : 03928667 (print) 18277969 (digital)”. No ISBNs were present. The presence of an ISSN and the word “article” gave COAR type “article”.\n",
      "2025/09/30 15:25:57 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n",
      "2025/09/30 15:25:57 INFO dspy.teleprompt.gepa.gepa: Iteration 12: New subsample score is not better, skipping\n",
      "GEPA Optimization:  22%|██▏       | 712/3200 [24:50<2:00:49,  2.91s/rollouts]2025/09/30 15:25:57 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Selected program 8 score: 0.6461084054834055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.7%): 100%|██████████| 3/3 [00:04<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:26:02 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:27:38 INFO dspy.teleprompt.gepa.gepa: Iteration 13: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** containing:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).\n",
      "* **pages** – list of page objects, each with a `page` number and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your task is to **parse this information and output a flat list of metadata fields** (one field per line, exactly as shown in the examples). The output must be ready to be turned into a JSON record later.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the majority of visible words, **not** from PDF metadata. |\n",
      "| **title** | string or `None` | Full title exactly as it appears on the title page (including subtitle, colon, line‑breaks that belong to the same logical title). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (see splitting rules below). Preserve the order they appear. |\n",
      "| **year** | integer or `None` | Publication year (4‑digit, 1900‑2100). |\n",
      "| **publisher** | list of strings | Publishing institution(s) exactly as they appear (do **not** translate). |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalised: remove hyphens, spaces, surrounding parentheses; keep only the digit string (13‑digit for ISBN‑13, 10‑digit for ISBN‑10). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be **exactly one** of: `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book review`, `article`, `report`, `research report`, `conference paper`. |\n",
      "| **reasoning** *(optional)* | free text | One‑ or two‑sentence paragraph explaining how you derived the values. This field is optional and does not affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Every field name appears on its own line, **exactly** as shown above.\n",
      "* The value appears on the **next line**.\n",
      "* Python‑style list syntax must be used, e.g. `['value1', 'value2']`.\n",
      "* `None` is written literally (no quotes).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words:\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `yliopisto`, `julkaisija`.\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `universitet`, `utbildning`.\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `research`, `university`, `analysis`.\n",
      "\n",
      "2. Choose the language with the highest count. If counts are tied or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **first page** that contains a line that is either:\n",
      "   * In **ALL CAPS**, or\n",
      "   * Marked as a markdown heading (`#`, `##`, `###`, etc.) with a relatively large font hint (surrounded by `#` characters in the extracted text).\n",
      "\n",
      "2. Take that line as the **main title**.  \n",
      "   *If the next line(s) are part of the same logical heading* (e.g., a subtitle after a colon, or a line directly below without a blank line), concatenate them with a single space.\n",
      "\n",
      "3. Strip any surrounding whitespace, page numbers, section headings, footers, or decorative characters (`*`, `_`, etc.). Preserve punctuation, diacritics, and original language exactly.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for a second title that is explicitly labelled as “Title (English)”, “English title”, “Original title”, “Original title (Finnish)”, etc.  \n",
      "* Capture it as a separate string in `alt_title`.  \n",
      "* Do **not** duplicate the main `title`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Locate author lines by searching for keywords (case‑insensitive): `Author`, `Authors`, `Förrättare`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`.  \n",
      "2. Extract the text after the keyword up to the end of the line (or up to a line break if the name continues on the next line).  \n",
      "3. Split multiple authors using any of the delimiters: `,`, `;`, `&`, the word `and`. Preserve the order they appear.  \n",
      "4. For each individual name:\n",
      "   * If it already contains a comma, keep it unchanged (assumed `Last, First`).  \n",
      "   * Otherwise split on the **last** space: `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Preserve diacritics and original capitalisation.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Search the **first two pages** for a 4‑digit number that looks like a year (1900‑2100).  \n",
      "2. If none, look for a line containing `©` or the word `Copyright` followed by a year.  \n",
      "3. If still not found, use `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`). Extract the `YYYY` part.  \n",
      "4. Return the year as an **integer**; if no year can be found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Scan all pages for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `College`, `School`, `Institute for`, `Institute of`.  \n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (or up to a line break).  \n",
      "3. If multiple distinct publishers appear, list them in order of appearance.  \n",
      "4. Do **not** modify the captured text (keep hyphens, abbreviations, diacritics, etc.).\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Use the regex (case‑insensitive): `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "* Return only the captured DOI (strip surrounding whitespace or punctuation).  \n",
      "* If no DOI is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search for patterns containing the words `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Determine the **qualifier** from surrounding text:\n",
      "   * Electronic / online qualifiers: `(PDF)`, `e‑ISBN`, `Electronic`, `Online`, `online`, `e‑ISSN`.\n",
      "   * Print qualifiers: `Print`, `Hardcover`, `Paperback`, `Print version`, `print`, `Hardcover`, `Paperback`.\n",
      "   * If **no qualifier** is present, place the identifier in **both** the electronic and print lists (or both ISSN fields).  \n",
      "\n",
      "3. Extract the numeric part:\n",
      "   * For ISBN: keep only digits (10‑ or 13‑digit). Remove hyphens, spaces, and any surrounding parentheses.\n",
      "   * For ISSN: keep exactly 8 digits (remove hyphens).  \n",
      "\n",
      "4. Add each cleaned identifier to the appropriate list (`e_isbn`, `p_isbn`, `e_issn`, `p_issn`).  \n",
      "5. Preserve the order of appearance; duplicate values are allowed if they appear separately with different qualifiers.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "| Keyword(s) found in document | `type_coar` value |\n",
      "|------------------------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, plus a publisher that is a book‑publisher | `book` |\n",
      "| “Book review”, “Recension”, “Review of” (and a DOI that resolves to a journal) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN | `article` |\n",
      "| “Report”, “Technical report”, “Research report” **or** the phrase “Research Discussion Paper” | `report` |\n",
      "| “Research report”, “Research paper”, “Discussion paper” (explicitly labelled as a research report) | `research report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| If none of the above apply, output `None`. |\n",
      "\n",
      "*The mapping is case‑insensitive and should match whole words (e.g., “report” should not match “reporter”).*\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "2025/09/30 15:27:43 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/09/30 15:27:43 INFO dspy.teleprompt.gepa.gepa: Iteration 13: New subsample score is not better, skipping\n",
      "GEPA Optimization:  22%|██▏       | 718/3200 [26:36<2:35:50,  3.77s/rollouts]2025/09/30 15:27:43 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Selected program 9 score: 0.6372395833333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:07<00:00,  2.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:27:51 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:29:52 INFO dspy.teleprompt.gepa.gepa: Iteration 14: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line). The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). |\n",
      "| `title` | string or `None` | Full main title exactly as it appears on the title page, including subtitle(s) that belong to the same logical heading. |\n",
      "| `alt_title` | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). |\n",
      "| `year` | integer or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | list of strings | Publishing institution(s) exactly as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version, normalized to a plain digit string (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | string or `None` | COAR resource type, one of the **lower‑case** values listed in **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The value on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes) for missing values.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`.  \n",
      "2. If a line matches one of the explicit language markers (case‑insensitive):\n",
      "   * `Kieli: suomi` → `fi`\n",
      "   * `Language: English` → `en`\n",
      "   * `Språk: svenska` → `sv`  \n",
      "   treat it as a **strong signal** and **override** everything else.\n",
      "3. Otherwise count occurrences of the following stop‑word seeds (case‑insensitive). The language with the highest count wins. If there is a tie or no matches, output `None`.\n",
      "\n",
      "| Language | Seed words |\n",
      "|----------|------------|\n",
      "| `fi` | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu` |\n",
      "| `sv` | `och`, `för`, `av`, `liv`, `historien`, `språk` |\n",
      "| `en` | `the`, `and`, `of`, `method`, `introduction`, `chapter` |\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – usually the first page that contains a *heading*:\n",
      "   * A line preceded by markdown heading markers (`#`, `##`, `###`) – **strip the markers** and treat the remaining text as the title line.\n",
      "   * OR a line that is the **only non‑blank line** (or the first non‑blank line) on the page and is **not** a known heading like “Report”, “Thesis”, “Abstract”, etc.\n",
      "2. **Capture the full logical title**:\n",
      "   * If the next line (or the same line after a colon) is non‑blank and looks like a subtitle (i.e. it does **not** start with “Author”, “Publisher”, “©”, etc.), concatenate it to the title with a single space.\n",
      "   * Preserve original punctuation, diacritics, and case.\n",
      "3. Remove any surrounding markdown markers, page numbers, footers, or surrounding whitespace.\n",
      "4. If the document contains a *second* title in another language (often labelled “Title (English)”, “English title”, “Original title”, etc.), **do not** use it for `title`; store it in `alt_title` (see 2.3).\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier (case‑insensitive) such as:\n",
      "  * `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Originaltitel (Finnish)`, etc.\n",
      "* The text **following** the qualifier (same line, or the next non‑blank line) is the alternate title.\n",
      "* Apply the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for author lines. Typical keywords (case‑insensitive):\n",
      "   * `Author`, `Authors`, `Author(s)`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: `,`, `;`, `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **first two pages** for a four‑digit number between 1900 and 2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of the following keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Vuodelta`.\n",
      "3. If a year is found **and** it also appears in the PDF metadata (`pdfinfo.creationDate` or `pdfinfo.modDate`), use the year from the text.  \n",
      "   If the year appears **only** in the metadata and **not** in the visible text, output `None` (the metadata is considered unreliable unless corroborated by the document).\n",
      "4. Return the year as an integer; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive):\n",
      "   * `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, `Routledge`, `Springer`, `Elsevier`, `Cambridge`, `Oxford`, `Wiley`, etc.\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation).  \n",
      "   * If the line consists solely of an institution name (e.g. `Turun yliopisto`, `University of Helsinki`, `Taideyliopisto`), treat that as the publisher.\n",
      "3. If more than one distinct publisher appears, list them **in order of first appearance**.\n",
      "4. Do **not** include printing houses or distribution companies **unless** they are the only publisher mentioned.\n",
      "5. If no publisher can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Use the regex (case‑insensitive):  \n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "* Capture group 1, then strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Extract the numeric identifier that follows, which may be surrounded by hyphens, spaces, or parentheses, e.g. `ISBN 978‑952‑302‑949‑1`, `(ISBN: 978 952 302 949 1)`, `URN:ISBN:978-952-302-949-1`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * Electronic indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkoaineisto`, `online`.\n",
      "   * Print indicators (case‑insensitive): `Print`, `PRINT`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to the corresponding list(s).  \n",
      "   * If **no** qualifier is present, add the identifier to **both** `e_isbn` (or `e_issn`) **and** `p_isbn` (or `p_issn`).\n",
      "4. **Normalisation**:  \n",
      "   * ISBN – keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * ISSN – keep exactly 8 digits (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Detect the resource type by searching for the following keywords (case‑insensitive) **anywhere** in the document. Use the **first matching row** in the table below (top‑to‑bottom priority). If multiple rows match, the earliest row wins.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, “Master‑thesis” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, “Doctoral‑thesis” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma”, “B.Sc. thesis” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge, Oxford, Wiley, Elsevier) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and the surrounding text mentions a journal) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report”, “Raportti”, “Rapport” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag”, “Konferenspaper” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest; the title was taken from the first markdown heading; the author line provided a single name that was converted to “Last, First”; the year 2021 appeared on the copyright line; no DOI, ISBN or ISSN were found; the document contains the word “Master’s thesis”, so the COAR type is “master thesis”.\n",
      "2025/09/30 15:29:58 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n",
      "2025/09/30 15:29:58 INFO dspy.teleprompt.gepa.gepa: Iteration 14: New subsample score is not better, skipping\n",
      "GEPA Optimization:  23%|██▎       | 724/3200 [28:51<3:34:21,  5.19s/rollouts]2025/09/30 15:29:58 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Selected program 7 score: 0.37445887445887444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 0.91 / 3 (30.3%): 100%|██████████| 3/3 [00:08<00:00,  2.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:30:07 INFO dspy.evaluate.evaluate: Average Metric: 0.9090909090909092 / 3 (30.3%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:31:52 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a **single JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata such as `title`, `author`, `creationDate`, `modDate`, etc.\n",
      "* **pages** – a list of page objects, each with a `page` number (integer) and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and produce a **flat list of metadata fields**.  \n",
      "Each field name is written on its own line, followed by its value on the next line, exactly as shown in the *Output format* section.\n",
      "\n",
      "All list values must be valid Python‑style lists (single quotes, commas, no trailing commas).  \n",
      "If a piece of information cannot be found, output the *missing‑value placeholder* described in the *Missing‑value handling* table.\n",
      "\n",
      "Below are the complete extraction rules, normalization steps, and common pitfalls to avoid.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the **document language** (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** in the pages (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle, colon, and line‑breaks that belong to the same logical heading. Do **not** trim trailing spaces, do not add extra punctuation. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not repeat the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Split a single‑string name on the **last space** only. If the name already contains a comma, keep it unchanged. Separate multiple authors using commas, semicolons, or the word “and”. If none, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint string(s) (e.g. university, department, institute). Preserve diacritics, hyphens, and spacing. If multiple institutions are listed, each becomes a separate list element in the order they appear. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** (hyphens, spaces, parentheses) and keep the 13‑digit number only. Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. Include only if an explicit print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an explicit online qualifier is present. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. Include only if an explicit print qualifier is present. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the whole document into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters:  \n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided the count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – the first page (or first two pages) that contain the **largest centred heading(s)** (often in ALL‑CAPS or title‑case, sometimes preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) or appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve **exact line breaks** (use a single space when joining lines for the output; do **not** insert extra line‑break characters).  \n",
      "4. Do **not** include page numbers, section headings, or catalogue codes.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a title in a **different language** (usually English). Typical markers: “English title”, “Title (English)”, or a second heading placed beneath the main title. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names (often directly under the title, or preceded by “by”, “author”, “kirjoittanut”, etc.).  \n",
      "3. Split each name on the **last space** only:  \n",
      "\n",
      "   ```\n",
      "   \"First Middle Last\" → \"Last, First Middle\"\n",
      "   \"Müller, Anna\"    → unchanged\n",
      "   ```\n",
      "\n",
      "4. Trim whitespace.  \n",
      "5. If multiple authors appear, they may be separated by commas, semicolons, “and”, or line breaks – treat each as a separate author.  \n",
      "6. Return the list in the order found.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line** – usually after the title, subtitle, author, and before the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, or “and”, split them into separate list items **preserving the original spelling**.  \n",
      "4. Do **not** alter diacritics or add/remove words.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following patterns (case‑insensitive):\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**  \n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**: remove all non‑digit characters (for ISBN) or hyphens (for ISSN). Keep the resulting digit string (ISBN should be 13 digits; if 10 digits, still keep after removal).  \n",
      "4. Determine the format from the qualifier(s) on the same line:  \n",
      "\n",
      "   * If an electronic qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a print qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, ignore the number completely.\n",
      "\n",
      "5. Do **not** guess the format; only explicit qualifiers count.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page and imprint) for the following key phrases (case‑insensitive). The first matching rule determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) without “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Example:\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title and subtitle were taken from the first page where the largest centred heading appears; the year 2022 is printed on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 15:31:59 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n",
      "2025/09/30 15:32:47 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:32:49 INFO dspy.evaluate.evaluate: Average Metric: 42.33939393939394 / 64 (66.2%)\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: New program is on the linear pareto front\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Full valset score for new program: 0.6615530303030303\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Full train_val score for new program: 0.6615530303030303\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Individual valset scores for new program: [0.7272727272727273, 0.6363636363636364, 0.7878787878787878, 0.6363636363636364, 0.7272727272727273, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.9090909090909091, 0.6363636363636364, 0.696969696969697, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7727272727272727, 0.7272727272727273, 0.9090909090909091, 0.5454545454545454, 0.5363636363636364, 0.9090909090909091, 0.42424242424242425, 0.9090909090909091, 0.7878787878787878, 0.8181818181818182, 0.5151515151515151, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.9090909090909091, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.36363636363636365, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5151515151515151, 0.6060606060606061, 0.5757575757575757, 0.6363636363636364, 0.6363636363636364, 0.6060606060606061, 0.6060606060606061, 0.6363636363636364]\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.6060606060606061, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Full valset pareto front score: 0.7393939393939394\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Updated valset pareto front programs: [{8, 3, 6}, {3}, {0, 10}, {8, 10}, {6}, {8, 1, 4}, {8, 10, 3}, {8, 9}, {3}, {4}, {3, 4, 8, 9, 10}, {8}, {8}, {10}, {9, 7}, {10}, {8, 10, 6}, {2, 4, 5}, {9}, {10}, {0}, {2, 3}, {8, 10, 7}, {3}, {8}, {8, 10, 4}, {0, 10, 3}, {9}, {8, 10, 4}, {8}, {3}, {9, 2, 6}, {8, 9, 10}, {8}, {8, 10}, {5}, {5}, {8, 9, 10}, {0}, {2, 4}, {8, 9}, {8, 9, 10, 4}, {0, 2, 4, 6, 8, 9, 10}, {10}, {9, 10, 4}, {2, 10, 6}, {7}, {0, 1, 2, 3, 6, 8, 9, 10}, {10}, {8}, {0}, {9, 10, 3, 6}, {0}, {10, 2, 3}, {8, 9, 10}, {10, 3, 6}, {9, 3}, {10}, {8}, {7}, {2}, {7}, {7}, {8, 9}]\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: Linear pareto front program index: 10\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 15: New program candidate index: 10\n",
      "GEPA Optimization:  25%|██▍       | 794/3200 [31:42<2:26:32,  3.65s/rollouts]2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 16: No merge candidates found\n",
      "2025/09/30 15:32:49 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Selected program 6 score: 0.5591856060606061\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.70 / 3 (56.6%): 100%|██████████| 3/3 [00:07<00:00,  2.62s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:32:57 INFO dspy.evaluate.evaluate: Average Metric: 1.6969696969696968 / 3 (56.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:34:44 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Proposed new text for predict: markdown\n",
      "# Revised Task Specification – Bibliographic Metadata Extraction from PDF‑Text JSON\n",
      "\n",
      "You will receive a JSON object that contains:\n",
      "\n",
      "* `pdfinfo` – metadata extracted by the PDF parser (may include `title`, `author`, `creationDate`, `modDate`).\n",
      "* `pages` – an ordered list of objects `{ \"page\": <number>, \"text\": \"<raw page text>\" }`.\n",
      "\n",
      "Your job is to **produce a single JSON object** that follows the schema below, **populated only with information that can be found in the supplied text** (or, when absolutely necessary, from `pdfinfo`).  \n",
      "All fields must be present; when a value is not available use `null` (for scalar fields) or an empty list `[]` (for list fields).\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output Schema\n",
      "\n",
      "| Field | Type | Description | Required |\n",
      "|-------|------|-------------|----------|\n",
      "| `language` | string | ISO‑639‑1 two‑letter code (`fi`, `sv`, `en`, …). Detect the primary language of the document from visible headings, explicit “Language:” lines, or from the language of the title. | ✅ |\n",
      "| `title` | string | The **main title** exactly as it appears (preserve capitals, punctuation, diacritics). Remove any surrounding markdown symbols (`#`, `**`, etc.) and trim whitespace. | ✅ |\n",
      "| `alt_title` | list of strings | Any **alternative titles** (sub‑titles, translations, “also known as” lines). Keep each line as a separate string, in the order encountered. If none, return `[]`. | ✅ |\n",
      "| `creator` | list of strings | Primary **author(s)** only. Format each as `\"Surname, First Middle\"` (surname = last word of the name). Do **not** include supervisors, editors, translators, committee members, or any other contributors. If no author can be identified, return `[]`. | ✅ |\n",
      "| `year` | integer or null | Publication year (four‑digit). Prefer the year that appears in a copyright line, imprint line, or a “Publication year” label. If no year is found, return `null`. | ✅ |\n",
      "| `publisher` | list of strings | Institution(s) that issued the publication (e.g., “Tilastokeskus”, “University of Turku”, “Institutet för hälsa och välfärd”). Exclude city/location, series titles, printing houses, or imprint details. If none, return `[]`. | ✅ |\n",
      "| `doi` | string or null | First DOI found, exactly as it appears (e.g., `10.1007/xyz`). If none, return `null`. | ✅ |\n",
      "| `e_isbn` | list of strings | ISBN(s) for the **electronic** version. Strip **all** hyphens, spaces and line‑breaks; keep the raw 10‑ or 13‑digit number (e.g., `\"9789512986873\"`). If none, return `[]`. | ✅ |\n",
      "| `p_isbn` | list of strings | ISBN(s) for the **print** version, same normalisation as `e_isbn`. | ✅ |\n",
      "| `e_issn` | list of strings or null | ISSN(s) for the **electronic** version, digits only (e.g., `\"23433167\"`). If none, return `null`. | ✅ |\n",
      "| `p_issn` | list of strings or null | ISSN(s) for the **print** version, same normalisation. | ✅ |\n",
      "| `type_coar` | string | COAR‑compatible resource type. Accept **exactly** one of the following values (case‑sensitive):  \n",
      "\n",
      "  - `book`  \n",
      "  - `bachelor thesis`  \n",
      "  - `doctoral thesis`  \n",
      "  - `statistical report`  \n",
      "  - `research report`  \n",
      "  - `book part`  \n",
      "\n",
      "  Choose the **most specific** type that can be inferred (see rules below). | ✅ |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. General Extraction Workflow\n",
      "\n",
      "1. **Build a searchable string**  \n",
      "   Concatenate `pages` in order, preserving line breaks (`\\n`). This makes line‑based regexes easier.\n",
      "\n",
      "2. **Detect language** (order of preference)  \n",
      "   * Look for an explicit line such as `Language: Finnish`, `Språk: svenska`, `Kieli: suomi`, etc.  \n",
      "   * If none, examine headings:  \n",
      "     - Finnish cues: “YHTEISTIEDOT”, “Kansikuva”, “Julkaisu”, “ISBN”.  \n",
      "     - Swedish cues: “Författare”, “Utgivare”, “ISBN”, “Utgivningsår”.  \n",
      "     - English cues: “Author”, “Publisher”, “ISBN”, “Abstract”.  \n",
      "   * If still ambiguous, use the language of the main title (most of the words belong to one language).  \n",
      "   * Return the two‑letter ISO‑639‑1 code (`fi`, `sv`, `en`).\n",
      "\n",
      "3. **Extract the main title**  \n",
      "   * Scan the text from the start for a line that looks like a title:  \n",
      "     - Markdown heading (`#`, `##`, `###`) or fully‑uppercase line.  \n",
      "     - Centered/large font lines often appear without markup but are surrounded by blank lines.  \n",
      "   * The **first** such line is the main title.  \n",
      "   * Strip any leading markdown symbols (`#`, `**`, `*`) and surrounding whitespace.\n",
      "\n",
      "4. **Collect alternative titles**  \n",
      "   * After the main title, look for:  \n",
      "     - Subtitle lines (usually separated by a colon, dash, or placed on the next line).  \n",
      "     - Lines that contain the same title in another language.  \n",
      "   * Add each distinct line (cleaned of markdown symbols) to `alt_title` in the order found.\n",
      "\n",
      "5. **Identify primary authors**  \n",
      "   * Search for language‑specific author labels:  \n",
      "\n",
      "     | Language | Labels |\n",
      "     |----------|--------|\n",
      "     | Finnish  | `Tekijä:`, `Kirjoittaja:`, `Author:` (if the rest of the document is Finnish) |\n",
      "     | Swedish  | `Författare:`, `Author:` (if the rest of the document is Swedish) |\n",
      "     | English  | `Author:`, `Authors:` |\n",
      "\n",
      "   * **Only** use the line that is *explicitly* labelled as author.  \n",
      "   * Split the names on commas, semicolons, or the word “and” **only when** those separators are not part of a single name (e.g., “Van der Waals, Jan”).  \n",
      "   * For each name:  \n",
      "     1. Remove titles (`Prof.`, `Dr.`, `Mr.`, `Ms.`, etc.).  \n",
      "     2. Trim whitespace.  \n",
      "     3. Assume the last word is the surname; everything before it is the given name(s).  \n",
      "     4. Re‑format as `\"Surname, First Middle\"`.  \n",
      "   * Preserve the original order.  \n",
      "   * If no author line is found, return an empty list.\n",
      "\n",
      "6. **Determine the publication year**  \n",
      "   * Look, in this order, for a four‑digit year (1900‑2099) that appears:  \n",
      "     1. After a copyright symbol: `© 2020`, `Copyright 2021`.  \n",
      "     2. In a line starting with `Publication year:`, `Julkaisuvuosi`, `Utgivningsår`.  \n",
      "     3. Inside an imprint line like `Helsinki – 2020`.  \n",
      "   * If multiple candidates exist, choose the one **closest** (by line distance) to the publisher/ISBN block.  \n",
      "   * If still ambiguous, fall back to the year extracted from `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYY…`).  \n",
      "   * If no year can be located, set `year` to `null`.\n",
      "\n",
      "7. **Extract publisher(s)**  \n",
      "   * Search for lines containing any of the following keywords (case‑insensitive): `Kustantaja`, `Publisher`, `Utgivare`, `Julkaisija`, `Institutet`, `University`, `College`, `Centre`, `Institute`, `Tilastokeskus`, `TELA`, `TELA ry`, `TELA –`, `TELA –`.  \n",
      "   * From each candidate line, **remove** any city, country, or series information (e.g., “Helsinki –”, “Stockholm:”).  \n",
      "   * Keep the **exact organisation name** as it appears (including diacritics).  \n",
      "   * If more than one distinct organisation appears, list them in the order encountered.  \n",
      "   * If no publisher can be identified, return an empty list.\n",
      "\n",
      "8. **DOI**  \n",
      "   * Regex: `10\\.\\d{4,9}/\\S+` (stop at whitespace).  \n",
      "   * Return the **first** match, unchanged. If none, `null`.\n",
      "\n",
      "9. **ISBN extraction**  \n",
      "   * Primary regex (covers most layouts):  \n",
      "\n",
      "     ```\n",
      "     ISBN\\s*[:]?[\\s]*([0-9Xx][0-9Xx\\-\\s]{8,}[0-9Xx])\\s*\\(?\\s*(PRINT|PDF|E[-\\s]?BOOK|ONLINE|PDF|E‑BOOK)\\s*\\)?\n",
      "     ```\n",
      "\n",
      "   * Capture the number and the qualifier (PRINT vs. electronic).  \n",
      "   * Normalise the number: remove **all** hyphens, spaces, line‑breaks.  \n",
      "   * If the qualifier contains `PRINT` → add to `p_isbn`; otherwise → add to `e_isbn`.  \n",
      "   * If the qualifier is missing, infer from surrounding text:  \n",
      "     - Presence of the word “PDF”, “online”, “e‑book” → electronic.  \n",
      "     - Presence of “Print”, “hardcover”, “paperback” → print.  \n",
      "   * If inference fails, place the ISBN in **both** lists.\n",
      "\n",
      "10. **ISSN extraction**  \n",
      "    * Regex (similar to ISBN):  \n",
      "\n",
      "      ```\n",
      "      ISSN\\s*[:]?[\\s]*([0-9Xx][0-9Xx\\-\\s]{7}[0-9Xx])\\s*\\(?\\s*(PRINT|ONLINE|E[-\\s]?ISSN|P[-\\s]?ISSN)\\s*\\)?\n",
      "      ```\n",
      "\n",
      "    * Normalise by stripping hyphens/spaces.  \n",
      "    * Assign to `p_issn` if qualifier contains `PRINT` (or if qualifier absent).  \n",
      "    * Assign to `e_issn` if qualifier contains `ONLINE`, `E‑ISSN`, or similar.\n",
      "\n",
      "11. **Determine `type_coar`** (apply the **most specific** rule that matches; order of precedence shown):\n",
      "\n",
      "    1. **bachelor thesis** – any of the following phrases (case‑insensitive):\n",
      "       * Swedish: “Examensarbete”, “Kandidatexamen”, “Kandidaatintyö”.\n",
      "       * Finnish: “Kandidaatintyö”, “Kandidaatintyö”.\n",
      "       * English: “Bachelor thesis”, “Undergraduate thesis”.\n",
      "    2. **doctoral thesis** – phrases like “Doctoral dissertation”, “Doctoral thesis”, “PhD thesis”, “Licentiate”, “Dissertation”.\n",
      "    3. **statistical report** – the publisher is a national statistics agency **and** the document contains words such as “Report”, “Rapport”, “Statistical Report”, “Tilastokeskus”, “Statistics Finland”.  \n",
      "    4. **research report** – the document is a **report** (contains “Report”, “Rapport”, “Study”, “Research”) but the publisher is **not** a statistics agency and no thesis‑specific keywords are present.\n",
      "    5. **book part** – the document is explicitly a chapter or part of a larger book (look for “Chapter”, “Part of”, “In:” followed by a book title).\n",
      "    6. **book** – default when none of the above apply, especially when both print and electronic ISBNs are present.\n",
      "\n",
      "    *Return the first matching type according to this priority list.*\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Normalisation Details\n",
      "\n",
      "| Item | Rule |\n",
      "|------|------|\n",
      "| **ISBN / ISSN** | Remove **all** hyphens (`-`), spaces, line‑breaks. Keep the raw digit string (10‑ or 13‑digit). |\n",
      "| **Author names** | Trim whitespace, strip titles (`Prof.`, `Dr.`, `Mr.`, `Ms.`). Convert “First Middle Last” → `\"Last, First Middle\"`. Preserve diacritics. |\n",
      "| **Publisher** | Keep the exact organisation name as it appears, but trim surrounding punctuation and whitespace. |\n",
      "| **Year** | Return as an integer (e.g., `2021`). If not found → `null`. |\n",
      "| **Language** | ISO‑639‑1 two‑letter lower‑case (`fi`, `sv`, `en`). |\n",
      "| **DOI** | Return exactly as matched (no extra whitespace). |\n",
      "| **type_coar** | Use one of the exact strings listed in the schema (case‑sensitive). |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Edge‑Case Handling Checklist (to avoid common pitfalls)\n",
      "\n",
      "| Situation | Correct Action |\n",
      "|-----------|----------------|\n",
      "| **Hyphenated ISBNs** | Always strip hyphens before storing. |\n",
      "| **Author line contains editors or supervisors** | Ignore any line that is labelled `Editor:`, `Toim.`, `Handledare`, `Supervisor`, etc. Only use the explicit author label. |\n",
      "| **Publisher line includes city or imprint** | Remove the city/location (e.g., “Helsinki –”) and keep only the institution name. |\n",
      "| **Multiple ISBNs without qualifiers** | If you cannot decide print vs. electronic, add the ISBN to **both** `p_isbn` and `e_isbn`. |\n",
      "| **ISSN qualifier missing** | Assume it is a print ISSN (`p_issn`). |\n",
      "| **No year present** | Set `year` to `null`. |\n",
      "| **No DOI** | Set `doi` to `null`. |\n",
      "| **No ISSN** | Set `e_issn` and/or `p_issn` to `null`. |\n",
      "| **Incorrect `type_coar` due to ambiguous keywords** | Follow the precedence order strictly; do not default to “book” when “report” keywords are present. |\n",
      "| **Language detection ambiguous** | Prefer an explicit “Language:” line; otherwise fall back to the language of the title. |\n",
      "| **Alternative titles that are just decorative headings** | Only include lines that look like subtitles (contain a colon, dash, or are directly under the main title). |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Expected Output Format\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"fi\",\n",
      "  \"title\": \"Työeläkelaitosten tilinpäätöstiedot 2020\",\n",
      "  \"alt_title\": [],\n",
      "  \"creator\": [],\n",
      "  \"year\": 2021,\n",
      "  \"publisher\": [\"Eläketurvakeskus\", \"Työeläkevakuuttajat TELA ry\"],\n",
      "  \"doi\": null,\n",
      "  \"e_isbn\": [],\n",
      "  \"p_isbn\": [],\n",
      "  \"e_issn\": null,\n",
      "  \"p_issn\": null,\n",
      "  \"type_coar\": \"research report\"\n",
      "}\n",
      "2025/09/30 15:34:50 INFO dspy.evaluate.evaluate: Average Metric: 1.787878787878788 / 3 (59.6%)\n",
      "2025/09/30 15:35:26 INFO dspy.evaluate.evaluate: Average Metric: 35.68181818181817 / 64 (55.8%)\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Full valset score for new program: 0.5575284090909091\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Full train_val score for new program: 0.5575284090909091\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Individual valset scores for new program: [0.6363636363636364, 0.45454545454545453, 0.45454545454545453, 0.2727272727272727, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.2727272727272727, 0.7272727272727273, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.45454545454545453, 0.6060606060606061, 0.7272727272727273, 0.36363636363636365, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.45454545454545453, 0.3333333333333333, 0.6363636363636364, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.2727272727272727, 0.45454545454545453, 0.36363636363636365, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.4696969696969697, 0.45454545454545453, 0.6363636363636364, 0.3939393939393939, 0.7272727272727273, 0.7878787878787878]\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.6060606060606061, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Full valset pareto front score: 0.740814393939394\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Updated valset pareto front programs: [{8, 3, 6}, {3}, {0, 10}, {8, 10}, {6}, {8, 1, 11, 4}, {8, 10, 3}, {8, 9}, {3}, {4}, {3, 4, 8, 9, 10}, {8}, {8}, {10}, {9, 7}, {10}, {8, 10, 6}, {2, 4, 5}, {9}, {10}, {0}, {2, 3}, {8, 10, 7}, {3}, {8}, {8, 10, 4}, {0, 10, 3}, {9}, {8, 10, 4}, {8}, {3}, {9, 2, 6}, {8, 9, 10}, {8}, {8, 10}, {5}, {5}, {8, 9, 10}, {0}, {2, 4}, {8, 9}, {8, 9, 10, 4}, {11}, {10}, {9, 10, 4}, {2, 10, 6}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11}, {10}, {8}, {0}, {3, 6, 9, 10, 11}, {0}, {10, 2, 3}, {8, 9, 10}, {10, 3, 6}, {9, 3}, {10}, {8}, {7}, {2}, {7}, {11, 7}, {8, 9}]\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: Linear pareto front program index: 10\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 16: New program candidate index: 11\n",
      "GEPA Optimization:  27%|██▋       | 864/3200 [34:19<1:57:43,  3.02s/rollouts]2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 17: No merge candidates found\n",
      "2025/09/30 15:35:26 INFO dspy.teleprompt.gepa.gepa: Iteration 17: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.88 / 3 (62.6%): 100%|██████████| 3/3 [00:07<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:35:33 INFO dspy.evaluate.evaluate: Average Metric: 1.878787878787879 / 3 (62.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:37:02 INFO dspy.teleprompt.gepa.gepa: Iteration 17: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a **single JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* **pages** – a list of page objects, each with a `page` number (integer) and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and produce a **flat list of metadata fields**.  \n",
      "Each field name is written on its own line, followed by its value on the next line, exactly as shown in the *Output format* section.\n",
      "\n",
      "If a piece of information cannot be found, output the **missing‑value placeholder** described in the *Missing‑value handling* table.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language: `fi`, `en`, `sv`, `se`. Detect from the majority of visible words (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (including subtitle). Preserve line breaks by joining lines with a single space; do **not** add extra spaces or punctuation. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not repeat the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Split a name on the **last space only** (unless it already contains a comma). Preserve diacritics. If none, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint institution(s). Capture the line(s) that constitute the **imprint** (usually after the author and before the location/year). If multiple institutions are separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling and diacritics**. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without any prefix** (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. **Normalise** by **removing every non‑digit character** (hyphens, spaces, parentheses) and keep the resulting digit string (13‑digit preferred, but keep whatever digit count remains). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version. Normalise exactly as for `e_isbn`. Include only if a print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by **removing hyphens**. Include only if an explicit online qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if an explicit print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the whole document into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided the count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – the first page (or first two pages) that contain the **largest centred heading(s)** (often ALL‑CAPS or title‑case, possibly preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Join the captured lines with a **single space** (do **not** insert line‑break characters).  \n",
      "4. Do **not** include page numbers, section headings, catalogue codes, or the word “Abstract”.  \n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the immediate next page) for a title in a **different language**. Typical markers: “English title”, “Title (English)”, or a second heading placed beneath the main title. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, locate lines on the title page that contain personal names (often directly under the title, or preceded by “by”, “author”, “kirjoittanut”, etc.).  \n",
      "3. For each name:  \n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** and reformat as `\"Last, First [Middle]\"`.  \n",
      "4. Trim surrounding whitespace.  \n",
      "5. If multiple authors appear, they may be separated by commas, semicolons, “and”, or line breaks – treat each as a separate author, preserving the order found.  \n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line(s)** – the line(s) that appear **after** the author (or title) and **before** the location/year.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling and diacritics**.  \n",
      "4. Do **not** include departmental or faculty names unless they are part of the official imprint (i.e., appear on the same line as the institution name).  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document (all pages) for any of the following patterns (case‑insensitive):\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (e.g., `9789512987112`).  \n",
      "   * ISSN – remove hyphens only (e.g., `14564491`).  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * Electronic qualifier present → add to `e_isbn` / `e_issn`.  \n",
      "   * Print qualifier present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use Python‑style literal syntax for lists (single quotes, commas, no trailing commas). Do **not** add extra blank lines before, after, or between fields.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title and subtitle were taken from the first page where the largest centred heading appears; the year 2022 is printed on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 15:37:28 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:37:28 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 15:37:30 INFO dspy.evaluate.evaluate: Average Metric: 1.8044077134986227 / 3 (60.1%)\n",
      "2025/09/30 15:37:30 INFO dspy.teleprompt.gepa.gepa: Iteration 17: New subsample score is not better, skipping\n",
      "GEPA Optimization:  27%|██▋       | 870/3200 [36:23<2:33:00,  3.94s/rollouts]2025/09/30 15:37:30 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Selected program 2 score: 0.5495822192513369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.76 / 3 (58.8%): 100%|██████████| 3/3 [00:08<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:37:39 INFO dspy.evaluate.evaluate: Average Metric: 1.7636363636363637 / 3 (58.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:39:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Proposed new text for predict: markdown\n",
      "# Task: Structured metadata extraction from PDF‑derived text\n",
      "\n",
      "You will receive a single JSON object with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – a dictionary containing the raw PDF metadata (e.g. `title`, `author`, `creationDate`, …).  \n",
      "* **pages** – a list of page objects, each with:\n",
      "  * **page** – the page number (integer, 1‑based).  \n",
      "  * **text** – the plain‑text extracted from that page (UTF‑8, may contain markdown, hyperlinks, footnotes, line‑breaks, etc.).\n",
      "\n",
      "Your job is to **produce ONE JSON object** that contains **exactly** the fields listed below (order does not matter).  \n",
      "If a field cannot be determined, use the value prescribed in the *Missing‑data handling* section.\n",
      "\n",
      "---\n",
      "\n",
      "## Output fields\n",
      "\n",
      "| Field | Type | Description | Extraction rules |\n",
      "|-------|------|-------------|------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language (`en`, `fi`, `sv`, …). | Detect **only from the body text** (never from `pdfinfo[\"language\"]`). Use a simple stop‑word count: <br>‑ English stop‑words: `the, and, of, to, a, in, that, is, for, with` <br>‑ Finnish stop‑words: `ja, on, että, se, ei, mutta, kuin, myös, tämän` <br>‑ Swedish stop‑words: `och, att, är, i, som, på, för, med, den` <br>Count occurrences (case‑insensitive). Choose the language with the highest count **if the count ≥ 3**; otherwise return `und`. |\n",
      "| **title** | string | Primary title exactly as it appears in the document (include subtitle after a colon). | 1. If `pdfinfo[\"title\"]` exists and is not empty/“Untitled”, use it after stripping surrounding whitespace and markdown symbols (`#`, `*`, `**`). <br>2. Otherwise scan pages in order for the first line that: <br> • Starts with a level‑1 markdown heading (`# `) **or** is bold (`**…**` or `*…*`). <br> • Contains a colon (common in “Title: Subtitle”). <br>Take that line, strip leading markdown characters and surrounding whitespace. |\n",
      "| **alt_title** | list of strings | Any alternative titles (subtitle only, translation, etc.). | Look for a level‑2 heading (`## `) that appears **immediately after** the primary title, or a line that looks like a translation of the title (e.g., same words in another language). Add each distinct candidate; if none, return `[]`. |\n",
      "| **creator** | list of strings | Authors formatted as **“LastName, FirstName”** (one entry per author). | 1. Find lines containing the words **Author**, **Authors**, **Kirjoittajat**, **Författare**, or lines that start with “**Author(s):**”. <br>2. Split the line on commas, the words `and`, `&`, or line‑breaks. <br>3. For each name:<br> a. If it already contains a comma, assume “Last, First” and keep it.<br> b. Otherwise assume “First Last” (or “First Middle Last”) and invert to “Last, First Middle”. Preserve diacritics and capitalisation.<br>4. Discard generic placeholders like “et al.”. Return `[]` if no names are found. |\n",
      "| **year** | integer | Four‑digit publication year. | 1. Look for a line containing `Year:` or the copyright symbol `©` followed by a 4‑digit number. <br>2. If not found, search any line for a standalone 4‑digit number that looks like a year (1900‑2099). <br>3. If several candidates exist, choose the **largest** (most recent) year. <br>4. If still none, extract the year from `pdfinfo[\"creationDate\"]` which has the form `D:YYYY…`. Return `null` if no year can be determined. |\n",
      "| **publisher** | list of strings | Institution, university, journal, or publishing house. | Scan all lines for keywords: `University`, `Institute`, `College`, `School of`, `Journal of`, `Proceedings of`, `Publisher:`, `Press`, `Society`, `Research Centre`, `Centre`, `Department` (only when it appears as the top‑level entity, e.g., “University of Turku”). <br>Extract the full phrase up to the next punctuation mark (comma, period, line‑break) and trim whitespace. Keep each distinct entity; do **not** split a single publisher into sub‑units (e.g., keep “University of Turku” but not “Faculty of Medicine”). Return `[]` if none. |\n",
      "| **doi** | string or null | Digital Object Identifier (without the URL). | Find any URL matching `https?://doi\\.org/([^\\s\\)]+)`. Capture group 1, strip trailing punctuation (`.`, `)`, `]`). Return the captured string; if none, return `null`. |\n",
      "| **e_isbn** | list of strings | Electronic ISBN numbers (digits only, no hyphens/spaces). | Regex `ISBN(?:‑13)?:?\\s*([0-9][0-9\\-\\s]{9,})`. For each match, look at the surrounding text: if it contains `electronic`, `e‑ISBN`, `PDF`, or `(PDF)` treat it as electronic. Clean the captured value by removing spaces and hyphens, leaving only digits. Add to list. Return `[]` if none. |\n",
      "| **p_isbn** | list of strings | Print ISBN numbers (digits only). | Same regex as above, but treat the match as print if the surrounding text contains `print`, `hardcover`, `paperback`, `PRINT`, or `(PRINT)`. Clean to digits only. Return `[]` if none. |\n",
      "| **e_issn** | string or null | Electronic ISSN (`####-####`). | Regex `ISSN\\s*[:]?[\\s]*([0-9]{4}\\s*[-‑]\\s*[0-9]{3}[0-9X])`. If the surrounding text contains `electronic`, `e‑ISSN`, `online`, or `Online`, assign to `e_issn`. Return `null` if not found. |\n",
      "| **p_issn** | string or null | Print ISSN (`####-####`). | Same regex; assign to `p_issn` when surrounding text contains `print`, `Print`, `paper`, or `Print version`. Return `null` if not found. |\n",
      "| **type_coar** | string | COAR‑controlled resource type (lower‑case). | Detect based on keywords (case‑insensitive): <br>• `Doctoral Dissertation`, `PhD thesis` → `doctoral thesis` <br>• `Master’s thesis`, `Master thesis` → `master thesis` <br>• `Bachelor thesis`, `Kandidatavhandling` → `bachelor thesis` <br>• `Thesis` alone → `thesis` (but prefer a more specific level if present) <br>• `Journal article`, `Article`, `Paper` → `journal article` <br>• `Proceedings`, `Conference paper` → `conference paper` <br>• `Report`, `Technical report` → `report` <br>• `Book` → `book` <br>• `Book chapter`, `Chapter` → `book chapter` <br>• `Dataset` → `dataset` <br>• `Software` → `software` <br>• `Book part` (e.g., a chapter in a edited volume) → `book part` <br>Choose the most specific match; if none match, return `null`. |\n",
      "| **reasoning** *(optional)* | string | Short human‑readable explanation of how the fields were derived. | May be omitted. |\n",
      "\n",
      "---\n",
      "\n",
      "## Missing‑data handling  \n",
      "\n",
      "| Type | Value to use when data is missing |\n",
      "|------|-----------------------------------|\n",
      "| String (`title`, `doi`, `e_issn`, `p_issn`) | `null` |\n",
      "| Integer (`year`) | `null` |\n",
      "| List (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) | `[]` |\n",
      "| `language` | `\"und\"` |\n",
      "| `type_coar` | `null` |\n",
      "\n",
      "---\n",
      "\n",
      "## General extraction strategy (must be followed for every input)\n",
      "\n",
      "1. **Pre‑process page text**  \n",
      "   * Replace Windows line endings `\\r\\n` with `\\n`.  \n",
      "   * Remove markdown image syntax (`![](...)`) and any HTML‑like tags (`<...>`).  \n",
      "   * **Do not** collapse whitespace globally before headings are identified – keep line breaks for title detection.\n",
      "\n",
      "2. **Primary title** – follow the rules in the *title* row above.\n",
      "\n",
      "3. **Alternative titles** – follow the rules in the *alt_title* row.\n",
      "\n",
      "4. **Creators** – follow the rules in the *creator* row. Preserve diacritics (e.g., `López‑Íñiguez`).\n",
      "\n",
      "5. **Year** – follow the rules in the *year* row.\n",
      "\n",
      "6. **Publisher** – follow the rules in the *publisher* row. Return only the highest‑level entity (e.g., “University of Turku”, not “Faculty of Medicine”).\n",
      "\n",
      "7. **DOI** – apply the regex in the *doi* row.\n",
      "\n",
      "8. **ISBN / ISSN** – apply the regexes and context rules in the corresponding rows; strip hyphens/spaces from ISBNs, keep the hyphen in ISSNs.\n",
      "\n",
      "9. **COAR type** – apply the mapping in the *type_coar* row, preferring the most specific term.\n",
      "\n",
      "10. **Language detection** – apply the stop‑word counting method in the *language* row.\n",
      "\n",
      "11. **Assemble the output JSON** – ensure **all** fields listed above are present (even if `null` or empty). Do **not** include any extra keys.\n",
      "\n",
      "---\n",
      "\n",
      "## Example of a correct output (format only)\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"en\",\n",
      "  \"title\": \"Embracing a learner identity: An Autoethnographic duet exploring disruptive critical incidents in instrumental music pedagogy\",\n",
      "  \"alt_title\": [],\n",
      "  \"creator\": [\"López‑Íñiguez, Guadalupe\", \"Coutts, Leah\"],\n",
      "  \"year\": 2020,\n",
      "  \"publisher\": [\"International Society for Music Education (ISME)\"],\n",
      "  \"doi\": null,\n",
      "  \"e_isbn\": [],\n",
      "  \"p_isbn\": [\"9781922303042\"],\n",
      "  \"e_issn\": null,\n",
      "  \"p_issn\": null,\n",
      "  \"type_coar\": \"book part\",\n",
      "  \"reasoning\": \"Title taken from level‑1 heading; authors extracted from author line and inverted; year from Year: field; publisher identified from ISME mention; ISBN classified as print because of '(Print)'; COAR type inferred as book part from 'Proceedings of the 23rd International Seminar…'.\"\n",
      "}\n",
      "2025/09/30 15:39:13 INFO dspy.evaluate.evaluate: Average Metric: 2.5 / 3 (83.3%)\n",
      "2025/09/30 15:40:04 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:40:04 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 15:40:07 ERROR dspy.utils.parallelizer: Error for Example({'content': '{\"pdfinfo\": {\"creationDate\": \"D:20190201172353+02\\'00\\'\", \"modDate\": \"D:20190205145415+02\\'00\\'\"}, \"pages\": [{\"page\": 1, \"text\": \"#### **Munnuide \\\\u0161add\\\\u00e1**\\\\n# **NJUORATM\\\\u00c1NN\\\\u00c1**\\\\nOahpis m\\\\u00e1n\\\\u00e1 vuordimii ja dik\\\\u0161umii\\\\n\\\\n\\\\n\"}, {\"page\": 2, \"text\": \"Munnuide \\\\u0161add\\\\u00e1 njuoratm\\\\u00e1nn\\\\u00e1 \\\\u2013oahpis lea almmustahtton juo\\\\n1980-logu \\\\u00e1lggus. \\\\u00c1lgo\\\\u00e1lgosa\\\\u0161 oahpp\\\\u00e1sa teavsttas stuorimus\\\\novddasv\\\\u00e1st\\\\u00e1dusa guttii sosi\\\\u00e1lah\\\\u00e1lddahusa psykologa Sirpa Taskinen. Go\\\\njagit leat gollan, de sisdoallu lea dievasmahttojuvvon ja doaimmahuvvon\\\\nmoanaid gerddiid. Doaimmahusgoddi giit\\\\u00e1 liggosit buohkaid d\\\\u00e1n\\\\no\\\\u0111asmahtton ver\\\\u0161uvnna beaiv\\\\u00e1deapm\\\\u00e1i oass\\\\u00e1last\\\\u00e1n \\\\u00e1\\\\u0161\\\\u0161edovdiid ja\\\\n\\\\nm\\\\u00e1nn\\\\u00e1bearra\\\\u0161iid v\\\\u00e1nhemiid.\\\\nDoaimmahusgoddi:\\\\nTuovi Hakulinen, DBL\\\\nMarjaana Pelkonen, SDM\\\\nJarmo Salo, DBL\\\\nMaria Kuronen, DBL\\\\n\\\\n\\\\n\\\\u00a9 THL\\\\nGr\\\\u00e1fala\\\\u0161 pl\\\\u00e1nen ja m\\\\u00e1hccun: Seija Puro\\\\nBearpma govva: Vastavalo.fi\\\\nISBN neahtta 978-952-343-286-4\\\\n\\\\n\\\\nhttp://urn.fi/URN:ISBN:978-952-343-286-4\\\\nMUU 331\\\\n\\\\n\\\\n\"}, {\"page\": 3, \"text\": \"R\\\\u00e1vagirji njuoratm\\\\u00e1n\\\\u00e1\\\\nvuordimii ja dik\\\\u0161umii\\\\n\\\\n\\\\n\"}, {\"page\": 5, \"text\": \"M\\\\u00e1n\\\\u00e1t rieg\\\\u00e1dit ie\\\\u0161gu\\\\u0111etl\\\\u00e1gan bearra\\\\u0161iidda ja eallindiliide:\\\\n\\\\nvuosttasrieg\\\\u00e1deaddjin dahje oapp\\\\u00e1\\\\u0161doahkk\\\\u00e1i, dat leat guhkk\\\\u00e1\\\\n\\\\nvurdojuvvon dahje s\\\\u00e1httet boahtit hui vuorddekeahtt\\\\u00e1.\\\\nD\\\\u00e1n r\\\\u00e1vagirj\\\\u00e1i leat \\\\u010dohkkejuvvon \\\\u00e1igeguovdilis die\\\\u0111ut m\\\\u00e1n\\\\u00e1 vuordimis,\\\\n\\\\nrieg\\\\u00e1dahttimis, v\\\\u00e1nhenvuo\\\\u0111as, m\\\\u00e1n\\\\u00e1 dik\\\\u0161umis sihke m\\\\u00e1nn\\\\u00e1bearra\\\\u0161iid\\\\n\\\\nb\\\\u00e1lvalusain ja sosi\\\\u00e1ladorvvus. Mii doaivut, ahte oa\\\\u010d\\\\u010dut r\\\\u00e1vagirjji die\\\\u0111uin\\\\n\\\\nja geavatla\\\\u0161 neavvuin doarjaga ie\\\\u017eat jurdda\\\\u0161eapm\\\\u00e1i ja gea\\\\u017eidemiid\\\\n\\\\ndoaibmi \\\\u00e1rgga v\\\\u00e1r\\\\u00e1s.\\\\nEtniid- ja m\\\\u00e1n\\\\u00e1idr\\\\u00e1vvehagas sihke rieg\\\\u00e1dahttinklinihkas oa\\\\u010d\\\\u010dut maid\\\\n\\\\neanet persovnnala\\\\u0161 r\\\\u00e1vvema ja doarjaga v\\\\u00e1nhenvuhtii ja m\\\\u00e1n\\\\u00e1 dik\\\\u0161umii.\\\\nOrganisa\\\\u0161uvnnat, mat vudjot m\\\\u00e1n\\\\u00e1id ja bearra\\\\u0161iid \\\\u00e1\\\\u0161\\\\u0161iide, buvttadit\\\\n\\\\nluohtehahtti die\\\\u0111u, mii g\\\\u00e1vdno \\\\u00e1lkit neahtas. R\\\\u00e1vagirjji loahpas leat\\\\n\\\\ngea\\\\u017eideamit diehtog\\\\u00e1lduide.\\\\nBuriid lohkanbottuid!\\\\nDoaimmahus\\\\nMUNNUIDE \\\\u0160ADD\\\\u00c1 NJUORATM\\\\u00c1NN\\\\u00c1 5\\\\n\\\\n\\\\n\"}, {\"page\": 6, \"text\": \"**SISDOALLU**\\\\n**\\\\u00c1HPEHISVUO\\\\u0110A \\\\u00c1IGI**\\\\n\\\\u00c1hpehisvuo\\\\u0111a ovd\\\\u00e1neapmi 8\\\\n\\\\u00c1hpehisvuo\\\\u0111a kaleanddar 10\\\\nBuresbirgejumis fuolaheapmi 12\\\\n\\\\u00c1hpehisvuo\\\\u0111a \\\\u00e1iggi vuhttomat 18\\\\nDahkkit mat bidjet \\\\u00e1hpehisvuo\\\\u0111a v\\\\u00e1ra vuoll\\\\u00e1i 22\\\\nEtniidr\\\\u00e1vvehagas 28\\\\nV\\\\u00e1nhenvuhtii r\\\\u00e1hkkaneapmi 34\\\\nP\\\\u00e1rragaskavuohta 37\\\\nNjuoratm\\\\u00e1n\\\\u00e1 biergasat 39\\\\n**RIEG\\\\u00c1DAHTTIN**\\\\nRieg\\\\u00e1dahttimii r\\\\u00e1hkkaneapmi 42\\\\nRieg\\\\u00e1dahttimii 46\\\\nM\\\\u00e1nn\\\\u00e1sea\\\\u014bgaossodagas 51\\\\nRieg\\\\u00e1dahttimis \\\\u00e1hp\\\\u00e1iduvvan 53\\\\n**NJUORATM\\\\u00c1N\\\\u00c1 DIK\\\\u0160UN**\\\\nVuosttas m\\\\u00e1notbadji 60\\\\nNjuoratm\\\\u00e1n\\\\u00e1 biebmu 66\\\\nBuhtisvuohta 77\\\\nOa\\\\u0111\\\\u0111in ja nohkadeapmi 79\\\\nNjuoratm\\\\u00e1n\\\\u00e1 \\\\u0161addan ja ovd\\\\u00e1neapmi 81\\\\nNjuoratm\\\\u00e1nn\\\\u00e1bearra\\\\u0161a \\\\u00e1rga 88\\\\nM\\\\u00e1n\\\\u00e1 dorvvola\\\\u0161vuohta 91\\\\nNjuoratm\\\\u00e1n\\\\u00e1 buohcan 92\\\\n**M\\\\u00c1NN\\\\u00c1BEARRA\\\\u0160IID B\\\\u00c1LVALUSAT**\\\\nM\\\\u00e1n\\\\u00e1idr\\\\u00e1vvehatb\\\\u00e1lvalusat 98\\\\nSosi\\\\u00e1lab\\\\u00e1lvalusat 100\\\\nBearra\\\\u0161iid ear\\\\u00e1 b\\\\u00e1lvalusat 102\\\\nM\\\\u00e1nn\\\\u00e1bearra\\\\u0161iid sosi\\\\u00e1ladorvu 103\\\\nEarenoam\\\\u00e1\\\\u0161 dilit 104\\\\n\\\\u00c1h\\\\u010d\\\\u010divuo\\\\u0111a \\\\u010dielggadeapmi 105\\\\nM\\\\u00e1n\\\\u00e1 fuolaheaddjivuohta sihke ealihanveahkki ja ealihandoarjja 107\\\\nOrganisa\\\\u0161uvnnat, mat dorjot m\\\\u00e1nn\\\\u00e1bearra\\\\u0161iid 108\\\\n\\\\n\\\\n6 MUNNUIDE \\\\u0160ADD\\\\u00c1 NJUORATM\\\\u00c1NN\\\\u00c1\\\\n\\\\n\\\\n\"}, {\"page\": 109, \"text\": \"Vuosttamus jagi \\\\u00e1igge m\\\\u00e1nn\\\\u00e1 lea \\\\u0161addan veahkehis unna gurppis\\\\nv\\\\u00e1zzima oahpahalli unna olmmo\\\\u017ein. Almm\\\\u00e1 vuorrov\\\\u00e1ikkuhusa\\\\nnuppi olbmuiguin d\\\\u00e1t ii liv\\\\u010d\\\\u010dii vejola\\\\u0161.\\\\nJuohkeha\\\\u0161 m\\\\u00e1nn\\\\u00e1 lea earenoam\\\\u00e1\\\\u0161 ja ovd\\\\u00e1na ie\\\\u017eas leavttuin\\\\nv\\\\u00e1nhemiin o\\\\u017e\\\\u017eojuvvon \\\\u00e1rbedahkkiid ja birrasa gealdd\\\\u00e1hagaid\\\\noahpisteami mielde. M\\\\u00e1n\\\\u00e1 ii g\\\\u00e1nnet goassige veard\\\\u00e1dallat ear\\\\u00e1ide.\\\\nM\\\\u00e1nn\\\\u00e1i lea deh\\\\u00e1la\\\\u0161, ahte v\\\\u00e1nhemat illudit aiddo sus ja su o\\\\u0111\\\\u0111a\\\\n\\\\nbero\\\\u0161tumiin.\\\\nM\\\\u00e1nn\\\\u00e1 \\\\u0161add\\\\u00e1 ja muhtta\\\\u0161uvv\\\\u00e1 johtilit maidd\\\\u00e1i vuosttamus jagi\\\\nma\\\\u014b\\\\u014b\\\\u00e1. Juohke ovd\\\\u00e1nanmuddu s\\\\u00e1htt\\\\u00e1 leat v\\\\u00e1nhemiidda \\\\u00e1igi mii\\\\nadd\\\\u00e1 olu ja bukt\\\\u00e1 stuorra ilu.\\\\nIllut m\\\\u00e1n\\\\u00e1s!\\\\nM\\\\u00e1nn\\\\u00e1bearra\\\\u0161iid b\\\\u00e1lvalusat | MUNNUIDE \\\\u0160ADD\\\\u00c1 NJUORATM\\\\u00c1NN\\\\u00c1 109\\\\n\\\\n\\\\n\"}, {\"page\": 110, \"text\": \"_Munnuide \\\\u0161add\\\\u00e1 njuoratm\\\\u00e1nn\\\\u00e1_ add\\\\u00e1 die\\\\u0111u ja geavatla\\\\u0161\\\\ngea\\\\u017eidemiid buori \\\\u00e1rgii ja v\\\\u00e1nhenvuhtii.\\\\nTerveyden ja hyvinvoinnin laitos\\\\nISBN: 978-952-343-286-4 Puhelin: 029 524 60000\\\\nwww.thl.fi\\\\n\\\\n\\\\n\"}]}', 'metadata': '{\"language\": \"se\", \"title\": \"Munnuide \\\\u0161add\\\\u00e1 njuoratm\\\\u00e1nn\\\\u00e1 : r\\\\u00e1vagirji njuoratm\\\\u00e1n\\\\u00e1 vuordimii ja dik\\\\u0161umii\", \"year\": \"2019\", \"publisher\": [\"THL\"], \"e_isbn\": [\"9789523432864\"], \"type_coar\": \"book\"}'}) (input_keys={'content'}): 1 validation error for nullable[str]\n",
      "  Input should be a valid string [type=string_type, input_value=2020, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py\", line 55, in safe_func\n",
      "    return user_function(item)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/evaluate/evaluate.py\", line 158, in process_item\n",
      "    prediction = program(**example.inputs())\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/primitives/module.py\", line 78, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/chain_of_thought.py\", line 37, in forward\n",
      "    return self.predict(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/predict.py\", line 103, in __call__\n",
      "    return super().__call__(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/primitives/module.py\", line 78, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/predict.py\", line 192, in forward\n",
      "    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n",
      "    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n",
      "    raise e\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 128, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 89, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 169, in parse\n",
      "    fields[k] = parse_value(v, signature.output_fields[k].annotation)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/utils.py\", line 163, in parse_value\n",
      "    return TypeAdapter(annotation).validate_python(value)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/pydantic/type_adapter.py\", line 421, in validate_python\n",
      "    return self.validator.validate_python(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "pydantic_core._pydantic_core.ValidationError: 1 validation error for nullable[str]\n",
      "  Input should be a valid string [type=string_type, input_value=2020, input_type=int]\n",
      "    For further information visit https://errors.pydantic.dev/2.11/v/string_type\n",
      "\n",
      "2025/09/30 15:40:07 INFO dspy.evaluate.evaluate: Average Metric: 35.53636363636362 / 64 (55.5%)\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Full valset score for new program: 0.5552556818181819\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Full train_val score for new program: 0.5552556818181819\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.6060606060606061, 0.36363636363636365, 0.7272727272727273, 0.2727272727272727, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.45454545454545453, 0.696969696969697, 0.5454545454545454, 0.3939393939393939, 0.7878787878787878, 0.45454545454545453, 0.6060606060606061, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.9090909090909091, 0.45454545454545453, 0.5363636363636364, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.0, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.696969696969697, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.7272727272727273, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.36363636363636365, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.2424242424242424, 0.696969696969697]\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: New valset pareto front scores: [0.8181818181818182, 0.6666666666666666, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.6060606060606061, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Full valset pareto front score: 0.740814393939394\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Updated valset pareto front programs: [{8, 3, 12, 6}, {3}, {0, 10}, {8, 10}, {6}, {8, 1, 11, 4}, {8, 10, 3}, {8, 9}, {3}, {4}, {3, 4, 8, 9, 10}, {8}, {8}, {10}, {9, 7}, {10}, {8, 10, 6}, {2, 4, 5}, {9}, {10, 12}, {0, 12}, {2, 3}, {8, 10, 7}, {3}, {8}, {8, 10, 4, 12}, {0, 10, 3}, {9}, {8, 10, 4}, {8}, {3}, {9, 2, 6}, {8, 9, 10}, {8}, {8, 10}, {5}, {5}, {8, 9, 10}, {0}, {2, 4}, {8, 9}, {4, 8, 9, 10, 12}, {11}, {10}, {9, 10, 4}, {2, 10, 6}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11}, {10}, {8}, {0}, {3, 6, 9, 10, 11, 12}, {0}, {10, 2, 3}, {8, 9, 10}, {10, 3, 6}, {9, 3}, {10}, {8}, {7}, {2}, {7}, {11, 7}, {8, 9}]\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: Linear pareto front program index: 10\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 18: New program candidate index: 12\n",
      "GEPA Optimization:  29%|██▉       | 940/3200 [39:00<1:58:45,  3.15s/rollouts]2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 19: No merge candidates found\n",
      "2025/09/30 15:40:07 INFO dspy.teleprompt.gepa.gepa: Iteration 19: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.09 / 3 (69.7%): 100%|██████████| 3/3 [00:05<00:00,  1.98s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:40:13 INFO dspy.evaluate.evaluate: Average Metric: 2.090909090909091 / 3 (69.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:42:17 INFO dspy.teleprompt.gepa.gepa: Iteration 19: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata such as `title`, `author`, `creationDate`, `modDate`, etc.\n",
      "* **pages** – a list of page objects, each with a `page` number (integer) and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and produce a **flat list of metadata fields**.  \n",
      "Each field name is written on its own line, followed by its value on the next line, exactly as shown in the *Output format* section below.\n",
      "\n",
      "All list values must be valid Python‑style lists (single quotes, commas, no trailing commas).  \n",
      "If a piece of information cannot be found, output the *missing‑value placeholder* described in the *Missing‑value handling* table.\n",
      "\n",
      "Below are the complete extraction rules, normalisation steps, and common pitfalls that you must follow **exactly**.  They incorporate all nuances discovered from previous attempts.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the **document language** (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle, colon, and line‑breaks that belong to the same logical heading. Do **not** trim trailing spaces, do not add extra punctuation, do **not** insert line‑break characters – join the lines with a single space. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not repeat the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). **Split a name on the last space only**. If the name already contains a comma, keep it unchanged. Separate multiple authors using commas, semicolons, the word “and”, or line breaks – treat each as a distinct author. Preserve diacritics and original capitalisation. If none, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint string(s). Preserve diacritics, hyphens, and spacing. If the imprint line contains several entities separated by commas, slashes, or the word “and”, split them into separate list items **in the order they appear**. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. **Normalise** by **removing every non‑digit character** (hyphens, spaces, parentheses) and keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what is present). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. Include only if an explicit print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an explicit online qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if an explicit print qualifier is present on the same line. If an ISSN line has **no qualifier**, treat it as a **print** ISSN (i.e. assign to `p_issn`). |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the whole document into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided the count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – the first page (or the first two pages) that contain the **largest centred heading(s)** (often in ALL‑CAPS or title‑case, sometimes preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve the exact wording and punctuation, but **join the captured lines with a single space** for the output value.  \n",
      "4. Do **not** include page numbers, catalogue codes, section headings, or any surrounding decorative text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a title in a **different language**. Typical markers: “English title”, “Title (English)”, “Englisch”, or a second heading placed beneath the main title. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names (often directly under the title, or preceded by “by”, “author”, “kirjoittanut”, “tekijä”, etc.).  \n",
      "3. For each candidate name:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only**:  \n",
      "\n",
      "     ```\n",
      "     \"First Middle Last\" → \"Last, First Middle\"\n",
      "     \"Mikko Laitinen\"   → \"Laitinen, Mikko\"\n",
      "     ```\n",
      "\n",
      "   * Trim leading/trailing whitespace.  \n",
      "4. If multiple authors appear, they may be separated by commas, semicolons, “and”, or line breaks – treat each as a separate author, preserving the order found.  \n",
      "5. Return the list; if no author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, imprint line, and any line containing the word “©”, “Copyright”, or “©”.  \n",
      "2. Look for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "3. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "4. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "5. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line(s)** – usually after the title, subtitle, author, and before the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling, diacritics, and spacing**.  \n",
      "4. Do **not** alter words, add or remove anything. If no imprint can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document (all pages) for any of the following patterns (case‑insensitive):\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string (e.g. `10.1234/abcd.efg`). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number; case‑insensitive):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the word `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * **ISBN** – remove **all** non‑digit characters; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what is present).  \n",
      "   * **ISSN** – remove hyphens only (the ISSN consists of 8 digits, optionally with a hyphen).  \n",
      "\n",
      "4. Determine the format from the qualifier(s) **on the same line**:\n",
      "\n",
      "   * If an **electronic qualifier** is present → add the normalised number to `e_isbn` / `e_issn`.  \n",
      "   * If a **print qualifier** is present → add the normalised number to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present:  \n",
      "\n",
      "     * For **ISBN** – ignore the number (do not add to either list).  \n",
      "     * For **ISSN** – treat it as a **print ISSN** and assign to `p_issn`.  \n",
      "\n",
      "5. Preserve the order of appearance when populating the lists.  \n",
      "6. Do **not** guess a format; only explicit qualifiers count (except the ISSN fallback rule above).\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any “type” line) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Kandidaatin tutkielma”, “Kandidaatin tutkielma” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation”, “Tohtorintutkielma” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**.  Follow the exact ordering below:\n",
      "\n",
      "```\n",
      "language\n",
      "<value>\n",
      "title\n",
      "<value>\n",
      "alt_title\n",
      "<value>\n",
      "creator\n",
      "<value>\n",
      "year\n",
      "<value>\n",
      "publisher\n",
      "<value>\n",
      "doi\n",
      "<value>\n",
      "e_isbn\n",
      "<value>\n",
      "p_isbn\n",
      "<value>\n",
      "e_issn\n",
      "<value>\n",
      "p_issn\n",
      "<value>\n",
      "type_coar\n",
      "<value>\n",
      "reasoning\n",
      "<optional free‑text explanation>\n",
      "2025/09/30 15:42:23 INFO dspy.evaluate.evaluate: Average Metric: 2.0606060606060606 / 3 (68.7%)\n",
      "2025/09/30 15:42:23 INFO dspy.teleprompt.gepa.gepa: Iteration 19: New subsample score is not better, skipping\n",
      "GEPA Optimization:  30%|██▉       | 946/3200 [41:16<2:37:43,  4.20s/rollouts]2025/09/30 15:42:23 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Selected program 9 score: 0.6372395833333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.64 / 3 (54.5%): 100%|██████████| 3/3 [00:07<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:42:31 INFO dspy.evaluate.evaluate: Average Metric: 1.6363636363636362 / 3 (54.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:44:33 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line). The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | string or `None` | Full main title exactly as it appears on the title page, including subtitle(s) that belong to the same logical heading. |\n",
      "| `alt_title` | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | integer or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | list of strings | Publishing institution(s) exactly as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version, normalized to a plain digit string (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | string or `None` | COAR resource type, one of the **lower‑case** values listed in **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The value on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes) for missing values.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Strong signals** – Scan every page for a line that explicitly states the language, e.g.  \n",
      "   * `Kieli: suomi` → `fi`  \n",
      "   * `Language: English` → `en`  \n",
      "   * `Språk: svenska` → `sv`  \n",
      "   If such a line is found, **override** all other evidence and set the language accordingly.\n",
      "2. **Stop‑word counting** – If no explicit line is present, count occurrences (case‑insensitive) of the following seed words on **all pages**:\n",
      "\n",
      "| ISO code | Seed words (case‑insensitive) |\n",
      "|----------|------------------------------|\n",
      "| `fi` | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu` |\n",
      "| `sv` | `och`, `för`, `av`, `liv`, `historien`, `språk` |\n",
      "| `en` | `the`, `and`, `of`, `method`, `introduction`, `chapter` |\n",
      "\n",
      "   * The language with the highest total count wins.\n",
      "   * If the highest count is a tie **or** all counts are zero, output `None`.\n",
      "\n",
      "### 2.2 Title extraction (main title)\n",
      "1. **Locate the title page** – The first page that satisfies **any** of the following:\n",
      "   * Contains a line that is **all‑caps** (ignoring punctuation) and is the **only non‑blank line** on that page, **or** the **first non‑blank line** on the page.\n",
      "   * Contains a Markdown heading (`#`, `##`, `###`) whose text (after stripping the heading markers) is not empty.\n",
      "2. **Capture the logical title**:\n",
      "   * Take the identified line as the **main title**.\n",
      "   * If the **next line** (or the line directly following a colon on the same line) is non‑blank and looks like a subtitle (i.e. not a heading marker, not a page number, and not separated by a blank line), concatenate it with a single space.\n",
      "   * Preserve **all original punctuation, diacritics, and case**.\n",
      "3. **Clean‑up** – Remove any surrounding whitespace and any surrounding heading markers (`#`, `##`, `###`). Do **not** remove internal punctuation or capitalization.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "1. Look for lines that contain any of the following **qualifiers** (case‑insensitive):  \n",
      "   `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Title (Finnish)`, `Titel (Svenska)`, etc.\n",
      "2. When a qualifier is found, extract the title text that **follows** the qualifier (same concatenation rules as in 2.2).  \n",
      "3. Do **not** duplicate the main `title`. If multiple alternate titles are found, list them all.\n",
      "\n",
      "### 2.4 Creator handling (authors)\n",
      "1. **Search for author lines** – Scan pages (preferably the first three) for any line that contains one of the following keywords (case‑insensitive):  \n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Kirjoittaja`, `Kirjoittajat`, `Authors:`, `Tekijä:`, `Tekijät:`, `Kirjoittaja:`, `Kirjoittajat:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. **Extract the raw name string** – The part of the line after the keyword (or after a colon) is the raw list of names.\n",
      "3. **Split into individual names** – Names may be separated by any of these delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, Finnish/Swedish equivalents `ja`, `och`.\n",
      "4. **Normalise each name**  \n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged (trim surrounding whitespace).  \n",
      "   * Otherwise, split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "     * Preserve diacritics and original capitalisation.\n",
      "5. **Preserve order of appearance** and return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "6. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **pages 1 – 2** for a four‑digit number between 1900 and 2100 that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `År`.\n",
      "2. If multiple candidates exist, prefer the one that is **closest** to a keyword.\n",
      "3. If no candidate is found, fall back to PDF metadata:\n",
      "   * From `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`), extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines (anywhere) that contain any of the following keywords (case‑insensitive):  \n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, `Routledge`, `Springer`, `Cambridge`, `Elsevier`, `Wiley`, `Metropolia`, `Åbo Akademi`, etc.\n",
      "2. **Capture the full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as `. , ; :`).  \n",
      "   * If the line **contains only the publisher name** without a preceding keyword, treat the whole line as a publisher (e.g. `Kajaanin ammattikorkeakoulu` on its own line).\n",
      "3. Remove any surrounding whitespace, but **preserve the exact spelling and diacritics**.\n",
      "4. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "5. If no publisher can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Apply the case‑insensitive regex:  \n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "* Capture group 1, then strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. **Extract the identifier** that follows, allowing for optional surrounding characters such as `:` `(` `)` and optional hyphens/spaces.  \n",
      "   Example patterns to recognise:  \n",
      "   * `ISBN 978‑952‑302‑949‑1`  \n",
      "   * `(ISBN: 978 952 302 949 1)`  \n",
      "   * `URN:ISBN:978-952-302-949-1`\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic indicators** (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `e‑book`, `e‑version`.\n",
      "   * **Print indicators**: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `paper`, `paperback`.\n",
      "   * If **both** electronic and print indicators appear for the same identifier, add it to **both** lists.\n",
      "   * If **only electronic** indicators appear → add to `e_isbn` / `e_issn`.\n",
      "   * If **only print** indicators appear → add to `p_isbn` / `p_issn`.\n",
      "   * **If no qualifier is present**, **add the identifier to `e_isbn` (or `e_issn`) only**. This rule matches the evaluation expectations where an unqualified ISBN is treated as an electronic identifier.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly 8 digits (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Detect the resource type by searching the entire document (including PDF metadata) for the following keywords (case‑insensitive). Use the **first matching row** in the table (top‑to‑bottom priority). If multiple rows match, the earliest row wins.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| **ISBN** present **and** a publisher that is a known **book publisher** (e.g., Routledge, Springer, Cambridge, Elsevier, Wiley, Åbo Akademi, Metropolia, etc.) **and** no thesis‑related keywords → `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI contains a known journal prefix) → `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present → `article` |\n",
      "| “Report”, “Technical report”, “Research report” → `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” → `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (publisher in DOI URL is a book publisher) → `book part` |\n",
      "| *(none of the above)* → `None` |\n",
      "\n",
      "**Important:** Because some documents contain both ISBN and thesis‑related wording, the **book rule must be evaluated *before* the thesis rules** (i.e., place the “ISBN + book publisher” row above the thesis rows). This prevents mis‑classifying a book as a thesis.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "2025/09/30 15:44:40 INFO dspy.evaluate.evaluate: Average Metric: 2.1272727272727274 / 3 (70.9%)\n",
      "2025/09/30 15:45:17 INFO dspy.evaluate.evaluate: Average Metric: 41.28051948051947 / 64 (64.5%)\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Full valset score for new program: 0.6450081168831169\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Full train_val score for new program: 0.6450081168831169\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Individual valset scores for new program: [0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.2727272727272727, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.696969696969697, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.9090909090909091, 0.8181818181818182, 0.5454545454545454, 0.5272727272727272, 0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.4805194805194805, 0.6363636363636364, 0.2727272727272727, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.5151515151515151, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.7878787878787878]\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.6060606060606061, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Full valset pareto front score: 0.7431818181818182\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Updated valset pareto front programs: [{8, 3, 12, 6}, {13}, {0, 10}, {8, 10}, {13, 6}, {8, 1, 11, 4}, {8, 10, 3, 13}, {8, 9}, {3}, {4}, {3, 4, 8, 9, 10}, {8}, {8}, {10}, {9, 7}, {10}, {8, 10, 6}, {2, 4, 5}, {9, 13}, {10, 12}, {0, 12}, {2, 3, 13}, {8, 10, 7}, {3}, {13}, {8, 10, 4, 12}, {0, 10, 3, 13}, {9}, {8, 10, 4}, {8}, {3}, {9, 2, 6}, {8, 9, 10, 13}, {8}, {8, 10, 13}, {5}, {5}, {8, 9, 10, 13}, {0}, {2, 4}, {8, 9}, {4, 8, 9, 10, 12, 13}, {11}, {10}, {9, 10, 4, 13}, {2, 10, 6}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13}, {10}, {8}, {0}, {3, 6, 9, 10, 11, 12}, {0}, {10, 2, 3, 13}, {8, 9, 10, 13}, {10, 3, 6}, {9, 3}, {10}, {8}, {13, 7}, {2}, {7}, {11, 7}, {8, 9}]\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: Linear pareto front program index: 10\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 20: New program candidate index: 13\n",
      "GEPA Optimization:  32%|███▏      | 1016/3200 [44:10<2:03:21,  3.39s/rollouts]2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 21: No merge candidates found\n",
      "2025/09/30 15:45:17 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Selected program 5 score: 0.4560188279857397\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.55 / 3 (51.5%): 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:45:23 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:47:19 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Proposed new text for predict: markdown\n",
      "# Precise Metadata Extraction from PDF‑derived Text  \n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* `pdfinfo` – raw PDF metadata (e.g. `title`, `author`, `creationDate`, …).  \n",
      "* `pages` – an ordered list of page objects, each containing  \n",
      "  * `page` – page number (1‑based integer)  \n",
      "  * `text` – the plain‑text extracted from that page (may contain markdown headings, bold/italic markup, hyperlinks, footnotes, line‑breaks, etc.).\n",
      "\n",
      "Your task is to produce **exactly one JSON object** that contains **all fields listed in the table below** (order does not matter). Do **not** add any extra keys.  \n",
      "If a field cannot be determined, use the value specified in the *Missing‑Data Handling* section.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. General Pre‑processing (apply to every page **before** any extraction)\n",
      "\n",
      "1. Replace Windows line endings `\\r\\n` with `\\n`.  \n",
      "2. Remove **markdown image syntax** `![](...)` and any HTML‑like tags `<...>`.  \n",
      "3. Split the page text into **lines** on `\\n`.  \n",
      "4. Trim leading and trailing whitespace from each line.  \n",
      "5. Preserve empty lines – they are important for detecting multi‑line titles.  \n",
      "6. **Do not** collapse multiple spaces until after headings have been identified (to keep line‑break information for titles that span several lines).  \n",
      "\n",
      "---\n",
      "\n",
      "## 2. Field Extraction Details  \n",
      "\n",
      "| Field | Type | Extraction rules |\n",
      "|-------|------|------------------|\n",
      "| **language** | string | Detect from the **body text** (ignore `pdfinfo[\"language\"]`).<br>1. Build three stop‑word lists (see below).<br>2. Tokenise every word in the whole document: lower‑case, strip surrounding punctuation, split on whitespace.<br>3. Count occurrences of each language’s stop‑words.<br>4. If the highest count is **≥ 3** and is **unique**, return its ISO‑639‑1 code (`fi`, `sv`, `en`).<br>5. Otherwise return `\"und\"` (undetermined). |\n",
      "| **title** | string | 1. Scan pages in order for the **first level‑1 markdown heading** (`# …`).<br>2. If the heading is **followed immediately by one or more non‑empty lines that are not headings**, treat those lines as a continuation of the title (concatenate with a space). Stop when an empty line or another heading appears.<br>3. Strip the leading `#` and any surrounding `*`/`**`, then trim whitespace.<br>4. If **no level‑1 heading** is found, look for the **first bold line** (`**…**` or `*…*`). Apply the same “continue on next line if no empty line” rule and strip the asterisks.<br>5. If still none, fall back to `pdfinfo[\"title\"]` **only if** it looks like a real title (contains at least one letter, a space, and is not the literal string “Untitled” or empty). Strip surrounding whitespace.<br>6. If still none, set to `null`. |\n",
      "| **alt_title** | list of strings | 1. After the primary title has been identified, look **immediately** (no intervening non‑heading text) for a **level‑2 heading** (`## …`). If found, strip the leading `##` and any surrounding asterisks, trim, and add to the list. <br>2. Additionally, if the line **directly after** the primary title (or after the level‑2 heading, if present) is a **translation** (i.e., its language, detected with the same stop‑word method, differs from the main document language), treat that line as an alternative title (trim it). <br>3. Return distinct values in the order found. If none, return `[]`. |\n",
      "| **creator** | list of strings | 1. Gather all lines that contain **any** of the following keywords (case‑insensitive): `author`, `authors`, `tekijä`, `kirjoittaja`, `kirjoittajat`, `author(s)`, `author:`. Also consider `pdfinfo[\"author\"]` as a candidate line. <br>2. For each candidate line, split on commas, semicolons, the word “and”, “&”, or line breaks. <br>3. For each token:<br>   • Trim punctuation and whitespace.<br>   • Discard generic placeholders such as “et al.”, “and others”, “author”, “authors”.<br>   • If the token **contains a comma**, assume it is already “Last, First”.<br>   • Otherwise assume “First Last” (or “First Middle Last”) and **invert** to “Last, First”. Preserve diacritics and original capitalisation.<br>4. Remove duplicate names, keep the order of first appearance. If no names are found, return `[]`. |\n",
      "| **year** | integer | 1. Scan every line for a **four‑digit number** between 1900‑2099 that appears **next to** any of these cues (case‑insensitive): `Year:`, `©`, `©`, `Datum`, `Date`, `Käyntivuosi`, `Published`, `Published:` , `Käyntivuosi`, `Käyttövuosi`, `Käyttö`, `Käyttöaika`, `Käytetty`, `Käytetty:` , `Käyttäjä`, `Käyttäjän`, `Käyttäjien`, `Käyttäjänä`, `Käyttäjänä:` , `Käyttäjänä`, `Käyttäjänä`, `Käyttäjänä`, `Käyttäjänä`. <br>2. Also accept a year that appears alone on a line that looks like a **date line** (e.g., “Karelia‑ammattikorkeakoulu 2021”). <br>3. Collect **all** candidate years; if more than one, **choose the latest** (largest number). <br>4. If none are found, extract from `pdfinfo[\"creationDate\"]` using the pattern `D:YYYY…`. <br>5. If still none, return `null`. |\n",
      "| **publisher** | list of strings | 1. Look for lines containing any of the following **keywords** (case‑insensitive): `university`, `universitet`, `university of`, `college`, `institute`, `school of`, `journal of`, `publisher:`, `published by`, `Karelia‑ammattikorkeakoulu`, `Hansaprint Oy`, `Yrkeshögskolan`, `Novia`, `Novia University of Applied Sciences`, `Novia‑ammattikorkeakoulu`, `Laurea‑ammattikorkeakoulu`, `Laurea University of Applied Sciences`, `Yrkeshögskolan Novia`, `Yrkeshögskolan`, `Yrkeshögskolan`, `Yrkeshögskolan`, `Yrkeshögskolan`, `Yrkeshögskolan`, `Yrkeshögskolan`, `Yrkeshögskolan`, `Yrkeshögskolan`, `Yrkeshögskolan`. <br>2. If a line matches, **extract the full entity name** (trim surrounding punctuation such as commas, periods, brackets). <br>3. Do **not** treat plain city or country names as publishers unless they appear together with a keyword above. <br>4. Keep distinct entries, preserving order of first appearance. If none, return `[]`. |\n",
      "| **doi** | string | Find any URL matching `https?://doi\\.org/([^\\s\\)]+)`. Capture the part after the domain, then strip trailing punctuation characters `. ) ]`. If none, return `null`. |\n",
      "| **e_isbn** | list of strings | 1. Regex to locate ISBNs: `ISBN(?:‑13)?:?\\s*([0-9][0-9\\-\\s]{9,})` (case‑insensitive). <br>2. For each match, **remove spaces and hyphens** to obtain a continuous digit string. <br>3. Classify as **electronic** only if the **same line** (or the line immediately preceding/following it) contains any of these cues (case‑insensitive): `online`, `electronic`, `verkkojulkaisu`, `e‑isbn`, `e‑ISBN`, `e‑isbn`, `e‑ISBN`. <br>4. Keep only those classified as electronic. Return a list of unique cleaned ISBN strings. If none, return `[]`. |\n",
      "| **p_isbn** | list of strings | Same regex as for `e_isbn`. Classify as **print** if the line contains any of: `print`, `painettu`, `p‑isbn`, `p‑ISBN`, `p‑isbn`, `p‑ISBN`. If **no electronic cue** is present on that line, treat the ISBN as print. Return unique cleaned strings. If none, return `[]`. |\n",
      "| **e_issn** | string | Regex: `ISSN\\s*[:]?[\\s]*([0-9]{4}\\s*[-‑]\\s*[0-9]{3}[0-9X])` (case‑insensitive). <br>Classify as electronic when the same line also contains any electronic cue from the ISBN rule. Return the cleaned value in the form `####-####`. If none, return `null`. |\n",
      "| **p_issn** | string | Same regex as for `e_issn`. Classify as print when the line contains any print cue from the ISBN rule **or when no electronic cue is present**. Return cleaned value `####-####`. If none, return `null`. |\n",
      "| **type_coar** | string | Map the document to a COAR type (lower‑case) using the **most specific** matching keyword(s) (case‑insensitive). Use the table below; if several categories match, choose the one that appears later in the table (more specific). If none match, default to `\"report\"`. |\n",
      "| **reasoning** *(optional)* | string | Free‑form short explanation of how each field was derived. May be omitted. |\n",
      "\n",
      "### COAR Mapping Table (most specific → least specific)\n",
      "\n",
      "| Keyword(s) (case‑insensitive) | COAR type |\n",
      "|-------------------------------|-----------|\n",
      "| `master’s thesis`, `master thesis`, `kandidaatintutkielma`, `master thesis` | `master thesis` |\n",
      "| `bachelor thesis`, `bachelor’s thesis`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| `doctoral thesis`, `phd thesis`, `väitöskirja`, `dissertation` | `doctoral thesis` (or simply `thesis` if you prefer the generic term) |\n",
      "| `report`, `technical report`, `research report`, `tutkimusraportti` | `research report` |\n",
      "| `journal article`, `article`, `paper`, `artikkeli` | `journal article` |\n",
      "| `conference paper`, `proceedings`, `konferenssijulkaisu` | `conference paper` |\n",
      "| `book chapter`, `chapter` | `book chapter` |\n",
      "| `book` | `book` |\n",
      "| `dataset`, `software` | same term (`dataset`, `software`) |\n",
      "| *(no match)* | `report` |\n",
      "\n",
      "### Language Stop‑word Lists  \n",
      "\n",
      "| Language | Stop‑words (case‑insensitive) |\n",
      "|----------|------------------------------|\n",
      "| **fi** | `ja`, `on`, `että`, `tämä`, `niin`, `mutta`, `tai`, `kun`, `se`, `kanssa` |\n",
      "| **sv** | `och`, `att`, `är`, `det`, `så`, `men`, `eller`, `som`, `på` |\n",
      "| **en** | `and`, `the`, `of`, `in`, `to`, `for`, `with`, `that`, `by`, `as`, `is`, `on` |\n",
      "\n",
      "*Tokenisation*: split on whitespace, lower‑case, strip surrounding punctuation (`.,:;!?()[]{}\"` etc.).\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑Data Handling  \n",
      "\n",
      "| Field type | Value when missing |\n",
      "|------------|-------------------|\n",
      "| String (`title`, `doi`, `e_issn`, `p_issn`, `type_coar`) | `null` |\n",
      "| Integer (`year`) | `null` |\n",
      "| List (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) | `[]` |\n",
      "| `language` | `\"und\"` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output Format  \n",
      "\n",
      "Produce **one** valid JSON object containing **exactly** the following keys (order does not matter; include `reasoning` only if you want to provide it):\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"...\",\n",
      "  \"title\": \"...\",\n",
      "  \"alt_title\": [...],\n",
      "  \"creator\": [...],\n",
      "  \"year\": ...,\n",
      "  \"publisher\": [...],\n",
      "  \"doi\": \"...\",\n",
      "  \"e_isbn\": [...],\n",
      "  \"p_isbn\": [...],\n",
      "  \"e_issn\": \"...\",\n",
      "  \"p_issn\": \"...\",\n",
      "  \"type_coar\": \"...\",\n",
      "  \"reasoning\": \"...\"\n",
      "}\n",
      "2025/09/30 15:47:28 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/09/30 15:48:21 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:48:28 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 15:48:28 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 15:48:33 INFO dspy.evaluate.evaluate: Average Metric: 36.490909090909085 / 64 (57.0%)\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Full valset score for new program: 0.5701704545454546\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Full train_val score for new program: 0.5701704545454546\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Individual valset scores for new program: [0.6363636363636364, 0.36363636363636365, 0.45454545454545453, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.9090909090909091, 0.45454545454545453, 0.6060606060606061, 0.5454545454545454, 0.36363636363636365, 0.7272727272727273, 0.5454545454545454, 0.6060606060606061, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.696969696969697, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.4454545454545455, 0.7272727272727273, 0.4848484848484848, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.5151515151515151, 0.36363636363636365, 0.42424242424242425, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.22727272727272727, 0.45454545454545453, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.3333333333333333, 0.5151515151515151, 0.4848484848484848, 0.36363636363636365, 0.5454545454545454, 0.36363636363636365, 0.42424242424242425, 0.6363636363636364]\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.6060606060606061, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Full valset pareto front score: 0.7446022727272728\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Updated valset pareto front programs: [{8, 3, 12, 6}, {13}, {0, 10}, {8, 10}, {13, 6}, {1, 4, 8, 11, 14}, {8, 10, 3, 13}, {8, 9}, {3}, {4}, {14}, {8}, {8}, {10}, {9, 7}, {10}, {8, 10, 6}, {2, 4, 5}, {9, 13}, {10, 12}, {0, 12}, {2, 3, 13}, {8, 10, 7}, {3}, {13}, {8, 10, 4, 12}, {0, 3, 10, 13, 14}, {9}, {8, 10, 4}, {8}, {3}, {9, 2, 6}, {8, 9, 10, 13}, {8}, {8, 10, 13}, {5}, {5}, {8, 9, 10, 13}, {0}, {2, 4}, {8, 9}, {4, 8, 9, 10, 12, 13}, {11}, {10}, {9, 10, 4, 13}, {2, 10, 6, 14}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14}, {10}, {8}, {0}, {3, 6, 9, 10, 11, 12}, {0}, {10, 2, 3, 13}, {8, 9, 10, 13}, {10, 3, 6, 14}, {9, 3}, {10}, {8}, {13, 7}, {2}, {7}, {11, 7}, {8, 9}]\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: Linear pareto front program index: 10\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 21: New program candidate index: 14\n",
      "GEPA Optimization:  34%|███▍      | 1086/3200 [47:26<1:51:05,  3.15s/rollouts]2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 22: No merge candidates found\n",
      "2025/09/30 15:48:33 INFO dspy.teleprompt.gepa.gepa: Iteration 22: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.7%): 100%|██████████| 3/3 [00:08<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:48:42 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:50:33 INFO dspy.teleprompt.gepa.gepa: Iteration 22: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata such as `title`, `author`, `creationDate`, `modDate`, etc.\n",
      "* **pages** – an ordered list of page objects, each with a `page` number (integer) and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and produce a **flat list of metadata fields**.  \n",
      "Each field name is written on its own line, followed by its value on the next line, exactly as shown in the *Output format* section below.\n",
      "\n",
      "All list values must be **valid Python‑style lists** (single quotes, commas, no trailing commas).  \n",
      "If a piece of information cannot be found, output the *missing‑value placeholder* described in the *Missing‑value handling* table.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the **document language** (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle, colon, and line‑breaks that belong to the same logical heading. Preserve the original spelling and punctuation, **do not trim trailing spaces**. Collapse line‑breaks to a **single space** when writing the value (i.e. the output must be one line). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do **not** repeat the main title. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a line that is clearly a translation. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Split a single‑string name on the **last space only** (unless the name already contains a comma, in which case keep it unchanged). Separate multiple authors using commas, semicolons, “and”, or line breaks – treat each as a distinct author. Preserve diacritics. If none, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If several candidates exist, choose the one **closest (by line distance) to the title**. If none found, fall back to `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`). Return as an integer; otherwise `None`. |\n",
      "| **publisher** | list of strings | Exact imprint string(s) (e.g. university, department, institute, publishing house). Capture only lines that are **clearly the publishing imprint** – they usually contain words like “Press”, “Publishing”, “JULKAISU”, “Publisher”, “University”, “Arcada”, etc. Do **not** treat generic department or faculty lines as publisher unless they appear as part of a formal imprint line. Preserve diacritics, hyphens, and spacing. If multiple institutions are listed on the same line, split on commas, slashes or the word “and” while preserving order. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect any of the patterns listed in 2.7, strip surrounding punctuation and output the raw DOI. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** (hyphens, spaces, parentheses) and keep the resulting digit string (13‑digit preferred, but keep 10‑digit if present). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. Include only if an explicit print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an explicit online qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. Include only if an explicit print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of the following (add new ones only if they appear in the source): `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `article`, `report`, `research report`, `conference paper`, `book part`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the whole document into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided the count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – the first page (or first two pages) that contain the **largest centred heading(s)** (often in ALL‑CAPS or title‑case, sometimes preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve **exact spelling and punctuation**. When writing the output, replace the original line‑breaks with a **single space** (do not insert extra line‑break characters).  \n",
      "4. Do **not** include page numbers, section headings, catalogue codes, or imprint lines.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a title in a **different language** (usually English). Typical markers:\n",
      "\n",
      "* “English title”, “Title (English)”, “Title in English”\n",
      "* A second heading placed directly beneath the main title, often separated by a blank line only.\n",
      "* The word “Translation” or “Translated title”.\n",
      "\n",
      "Add each distinct string to `alt_title`. Do not duplicate the main title. If none found, output `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names (often directly under the title, or preceded by “by”, “author”, “kirjoittanut”, “Tekijä”, etc.).  \n",
      "3. For each name:  \n",
      "\n",
      "   ```\n",
      "   if name contains a comma → keep unchanged\n",
      "   else split on the LAST space only → \"First Middle Last\" → \"Last, First Middle\"\n",
      "   ```\n",
      "\n",
      "4. Trim whitespace.  \n",
      "5. If multiple authors appear, they may be separated by commas, semicolons, “and”, or line breaks – treat each as a separate author, preserving order.  \n",
      "6. Return the list; if none, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line(s)** – usually after the title, subtitle, author, and before the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. **Only** treat a line as a publisher if it contains clear publishing terminology (e.g., “Press”, “Publishing”, “JULKAISU”, “Publisher”, “University”, “Arcada”, “Yrkeshögskolan”, “Institute”, “Centre”, etc.). Generic department/faculty lines (e.g., “Humanistinen tiedekunta”) are **not** publishers unless they appear together with a publishing term.  \n",
      "4. If the line contains multiple entities separated by commas, slashes, or “and”, split them into separate list items **preserving the original spelling**.  \n",
      "5. Do **not** alter diacritics or add/remove words.  \n",
      "6. If no clear imprint line is found, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the **raw DOI** string.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**  \n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if present).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "\n",
      "   * Electronic qualifier present → add to `e_isbn` / `e_issn`.  \n",
      "   * Print qualifier present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Do **not** guess the format; only explicit qualifiers count.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Kandidaatintutkielma”, “Bachelor’s thesis”, “Kandidat”, “Kandidaatti” | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If the document is a **part of a larger work** (e.g., “Chapter”, “Section”, “Part”, “Book part”) and an ISBN is present, treat as `book part`. |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**.  \n",
      "Lists must use Python syntax with single quotes. Example:\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title and subtitle were taken from the first page where the largest centred heading appears; the year 2022 is printed on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 15:50:40 INFO dspy.evaluate.evaluate: Average Metric: 2.090909090909091 / 3 (69.7%)\n",
      "2025/09/30 15:50:40 INFO dspy.teleprompt.gepa.gepa: Iteration 22: New subsample score is not better, skipping\n",
      "GEPA Optimization:  34%|███▍      | 1092/3200 [49:34<2:20:37,  4.00s/rollouts]2025/09/30 15:50:40 INFO dspy.teleprompt.gepa.gepa: Iteration 23: Selected program 8 score: 0.6461084054834055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.53 / 3 (51.1%): 100%|██████████| 3/3 [00:05<00:00,  1.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:50:46 INFO dspy.evaluate.evaluate: Average Metric: 1.5324675324675323 / 3 (51.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:52:25 INFO dspy.teleprompt.gepa.gepa: Iteration 23: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** containing:\n",
      "\n",
      "* `pdfinfo` – optional dictionary with PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).\n",
      "* `pages` – a list of page objects, each with a `page` number and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field per line, exactly as shown in the examples).  \n",
      "The output must be ready to be turned into a JSON record later.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the majority of visible words (see §2.1). |\n",
      "| **title** | `string` or `None` | Full title exactly as it appears on the title page (including subtitle, colon, line‑breaks that belong to the same logical title). |\n",
      "| **alt_title** | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). If none, output `[]`. |\n",
      "| **creator** | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (see §2.4). Preserve the order they appear. If none, output `[]`. |\n",
      "| **year** | `int` or `None` | Publication year (1900‑2100). Prefer a 4‑digit year on the title page, copyright line, or from `pdfinfo.creationDate`/`modDate`. |\n",
      "| **publisher** | `list` of `string` | Publishing institution(s) exactly as they appear. If none, output `[]`. |\n",
      "| **doi** | `string` or `None` | DOI **without** any prefix (`10.` …). Detect patterns such as `doi:10.xxxx/…`, `DOI 10.xxxx/…`, or URLs like `https://doi.org/10.xxxx/…`. |\n",
      "| **e_isbn** | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing all hyphens, spaces and surrounding parentheses**, leaving only the digit string (13‑digit ISBN‑13 or 10‑digit ISBN‑10). |\n",
      "| **p_isbn** | `list` of `string` | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. |\n",
      "| **e_issn** | `string` or `None` | ISSN for the **online** version, **keep the hyphen** (e.g. `1234-5678`). |\n",
      "| **p_issn** | `string` or `None` | ISSN for the **print** version, keep the hyphen. |\n",
      "| **type_coar** | `string` or `None` | COAR resource type. Use **exactly one** of the following lower‑case values: `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book review`, `article`, `report`, `research report`, `conference paper`. Determine from explicit wording (see §2.9). |\n",
      "| **reasoning** *(optional)* | `string` | One‑ or two‑sentence paragraph explaining how you derived the values. This field is optional and does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Each field name appears on its own line, **exactly** as shown above.\n",
      "* The value appears on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive):\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `julkaisu`, `tietoa`, `digitalisaatio`, `yhteistyö`.\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `publikation`, `statistik`, `siffror`, `rapport`, `undersökning`.\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `study`, `report`, `statistics`.\n",
      "2. Choose the language with the highest count. If there is a tie or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **first page** that contains a line in **ALL CAPS** *or* a line that looks like a heading (e.g. surrounded by `#`, `##`, or preceded/followed by blank lines).\n",
      "2. Take that line as the **main title**.\n",
      "3. If the next line(s) are a subtitle (they follow a colon, dash, or appear directly below without an intervening blank line), concatenate them to the main title with a single space.\n",
      "4. Preserve original punctuation, diacritics, and casing. Do **not** include page numbers, footers, or section headings.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Search for a second title that is explicitly marked as being in another language (e.g. “Title (English)”, “English title”, “Original title”, “Original title (Finnish)”, “Original title (Swedish)”, etc.).\n",
      "* Capture each such title as a separate string in `alt_title`.\n",
      "* Do not duplicate the main `title`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Look for lines that contain any of the keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`.\n",
      "2. Extract the name(s) that follow the keyword on the same line, or on the next line if the line ends with a colon.\n",
      "3. Split multiple authors using any of the delimiters: `,`, `;`, `&`, `and`.\n",
      "4. For each name:\n",
      "   * If it already contains a comma, keep it unchanged (assumed `Last, First`).\n",
      "   * Otherwise split on the **last** space: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "5. Preserve diacritics and original case.\n",
      "6. **Do not** treat publisher or institution lines as creators.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the first two pages for a 4‑digit number that looks like a year (1900‑2100). Prefer the first such number that appears in a line that also contains words like `©`, `Copyright`, `Julkaistu`, `Published`, `Publicerad`, `Utgivningsår`, etc.\n",
      "2. If none is found, look at `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`). Extract the `YYYY` part.\n",
      "3. Return the year as an integer; if no year can be found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Keskus`, `Institute of`, `Institut`, `Faculté`, `Fakultet`, `Institutet`.\n",
      "2. Capture the **full phrase** exactly as it appears (including abbreviations, hyphens, and diacritics).  \n",
      "3. If several distinct publishers appear, list them in order of appearance.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Use the regex (Python syntax):  \n",
      "  ```python\n",
      "  r'(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)'\n",
      "  ```  \n",
      "* Return only the captured DOI (strip surrounding whitespace and trailing punctuation).\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Find every occurrence of the word `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Extract the following digit string, allowing hyphens, spaces, or surrounding parentheses. Example matches: `ISBN 978-952-03-1405-7`, `(ISBN: 978 951 2986477)`.\n",
      "3. Determine the **qualifier** (electronic vs. print):\n",
      "   * If the same line (or the line immediately before/after) contains any of `PDF`, `e‑ISBN`, `Electronic`, `Online`, `e‑ISSN`, `online version`, treat it as **electronic**.\n",
      "   * If it contains any of `Print`, `Hardcover`, `Paperback`, `Print version`, `paper version`, treat it as **print**.\n",
      "   * If no qualifier is present, **add the identifier to both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**\n",
      "   * **ISBN**: remove **all** characters except digits (`0‑9`). Keep the resulting digit string (13‑digit ISBN‑13 or 10‑digit ISBN‑10). Store in the appropriate list.\n",
      "   * **ISSN**: keep the hyphen between the two 4‑digit blocks (e.g. `1234-5678`). Remove any surrounding whitespace or parentheses.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the whole document for the following keywords (case‑insensitive). The **first** matching rule determines the value.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, “Doctoral degree” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, plus a publisher that is a book‑publisher | `book` |\n",
      "| “Book review”, “Recension”, “Review of” (and a DOI that resolves to a journal) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN | `article` |\n",
      "| “Report”, “Technical report”, “Research report”, “Rapport” | `report` |\n",
      "| “Research report”, “Research‑report”, “Research report” (when the document is a study but not a thesis) | `research report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| If none of the above apply, output `None`. |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "2025/09/30 15:52:32 INFO dspy.evaluate.evaluate: Average Metric: 1.487012987012987 / 3 (49.6%)\n",
      "2025/09/30 15:52:32 INFO dspy.teleprompt.gepa.gepa: Iteration 23: New subsample score is not better, skipping\n",
      "GEPA Optimization:  34%|███▍      | 1098/3200 [51:25<2:52:13,  4.92s/rollouts]2025/09/30 15:52:32 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Selected program 0 score: 0.5871324855699855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.27 / 3 (75.8%): 100%|██████████| 3/3 [00:06<00:00,  2.24s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:52:38 INFO dspy.evaluate.evaluate: Average Metric: 2.2727272727272725 / 3 (75.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:53:48 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Proposed new text for predict: markdown\n",
      "# Task: Extract Structured Bibliographic Metadata from PDF‑Extracted Text\n",
      "\n",
      "You will receive a JSON object that contains the raw text of each page of a PDF (`pages`) together with optional PDF‑level metadata (`pdfinfo`).  \n",
      "Your job is to read this information and produce **exactly** the set of metadata fields listed below, following the rules and conventions described in this instruction.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required Output Fields  \n",
      "\n",
      "| Field | Type | Description / Extraction Rules |\n",
      "|-------|------|--------------------------------|\n",
      "| `language` | string | ISO‑639‑1 code of the language of the main document (e.g. `fi`, `sv`, `en`). Detect from the majority of the visible text (title, abstract, headings). Do **not** default to Finnish; use a simple language‑detect heuristic (e.g., presence of Swedish‑specific characters `åäö` or common Swedish words, otherwise Finnish‑specific words, otherwise English). |\n",
      "| `title` | string | The primary title in the original language of the document. Usually appears as a large heading on the first few pages, often after the author name. Strip surrounding whitespace and line‑break artefacts. |\n",
      "| `alt_title` | list of strings | Any alternative title(s) in a different language (most commonly an English title). Look for a separate heading that is a literal translation of the primary title, or an English title on the “Abstract” page. Return an empty list `[]` if none is found. |\n",
      "| `creator` | list of strings | All authors of the work. Each name must be normalized to **“Last, First”** (or “Last, First Middle” when a middle name is present). Use the “Tekijä”, “Author”, “Creator”, or similar label to locate the names. If the PDF lists multiple authors, include each as a separate list element. |\n",
      "| `year` | integer | Four‑digit publication year. Prefer the year from `pdfinfo.creationDate` (e.g. `D:20201117153420+02'00'` → `2020`). If that is missing, look for a date line (e.g., “19.10.2020”, “22 January 2020”). |\n",
      "| `publisher` | list of strings | Institution or organisation that issued the work (e.g. a university, college, research institute, newspaper). Do **not** include project partners or sponsors unless they are explicitly identified as the publisher. Return an empty list `[]` if no publisher can be identified. |\n",
      "| `doi` | string | The DOI if present (pattern `10.\\d{4,9}/[-._;()/:A-Z0-9]+`). Return `None` when absent. |\n",
      "| `e_isbn` | list of strings | Electronic ISBN numbers (ISBN‑13 or ISBN‑10, usually prefixed with “ISBN‑13:” or “ISBN”). Return an empty list if none. |\n",
      "| `p_isbn` | list of strings | Print ISBN numbers. Same format as `e_isbn`. |\n",
      "| `e_issn` | string | Electronic ISSN (format `####-####`). Return `None` if absent. |\n",
      "| `p_issn` | string | Print ISSN. Return `None` if absent. |\n",
      "| `type_coar` | string | COAR‑type of the resource. Use the following mapping (case‑insensitive):  <br>• If the document mentions a **Bachelor** degree, “bachelor thesis”. <br>• If it mentions a **Master** degree, “master thesis”. <br>• If it is a **Doctoral** dissertation, “doctoral thesis”. <br>• If the word “Report”, “Rapport”, “Rapportti” etc. appears as the type, use “report”. <br>• If the source is a newspaper or magazine article, use “newspaper article”. <br>• Otherwise, use the most specific term you can infer (e.g., “thesis”, “article”). Return the term exactly as shown (lower‑case). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. General Extraction Strategy  \n",
      "\n",
      "1. **Parse PDF‑level metadata** (`pdfinfo`).  \n",
      "   - `creationDate` → extract the first four digits after the leading `D:` → candidate year.  \n",
      "\n",
      "2. **Iterate pages in order** (starting at page 1).  \n",
      "   - Keep a running list of candidate titles, authors, dates, publisher names, DOI/ISBN/ISSN patterns.  \n",
      "   - Stop searching for a field once it has been confidently identified, but continue scanning for other fields.\n",
      "\n",
      "3. **Title detection**  \n",
      "   - The first line that is all‑caps or title‑case and appears **after** an author line is usually the main title.  \n",
      "   - If a later page (often the “Abstract” page) contains a title that is the literal translation of the first title, treat it as `alt_title`.  \n",
      "\n",
      "4. **Author detection**  \n",
      "   - Look for lines preceded by keywords: `Tekijä`, `Author`, `Creator`, `Authors`, `Tekijät`.  \n",
      "   - Extract the following line(s) until a blank line or a known label (e.g., `Otsikko`, `Title`).  \n",
      "   - Split names on spaces, assume the last token is the family name, everything before it is the given name(s).  \n",
      "\n",
      "5. **Publisher detection**  \n",
      "   - Keywords: `Metropolia Ammattikorkeakoulu`, `University`, `College`, `Institute`, `Svenska Österbottens förbund för utbildning och kultur`, `YIT`, newspaper mastheads, etc.  \n",
      "   - Prefer the institution that appears on the **title page** or **cover page**.  \n",
      "\n",
      "6. **Date detection**  \n",
      "   - Regexes for Finnish dates (`\\d{1,2}\\.\\d{1,2}\\.\\d{4}`) and English dates (`\\d{1,2}\\s+[A-Za-z]+\\s+\\d{4}`).  \n",
      "   - Use the earliest year found (usually the publication year).  \n",
      "\n",
      "7. **DOI / ISBN / ISSN detection**  \n",
      "   - DOI regex: `10\\.\\d{4,9}/[-._;()/:A-Z0-9]+` (case‑insensitive).  \n",
      "   - ISBN regex: `(?:ISBN(?:‑13)?:?\\s*)?(\\d{9}[\\dX]|\\d{13})` – capture the number only.  \n",
      "   - ISSN regex: `\\d{4}-\\d{3}[\\dX]`.  \n",
      "\n",
      "8. **Language detection**  \n",
      "   - Count occurrences of language‑specific characters/words:  \n",
      "     - Swedish: `å`, `ä`, `ö`, words like “och”, “för”, “är”.  \n",
      "     - Finnish: `ä`, `ö`, words like “ja”, “on”, “kanssa”.  \n",
      "     - English: absence of the above and presence of common English stop‑words.  \n",
      "   - Choose the language with the highest count.  \n",
      "\n",
      "9. **COAR type determination**  \n",
      "   - Scan for degree level keywords: `Bachelor`, `Bachelors`, `Bachelor of Engineering`, `Opinnäytetyö` together with “Bachelor”.  \n",
      "   - For master: `Master`, `Master’s`, `Graduates`, `Opinnäytetyö` together with “Master”.  \n",
      "   - For report: explicit word “Report”, “Rapport”, “Rapportti”.  \n",
      "   - For newspaper article: presence of newspaper masthead, date line typical of news, or the word “Artikel”.  \n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output Formatting  \n",
      "\n",
      "- Return **only** the JSON‑like key/value pairs shown in the examples (no extra commentary).  \n",
      "- Use `None` (capital N) for missing singular values, and `[]` for missing list values.  \n",
      "- Preserve the order of fields as listed in the table above.  \n",
      "\n",
      "**Example of a correct response**\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"fi\",\n",
      "  \"title\": \"Mallipohjaisen tuotannon haasteet työnjohdon kannalta\",\n",
      "  \"alt_title\": [\"Challenges of model-based production for job management\"],\n",
      "  \"creator\": [\"Partanen, Marko\"],\n",
      "  \"year\": 2020,\n",
      "  \"publisher\": [\"Metropolia Ammattikorkeakoulu\"],\n",
      "  \"doi\": null,\n",
      "  \"e_isbn\": [],\n",
      "  \"p_isbn\": [],\n",
      "  \"e_issn\": null,\n",
      "  \"p_issn\": null,\n",
      "  \"type_coar\": \"master thesis\"\n",
      "}\n",
      "2025/09/30 15:53:54 INFO dspy.evaluate.evaluate: Average Metric: 2.6363636363636362 / 3 (87.9%)\n",
      "2025/09/30 15:54:27 INFO dspy.evaluate.evaluate: Average Metric: 40.625 / 64 (63.5%)\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Full valset score for new program: 0.634765625\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Full train_val score for new program: 0.634765625\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Individual valset scores for new program: [0.7272727272727273, 0.6363636363636364, 0.696969696969697, 0.36363636363636365, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.7575757575757577, 0.7159090909090909, 0.8181818181818182, 0.36363636363636365, 0.696969696969697, 0.8181818181818182, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.696969696969697, 0.45454545454545453, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.5454545454545454, 0.2727272727272727, 0.8181818181818182, 0.6060606060606061, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.8181818181818182]\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.7878787878787878, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Full valset pareto front score: 0.7450757575757576\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Updated valset pareto front programs: [{8, 3, 12, 6}, {13}, {0, 10}, {8, 10}, {13, 6}, {1, 4, 8, 11, 14}, {8, 10, 3, 13}, {8, 9}, {3}, {4}, {14}, {8}, {8}, {10, 15}, {9, 7}, {10}, {8, 10, 6}, {2, 4, 5}, {9, 13}, {10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 7}, {3}, {13, 15}, {8, 10, 4, 12}, {0, 3, 10, 13, 14, 15}, {9}, {8, 10, 4}, {8}, {3}, {9, 2, 6}, {8, 9, 10, 13, 15}, {8}, {8, 10, 13, 15}, {5}, {5}, {8, 9, 10, 13}, {0}, {2, 4, 15}, {8, 9}, {4, 8, 9, 10, 12, 13, 15}, {11}, {10}, {4, 9, 10, 13, 15}, {2, 10, 6, 14}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15}, {10}, {8}, {0}, {3, 6, 9, 10, 11, 12}, {0}, {10, 2, 3, 13}, {8, 9, 10, 13, 15}, {3, 6, 10, 14, 15}, {9, 3}, {15}, {8, 15}, {13, 7}, {2}, {7}, {11, 7}, {8, 9, 15}]\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: Linear pareto front program index: 10\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 24: New program candidate index: 15\n",
      "GEPA Optimization:  36%|███▋      | 1168/3200 [53:20<1:49:44,  3.24s/rollouts]2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 25: No merge candidates found\n",
      "2025/09/30 15:54:27 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Selected program 9 score: 0.6372395833333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:08<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:54:35 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:56:19 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case) – see **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The **value** on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` **literally** (no quotes) for missing values.\n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use these seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`) **overriding** the stop‑word count.\n",
      "3. Otherwise choose the language with the highest stop‑word count. If there is a tie or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – usually the first page that contains a line in **ALL CAPS** *or* a line that is a markdown heading (`#`, `##`, `###`, …).  \n",
      "   *In OCR output, headings are often surrounded by blank lines; treat a line that is the **only non‑blank line** on the page (or the first non‑blank line) and is in all caps as the title line.*\n",
      "\n",
      "2. **Capture the full logical title**:  \n",
      "   * If the next line(s) are a subtitle (no blank line between them, or the subtitle follows a colon `:`), concatenate them with a single space.  \n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons).  \n",
      "   * Example:  \n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "3. Strip any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`.\n",
      "3. If still not found, fall back to the PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "   * If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Työväen historian ja perinteen tutkimuksen seura`), treat the whole line as a publisher entry.\n",
      "3. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "4. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to the corresponding list(s).  \n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn` (or `e_issn`) **and** `p_isbn` (or `p_issn`).\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and its prefix belongs to a journal publisher) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "--- \n",
      "\n",
      "**Remember:**  \n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 15:56:28 INFO dspy.evaluate.evaluate: Average Metric: 2.1515151515151514 / 3 (71.7%)\n",
      "2025/09/30 15:57:03 INFO dspy.evaluate.evaluate: Average Metric: 42.08363636363634 / 64 (65.8%)\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Full valset score for new program: 0.6575568181818182\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Full train_val score for new program: 0.6575568181818182\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.696969696969697, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 0.5272727272727272, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.5454545454545454, 0.696969696969697, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.7727272727272727, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.4454545454545455, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.4848484848484848, 0.6363636363636364, 0.2727272727272727, 0.6363636363636364, 0.7272727272727273, 0.9090909090909091, 0.36363636363636365, 0.5151515151515151, 0.5454545454545454, 0.7321212121212121, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.696969696969697, 0.8787878787878788]\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6090909090909091, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Full valset pareto front score: 0.7479924242424243\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Updated valset pareto front programs: [{3, 6, 8, 12, 16}, {13}, {0, 10}, {8, 10}, {13, 6}, {1, 4, 8, 11, 14}, {8, 10, 3, 13}, {8, 9}, {3}, {4}, {14}, {8}, {8, 16}, {16, 10, 15}, {9, 7}, {16, 10}, {8, 10, 6}, {2, 4, 5}, {9, 13}, {10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 7}, {3}, {13, 15}, {8, 10, 4, 12}, {0, 3, 10, 13, 14, 15, 16}, {9}, {8, 16, 10, 4}, {8}, {3}, {9, 2, 6}, {8, 9, 10, 13, 15, 16}, {8}, {8, 10, 13, 15}, {5}, {5}, {8, 9, 10, 13, 16}, {16}, {2, 4, 15}, {8, 9, 16}, {4, 8, 9, 10, 12, 13, 15, 16}, {11}, {16, 10}, {4, 9, 10, 13, 15, 16}, {2, 10, 6, 14}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16}, {10}, {8}, {0}, {3, 6, 9, 10, 11, 12}, {0, 16}, {10, 2, 3, 13}, {16}, {3, 6, 10, 14, 15}, {9, 3}, {15}, {16}, {13, 7}, {2}, {7}, {11, 7}, {16}]\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: Linear pareto front program index: 10\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 25: New program candidate index: 16\n",
      "GEPA Optimization:  39%|███▊      | 1238/3200 [55:56<1:32:04,  2.82s/rollouts]2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 26: No merge candidates found\n",
      "2025/09/30 15:57:03 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.54 / 3 (51.2%): 100%|██████████| 3/3 [00:07<00:00,  2.43s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:57:10 INFO dspy.evaluate.evaluate: Average Metric: 1.5363636363636364 / 3 (51.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:58:54 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will be given **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (e.g. `title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – a list of page objects, each with an integer `page` number and a string `text` that contains the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your task is to **scan the whole document** (all pages) and output a **flat list of metadata fields** exactly in the format described in the *Output format* section below.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. General output rules\n",
      "\n",
      "* Write each field name on a line **by itself**, then write its value on the **next line**.  \n",
      "* The order of fields must be exactly as listed in the table under **1.1 Output fields**.  \n",
      "* All list values must be **valid Python‑style lists**: single quotes, commas, no trailing comma.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be included **after** `type_coar`. It does **not** affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle, colon, and line‑breaks that belong to the same logical heading. Do **not** trim trailing spaces or add extra punctuation. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Split a name on the **last space only** unless it already contains a comma. Preserve diacritics. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, use `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint institution(s). Preserve diacritics and original spelling. If the imprint line contains a university followed by a department separated by a comma, **only keep the university name** (the text before the first comma). If multiple distinct institutions are listed (separated by slashes, “and”, or a new line), each becomes a separate list element in the order they appear. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** and keep the resulting digit string (13‑digit if present, otherwise keep what is left). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if an explicit print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an explicit online qualifier is present. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. Include only if an explicit print qualifier is present. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `research article`, `report`, `research report`, `conference paper`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters (case‑insensitive):\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – the first page (or first two pages) that contain the **largest centred heading(s)**. Typical clues: ALL‑CAPS, title‑case, surrounded by blank lines, or preceded by `#`/`###` markdown headings.  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve **exact line breaks** by joining the captured lines with a **single space** (do **not** insert `\\n`).  \n",
      "4. Do **not** include page numbers, section headings, catalogue codes, or any text that is not part of the logical heading.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the next page) for a heading that is clearly a title in a **different language**. Common markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names. Typical markers: “by”, “author”, “kirjoittanut”, “tekijä”, or a line directly under the title that consists mainly of capitalised names.  \n",
      "3. **Do not** treat place names, department names, or acknowledgements as authors.  \n",
      "4. For each name:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors that are delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order in which they appear.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **first institution name** before any comma (e.g. `\"Tampereen yliopisto, Johtamisen ja talouden tiedekunta\"` → keep `\"Tampereen yliopisto\"`).  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element **preserving the original spelling**.  \n",
      "4. Do not include department names, city names, or publisher addresses unless they are themselves separate institutions.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit if present, otherwise keep what remains).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "\n",
      "   * If an electronic qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a print qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above *and* the document is a research article (explicitly says “research article”, “original article”, “peer‑reviewed article”) | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format (example)\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Evaluation of renewable energy development in power generation in Finland\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Aslani, Alireza', 'Helo, Petri', 'Naaranoja, Marja']\n",
      "year\n",
      "2013\n",
      "publisher\n",
      "['AIP Publishing']\n",
      "doi\n",
      "10.1063/1.4855095\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "1941-7012\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "research article\n",
      "reasoning\n",
      "The title was taken from the first heading line; the year 2013 appears on the imprint; the DOI was extracted from the “doi.org” URL; no ISBN/ISSN qualifiers were found, so the lists are empty; the document contains a journal volume and ISSN, therefore the COAR type is “research article”.\n",
      "2025/09/30 15:59:01 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n",
      "2025/09/30 15:59:33 INFO dspy.evaluate.evaluate: Average Metric: 36.800000000000004 / 64 (57.5%)\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Full valset score for new program: 0.575\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Full train_val score for new program: 0.575\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Individual valset scores for new program: [0.6727272727272727, 0.6363636363636364, 0.7878787878787878, 0.36363636363636365, 0.45454545454545453, 0.42424242424242425, 0.5909090909090909, 0.7727272727272727, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.36363636363636365, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.6060606060606061, 0.6363636363636364, 0.3181818181818182, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.6272727272727273, 0.9090909090909091, 0.36363636363636365, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.36363636363636365, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.2727272727272727, 0.36363636363636365, 0.45454545454545453, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.36363636363636365, 0.36363636363636365, 0.36363636363636365, 0.6363636363636364, 0.6363636363636364]\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Full valset pareto front score: 0.7482765151515152\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Updated valset pareto front programs: [{3, 6, 8, 12, 16}, {13}, {0, 17, 10}, {8, 10}, {13, 6}, {1, 4, 8, 11, 14}, {8, 10, 3, 13}, {8, 9}, {3}, {4}, {14}, {8}, {8, 16}, {16, 10, 15}, {9, 7}, {16, 10}, {8, 10, 6}, {2, 4, 5}, {9, 13}, {17, 10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 7}, {3}, {13, 15}, {4, 8, 10, 12, 17}, {0, 3, 10, 13, 14, 15, 16, 17}, {17}, {4, 8, 10, 16, 17}, {8}, {3}, {9, 2, 6}, {8, 9, 10, 13, 15, 16, 17}, {8}, {8, 10, 13, 15}, {5}, {5}, {8, 9, 10, 13, 16}, {16}, {2, 4, 15}, {8, 9, 16}, {4, 8, 9, 10, 12, 13, 15, 16}, {11}, {16, 10}, {4, 9, 10, 13, 15, 16}, {2, 10, 6, 14}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17}, {10}, {8}, {0}, {3, 6, 9, 10, 11, 12, 17}, {0, 16}, {2, 3, 10, 13, 17}, {16}, {3, 6, 10, 14, 15, 17}, {9, 3}, {15}, {16}, {13, 7}, {2}, {7}, {11, 7}, {16}]\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: Linear pareto front program index: 10\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 26: New program candidate index: 17\n",
      "GEPA Optimization:  41%|████      | 1308/3200 [58:26<1:20:52,  2.56s/rollouts]2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 27: No merge candidates found\n",
      "2025/09/30 15:59:33 INFO dspy.teleprompt.gepa.gepa: Iteration 27: Selected program 3 score: 0.5903882575757575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.45 / 3 (81.8%): 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 15:59:40 INFO dspy.evaluate.evaluate: Average Metric: 2.4545454545454546 / 3 (81.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:00:49 INFO dspy.teleprompt.gepa.gepa: Iteration 27: Proposed new text for predict: ## Task Overview\n",
      "You are given a JSON object that represents the textual content of a PDF document.  \n",
      "Your job is to **extract the bibliographic metadata** required for the following fields and output them **exactly** in the format shown below:\n",
      "\n",
      "```\n",
      "language\n",
      "<value>\n",
      "title\n",
      "<value>\n",
      "alt_title\n",
      "<list>\n",
      "creator\n",
      "<list>\n",
      "year\n",
      "<value>\n",
      "publisher\n",
      "<list>\n",
      "doi\n",
      "<value>\n",
      "e_isbn\n",
      "<list>\n",
      "p_isbn\n",
      "<list>\n",
      "e_issn\n",
      "<value>\n",
      "p_issn\n",
      "<value>\n",
      "type_coar\n",
      "<value>\n",
      "```\n",
      "\n",
      "*Scalar values* (`language`, `title`, `year`, `doi`, `e_issn`, `p_issn`, `type_coar`) must be printed as plain strings or the literal word `None` (without quotes).  \n",
      "*List values* (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) must be printed as a **JSON array** (e.g. `['Doe, John', 'Smith, Anna']`). Empty lists are printed as `[]`.\n",
      "\n",
      "No additional text, headings, or formatting is allowed.\n",
      "\n",
      "---\n",
      "\n",
      "## Detailed Extraction Rules\n",
      "\n",
      "### 1. Language (`language`)\n",
      "1. Look for an explicit language tag in the PDF metadata (`pdfinfo`) – if present, use it.\n",
      "2. If not present, infer from the dominant language of the visible text:\n",
      "   - Finnish → `fi`\n",
      "   - Swedish → `sv`\n",
      "   - English → `en`\n",
      "   - Otherwise use the two‑letter ISO‑639‑1 code you are most confident about.\n",
      "3. If you cannot determine a language, output `None`.\n",
      "\n",
      "### 2. Title (`title`)\n",
      "1. Use the **main title** of the document – the largest heading that appears on the first page(s) and is not a section heading.\n",
      "2. Remove trailing whitespace and line‑break artefacts.\n",
      "3. Preserve original capitalization and diacritics.\n",
      "4. If no clear title can be found, output `None`.\n",
      "\n",
      "### 3. Alternative Title (`alt_title`)\n",
      "1. Populate only if the document explicitly lists an alternative title (e.g., “Also known as”, “Subtitle”, “Original title”).\n",
      "2. Return a list of *exact* alternative titles (strings).  \n",
      "   If none, return `[]`.\n",
      "\n",
      "### 4. Creator (`creator`)\n",
      "1. **Authors** are the primary creators. Extract them from:\n",
      "   - The author line on the first page (often after the title).\n",
      "   - The citation line if the document is a conference paper or journal article.\n",
      "   - The thesis cover page (name + “Thesis”/“Dissertation”).\n",
      "2. Convert each name to **“Family name, Given name(s)”** format, preserving middle names/initials.  \n",
      "   Example: `Aki Korpela` → `Korpela, Aki`.\n",
      "3. Preserve the order in which the authors appear in the source document.\n",
      "4. If the document has **no identifiable creator** (e.g., a corporate report), return an empty list `[]`.\n",
      "\n",
      "### 5. Year (`year`)\n",
      "1. Prefer the **publication year** found in:\n",
      "   - The citation line (e.g., “(2019)”, “2020.”).\n",
      "   - The cover page of a thesis/dissertation.\n",
      "   - A date line that clearly states “Published 2021”, “© 2022”, etc.\n",
      "2. If multiple years appear, choose the **most recent year that is explicitly linked to the publication**.\n",
      "3. If no year can be identified, output `None`.\n",
      "\n",
      "### 6. Publisher (`publisher`)\n",
      "1. Identify the institution or organization that issued the document:\n",
      "   - For conference papers: the conference organizer or the university hosting the conference.\n",
      "   - For journal articles: the journal name (if clearly present) **or** the publishing house.\n",
      "   - For theses/dissertations: the university granting the degree.\n",
      "2. Return a list of distinct publisher names in the order they appear.\n",
      "3. If no publisher can be determined, return `[]`.\n",
      "\n",
      "### 7. DOI (`doi`)\n",
      "1. Search the whole text for a pattern matching a DOI: `10.\\d{4,9}/[-._;()/:A-Z0-9]+` (case‑insensitive).\n",
      "2. If found, output the DOI exactly as it appears (including the `10.` prefix).  \n",
      "   If multiple DOIs appear, output the first one.\n",
      "3. If none, output `None`.\n",
      "\n",
      "### 8. Electronic ISBN (`e_isbn`) & Print ISBN (`p_isbn`)\n",
      "1. Look for ISBN strings:\n",
      "   - ISBN‑13: `978‑...` or `979‑...` (13 digits, optionally with hyphens/spaces).\n",
      "   - ISBN‑10: 10‑digit pattern (may contain `X` as check digit).\n",
      "2. Determine whether the ISBN refers to an **electronic** or **print** version:\n",
      "   - Keywords like “e‑ISBN”, “electronic ISBN”, “ISBN‑13 (Online)”, “ISBN‑10 (Print)” indicate the type.\n",
      "   - If the type cannot be inferred, place the ISBN in both lists.\n",
      "3. Return each list as a JSON array of the raw ISBN strings (preserve hyphens/spaces).  \n",
      "   If none, return `[]`.\n",
      "\n",
      "### 9. Electronic ISSN (`e_issn`) & Print ISSN (`p_issn`)\n",
      "1. Search for ISSN patterns: `\\d{4}-\\d{3}[0-9X]`.\n",
      "2. Determine electronic vs print by surrounding keywords (“e‑ISSN”, “Print ISSN”, “Electronic ISSN”).\n",
      "3. If only one ISSN is found and its type is ambiguous, output it as `e_issn` **and** `p_issn` (the same value).  \n",
      "   If none, output `None` for the respective field.\n",
      "\n",
      "### 10. COAR Type (`type_coar`)\n",
      "Map the document type to the **COAR Controlled Vocabulary** using the following hierarchy (first match wins):\n",
      "\n",
      "| Detected clue in text                                 | COAR type            |\n",
      "|------------------------------------------------------|---------------------|\n",
      "| contains “conference”, “proceedings”, “paper” *and* a conference name or “TAMK‑konferenssi”, “Proceedings of …” | `conference paper` |\n",
      "| contains “journal”, “article”, “vol.”, “issue”, “pages” and a journal title | `journal article` |\n",
      "| contains “master’s thesis”, “master thesis”, “MSc thesis”, “Master’s dissertation” | `master thesis` |\n",
      "| contains “doctoral dissertation”, “PhD thesis”, “Doctoral thesis” | `doctoral dissertation` |\n",
      "| contains “book”, “monograph”, “ISBN” and no journal or conference cues | `book` |\n",
      "| contains “report”, “technical report”, “white paper”, and a corporate author | `report` |\n",
      "| otherwise default to `other` |\n",
      "\n",
      "**Important:**  \n",
      "- Do **not** output “journal article” for conference papers (common error in previous attempts).  \n",
      "- For theses, use `master thesis` or `doctoral dissertation` exactly as shown.  \n",
      "- The value must be a plain string (e.g., `conference paper`).\n",
      "\n",
      "---\n",
      "\n",
      "## General Strategy (to be applied for every input)\n",
      "\n",
      "1. **Parse the JSON** – extract `pdfinfo` (if present) and concatenate the `text` of all pages in order, preserving line breaks.\n",
      "2. **Run a quick language detection** on the concatenated text if `pdfinfo.language` is missing.\n",
      "3. **Identify the title** by looking at the first 1‑3 pages for the biggest heading (often uppercase, centered, or followed by a line break). Use heuristics:\n",
      "   - Lines in ALL CAPS or Title‑Case with a larger font size (if font information is available) are strong candidates.\n",
      "   - Exclude lines that contain the word “Abstract”, “Keywords”, or author names.\n",
      "4. **Extract authors** using regular expressions for common patterns:\n",
      "   - `Lastname, Firstname`  \n",
      "   - `Firstname Lastname` (convert to required format)  \n",
      "   - Lists separated by commas or semicolons.\n",
      "5. **Search for year** with regex `\\b(19|20)\\d{2}\\b` and keep the one that appears near “Published”, “©”, “(year)”, or inside a citation.\n",
      "6. **Detect publisher** by looking for university names, conference names, journal titles, or corporate entities near the title/author block.\n",
      "7. **Find DOI, ISBN, ISSN** using the patterns described above.\n",
      "8. **Determine COAR type** by scanning for the key phrases in the table; prioritize conference > journal > thesis > dissertation > book > report.\n",
      "9. **Assemble the output** following the exact ordering and formatting rules.  \n",
      "   - For list fields, use Python‑style single‑quoted strings inside square brackets, no extra spaces: `['Doe, John', 'Smith, Anna']`.\n",
      "   - For scalar fields, output the raw string or `None` (capital N).\n",
      "\n",
      "---\n",
      "\n",
      "## Edge Cases & Common Pitfalls\n",
      "\n",
      "| Pitfall | How to avoid |\n",
      "|---------|--------------|\n",
      "| **Wrong COAR type** (e.g., labeling a conference paper as `journal article`) | Apply the hierarchy table; look for conference‑specific words first. |\n",
      "| **Creator list includes corporate author** | Only include *personal* names. If the only author is a corporate entity, return `[]`. |\n",
      "| **Multiple ISBNs without type clues** | Place each ISBN in both `e_isbn` and `p_isbn`. |\n",
      "| **ISSN appears without “e‑” or “Print” qualifier** | Duplicate the value for both `e_issn` and `p_issn`. |\n",
      "| **Language detection fails** | Default to `None` rather than guessing. |\n",
      "| **Extra whitespace or line‑break artefacts in titles** | Strip leading/trailing whitespace and replace internal newlines with a single space. |\n",
      "| **Output formatting errors** (extra quotes, missing brackets) | Verify that list values are exactly `[...]` with single quotes around each element and no trailing commas. |\n",
      "\n",
      "---\n",
      "\n",
      "## Final Output Example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Investing in Prevention: Exploring Decision‑Making Drivers\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Kuperstein Blasco, Deborah Karen']\n",
      "year\n",
      "2020\n",
      "publisher\n",
      "['Tampere University']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "2025/09/30 16:00:53 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n",
      "2025/09/30 16:00:53 INFO dspy.teleprompt.gepa.gepa: Iteration 27: New subsample score is not better, skipping\n",
      "GEPA Optimization:  41%|████      | 1314/3200 [59:46<1:35:24,  3.04s/rollouts]2025/09/30 16:00:53 INFO dspy.teleprompt.gepa.gepa: Iteration 28: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.45 / 3 (48.5%): 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:00:59 INFO dspy.evaluate.evaluate: Average Metric: 1.4545454545454546 / 3 (48.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:02:33 INFO dspy.teleprompt.gepa.gepa: Iteration 28: Proposed new text for predict: markdown\n",
      "# 📄 Task: Extract Structured Bibliographic Metadata from PDF‑extracted Text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "| Key      | Description |\n",
      "|----------|-------------|\n",
      "| `pdfinfo`| Optional dictionary containing PDF‑level metadata (e.g. `title`, `author`, `creationDate`, `modDate`). |\n",
      "| `pages`  | List of page objects. Each object has:<br>`page` – page number (int)<br>`text` – raw OCR/clipboard text of that page (string). |\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and produce a **flat list of metadata fields** following the exact format described in **Section 4**.  \n",
      "\n",
      "If a field cannot be found, output the *missing‑value placeholder* from **Section 3**.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Output Fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|--------------------------|\n",
      "| `language` | string | ISO‑639‑1 code of the **document language** (`fi`, `en`, `sv`, `se`). Detect by counting language‑specific stop‑words/characters (see 2.1). If ambiguous → `None`. |\n",
      "| `title` | string | Full title **exactly as it appears** on the title page (including subtitle). Preserve line breaks by joining the lines with a **single space** (no `\\n`). Do **not** trim trailing spaces or add punctuation. |\n",
      "| `alt_title` | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none → `[]`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`).<br>• If a name already contains a comma, keep it unchanged.<br>• Split a name on the **last space** only.<br>• Preserve diacritics.<br>• Order = appearance order.<br>If none → `[]`. |\n",
      "| `year` | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| `publisher` | list of strings | Exact imprint institution(s). Preserve spelling, diacritics, hyphens, and spacing. If multiple entities are listed on the same line, split on commas, slashes, or the word “and”. If none → `[]`. |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any of the patterns in 2.7. |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** (keep only digits). Keep the resulting digit string (13‑digit or 10‑digit) **without hyphens**. Include only if an **electronic qualifier** appears on the **same line** (see 2.8). |\n",
      "| `p_isbn` | list of strings | Same as `e_isbn` but for the **print** version (requires a print qualifier). |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalised by removing hyphens. Must have an electronic qualifier on the same line. |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Requires a print qualifier. |\n",
      "| `type_coar` | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`. Determined by key phrases (see 2.9). |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Normalisation & Extraction Rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition → output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – the first page (or first two pages) that contain the **largest centred heading(s)** (often ALL‑CAPS or title‑case).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line**, treat it as part of the title.  \n",
      "3. Join the captured lines with a **single space** (do **not** keep line‑break characters).  \n",
      "4. Do **not** include page numbers, section headings, catalogue codes, or any surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the title page (or the page immediately after) for a second heading in a **different language**. Typical markers: “English title”, “Title (English)”, or a second heading placed beneath the main title. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names (often directly under the title or preceded by “by”, “author”, “kirjoittanut”, etc.).  \n",
      "3. For each name:  \n",
      "   * If it already contains a comma → keep unchanged.  \n",
      "   * Otherwise split on the **last space only** and reorder to `\"Last, First …\"`.  \n",
      "4. Trim surrounding whitespace.  \n",
      "5. Separate multiple authors by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line** – usually after the title, subtitle, author, and before the year/location.  \n",
      "2. Capture the whole line (or consecutive lines) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling**.  \n",
      "4. Do **not** modify diacritics, hyphens, or spacing.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document (case‑insensitive) for any of the following patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string (e.g. `10.1234/abcde`).\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "Extraction steps:\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters** → keep the digit string (e.g. `9789523673243`).  \n",
      "   * ISSN – remove hyphens only (e.g. `17979714`).  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * Electronic qualifier → add to `e_isbn` / `e_issn`.  \n",
      "   * Print qualifier → add to `p_isbn` / `p_issn`.  \n",
      "   * Both qualifiers → add to **both** lists.  \n",
      "   * No qualifier → **ignore** the number completely.  \n",
      "5. Do **not** deduplicate; keep each occurrence that satisfies the qualifier rule.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none match → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| `language` | `None` |\n",
      "| `title` | `None` |\n",
      "| `alt_title` | `[]` |\n",
      "| `creator` | `[]` |\n",
      "| `year` | `None` |\n",
      "| `publisher` | `[]` |\n",
      "| `doi` | `None` |\n",
      "| `e_isbn` | `[]` |\n",
      "| `p_isbn` | `[]` |\n",
      "| `e_issn` | `None` |\n",
      "| `p_issn` | `None` |\n",
      "| `type_coar` | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ Output format\n",
      "\n",
      "Write each **field name** on a line **by itself**, then the **value** on the **next line**.  \n",
      "\n",
      "* Strings are written plain (no quotes).  \n",
      "* Lists must be valid Python‑style lists: single quotes around items, commas separating them, no trailing comma.  \n",
      "* `None` is written exactly as `None` (capital N, no quotes).  \n",
      "\n",
      "### Example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the largest centred heading on the first page; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 16:02:40 INFO dspy.evaluate.evaluate: Average Metric: 1.3636363636363635 / 3 (45.5%)\n",
      "2025/09/30 16:02:40 INFO dspy.teleprompt.gepa.gepa: Iteration 28: New subsample score is not better, skipping\n",
      "GEPA Optimization:  41%|████▏     | 1320/3200 [1:01:33<2:02:30,  3.91s/rollouts]2025/09/30 16:02:40 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.68 / 3 (56.1%): 100%|██████████| 3/3 [00:07<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:02:47 INFO dspy.evaluate.evaluate: Average Metric: 1.6818181818181819 / 3 (56.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:04:23 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Proposed new text for predict: markdown\n",
      "# Task: Structured metadata extraction from PDF‑extracted text  \n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `title`, `author`, `creationDate`, `modDate`).\n",
      "* `pages` – a list of page objects, each with:\n",
      "  * `page` – integer page number  \n",
      "  * `text` – the raw OCR/clipboard text of that page (preserve line breaks exactly as they appear).\n",
      "\n",
      "Your job is to **examine the whole document** (all pages) and produce a **flat list of metadata fields** in the exact format described below.  \n",
      "If a field cannot be determined, output the *missing‑value placeholder* shown in the table [3].\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format  \n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**.  \n",
      "All list values must be **valid Python‑style lists**:\n",
      "\n",
      "* use single quotes (`'`) around each string,\n",
      "* separate items with a comma and a space,\n",
      "* no trailing comma,\n",
      "* `[]` for an empty list.\n",
      "\n",
      "Do **not** output empty strings inside a list – they must be omitted.  \n",
      "The optional `reasoning` field (free‑text) may be included after all required fields; it does not affect scoring.\n",
      "\n",
      "**Exact order of fields** (required unless otherwise noted):\n",
      "\n",
      "```\n",
      "language\n",
      "title\n",
      "alt_title\n",
      "creator\n",
      "year\n",
      "publisher\n",
      "doi\n",
      "e_isbn\n",
      "p_isbn\n",
      "e_issn\n",
      "p_issn\n",
      "type_coar\n",
      "reasoning   (optional)\n",
      "2025/09/30 16:04:28 INFO dspy.evaluate.evaluate: Average Metric: 1.803030303030303 / 3 (60.1%)\n",
      "2025/09/30 16:05:12 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:05:12 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 16:05:15 INFO dspy.evaluate.evaluate: Average Metric: 38.51212121212121 / 64 (60.2%)\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Full valset score for new program: 0.601751893939394\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Full train_val score for new program: 0.601751893939394\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Individual valset scores for new program: [0.7272727272727273, 0.7272727272727273, 0.8787878787878788, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.9090909090909091, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.45454545454545453, 0.6060606060606061, 0.6363636363636364, 0.6060606060606061, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.4454545454545455, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.5151515151515151, 0.4, 0.6363636363636364, 0.2727272727272727, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.3939393939393939, 0.42424242424242425, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.36363636363636365, 0.5151515151515151, 0.5454545454545454, 0.6666666666666666, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.45454545454545453, 0.696969696969697]\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.8787878787878788, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Full valset pareto front score: 0.7539583333333333\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Updated valset pareto front programs: [{3, 6, 8, 12, 16}, {18, 13}, {18}, {8, 10}, {13, 6}, {18}, {18}, {8, 9}, {3}, {4}, {14}, {8}, {8, 16}, {16, 10, 15}, {9, 7}, {16, 10}, {8, 10, 6}, {2, 4, 5}, {9, 13}, {17, 10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 7}, {3}, {13, 15}, {4, 8, 10, 12, 17}, {0, 3, 10, 13, 14, 15, 16, 17, 18}, {17}, {4, 8, 10, 16, 17}, {8}, {3}, {9, 2, 6}, {8, 9, 10, 13, 15, 16, 17}, {8}, {8, 10, 13, 15}, {5}, {5}, {8, 9, 10, 13, 16}, {16}, {2, 4, 15}, {8, 9, 16}, {4, 8, 9, 10, 12, 13, 15, 16}, {11}, {16, 10}, {4, 9, 10, 13, 15, 16}, {2, 10, 6, 14}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18}, {10}, {8}, {0}, {18}, {0, 16}, {2, 3, 10, 13, 17}, {16}, {3, 6, 10, 14, 15, 17}, {9, 3}, {15}, {16}, {13, 7}, {2}, {7}, {11, 7}, {16}]\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: Linear pareto front program index: 10\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 29: New program candidate index: 18\n",
      "GEPA Optimization:  43%|████▎     | 1390/3200 [1:04:08<1:32:33,  3.07s/rollouts]2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 30: No merge candidates found\n",
      "2025/09/30 16:05:15 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Selected program 17 score: 0.575\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.91 / 3 (63.6%): 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:05:20 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:07:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** per request.  \n",
      "It contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – an ordered list of page objects, each with an integer `page` and a string `text` that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Do **not** carry any information from previous requests – treat each request as completely independent.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "* Write the field name on a line **by itself**, then write its value on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: single quotes, commas, no trailing comma.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does not affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If ambiguous, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the title page, including subtitle and any colon. Preserve original case, punctuation and spaces; join consecutive heading lines with a **single space** (do **not** insert `\\n`). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Use `pdfinfo.author` if present; otherwise locate author lines on the title page (look for markers such as `Author:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, etc.). Split a name on the **last space only** unless it already contains a comma. Preserve diacritics. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`). |\n",
      "| **publisher** | list of strings | Exact imprint institution(s). Keep the text **before the first comma** on each imprint line (e.g. `\"Tampereen yliopisto, Johtamisen...\"` → `\"Tampereen yliopisto\"`). If several distinct institutions appear (separated by `/`, the word “and”, or on separate lines), each becomes a separate list element, preserving original spelling. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep only numbers from the ISBN (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences (case‑insensitive) of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or first two pages) that contain the **largest centred heading(s)**. Clues: ALL‑CAPS, title‑case, surrounded by blank lines, or markdown headings (`#`, `##`, `###`).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve the exact wording (including case and punctuation). Join captured lines with a **single space** (do **not** insert line‑break characters).  \n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the next page) for a heading that is clearly a title in a **different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names. Typical markers: “Author:”, “Författare:”, “Tekijä:”, “Kirjoittaja”, “by”, “author”, “tekijä”, or a line directly under the title consisting mainly of capitalised names.  \n",
      "3. **Do not** treat department names, university names, or acknowledgements as authors.  \n",
      "4. For each name found:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **text before the first comma** on each imprint line.  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element, preserving the original spelling.  \n",
      "4. Do not include city names, department names, or addresses unless they are themselves separate institutions.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit if present, otherwise keep what remains).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "\n",
      "4. Look at the same line for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Master’s thesis” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” (combined with “thesis”) | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISBN(s)** **and** the word “part” or “chapter” indicating a contribution to a larger work | `book part` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations\n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, or language that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* If a field’s value is ambiguous (e.g., multiple possible titles, languages, or publishers), follow the specific disambiguation rules above; otherwise use the placeholder.  \n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example output (template)\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Creative leader’s impact on the working environment\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Forsander, Kim']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Yrkeshögskolan Novia']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "bachelor thesis\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "2025/09/30 16:07:09 INFO dspy.evaluate.evaluate: Average Metric: 2.2727272727272725 / 3 (75.8%)\n",
      "2025/09/30 16:07:57 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:07:58 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:07:58 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:08:00 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:08:00 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 16:08:04 INFO dspy.evaluate.evaluate: Average Metric: 37.43528138528138 / 64 (58.5%)\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Full valset score for new program: 0.5849262716450216\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Full train_val score for new program: 0.5849262716450216\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Individual valset scores for new program: [0.7272727272727273, 0.7272727272727273, 0.7878787878787878, 0.2727272727272727, 0.9090909090909091, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.09090909090909091, 0.6363636363636364, 0.696969696969697, 0.4772727272727273, 0.5454545454545454, 0.45454545454545453, 0.6883116883116883, 0.6363636363636364, 0.5454545454545454, 0.42424242424242425, 0.6363636363636364, 0.45454545454545453, 0.5, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.43636363636363634, 0.8181818181818182, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 1.0, 0.5151515151515151, 0.36363636363636365, 0.6363636363636364, 0.2727272727272727, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.36363636363636365, 0.45454545454545453, 0.2727272727272727, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273]\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 1.0, 0.6363636363636364, 0.45454545454545453, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Full valset pareto front score: 0.7582196969696969\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Updated valset pareto front programs: [{3, 6, 8, 12, 16}, {18, 19, 13}, {18}, {8, 10}, {19}, {18}, {18}, {8, 9}, {19, 3}, {4}, {19, 14}, {8}, {8, 16}, {16, 10, 15}, {9, 7}, {16, 10}, {8, 10, 6}, {2, 4, 5}, {9, 13}, {17, 10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 7}, {3}, {13, 15}, {4, 8, 10, 12, 17}, {0, 3, 10, 13, 14, 15, 16, 17, 18}, {17}, {4, 8, 10, 16, 17}, {8}, {3}, {9, 2, 6}, {19}, {8}, {8, 10, 13, 15}, {5}, {5}, {8, 9, 10, 13, 16}, {16, 19}, {2, 4, 15}, {8, 9, 16}, {4, 8, 9, 10, 12, 13, 15, 16, 19}, {11}, {16, 10}, {4, 9, 10, 13, 15, 16}, {2, 10, 6, 14}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19}, {10}, {8}, {0}, {18}, {0, 16}, {2, 3, 10, 13, 17}, {16}, {3, 6, 10, 14, 15, 17}, {9, 3}, {15}, {16}, {13, 7}, {2}, {7}, {11, 7}, {16}]\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: Linear pareto front program index: 10\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 30: New program candidate index: 19\n",
      "GEPA Optimization:  46%|████▌     | 1460/3200 [1:06:57<1:21:05,  2.80s/rollouts]2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 31: No merge candidates found\n",
      "2025/09/30 16:08:04 INFO dspy.teleprompt.gepa.gepa: Iteration 31: Selected program 16 score: 0.6575568181818182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.36 / 3 (78.8%): 100%|██████████| 3/3 [00:04<00:00,  1.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:08:08 INFO dspy.evaluate.evaluate: Average Metric: 2.3636363636363633 / 3 (78.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:09:57 INFO dspy.teleprompt.gepa.gepa: Iteration 31: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output must follow the exact format shown in the “Output format example” section, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case) – see **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The **value** on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` **literally** (no quotes) for missing values.\n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use these seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`) **overriding** the stop‑word count.\n",
      "3. Otherwise choose the language with the highest stop‑word count. If there is a tie or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – usually the first page that contains a line in **ALL CAPS** *or* a Markdown heading (`#`, `##`, `###`, …).  \n",
      "   *In OCR output, headings are often surrounded by blank lines; treat a line that is the **only non‑blank line** on the page (or the first non‑blank line) and is in all caps as the title line.*\n",
      "\n",
      "2. **Capture the full logical title**:  \n",
      "   * If the next line(s) are a subtitle (no blank line between them, or the subtitle follows a colon `:`), concatenate them with a single space.  \n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons).  \n",
      "   * Example:  \n",
      "\n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "\n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "3. Strip any surrounding Markdown markers (`#`, `##`, etc.) and surrounding whitespace **only**. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * If the name appears **fully capitalised** (e.g. `TUOMAS PIKKUAHO`) treat it as `First Last` and apply the rule above, preserving diacritics.\n",
      "   * Preserve diacritics and original capitalisation of the *surname* and *given name(s)*.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`.\n",
      "3. If still not found, fall back to the PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name without a preceding keyword (e.g. `UNIVERSITY OF VAASA` or `Tampere University`) treat the whole line as a publisher entry.\n",
      "4. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "5. Output an empty list `[]` if none can be identified.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * **Print** indicators (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** the electronic and the print list.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn` (or `e_issn`) **and** `p_isbn` (or `p_issn`).\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, **“Academic dissertation”** | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and its prefix belongs to a journal publisher) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, the author line “Jeba Akewak” was split into “Akewak, Jeba”, the year 2021 appears on the copyright line of page 1, no publisher or identifiers were found, and the presence of “Master’s thesis” yields the COAR type “master thesis”.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "### Quick checklist for common pitfalls observed in earlier attempts\n",
      "* **Publisher** – also accept lines that are *only* an institution name (e.g., `UNIVERSITY OF VAASA`, `Tampere University`). Do not require a preceding keyword.\n",
      "* **Creator** – when the name is all‑caps, treat it as “First Last” and convert to “Last, First”. Preserve diacritics.\n",
      "* **ISBN / ISSN** – always normalise to digit‑only strings. Add to both electronic and print lists if the qualifier is missing.\n",
      "* **COAR type** – include “Academic dissertation” as a synonym for doctoral thesis. Ensure that a dissertation with “Dissertation” or “Väitöskirja” maps to `doctoral thesis`.\n",
      "* **Year** – if a four‑digit number is found but outside 1900‑2100, ignore it.\n",
      "* **Reasoning** – optional but helpful for debugging; keep it concise (one or two sentences).\n",
      "\n",
      "Follow the rules precisely; the output will be parsed automatically into a JSON record. Good luck! 🚀\n",
      "2025/09/30 16:10:04 INFO dspy.evaluate.evaluate: Average Metric: 2.2727272727272725 / 3 (75.8%)\n",
      "2025/09/30 16:10:04 INFO dspy.teleprompt.gepa.gepa: Iteration 31: New subsample score is not better, skipping\n",
      "GEPA Optimization:  46%|████▌     | 1466/3200 [1:08:57<1:44:51,  3.63s/rollouts]2025/09/30 16:10:04 INFO dspy.teleprompt.gepa.gepa: Iteration 32: Selected program 16 score: 0.6575568181818182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:11<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:10:15 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:12:04 INFO dspy.teleprompt.gepa.gepa: Iteration 32: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must follow the exact format shown in the “Output format example” section** because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case) – see **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The **value** on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` **literally** (no quotes) for missing values.\n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use the following seed lists (you may extend them if you see additional obvious stop‑words, but never remove the ones below):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * Northern Sámi (`se`): `máŋggá`, `golle`, `sámi`, `čálli`, `buktá`, `vuostá`\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kielâ: sámegiella`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`) **overriding** the stop‑word count.\n",
      "\n",
      "3. Otherwise choose the language with the highest stop‑word count.  \n",
      "   *If there is a tie or no clear majority, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the first page that contains a line that is **either**  \n",
      "   * a line in **ALL CAPS** (ignoring surrounding whitespace and markdown markers), **or**  \n",
      "   * a markdown heading (`#`, `##`, `###`, …) possibly surrounded by blank lines.\n",
      "\n",
      "2. The **title line** is the all‑caps/heading line **after stripping any leading markdown symbols (`#`, `##`, …) and surrounding whitespace**.\n",
      "\n",
      "3. **Capture the full logical title**:  \n",
      "   * If the next line (or the line immediately after a colon `:` on the same line) is non‑blank and looks like a subtitle, concatenate it to the title with a single space.  \n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons).  \n",
      "   * Example:  \n",
      "\n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "\n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "4. Do **not** include page numbers, footers, headers, or any surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier (case‑insensitive), e.g.  \n",
      "  `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Titel (svenska)`, etc.\n",
      "* Apply the same concatenation rules as in **2.2** to the text that follows the qualifier.\n",
      "* Do **not** duplicate the main `title`. Return a list – if none are found, output `[]`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`.\n",
      "3. If still not found, fall back to the PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`, `Elsevier`, `Taylor & Francis`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Työväen historian ja perinteen tutkimuksen seura`), treat the whole line as a publisher entry.\n",
      "4. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "5. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * **Print** indicators (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn` (or `e_issn`) **and** `p_isbn` (or `p_issn`).\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | Additional condition(s) | `type_coar` value |\n",
      "|----------------|------------------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | – | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | – | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | – | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that matches a known book‑publisher (e.g., Routledge, Springer, Cambridge, Elsevier, Taylor & Francis) | – | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI whose prefix belongs to a journal publisher (e.g., `10.1007`, `10.1016`, `10.1080`) | – | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | – | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | – | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | – | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (prefix typical for book publishers, e.g., `10.1000`, `10.1017`) | – | `book part` |\n",
      "| *(none of the above)* | – | `None` |\n",
      "\n",
      "*If multiple rows match, the **earliest** row in the table wins.*\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, the author line was parsed and reformatted, the year was found on the copyright line, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ Important notes derived from previous feedback\n",
      "* **Language overrides** – an explicit “Language: …” line must dominate over stop‑word counts.\n",
      "* **Creator name order** – always output `Last, First …`. If the original string already contains a comma, keep it unchanged.\n",
      "* **ISBN/ISSN qualification** – respect the presence of “PDF”, “e‑ISBN”, “Print”, etc. When no qualifier is present, add the identifier to **both** electronic and print lists.\n",
      "* **Normalization** – ISBNs and ISSNs must contain **only digits** (no hyphens, spaces, or parentheses) in the final lists.\n",
      "* **COAR type** – ensure the correct row is selected; e.g., a document with ISBNs and a known book publisher but no thesis wording should be classified as `book`, not `master thesis`.\n",
      "* **Publisher extraction** – include any institution name that appears on its own line even if no keyword precedes it; avoid adding unrelated words (e.g., “Cover Design”) as publishers.\n",
      "* **Alt‑title detection** – only capture titles that are explicitly marked as an alternate language version; do not treat subtitle lines as alternate titles.\n",
      "* **Reasoning** is optional but helpful for debugging; keep it concise (one or two sentences).\n",
      "\n",
      "Follow the rules carefully; the output will be automatically parsed into a JSON record. Good luck! 🚀\n",
      "2025/09/30 16:12:14 INFO dspy.evaluate.evaluate: Average Metric: 1.727272727272727 / 3 (57.6%)\n",
      "2025/09/30 16:12:14 INFO dspy.teleprompt.gepa.gepa: Iteration 32: New subsample score is not better, skipping\n",
      "GEPA Optimization:  46%|████▌     | 1472/3200 [1:11:08<2:18:19,  4.80s/rollouts]2025/09/30 16:12:14 INFO dspy.teleprompt.gepa.gepa: Iteration 33: Selected program 4 score: 0.5814393939393939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.91 / 3 (63.6%): 100%|██████████| 3/3 [00:07<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:12:22 INFO dspy.evaluate.evaluate: Average Metric: 1.909090909090909 / 3 (63.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:13:52 INFO dspy.teleprompt.gepa.gepa: Iteration 33: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a JSON object that contains:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (e.g. `title`, `author`, `creationDate`, `modDate`).\n",
      "* **pages** – list of page objects, each with a `text` field that holds the OCR‑extracted text of that page.\n",
      "\n",
      "Your task is to **parse this information and output a flat list of metadata fields** (one field name line followed by its value line) that can later be turned into a JSON record.  \n",
      "All field names, value formats, and ordering rules are described below.  \n",
      "If a piece of information cannot be found, use the exact “missing‑value” placeholder indicated in the table.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "For every required field write **exactly two lines**:\n",
      "\n",
      "```\n",
      "field_name\n",
      "value\n",
      "```\n",
      "\n",
      "* `field_name` is the literal name from the table (e.g. `language`).\n",
      "* `value` must follow the type and formatting rules (see Section 2).  \n",
      "* Do **not** add extra whitespace, quotation marks, or commas except where required by the type (e.g. Python‑style lists).\n",
      "\n",
      "The fields may appear in any order, but every field listed in Section 1.2 must be present.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Required fields (order does not matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the *content language*: `fi` (Finnish), `sv` (Swedish), `en` (English). Detect from the majority of visible words (see “Language detection” below). If the language cannot be determined, output `None`. |\n",
      "| **title** | string or `None` | Full title **exactly as it appears** on the title page (including subtitle, colon, punctuation, line‑breaks that belong to the same logical title). Do not add extra whitespace. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a different language (e.g. English version of a Finnish title). If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"`. Split names that are given as “First Last” on the **last space**; keep names already in “Last, First” unchanged. Preserve diacritics and order. If multiple authors appear, list each separately. If none, output `[]`. |\n",
      "| **year** | integer or `None` | Publication year (4‑digit). Prefer a year found on the title page, copyright line, or in the PDF dates (`creationDate` / `modDate`). If none, output `None`. |\n",
      "| **publisher** | list of strings | Publishing institution exactly as it appears (including department names, university presses, etc.). Do not translate. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI without any prefix (`doi:` or `DOI`). Detect patterns starting with `10.`. If none, output `None`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Strip all hyphens, spaces, and surrounding parentheses; keep only the digits (13‑digit for ISBN‑13). If none, output `[]`. |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. If none, output `[]`. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalized (remove hyphens). If none, output `None`. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalized. If none, output `None`. |\n",
      "| **type_coar** | string or `None` | COAR type of the resource. Accept **exactly** one of the following values (lower‑case as shown): <br>`master thesis` <br>`doctoral thesis` <br>`book` <br>`book part` <br>`article` <br>`report` <br>`conference paper` <br>Determine the type from textual clues (see “COAR type mapping” below). If none can be inferred, output `None`. |\n",
      "| **reasoning** *(optional)* | free‑text | A short paragraph (one or two sentences) explaining how the values were derived. Include only if you wish; it does **not** affect scoring. |\n",
      "\n",
      "*All list values must be formatted exactly as Python‑style lists, e.g. `['value1', 'value2']`. Empty lists are `[]`.*\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Normalisation rules\n",
      "\n",
      "### 3.1 ISBN / ISSN\n",
      "* Remove hyphens (`-`), spaces, and surrounding parentheses.  \n",
      "* Keep only the digits (ISBN‑13) or the 8‑digit ISSN.  \n",
      "* Example: `ISBN 978-952-335-936-9 (PDF)` → `9789523359369` → placed in `e_isbn`.  \n",
      "* If the same numeric string appears with both “Print” and “PDF” qualifiers, add it to **both** lists.\n",
      "\n",
      "### 3.2 Creator name splitting\n",
      "* If the name already contains a comma, assume it is “Last, First” and keep unchanged.  \n",
      "* Otherwise split on the **last** space: `First Middle Last` → `Last, First Middle`.  \n",
      "* Multiple authors may be separated by commas, semicolons, or the word “and”. Treat each segment independently.  \n",
      "* Preserve diacritics and original capitalisation.\n",
      "\n",
      "### 3.3 Publisher\n",
      "* Use the exact wording that appears on the title page, imprint line, or in the PDF metadata.  \n",
      "* Do **not** translate university or institute names.\n",
      "\n",
      "### 3.4 Language detection\n",
      "1. Scan the first few pages (up to page 5) for language‑specific stop‑words.  \n",
      "2. Finnish indicators: `ja`, `on`, `tutkimus`, `käsittely`, `vuosi`, `luku`, `kirja`, `opinnäytetyö`, `väitteet`, etc.  \n",
      "3. Swedish indicators: `och`, `är`, `studie`, `författare`, `avhandling`, `kapitel`, `universitetet`, `å`, `ö`, `ä`.  \n",
      "4. English indicators: `and`, `the`, `study`, `author`, `thesis`, `chapter`, `university`, etc.  \n",
      "5. Count occurrences; the language with the highest count determines the code (`fi`, `sv`, `en`).  \n",
      "6. If counts are equal or no clear majority, output `None`.\n",
      "\n",
      "### 3.5 Title extraction\n",
      "* The title is the largest heading on the title page (usually the first line of text).  \n",
      "* Include any subtitle that follows a colon (`:`) or appears on the next line **without** an empty line separating it from the main title.  \n",
      "* Do not truncate at page numbers, section headings, or footers.\n",
      "\n",
      "### 3.6 Alt title\n",
      "* If an alternate‑language title appears (e.g., an English translation of a Finnish title, or a subtitle in another language), capture it as a separate string.  \n",
      "* Do **not** duplicate the main title.\n",
      "\n",
      "### 3.7 Year extraction\n",
      "1. Look for a four‑digit number on the title page, copyright line, or “© YYYY”.  \n",
      "2. If not found, fall back to the PDF dates: `creationDate` or `modDate` (format `D:YYYYMMDD…`). Extract the `YYYY`.  \n",
      "3. If still not found, output `None`.\n",
      "\n",
      "### 3.8 DOI detection\n",
      "* Regex pattern: `10\\.\\d{4,9}/\\S+` (allow any non‑space characters after the slash).  \n",
      "* Accept optional prefixes `doi:`, `DOI `, `https://doi.org/`. Strip the prefix and return the raw DOI.\n",
      "\n",
      "### 3.9 COAR type mapping\n",
      "| Clue in document | COAR type |\n",
      "|------------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Master’s thesis” | `master thesis` |\n",
      "| “Dissertation”, “Väitöskirja”, “Doctoral thesis”, “Doctoral dissertation”, “PhD”, “Licentiate” | `doctoral thesis` |\n",
      "| Contains “ISBN” **and** no thesis‑related wording, and the work is a standalone monograph or volume | `book` |\n",
      "| Contains “ISBN” **and** wording like “Chapter”, “Section”, “In:”, “In the book”, “In … (Ed.)”, or appears as a part of an edited volume | `book part` |\n",
      "| Contains “ISSN” and looks like a journal article (e.g., has volume/issue, page range) and **no** ISBN | `article` |\n",
      "| Contains the word “Report”, “Technical Report”, “Research Report”, or similar | `report` |\n",
      "| Contains “Proceedings”, “Conference”, “Conference paper”, “Paper presented at”, or similar | `conference paper` |\n",
      "| If none of the above apply, output `None`. |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Step‑by‑step processing checklist (you may follow this internally)\n",
      "\n",
      "1. **Load JSON**, extract `pdfinfo` and concatenate the `text` of the first few pages (up to page 5) into a single string for language and title detection.  \n",
      "2. **Detect language** using the word‑list method (Section 3.4).  \n",
      "3. **Extract title**: locate the first non‑empty line that is in a larger heading style (often preceded by `#`, `##`, or appears alone on the page). Include following subtitle line(s) if they are directly adjacent.  \n",
      "4. **Search for alternate title**: look for a second title line in a different language (e.g., English subtitle when the main title is Finnish/Swedish).  \n",
      "5. **Parse creators**:  \n",
      "   * Prefer the `author` field in `pdfinfo`.  \n",
      "   * If absent, look for lines starting with “Author(s):”, “Authors:”, “Kirjoittaja”, “Tekijä”, etc.  \n",
      "   * Apply name‑splitting rules (Section 3.2).  \n",
      "6. **Determine year** (Section 3.7).  \n",
      "7. **Identify publisher**: look for lines containing “Publisher”, “Press”, “University Press”, “Institute”, “Yliopisto”, “Universitetet”, etc. Capture the full phrase.  \n",
      "8. **Find DOI** using the regex (Section 3.8).  \n",
      "9. **Collect ISBN/ISSN**: locate all occurrences of “ISBN” and “ISSN”.  \n",
      "   * Check surrounding qualifiers “PDF”, “electronic”, “online” → `e_isbn` / `e_issn`.  \n",
      "   * Check “Print”, “hardcover”, “paperback”, “p.” → `p_isbn` / `p_issn`.  \n",
      "   * Normalise (Section 3.1).  \n",
      "10. **Map COAR type** using the clue table (Section 3.9).  \n",
      "11. **Assemble output** exactly as described in Section 1.  \n",
      "\n",
      "---\n",
      "\n",
      "## 6. Example (for reference only)\n",
      "\n",
      "```\n",
      "language\n",
      "sv\n",
      "title\n",
      "Kreativ ångest : en kulturekonomisk studie av skådespelares kreativa processer\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Storgård, Johan']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Åbo Akademis förlag']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "['9789523890039']\n",
      "p_isbn\n",
      "['9789523890046']\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "doctoral thesis\n",
      "2025/09/30 16:13:59 INFO dspy.evaluate.evaluate: Average Metric: 1.7272727272727275 / 3 (57.6%)\n",
      "2025/09/30 16:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 33: New subsample score is not better, skipping\n",
      "GEPA Optimization:  46%|████▌     | 1478/3200 [1:12:52<2:48:36,  5.87s/rollouts]2025/09/30 16:13:59 INFO dspy.teleprompt.gepa.gepa: Iteration 34: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.7%): 100%|██████████| 3/3 [00:04<00:00,  1.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:14:04 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:16:06 INFO dspy.teleprompt.gepa.gepa: Iteration 34: Proposed new text for predict: markdown\n",
      "# Revised Instruction for Extracting Structured Metadata from PDF‑Extracted Text\n",
      "\n",
      "You will receive **one JSON object** with the following top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).\n",
      "* **pages** – an ordered list of page objects, each with:\n",
      "  * `page` – integer page number (starting at 1)\n",
      "  * `text` – the raw OCR/clipboard text of that page (preserve line‑breaks exactly as they appear).\n",
      "\n",
      "Your task is to **scan the whole document** (all pages) and produce a **flat list of metadata fields**.  \n",
      "Each field name must be printed on its own line, followed by its value on the next line, exactly as shown in the *Output format* section below.\n",
      "\n",
      "All list values must be valid **Python‑style lists** (single quotes, commas, no trailing commas).  \n",
      "If a piece of information cannot be found, output the *missing‑value placeholder* described in the *Missing‑value handling* table.\n",
      "\n",
      "Below are the complete extraction rules, normalisation steps, and common pitfalls to avoid.  \n",
      "Follow them **exactly**; the evaluation checks for strict compliance.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the **document language** (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle and any line‑breaks that belong to the same logical heading. Do **not** trim trailing spaces or add punctuation. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do **not** repeat the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author name(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). See 2.4 for splitting rules. If no personal author is identifiable, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, imprint line, or a line that contains a location/date (e.g. “Helsinki den 20 februari 2017”). If still missing, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint string(s) that identify the **publishing institution(s)**. Capture the line(s) that contain the publisher name(s) **only**, not department names, university faculties, or other affiliations. If multiple publishers are listed, keep them in the order they appear. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.\\d+/[^\\s]+`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** and keep the resulting digit string (13‑digit preferred, but keep whatever remains). **Only include the number if the same line contains at least one electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. **Only include the number if the same line contains at least one print qualifier** (see 2.8). |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by removing hyphens. If the line contains an electronic qualifier, use that value; otherwise, if the line contains **no qualifier**, assume it is the **print** ISSN (see 2.8). |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by removing hyphens. Include the value if the line contains a print qualifier **or** if the line contains an ISSN **without any qualifier** (default to print). |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`. Determine using the wording rules in 2.9. |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the whole document into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters (case‑insensitive). Use the tables below:\n",
      "\n",
      "| Language | Sample stop‑words / characteristic characters |\n",
      "|----------|-----------------------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å”, “ä”, “ö”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count **wins** **provided** its count is **≥ 1.5 × the second‑highest**.  \n",
      "4. If no language satisfies this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – the first page (or the first two pages) that contain the **largest centred heading(s)** (often in ALL‑CAPS or title‑case, possibly surrounded by blank lines).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve the **exact line‑breaks** that belong to the title; when outputting, join the lines with a **single space** (do **not** insert additional line‑break characters).  \n",
      "4. Do **not** include page numbers, section headings, catalogue codes, or any surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the immediately following page) for a heading that is clearly in a **different language** (usually English). Typical markers: “English title”, “Title (English)”, or a second heading placed directly beneath the main title. Add each distinct string to `alt_title`. Do **not** duplicate the main title. If none found, output `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference** – use `pdfinfo.author` if it exists and looks like a personal name.  \n",
      "2. If missing, scan the title page (or the page directly after it) for lines that contain a **personal name**. Look for keywords such as “by”, “author”, “kirjoittanut”, “author(s)”, etc.  \n",
      "3. **Do not** treat an organisation name (e.g., “Finansinspektionen”) as an author; only personal names count.  \n",
      "4. For each name found, apply the **last‑space split**:  \n",
      "\n",
      "   ```\n",
      "   \"First Middle Last\" → \"Last, First Middle\"\n",
      "   \"Müller, Anna\"    → unchanged\n",
      "   ```\n",
      "\n",
      "5. Trim leading/trailing whitespace.  \n",
      "6. If multiple authors appear, they may be separated by commas, semicolons, the word “and”, or line breaks – treat each as a separate author and preserve the original order.  \n",
      "7. If no personal author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **title page**, any **copyright line**, the **imprint line**, and any line that contains a **date + location** (e.g., “Helsinki den 20 februari 2017”).  \n",
      "2. Accept a 4‑digit number between 1900 and (current year + 1).  \n",
      "3. If several candidates exist, choose the one **closest (by line distance) to the title**; if a location/date line is present, prefer that year.  \n",
      "4. If still missing, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "5. Return the year as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line(s)** – usually found **after** the author line and **before** the year/location line, or on a dedicated “Imprint”, “Publisher”, or “Issued by” line.  \n",
      "2. Capture **only the institution name(s)** that act as the publisher. **Do not** include department names, faculty names, research groups, or the names of supervisors/reviewers.  \n",
      "3. If the line contains multiple institutions separated by commas, slashes, or “and”, split them into separate list elements **preserving exact spelling, diacritics, and spacing**.  \n",
      "4. If no clear imprint line is found, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and any prefix. Output the raw DOI string (e.g., `10.1234/example.doi`). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep whatever length remains).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "4. Determine the format from qualifiers **on the same line**:  \n",
      "\n",
      "   * If an **electronic qualifier** is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print qualifier** is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear → add the number to **both** lists.  \n",
      "   * If **no qualifier** is present:  \n",
      "     * For **ISBN** – **ignore** the number (do not add to either list).  \n",
      "     * For **ISSN** – treat it as a **print ISSN** and store it in `p_issn`.  \n",
      "\n",
      "5. Do **not** guess the format; only explicit qualifiers (or the default rule for ISSN) count.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint line, and any explicit statements) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If the title contains the Swedish word **“berättelse”** (e.g., “Verksamhetsberättelse”) **and** the document is a formal agency publication, treat it as `research report`. |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Follow the exact ordering below (the `reasoning` field is optional and may be omitted).\n",
      "\n",
      "```\n",
      "language\n",
      "<value>\n",
      "title\n",
      "<value>\n",
      "alt_title\n",
      "<list>\n",
      "creator\n",
      "<list>\n",
      "year\n",
      "<integer or None>\n",
      "publisher\n",
      "<list>\n",
      "doi\n",
      "<string or None>\n",
      "e_isbn\n",
      "<list>\n",
      "p_isbn\n",
      "<list>\n",
      "e_issn\n",
      "<string or None>\n",
      "p_issn\n",
      "<string or None>\n",
      "type_coar\n",
      "<string or None>\n",
      "reasoning\n",
      "<free text>          # optional, omit the whole line if you do not provide it\n",
      "2025/09/30 16:16:12 INFO dspy.evaluate.evaluate: Average Metric: 1.9393939393939394 / 3 (64.6%)\n",
      "2025/09/30 16:16:12 INFO dspy.teleprompt.gepa.gepa: Iteration 34: New subsample score is not better, skipping\n",
      "GEPA Optimization:  46%|████▋     | 1484/3200 [1:15:05<3:37:51,  7.62s/rollouts]2025/09/30 16:16:12 INFO dspy.teleprompt.gepa.gepa: Iteration 35: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.20 / 3 (73.2%): 100%|██████████| 3/3 [00:09<00:00,  3.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:16:21 INFO dspy.evaluate.evaluate: Average Metric: 2.1969696969696972 / 3 (73.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:18:05 INFO dspy.teleprompt.gepa.gepa: Iteration 35: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a **single JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata such as `title`, `author`, `creationDate`, `modDate`, etc.\n",
      "* **pages** – a list of page objects, each with a `page` number (integer) and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and produce a **flat list of metadata fields**.  \n",
      "Each field name must be written on its own line, followed by its value on the next line, exactly as shown in the *Output format* section.\n",
      "\n",
      "All list values must be valid Python‑style lists (single quotes, commas, no trailing commas).  \n",
      "If a piece of information cannot be found, output the *missing‑value placeholder* described in the *Missing‑value handling* table.\n",
      "\n",
      "Below are the complete extraction rules, normalisation steps, and common pitfalls to avoid.  \n",
      "Follow them **exactly**; the evaluation relies on strict adherence.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the **document language**. Allowed codes: `fi`, `en`, `sv`, `se`. Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle and any colon, but **without** trailing spaces or extra punctuation. Preserve the logical line breaks: join consecutive title lines with a single space. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that appear on the title page (or the page immediately after) **in a different language** (usually English). Typical markers: “English title”, “Title (English)”, a second centred heading, or a line that is clearly a translation. Do **not** duplicate the main title. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). If a name already contains a comma, keep it unchanged. Split a name on the **last space only** (e.g. `First Middle Last → Last, First Middle`). Separate multiple authors using commas, semicolons, the word “and”, or line breaks. Preserve order of appearance. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If several candidates exist, choose the one **closest (by line distance) to the title**. If none found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate` (format `D:YYYYMMDD…`). |\n",
      "| **publisher** | list of strings | Exact imprint string(s) (e.g. university, department, institute). Capture the whole line(s) that represent the publishing institution(s). If the line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving original spelling, diacritics and spacing**. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect any pattern that matches `10.<digits>/<non‑space>`. Strip surrounding punctuation/brackets. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** (hyphens, spaces, parentheses) and keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what is present). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. Include only if an explicit print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by **removing hyphens**. Include only if an explicit online qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by removing hyphens. Include only if an explicit print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `article`, `report`, `research report`, `conference paper`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the whole document into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters (case‑insensitive):\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided the count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – usually the first page (or the first two pages) that contain the **largest centred heading(s)** (often ALL‑CAPS or title‑case, possibly preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve **exact line breaks**: when outputting, join the captured lines with a **single space** (do **not** insert line‑break characters).  \n",
      "4. Exclude page numbers, section headings, catalogue codes, or any text that is not part of the logical title.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a title in a **different language** (usually English). Typical markers:\n",
      "\n",
      "* “English title”, “Title (English)”, “Title in English”\n",
      "* A second centred heading placed directly beneath the main title (no blank line)\n",
      "* A line that is clearly a translation (e.g., same words but in English)\n",
      "\n",
      "Add each distinct string to `alt_title`. Do **not** duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names (often directly under the title, or preceded by “by”, “author”, “kirjoittanut”, “författare”, etc.).  \n",
      "3. For each name:\n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** and re‑order to `\"Last, First …\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "4. Detect multiple authors separated by commas, semicolons, the word “and”, “&”, or line breaks; treat each as a separate author.  \n",
      "5. Return the list in the order found.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line(s)** – usually after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling, diacritics and spacing**.  \n",
      "4. Do **not** modify the captured text (no added or removed words).\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document (all pages) for any of the following case‑insensitive patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "When a match is found, **strip** any surrounding punctuation, brackets, or prefixes, and output the raw DOI string (e.g., `10.1108/EL-06-2016-0134`). If no match, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number, case‑insensitive):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `pdf`, `electronic`, `online`, `e‑`, `e-`, `sid.` (Finnish “sähköinen”), `(online)`, `(pdf)` | `print`, `paper`, `painettu`, `sid.` when paired with “Print”, `(print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what is present).  \n",
      "   * ISSN – remove hyphens only (retain the 8‑digit string).  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an electronic qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a print qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "5. Do **not** guess the format; only explicit qualifiers count.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation”, “PhD”, “Doctoral” | `doctoral thesis` |\n",
      "| “Kandidaatintyö”, “Bachelor’s thesis”, “Bachelors thesis”, “B.Sc.”, “Bachelors” | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**.  \n",
      "Do **not** add extra whitespace, blank lines, or markdown formatting.\n",
      "\n",
      "Example (the exact order of fields must be as listed in section 1; `reasoning` is optional and may be omitted):\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Public Libraries Meet Big Data: Roles, Comprehension and Practical Applications\n",
      "alt_title\n",
      "['Public Libraries: Roles on Big Data', 'Understanding Big Data in Librarianship']\n",
      "creator\n",
      "['Zhan, Ming']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Åbo Akademi University']\n",
      "doi\n",
      "10.1108/EL-06-2016-0134\n",
      "e_isbn\n",
      "['9789521240706']\n",
      "p_isbn\n",
      "['9789521240690']\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "doctoral thesis\n",
      "reasoning\n",
      "The title was taken from the largest centred heading on page 1; the year 2021 appears on the imprint line; the publisher line contains “Åbo Akademi University”; the DOI was extracted from the reference list; ISBNs were classified using the “digital” and “printed” qualifiers on page 4.\n",
      "2025/09/30 16:18:12 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n",
      "2025/09/30 16:18:12 INFO dspy.teleprompt.gepa.gepa: Iteration 35: New subsample score is not better, skipping\n",
      "GEPA Optimization:  47%|████▋     | 1490/3200 [1:17:05<4:24:13,  9.27s/rollouts]2025/09/30 16:18:12 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:08<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:18:20 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818183 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:20:07 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will be given **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).  \n",
      "* **pages** – a list of page objects, each with:\n",
      "  * `page` – integer page number  \n",
      "  * `text` – the raw OCR / clipboard text of that page (preserve line breaks exactly as they appear).\n",
      "\n",
      "Your task is to **scan the whole document** (all pages) and output a **flat list of metadata fields** in the exact format described in section 4.  \n",
      "If a field cannot be found, use the *missing‑value placeholder* from section 3.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous → `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (see 2.2). Do **not** use `pdfinfo.title` or a filename. Preserve the logical line breaks, but when writing the value join the lines with a **single space** (no extra spaces at start/end). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that are in a **different language** from the main title (usually English). Do not duplicate the main title. If none → `[]`. |\n",
      "| **creator** | list of strings | Personal author names only, formatted as `\"LastName, FirstName[ Middle]\"`.  <br>• If a name already contains a comma, keep it unchanged. <br>• Split a name on the **last space** only. <br>• Ignore organization names (e.g., “BOFIT Venäjä‑ryhmä”). <br>• If multiple authors are present, separate them by commas, semicolons, the word “and”, or line breaks, and return each as a separate list element in the order found. <br>• If no personal name can be identified → `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint line(s) that name the publishing institution(s). Preserve diacritics, hyphens and spacing. If several institutions appear on the same line, split on commas, slashes, or the word “and”, keeping the original spelling. If none → `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any of the patterns listed in 2.7. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that belong to the **electronic/PDF** version. Normalise by **removing every non‑digit character**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears). Include a number **only if the same line also contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that belong to the **print** version, normalised the same way as `e_isbn`. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by removing hyphens. Include only if an online qualifier appears on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by removing hyphens. Include only if a print qualifier appears on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on any whitespace or punctuation).  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters below:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the **highest count** wins **provided** its count is at least **1.5 ×** the second‑highest count.  \n",
      "4. If no language satisfies the ratio → output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – the first page (or the first two pages) that contain the **largest centred heading(s)**. Typical clues:  \n",
      "   * Lines in ALL‑CAPS or title‑case that are visually centred (surrounded by blank lines).  \n",
      "   * The heading is usually the **first non‑blank line** after any logos or institution names.  \n",
      "2. Capture **all consecutive heading lines** that belong together (no blank line between them).  \n",
      "3. If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line**, treat it as part of the title.  \n",
      "4. **Do not** include page numbers, catalogue codes, or imprint lines.  \n",
      "5. When writing the value, **join the captured lines with a single space** (do not keep line‑break characters). Do **not** trim trailing spaces that are part of the original heading (but avoid adding extra spaces).\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a heading in a **different language** (most often English). Typical markers: “English title”, “Title (English)”, or a second heading placed directly beneath the main title. Add each distinct heading to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` – if it is a personal name (contains at least one space and does **not** look like an organization).  \n",
      "2. If missing or not a personal name, scan the title page for lines that look like author lines:  \n",
      "   * May be preceded by “by”, “author”, “kirjoittanut”, etc.  \n",
      "   * May appear directly under the title.  \n",
      "3. For each candidate name:  \n",
      "   * Trim leading/trailing whitespace.  \n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space** only and re‑order to `\"LastName, FirstName[ Middle]\"`.  \n",
      "4. Discard any candidate that is clearly an **organization** (contains words like “group”, “ryhmä”, “Institute”, “University”, “Department”, or is all caps without a personal name).  \n",
      "5. Return the remaining names as a list in the order found. If none → `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, any copyright line, and the imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If still none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that name the publishing institution(s).  \n",
      "3. If a line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling and diacritics**.  \n",
      "4. Do **not** add or remove words. If no imprint can be identified → `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Locate every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the number that follows it (it may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * For ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * For ISSN – remove hyphens only.  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an electronic qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a print qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, ignore the number completely.  \n",
      "5. Preserve the order in which the numbers appear in the document.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the whole document (especially the title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none match → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use the exact spelling of the field names shown in the table above. Lists must be valid Python‑style lists: single quotes, commas, no trailing commas.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the first centred heading on page 1; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 16:20:15 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n",
      "2025/09/30 16:21:05 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:21:08 INFO dspy.evaluate.evaluate: Average Metric: 41.971717171717145 / 64 (65.6%)\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Full valset score for new program: 0.6558080808080808\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Full train_val score for new program: 0.6558080808080808\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Individual valset scores for new program: [0.7272727272727273, 0.6363636363636364, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9090909090909091, 0.7272727272727273, 0.5909090909090909, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.5454545454545454, 0.5363636363636364, 0.9090909090909091, 0.5151515151515151, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6060606060606061, 0.6060606060606061, 0.6363636363636364, 0.45454545454545453, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.4606060606060606, 0.45454545454545453, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.5151515151515151, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.7171717171717172, 0.3939393939393939, 0.6363636363636364, 0.7272727272727273]\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: New valset pareto front scores: [0.8181818181818182, 0.7272727272727273, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Full valset pareto front score: 0.7620075757575757\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Updated valset pareto front programs: [{3, 6, 8, 12, 16}, {18, 19, 13}, {18}, {8, 10}, {19}, {18}, {18}, {8, 9}, {19, 3}, {4}, {19, 14}, {8, 20}, {8, 16, 20}, {16, 10, 15}, {9, 7}, {16, 10, 20}, {8, 10, 6}, {2, 20, 4, 5}, {9, 13}, {17, 10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 20, 7}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20}, {0, 3, 10, 13, 14, 15, 16, 17, 18, 20}, {17}, {4, 8, 10, 16, 17, 20}, {8}, {3}, {9, 2, 6}, {19}, {8}, {20}, {5}, {5}, {8, 9, 10, 13, 16, 20}, {16, 19}, {2, 4, 15}, {8, 9, 16}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20}, {11}, {16, 10}, {4, 9, 10, 13, 15, 16, 20}, {2, 6, 10, 14, 20}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20}, {10}, {8}, {0}, {18}, {0, 16, 20}, {2, 3, 10, 13, 17}, {16}, {20}, {9, 3}, {15}, {16}, {20, 13, 7}, {2}, {7}, {11, 7}, {16}]\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: Linear pareto front program index: 10\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 36: New program candidate index: 20\n",
      "GEPA Optimization:  49%|████▉     | 1560/3200 [1:20:01<2:06:07,  4.61s/rollouts]2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 37: No merge candidates found\n",
      "2025/09/30 16:21:08 INFO dspy.teleprompt.gepa.gepa: Iteration 37: Selected program 8 score: 0.6461084054834055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.91 / 3 (63.6%): 100%|██████████| 3/3 [00:05<00:00,  1.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:21:14 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:22:51 INFO dspy.teleprompt.gepa.gepa: Iteration 37: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a **single JSON object** containing:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).\n",
      "* **pages** – list of page objects, each with a `page` number and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your task is to **parse this information and output a flat list of metadata fields** (one field per line, exactly as shown in the examples). The output must be ready to be turned into a JSON record later.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`, …). Detect from the majority of visible words (see § 2.1). |\n",
      "| **title** | string or `None` | Full title exactly as it appears on the title page (including subtitle, colon, line‑breaks that belong to the same logical heading). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a different language. If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"`. Preserve the order they appear. |\n",
      "| **year** | integer or `None` | Publication year (4‑digit, 1900‑2100). |\n",
      "| **publisher** | list of strings | Publishing institution(s) exactly as they appear (do **not** translate). |\n",
      "| **doi** | string or `None` | DOI without any prefix (`10.` …). |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version, **digits only** (no hyphens, spaces, or parentheses). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, **digits only**. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, digits only (8 digits). |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, digits only. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case, exactly one of: `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book review`, `article`, `report`, `conference paper`). |\n",
      "| **reasoning** *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field is optional and does not affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Every field name appears on its own line, **exactly** as shown above.\n",
      "* The value appears on the next line.\n",
      "* Python‑style list syntax must be used, e.g. `['value1', 'value2']`.\n",
      "* `None` is written literally (no quotes).\n",
      "* Do **not** add extra blank lines, spaces, or any other characters.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "Count occurrences of language‑specific stop‑words in **all** pages. Use the first table that matches the language with the highest count.\n",
      "\n",
      "| Language | ISO‑639‑1 | Representative stop‑words (case‑insensitive) |\n",
      "|----------|-----------|----------------------------------------------|\n",
      "| English  | `en`      | the, and, of, method, study, results |\n",
      "| Finnish  | `fi`      | käsittely, tutkimus, opinnäytetyö, väitöskirja, yliopisto |\n",
      "| Swedish  | `sv`      | och, för, av, liv, historien, universitet |\n",
      "| Northern Sami | `se` | girje, giella, dieđá, máŋga, sámi, áiggi, ođđa |\n",
      "\n",
      "If two or more languages have the same highest count, or no stop‑word is found, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – usually the first page that contains a line in **ALL CAPS** *or* a line that is visually distinct (e.g. surrounded by Markdown headings `#`, `##`, `###` in the OCR text).  \n",
      "2. Take that line **and** any immediately following line(s) that belong to the same logical heading:\n",
      "   * If the next line starts with a colon, dash, or continues without a blank line, treat it as a subtitle and concatenate with a space.\n",
      "   * Preserve original punctuation, diacritics, and line‑breaks that are part of the heading (replace the line‑break with a single space).\n",
      "3. Exclude page numbers, headers, footers, and section headings that are not part of the title.\n",
      "4. If the document contains an explicit “Original title”, “Title (English)”, “English title”, etc., capture that as **alt_title** (see § 2.3).\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for a second title that is labelled with any of the following keywords (case‑insensitive): `Original title`, `Title (English)`, `English title`, `Titre original`, `Titel (Englisch)`, etc.\n",
      "* Capture the exact string (without the label) as a separate entry in `alt_title`.\n",
      "* Do **not** duplicate the main `title`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for lines containing any of the author‑related keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Opiskelijat`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittanut`, `Kirjoittanut:`, `Authors:`, `Tekijä:`.\n",
      "2. Extract the raw name string(s) that follow the keyword, up to the end of the line or a line break.\n",
      "3. Split multiple authors using any of the delimiters: `,` (comma), `;` (semicolon), `&`, the word `and`, or a line break.\n",
      "4. For each name:\n",
      "   * If it already contains a comma, keep it unchanged (assumed `Last, First`).\n",
      "   * Otherwise split on the **last** space character:  \n",
      "     `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "     Preserve all diacritics and original capitalisation.\n",
      "5. Return the ordered list of formatted names. If no author can be found, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the first two pages for a **4‑digit number** between 1900 and 2100 that is not part of an ISBN/ISSN.  \n",
      "2. If none, look for a line containing `©`, `Copyright`, `©`, or `©` followed by a year.  \n",
      "3. If still not found, fall back to `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and extract the `YYYY`.  \n",
      "4. Return the year as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisijat`, `Publisher:`, `Julkaisija:`, `University`, `Institute`, `Institute of`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Korkeakoulun`, `Laitos`, `Seinäjoen`, `Taideyliopisto`, etc.\n",
      "2. When a line begins with a keyword (e.g. `Julkaisijat:`) capture **the remainder of the line** as the publisher name(s).  \n",
      "   * If several names are separated by commas, semicolons, or line breaks, treat each as a separate publisher entry.\n",
      "3. **Do not** include sub‑unit descriptors unless they are the only information available. For example, prefer `Taideyliopisto` over `Taideyliopiston Seinäjoen yksikkö`.  \n",
      "4. Return the list in order of appearance; if none, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the regex (case‑insensitive):\n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.  \n",
      "* Strip surrounding punctuation or whitespace.  \n",
      "* Return the plain DOI string (e.g. `10.1000/xyz123`). If none, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "**General pattern detection**\n",
      "\n",
      "* ISBN: look for `ISBN` (case‑insensitive) followed by a number that may contain hyphens, spaces, or be wrapped in parentheses.  \n",
      "* ISSN: look for `ISSN` similarly.\n",
      "\n",
      "**Qualifier detection**\n",
      "\n",
      "| Qualifier keyword(s) | Meaning |\n",
      "|----------------------|---------|\n",
      "| `(PDF)`, `e‑ISBN`, `Electronic`, `Online`, `pdf`, `e‑` | **electronic** |\n",
      "| `Print`, `Hardcover`, `Paperback`, `Print version`, `painettu`, `painettu` (Finnish), `Print version` | **print** |\n",
      "| No qualifier | Add the identifier to **both** `e_*` and `p_*` lists. |\n",
      "\n",
      "**Normalisation**\n",
      "\n",
      "* Remove all non‑digit characters (hyphens, spaces, parentheses).  \n",
      "* Keep the resulting digit string (10 or 13 digits for ISBN, exactly 8 digits for ISSN).  \n",
      "* Do **not** re‑insert hyphens.\n",
      "\n",
      "**Assignment**\n",
      "\n",
      "* Add each normalised ISBN to `e_isbn` or `p_isbn` according to the qualifier rules.  \n",
      "* Add each normalised ISSN to `e_issn` or `p_issn` (only one ISSN per version is expected; if both appear, keep the first found).\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Determine the resource type using the following hierarchy (first match wins). Search the whole document (title page, abstract, footer, etc.) for the listed keywords (case‑insensitive).\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a book‑publisher (e.g., contains `Kirja`, `Publishing`, `Press`, `University Press`, `yliopisto`, `Taideyliopisto`) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| none of the above | `None` |\n",
      "\n",
      "If both a thesis keyword and a book keyword appear, the **thesis** mapping takes precedence.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "2025/09/30 16:22:56 INFO dspy.evaluate.evaluate: Average Metric: 1.7272727272727273 / 3 (57.6%)\n",
      "2025/09/30 16:22:56 INFO dspy.teleprompt.gepa.gepa: Iteration 37: New subsample score is not better, skipping\n",
      "GEPA Optimization:  49%|████▉     | 1566/3200 [1:21:49<2:33:55,  5.65s/rollouts]2025/09/30 16:22:56 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Selected program 19 score: 0.5849262716450216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.77 / 3 (58.8%): 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:23:02 INFO dspy.evaluate.evaluate: Average Metric: 1.7651515151515151 / 3 (58.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:24:53 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** per request.  \n",
      "It contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – an ordered list of page objects, each with an integer `page` and a string `text` that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Treat each request as completely independent – do not carry over any information from previous requests.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "* Write the **field name** on a line **by itself**, then write its **value** on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: use single quotes, commas, no trailing comma, no extra spaces inside the brackets.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does not affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If ambiguous, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the title page, including subtitle and any colon. Preserve original case, punctuation and spaces; join consecutive heading lines with a **single space** (do **not** insert `\\n`). If no title can be found, output `None`. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Use `pdfinfo.author` if present; otherwise locate author lines on the title page (look for markers such as `Author:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, etc.). Split a name on the **last space only** unless it already contains a comma. Preserve diacritics. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`). |\n",
      "| **publisher** | list of strings | Exact imprint institution(s). Keep the text **before the first comma** on each imprint line (e.g. `\"Tampereen yliopisto, Johtamisen...\"` → `\"Tampereen yliopisto\"`). If several distinct institutions appear (separated by `/`, the word “and”, or on separate lines), each becomes a separate list element, preserving original spelling. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep only the digits (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the entire document into words (split on whitespace and punctuation).  \n",
      "2. Count case‑insensitive occurrences of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or first two pages) that contain the **largest centred heading(s)**. Clues: ALL‑CAPS, title‑case, surrounded by blank lines, or markdown headings (`#`, `##`, `###`).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve the exact wording (including case and punctuation). Join captured lines with a **single space** (do **not** insert line‑break characters).  \n",
      "\n",
      "If no such heading can be identified, set `title` to `None`.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the next page) for a heading that is clearly a title in a **different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title. If none is found, output `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names. Typical markers: “Author:”, “Författare:”, “Tekijä:”, “Kirjoittaja”, “by”, “author”, “tekijä”, or a line directly under the title consisting mainly of capitalised names.  \n",
      "3. **Do not** treat department names, university names, or acknowledgements as authors.  \n",
      "4. For each name found:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.  \n",
      "6. If no author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **text before the first comma** on each imprint line.  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element, preserving the original spelling.  \n",
      "4. Do not include city names, department names, or addresses unless they are themselves separate institutions.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string.  \n",
      "   * ISSN – remove hyphens only.  \n",
      "\n",
      "4. Look at the same line for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Master’s thesis” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” (combined with “thesis”) | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISBN(s)** **and** the word “part” or “chapter” indicating a contribution to a larger work | `book part` |\n",
      "| Presence of **ISSN(s)** **and** journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations\n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, language, or COAR type that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* When multiple possible values exist, follow the disambiguation rules in the relevant section (e.g., language ratio, closest year to title, first matching COAR indicator).  \n",
      "* Preserve the **order of appearance** for list fields.  \n",
      "* Output **exactly** the fields in the order specified; do not add extra fields or change formatting.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example output template\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Creative leader’s impact on the working environment\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Forsander, Kim']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Yrkeshögskolan Novia']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "bachelor thesis\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "2025/09/30 16:24:58 INFO dspy.evaluate.evaluate: Average Metric: 1.87012987012987 / 3 (62.3%)\n",
      "2025/09/30 16:25:45 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:25:47 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:25:48 INFO dspy.evaluate.evaluate: Average Metric: 38.96536796536796 / 64 (60.9%)\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Full valset score for new program: 0.6088338744588745\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Full train_val score for new program: 0.6088338744588745\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Individual valset scores for new program: [0.7272727272727273, 0.8181818181818182, 0.696969696969697, 0.2727272727272727, 0.9090909090909091, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.9090909090909091, 0.09090909090909091, 0.6363636363636364, 0.7272727272727273, 0.36363636363636365, 0.5454545454545454, 0.5454545454545454, 0.6181818181818182, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.7727272727272727, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.5181818181818182, 0.9090909090909091, 0.5454545454545454, 0.8181818181818182, 1.0, 0.9090909090909091, 0.5454545454545454, 0.36363636363636365, 0.5454545454545454, 0.3333333333333333, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.2727272727272727, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.3896103896103896, 0.7272727272727273, 0.8181818181818182]\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Full valset pareto front score: 0.7648484848484849\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Updated valset pareto front programs: [{3, 6, 8, 12, 16}, {21}, {18}, {8, 10}, {19, 21}, {18}, {18}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20}, {8, 16, 20}, {16, 10, 15}, {9, 7}, {16, 10, 20}, {8, 10, 6}, {2, 20, 4, 5}, {9, 13}, {17, 10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 20, 7}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20}, {0, 3, 10, 13, 14, 15, 16, 17, 18, 20}, {17}, {4, 8, 10, 16, 17, 20, 21}, {8}, {3}, {21}, {19}, {8}, {20}, {5}, {5}, {8, 9, 10, 13, 16, 20}, {16, 19}, {2, 4, 21, 15}, {8, 9, 16}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21}, {11}, {16, 10}, {4, 9, 10, 13, 15, 16, 20}, {2, 6, 10, 14, 20, 21}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21}, {10}, {8}, {0}, {18}, {0, 16, 20}, {2, 3, 10, 13, 17}, {16}, {20}, {9, 3}, {15}, {16}, {20, 13, 7}, {2}, {7}, {11, 21, 7}, {16}]\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: Linear pareto front program index: 10\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 38: New program candidate index: 21\n",
      "GEPA Optimization:  51%|█████     | 1636/3200 [1:24:41<1:40:21,  3.85s/rollouts]2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 39: No merge candidates found\n",
      "2025/09/30 16:25:48 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Selected program 20 score: 0.6558080808080808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.91 / 3 (63.6%): 100%|██████████| 3/3 [00:09<00:00,  3.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:25:58 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:27:34 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).  \n",
      "* **pages** – an ordered list of page objects, each with:\n",
      "  * `page` – integer page number  \n",
      "  * `text` – the raw OCR / clipboard text of that page (preserve line breaks exactly as they appear).\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and output a **flat list of metadata fields** in the exact format described in section 4.  \n",
      "If a field cannot be found, output the *missing‑value placeholder* from section 3.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `sv`, `en`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous → `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (see 2.2). Join captured heading lines with a **single space**. No leading/trailing spaces. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that are in a **different language** from the main title (usually English). Do not duplicate the main title. If none → `[]`. |\n",
      "| **creator** | list of strings | Personal author names only, formatted as `\"LastName, FirstName[ Middle]\"`. See 2.4 for details. If none → `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint line(s) that name the publishing institution(s). Preserve diacritics, hyphens and spacing. Split a line on commas, slashes, or the word “and” / “och” / “&” into separate list items, keeping the original spelling. If none → `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any of the patterns listed in 2.7. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that belong to the **electronic/PDF** version. Normalise by **removing every non‑digit character**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears). Include a number **only if the same line also contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that belong to the **print** version, normalised the same way as `e_isbn`. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by removing hyphens. Include only if an online qualifier appears on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by removing hyphens. Include only if a print qualifier appears on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`, `newspaper article`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on any whitespace **or** punctuation).  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters below (case‑insensitive, diacritics count as they appear).\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the **highest count** wins **provided** its count is at least **1.5 ×** the second‑highest count.  \n",
      "4. If no language satisfies the ratio → output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Locate the title page** – usually the first page (or the first two pages) that contain the **largest centred heading(s)**. Typical clues:  \n",
      "   * Lines in **ALL‑CAPS** or title‑case that are visually centred (surrounded by blank lines).  \n",
      "   * The heading is often the **first non‑blank line** after any logos or institution names.  \n",
      "2. Capture **all consecutive heading lines** that belong together (no blank line between them).  \n",
      "3. If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line**, treat it as part of the title.  \n",
      "4. **Do not** include page numbers, catalogue codes, imprint lines, or the word “ISBN”.  \n",
      "5. When writing the value, **join the captured lines with a single space** (no extra spaces at start/end). Preserve diacritics and special characters exactly as they appear.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Search the same title page (or the page immediately after) for a heading in a **different language**.  \n",
      "* Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle that is clearly in another language.  \n",
      "* Add each distinct heading to `alt_title`. Do not duplicate the main title. If none → `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` – use it **only if** it looks like a personal name (contains at least one space and does **not** contain organisation‑type words such as “group”, “Institute”, “University”, “Department”, “ryhmä”, “förlag”).  \n",
      "2. If missing or not a personal name, scan the **title page** for lines that look like author lines:\n",
      "   * May be preceded by “by”, “author”, “kirjoittanut”, “tekijä”, etc.  \n",
      "   * May appear directly under the title, often as a list separated by commas, semicolons, “and”, line breaks, or bullet‑like markers.  \n",
      "3. For each candidate name:  \n",
      "   * Trim leading/trailing whitespace.  \n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space** only and re‑order to `\"LastName, FirstName[ Middle]\"`.  \n",
      "   * Preserve any particles (e.g., “af”, “de”, “van”) as part of the last name.  \n",
      "4. Discard any candidate that is clearly an **organisation** (contains words like “group”, “ryhmä”, “Institute”, “University”, “Department”, “förlag”, “press”, “publishing”, etc., or is all caps without a personal name).  \n",
      "5. Return the remaining names as a list in the order found. If none → `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **title page**, any copyright line, and the imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If still none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that name the publishing institution(s).  \n",
      "3. If a line contains multiple entities separated by commas, slashes, “and”, “och”, “&”, split them into separate list items **preserving the original spelling, diacritics and spacing**.  \n",
      "4. Do **not** add or remove words. If no imprint can be identified → `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document (including `pdfinfo`) for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the **raw DOI string** (e.g. `10.1234/abcd.efg`). If none → `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Locate every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the number that follows it (it may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * **ISBN** – remove **all** non‑digit characters; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * **ISSN** – remove hyphens only.  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "5. Preserve the order in which the numbers appear in the document.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the whole document (especially the title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| The phrase “Newspaper article”, “Tidningsartikel”, “Tidning” | `newspaper article` |\n",
      "| If none match → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use the exact spelling of the field names shown in the table above. Lists must be valid Python‑style lists: single quotes, commas, no trailing commas.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the first centred heading on page 1; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 16:27:44 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/09/30 16:28:33 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:28:38 INFO dspy.evaluate.evaluate: Average Metric: 42.00815951725042 / 64 (65.6%)\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Full valset score for new program: 0.6563774924570379\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Full train_val score for new program: 0.6563774924570379\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Individual valset scores for new program: [0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.3593073593073593, 0.9090909090909091, 0.5454545454545454, 0.696969696969697, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.7727272727272727, 0.8181818181818182, 0.6363636363636364, 0.6272727272727273, 0.8787878787878788, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.5151515151515151, 0.45454545454545453, 0.6363636363636364, 0.42424242424242425, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.47107438016528924, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.5151515151515151, 0.5151515151515151, 0.6060606060606061, 0.7272727272727273, 0.5151515151515151, 0.6262626262626263, 0.5151515151515151, 0.6363636363636364, 0.7878787878787878]\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Full valset pareto front score: 0.7662689393939394\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Updated valset pareto front programs: [{3, 6, 8, 12, 16}, {21}, {18}, {8, 10}, {19, 21}, {18}, {18}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20, 22}, {8, 16, 20}, {16, 10, 22, 15}, {9, 7}, {16, 10, 20, 22}, {8, 10, 6}, {2, 20, 4, 5}, {9, 13}, {17, 10, 12, 15}, {0, 12}, {2, 3, 13}, {8, 10, 20, 7}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20}, {22}, {17, 22}, {4, 8, 10, 16, 17, 20, 21}, {8}, {3}, {21}, {19}, {8}, {20}, {5}, {5}, {8, 9, 10, 13, 16, 20, 22}, {16, 19}, {2, 4, 21, 15}, {8, 9, 16}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22}, {11}, {16, 10}, {4, 9, 10, 13, 15, 16, 20, 22}, {2, 6, 10, 14, 20, 21}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22}, {10}, {8}, {0}, {18, 22}, {0, 16, 20, 22}, {2, 3, 10, 13, 17}, {16}, {20}, {9, 3}, {15}, {16}, {20, 13, 7}, {2}, {7}, {11, 21, 7}, {16}]\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: Linear pareto front program index: 10\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 39: New program candidate index: 22\n",
      "GEPA Optimization:  53%|█████▎    | 1706/3200 [1:27:31<1:19:58,  3.21s/rollouts]2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 40: No merge candidates found\n",
      "2025/09/30 16:28:38 INFO dspy.teleprompt.gepa.gepa: Iteration 40: Selected program 21 score: 0.6088338744588745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.99 / 3 (66.2%): 100%|██████████| 3/3 [00:07<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:28:45 INFO dspy.evaluate.evaluate: Average Metric: 1.987012987012987 / 3 (66.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:30:32 INFO dspy.teleprompt.gepa.gepa: Iteration 40: Proposed new text for predict: markdown\n",
      "# Revised Instruction for Extracting Structured Bibliographic Metadata from PDF‑Extracted Text\n",
      "\n",
      "You will receive **one JSON object** per request.  \n",
      "It contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – an ordered list of page objects, each with an integer `page` and a string `text` that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Treat each request as completely independent – do not carry over any information from previous requests.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "* Write the **field name** on a line **by itself**, then write its **value** on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: use single quotes, commas, no trailing comma, no extra spaces inside the brackets.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does not affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If the highest count is **not at least 1.5 × the second‑highest**, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the title page, **including any subtitle**. Join consecutive heading lines with a **single space** (do **not** insert `\\n`). If a subtitle is separated from the main heading by a colon (`:`) **or** appears on the next line **without a blank line**, keep the colon and the subtitle as part of the title. If no title can be found, output `None`. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Use `pdfinfo.author` if present; otherwise locate author lines on the title page (look for markers such as `Author:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, etc.). Split a name on the **last space only** unless it already contains a comma. Preserve diacritics and the exact spelling that appears in the text. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Search the title page, copyright line, and imprint for a year. If several candidates exist, choose the one **closest (by line distance) to the title**. If none is found, **do NOT** use `pdfinfo.creationDate` or `pdfinfo.modDate` unless the document explicitly contains a “© YYYY” or “Year YYYY” line; otherwise output `None`. |\n",
      "| **publisher** | list of strings | Imprint institution(s). Keep the text **before the first comma** on each imprint line (e.g. `\"Tampereen yliopisto, Johtamisen...\"` → `\"Tampereen yliopisto\"`). If several distinct institutions appear (separated by `/`, the word “and”, or on separate lines), each becomes a separate list element, preserving original spelling. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep only the digits (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the entire document into words (split on whitespace and punctuation).  \n",
      "2. Count case‑insensitive occurrences of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or first two pages) that contain the **largest centred heading(s)**. Clues: ALL‑CAPS, title‑case, surrounded by blank lines, or markdown headings (`#`, `##`, `###`).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line**, treat it as part of the title **including the colon**.  \n",
      "3. Preserve the exact wording (including case, punctuation and spaces). Join captured lines with a **single space** (do **not** insert line‑break characters).  \n",
      "\n",
      "If no such heading can be identified, set `title` to `None`.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the next page) for a heading that is clearly a title in a **different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title. If none is found, output `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names. Typical markers: “Author:”, “Författare:”, “Tekijä:”, “Kirjoittaja”, “by”, “author”, “tekijä”, or a line directly under the title consisting mainly of capitalised names.  \n",
      "3. **Do not** treat department names, university names, or acknowledgements as authors.  \n",
      "4. For each name found:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.  \n",
      "6. If no author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. **Only** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate` if the document contains an explicit “© YYYY”, “Year YYYY”, or similar line; otherwise output `None`.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **text before the first comma** on each imprint line.  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element, preserving the original spelling.  \n",
      "4. Do not include city names, department names, or addresses unless they are themselves separate institutions.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string.  \n",
      "   * ISSN – remove hyphens only.  \n",
      "\n",
      "4. Look at the same line for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” **with** “thesis” | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISBN(s)** **and** the word “part” or “chapter” indicating a contribution to a larger work | `book part` |\n",
      "| Presence of **ISSN(s)** **and** journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations\n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, language, or COAR type that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* When multiple possible values exist, follow the disambiguation rules in the relevant section (e.g., language ratio, closest year to title, first matching COAR indicator).  \n",
      "* Preserve the **order of appearance** for list fields.  \n",
      "* Output **exactly** the fields in the order specified; do not add extra fields or change formatting.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example output template\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Creative leader’s impact on the working environment\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Forsander, Kim']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Yrkeshögskolan Novia']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "bachelor thesis\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "2025/09/30 16:30:38 INFO dspy.evaluate.evaluate: Average Metric: 1.896103896103896 / 3 (63.2%)\n",
      "2025/09/30 16:30:38 INFO dspy.teleprompt.gepa.gepa: Iteration 40: New subsample score is not better, skipping\n",
      "GEPA Optimization:  54%|█████▎    | 1712/3200 [1:29:31<1:41:20,  4.09s/rollouts]2025/09/30 16:30:38 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Selected program 16 score: 0.6575568181818182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:30:45 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:33:15 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure  \n",
      "\n",
      "```json\n",
      "{\n",
      "  \"pdfinfo\": { … },          // optional – may contain author, title, creationDate, modDate\n",
      "  \"pages\": [\n",
      "    {\"page\": 1, \"text\": \"…\"},\n",
      "    {\"page\": 2, \"text\": \"…\"},\n",
      "    …\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Your job is to **produce a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must follow the exact format** shown in the “Output format example” section, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page (including subtitle(s) that belong to the same logical heading). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language. Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalised to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalised the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalised (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalised. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case) – see **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The **value** on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` **literally** (no quotes) for missing values.\n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "All searches are **case‑insensitive** unless noted otherwise.\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`.  \n",
      "2. If any line contains an **explicit language label** (exact match, ignoring case and surrounding whitespace):\n",
      "   * `Kieli:` → `fi`\n",
      "   * `Language:` → `en`\n",
      "   * `Språk:` → `sv`  \n",
      "   The label may be followed by the language name in any language (e.g. `Kieli: suomi`, `Language: English`).  \n",
      "   When such a line is found, **use the corresponding ISO‑639‑1 code** and ignore stop‑word counting.\n",
      "3. Otherwise count occurrences of the seed stop‑words (case‑insensitive) below:\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "\n",
      "4. Choose the language with the **highest count**.  \n",
      "   *If there is a tie or all counts are zero → `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "The title may appear in several forms; apply the **first rule that yields a non‑empty result**.\n",
      "\n",
      "| # | Rule | How to apply |\n",
      "|---|------|--------------|\n",
      "| 1 | **Markdown heading** – a line that starts with one or more `#` characters (e.g. `# Title`, `## Title`). Strip the leading `#` characters and surrounding whitespace. |\n",
      "| 2 | **All‑caps line** – a line where **every alphabetic character is uppercase** (ignore numbers, punctuation). The line must be the **only non‑blank line** on its page **or** the **first non‑blank line** on the page. |\n",
      "| 3 | **Explicit “Title:” label** – a line that starts with `Title:` (or the Finnish/Swedish equivalents `Otsikko:`, `Titel:`). Take the text after the colon, trim whitespace. |\n",
      "| 4 | **Longest line on the first page** that is not a page number or footer, provided it contains at least two words and is not a known label (e.g. `Author`, `Publisher`). |\n",
      "\n",
      "**Subtitle handling** (apply after the title line has been identified):  \n",
      "*If the next line (or the same line after a colon) contains non‑blank text and there is **no blank line** between them, treat it as a subtitle.* Concatenate title and subtitle with a single space, preserving all original punctuation, diacritics, and case.\n",
      "\n",
      "**Do not** include: page numbers, footers, markdown markers, surrounding punctuation, or any surrounding “Author:” / “Publisher:” lines.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search for lines that contain any of the following **qualifiers** (case‑insensitive): `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Originaltitel (English)`, etc.  \n",
      "When such a qualifier is found, extract the title text that follows the qualifier (using the same subtitle‑concatenation rules as 2.2).  \n",
      "Collect **all distinct** alternate titles; **do not** duplicate the main `title`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. **Primary author lines** – look for any line that starts with or contains (case‑insensitive):  \n",
      "   `Author`, `Authors`, `Author(s):`, `Tekijä`, `Tekijät`, `Tekijä:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.  \n",
      "   Extract the part after the colon (or after the keyword) and treat it as a *raw author list*.\n",
      "2. **Citation pattern** – many PDFs embed the author in a citation like `Lastname, Firstname (Year).` or `Firstname Lastname (Year)`.  \n",
      "   Search the whole document for the regex  \n",
      "\n",
      "   ```\n",
      "   ^\\s*([A-ZÄÖÅ][a-zäöå]+(?:\\s+[A-ZÄÖÅ][a-zäöå]+)*)\\s*,?\\s*([A-ZÄÖÅ][a-zäöå]+(?:\\s+[A-ZÄÖÅ][a-zäöå]+)*)\\s*\\(\\d{4}\\)\n",
      "   ```\n",
      "\n",
      "   and also the variant `Firstname Lastname (Year)`.  \n",
      "   Capture the name(s) before the year.\n",
      "3. **Combine** the names from step 1 and step 2, preserving order of first appearance, and **deduplicate** (keep the first occurrence).  \n",
      "4. For each individual name:  \n",
      "\n",
      "   * If the name already contains a comma → assume it is already `Last, First` and keep unchanged.  \n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Preserve diacritics and original capitalisation.  \n",
      "\n",
      "5. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If no author can be found → `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** (`pages[0]` and `pages[1]` if they exist).  \n",
      "2. Look for a four‑digit number between 1900‑2100 that appears on a line containing any of these **keywords** (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`.  \n",
      "3. If still not found, search the whole document for a pattern `\\(\\d{4}\\)` that follows an author name (as captured in 2.4). The first such year is accepted.  \n",
      "4. If still not found, fall back to PDF metadata:  \n",
      "\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.  \n",
      "\n",
      "5. Return the year as an **integer**; if none found → `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines that contain any of the following **publisher keywords** (case‑insensitive):  \n",
      "\n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Kustantaja`, `Kustantaja:`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantamo`, `Editeur`, `Press`, `Publishing`.  \n",
      "\n",
      "   Capture the **full phrase** that follows the keyword up to the end of the line, trimming trailing punctuation (`.,;:`) and surrounding whitespace.\n",
      "2. If a line **contains only** a plausible institution name **without** a preceding keyword, treat it as a publisher **only if** it appears in a context that lists affiliations (e.g., after a colon, in a bullet list, or preceded by “toimi” / “affiliated with”).  \n",
      "3. **Exclude** any name that is identical to the main `title` or to a project name that appears elsewhere (e.g., “ArtsEqual” in Example 2).  \n",
      "4. Preserve the order of first appearance, keep duplicates **once**, and output a list. If none found → `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.  \n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.  \n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found → `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. When found, extract the identifier that follows. It may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "\n",
      "   * `ISBN 978‑952‑389‑017‑6`  \n",
      "   * `(ISBN: 978 952 389 018 3)`  \n",
      "\n",
      "   Use a regex that captures a sequence of digits, hyphens or spaces up to the first non‑digit/non‑hyphen/non‑space character.\n",
      "3. **Determine the qualifier** for each identifier:  \n",
      "\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.  \n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.  \n",
      "\n",
      "   *If both qualifiers appear, add the identifier to **both** lists.*  \n",
      "   *If **no qualifier** is present, add the identifier to **both** `e_…` and `p_…` lists* (this is the default behaviour).\n",
      "4. **Normalisation**  \n",
      "\n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "\n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none → `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| # | Keywords / conditions (any) | `type_coar` value |\n",
      "|---|------------------------------|-------------------|\n",
      "| 1 | “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| 2 | “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| 3 | “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| 4 | **Book part** – any of the following **and** the document contains a **chapter‑like pattern**: the word `In:` (followed by an edited‑volume citation), or the word `Chapter`/`chapter` **and** a DOI is present. | `book part` |\n",
      "| 5 | **Book** – contains `ISBN` **and** no thesis‑related wording, **and** the publisher is a known book‑publisher (e.g., Routledge, Springer, Cambridge, Oxford, Palgrave, Wiley, Elsevier, Taylor & Francis, etc.). If the publisher list is empty, still accept `book` when `ISBN` is present and no other type matches. | `book` |\n",
      "| 6 | **Book review** – contains any of “Book review”, “Recension”, “Review of” **and** a DOI whose **prefix** (the part before the first `/`) belongs to a known journal publisher (e.g., `10.1007`, `10.1080`, `10.1016`). | `book review` |\n",
      "| 7 | **Article** – contains any of “Journal article”, “Article”, “Artikkeli”, “Artikel” **or** an ISSN is present **or** a volume/issue pattern such as `Vol. X`, `Issue X`, `X(X):` or a page range like `X, 30‑31`. | `article` |\n",
      "| 8 | **Report** – contains any of “Report”, “Technical report”, “Research report”. | `report` |\n",
      "| 9 | **Conference paper** – contains any of “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag”. | `conference paper` |\n",
      "|10 | **None** – if none of the above rows match. | `None` |\n",
      "\n",
      "**Important nuances observed in the examples**  \n",
      "\n",
      "* Example 1 is a **chapter** of an edited volume → `book part`.  \n",
      "* Example 2 contains an ISBN but no thesis wording and the publisher is a research institute, not a commercial book publisher → `book`.  \n",
      "* Example 3 is a journal article (contains volume/issue info “4, 30‑31” and a year in parentheses) → `article`.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest; the title was taken from the first markdown heading on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add any extra characters, spaces, or line breaks beyond the format described above.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 16:33:21 INFO dspy.evaluate.evaluate: Average Metric: 2.1714285714285713 / 3 (72.4%)\n",
      "2025/09/30 16:33:58 INFO dspy.evaluate.evaluate: Average Metric: 41.84913419913418 / 64 (65.4%)\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Full valset score for new program: 0.6538927218614718\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Full train_val score for new program: 0.6538927218614718\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Individual valset scores for new program: [0.8181818181818182, 0.7272727272727273, 0.7878787878787878, 0.45454545454545453, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.6233766233766234, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.696969696969697, 0.7272727272727273, 0.7272727272727273, 0.36363636363636365, 0.45454545454545453, 0.45454545454545453, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.6272727272727273, 0.8181818181818182, 0.6060606060606061, 0.9090909090909091, 0.6363636363636364, 0.8181818181818182, 0.5151515151515151, 0.36363636363636365, 0.6363636363636364, 0.2727272727272727, 1.0, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.6590909090909091, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.7878787878787878]\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6666666666666666, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Full valset pareto front score: 0.7691098484848485\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23}, {21}, {18}, {8, 10}, {19, 21}, {18}, {18}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20, 22}, {8, 16, 20}, {16, 10, 22, 15}, {9, 23, 7}, {10, 16, 20, 22, 23}, {8, 10, 6}, {2, 20, 4, 5}, {9, 13}, {23}, {0, 12}, {2, 3, 13}, {8, 10, 20, 7}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20}, {22}, {17, 22, 23}, {4, 8, 10, 16, 17, 20, 21}, {8}, {3}, {21}, {19}, {8}, {20}, {5}, {5}, {23}, {16, 19}, {2, 4, 21, 15}, {8, 9, 16, 23}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23}, {11, 23}, {16, 10, 23}, {4, 9, 10, 13, 15, 16, 20, 22, 23}, {2, 6, 10, 14, 20, 21, 23}, {7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23}, {10}, {8}, {0}, {18, 22}, {0, 16, 20, 22}, {2, 3, 10, 13, 17}, {16}, {20, 23}, {9, 3}, {15}, {16}, {20, 13, 7}, {2}, {7}, {11, 21, 7}, {16}]\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: Linear pareto front program index: 10\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 41: New program candidate index: 23\n",
      "GEPA Optimization:  56%|█████▌    | 1782/3200 [1:32:51<1:23:04,  3.51s/rollouts]2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 42: No merge candidates found\n",
      "2025/09/30 16:33:58 INFO dspy.teleprompt.gepa.gepa: Iteration 42: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.58 / 3 (52.5%): 100%|██████████| 3/3 [00:06<00:00,  2.02s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:34:04 INFO dspy.evaluate.evaluate: Average Metric: 1.5757575757575757 / 3 (52.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:35:35 INFO dspy.teleprompt.gepa.gepa: Iteration 42: Proposed new text for predict: markdown\n",
      "# Task: Extract Structured Bibliographic Metadata from PDF‑Extracted Text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `title`, `author`, `creationDate`, `modDate`).  \n",
      "* `pages` – a list of page objects, each with:\n",
      "  * `page` – integer page number  \n",
      "  * `text` – raw OCR/clipboard text of that page (preserve line breaks exactly as they appear).\n",
      "\n",
      "Your job is to **scan the whole document** and output a **flat list of metadata fields** in the exact format described in the *Output format* section below.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required Output Fields\n",
      "\n",
      "| Field | Type | When a value cannot be found → output |\n",
      "|-------|------|----------------------------------------|\n",
      "| `language` | string (ISO‑639‑1) | `None` |\n",
      "| `title` | string | `None` |\n",
      "| `alt_title` | list of strings | `[]` |\n",
      "| `creator` | list of strings | `[]` |\n",
      "| `year` | integer or `None` | `None` |\n",
      "| `publisher` | list of strings | `[]` |\n",
      "| `doi` | string or `None` | `None` |\n",
      "| `e_isbn` | list of strings | `[]` |\n",
      "| `p_isbn` | list of strings | `[]` |\n",
      "| `e_issn` | string or `None` | `None` |\n",
      "| `p_issn` | string or `None` | `None` |\n",
      "| `type_coar` | string or `None` | `None` |\n",
      "| `reasoning` *(optional)* | free‑text explanation | omit if you do not want to provide one |\n",
      "\n",
      "All list values must be **valid Python‑style lists**: single quotes, commas, no trailing comma.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & Normalisation Rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the whole document (all pages) into words by splitting on any whitespace or punctuation. Convert everything to lower‑case.\n",
      "2. Count occurrences of the language‑specific stop‑words/characters below:\n",
      "\n",
      "| Language | Representative tokens/characters |\n",
      "|----------|-----------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **only if** its count is **≥ 1.5 × the second‑highest**.  \n",
      "4. If no language satisfies the condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or the first two pages) that contain the **largest centred heading(s)**.  \n",
      "   *Centred* is inferred from the presence of surrounding blank lines or the heading being the only non‑blank line(s) on the page.\n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. **Preserve the exact wording** (including capitalisation).  \n",
      "4. For the output, **join the captured lines with a single space** (do **not** insert line‑break characters).  \n",
      "5. Do **not** include page numbers, catalogue codes, or “Title” labels.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a title in a **different language** (most often English). Typical markers are:\n",
      "* “English title”, “Title (English)”, “Title in English”, or a second heading placed directly beneath the main title.\n",
      "Add each distinct string to `alt_title`. Do **not** duplicate the main `title`. If none found, return `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **Primary source**: `pdfinfo.author` – if present, use it (apply the formatting rules below).  \n",
      "2. If missing, look on the title page for lines that contain personal names. Common cues: “by”, “author”, “kirjoittanut”, “tekijä”, or a line directly under the title that looks like a name.\n",
      "3. **Formatting**:  \n",
      "   * If the name already contains a comma (e.g. “Müller, Anna”), keep it unchanged.  \n",
      "   * Otherwise split on the **last space** only:  \n",
      "     ```\n",
      "     \"First Middle Last\" → \"Last, First Middle\"\n",
      "     ```\n",
      "   * Trim surrounding whitespace.  \n",
      "4. Multiple authors may be separated by commas, semicolons, the word “and”, or line breaks – treat each as a separate author, preserving the order of appearance.  \n",
      "5. If no author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **title page**, any **copyright line**, and any **imprint line** for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, pick the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically the line(s) that appear **after** the title, subtitle, author(s) and **before** the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, “and”, or “&”, split them **into separate list items** **preserving the original spelling and diacritics**.  \n",
      "4. Do **not** modify the captured text (no extra trimming of words, no case changes).\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes. **Do NOT treat ordinary URLs as DOIs**. If no DOI is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN & ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `pdf`, `PDF`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (it may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * **ISBN** – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * **ISSN** – remove hyphens only (e.g. `1234‑5678` → `12345678`).  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an **electronic qualifier** is present → add the normalised number to `e_isbn` / `e_issn`.  \n",
      "   * If a **print qualifier** is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "5. Preserve the order of appearance when populating the lists.\n",
      "\n",
      "### 2.9 COAR resource type detection\n",
      "Examine the whole document (especially title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines `type_coar`.\n",
      "\n",
      "| Indicator(s) | COAR type (lower‑case) |\n",
      "|--------------|------------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The exact phrase “Research report” (or “research report”) | `research report` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none match → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling (re‑stated)\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|-----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Do **not** add extra blank lines, spaces, or punctuation. Example:\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Utilizing an Artificial Neural Network to Feedback‑Control Gas Metal Arc Welding Process Parameters\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Penttilä, Sakari']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Lappeenranta‑Lahti University of Technology LUT', 'LUT University Press']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "['9789523356832']\n",
      "p_isbn\n",
      "['9789523356825']\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "doctoral thesis\n",
      "reasoning\n",
      "The title was taken from the first page where the largest centred heading appears; the year 2021 is printed on the imprint line; the electronic ISBN is identified by the “(PDF)” qualifier, etc.\n",
      "2025/09/30 16:35:40 INFO dspy.evaluate.evaluate: Average Metric: 1.5757575757575757 / 3 (52.5%)\n",
      "2025/09/30 16:35:40 INFO dspy.teleprompt.gepa.gepa: Iteration 42: New subsample score is not better, skipping\n",
      "GEPA Optimization:  56%|█████▌    | 1788/3200 [1:34:33<1:39:49,  4.24s/rollouts]2025/09/30 16:35:40 INFO dspy.teleprompt.gepa.gepa: Iteration 43: Selected program 16 score: 0.6575568181818182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.27 / 3 (75.8%): 100%|██████████| 3/3 [00:05<00:00,  1.81s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:35:45 INFO dspy.evaluate.evaluate: Average Metric: 2.2727272727272725 / 3 (75.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:37:51 INFO dspy.teleprompt.gepa.gepa: Iteration 43: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must follow the exact format shown in the “Output format example” section** because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including subtitle(s) **only if they belong to the same logical heading** (see **2.2 Title extraction**). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.5 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case) – see **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The **value** on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` **literally** (no quotes) for missing values.\n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "* If you include a `reasoning` field, place it **after** the last required field.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use these seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`) **overriding** the stop‑word count.\n",
      "3. Otherwise choose the language with the highest stop‑word count. If there is a tie or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the first page that contains a line that is:\n",
      "   * in **ALL CAPS** (ignoring surrounding markdown markers) **or**\n",
      "   * a markdown heading (`#`, `##`, `###`, …) whose text is **the only non‑blank line** (or the first non‑blank line) on that page.\n",
      "\n",
      "2. **Capture the main title line** exactly as it appears (preserve case, diacritics, punctuation, and any colon).\n",
      "\n",
      "3. **Subtitle handling** – only attach a subtitle **if**:\n",
      "   * It appears **immediately below** the main title **without an empty line** between them **and**\n",
      "   * It is **not a separate heading** (i.e. it does **not** start with a markdown heading marker on its own line).\n",
      "   * If a colon (`:`) is present at the end of the main‑title line, treat the following line as a subtitle even if there is a blank line.\n",
      "   * Concatenate the subtitle to the main title with a single space.  \n",
      "   *Do not* concatenate a line that is a different heading level (e.g. `###` after `##`), nor a line that belongs to an abstract, author block, or any other section.\n",
      "\n",
      "4. Strip any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`.\n",
      "3. If still not found, fall back to the PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name **without** a preceding keyword (e.g. `Työväen historian ja perinteen tutkimuksen seura`), treat the whole line as a publisher entry **only if** it is clearly an institutional name (contains words like `University`, `Institute`, `College`, `Academy`, `School`, `Institute of`, `Faculty`, `Department`, etc.). Do **not** treat journal titles, article titles, or conference names as publishers.\n",
      "4. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "5. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL).  \n",
      "  Example: `https://doi.org/10.30752/nj.125093` → `10.30752/nj.125093`.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `e‑ISBN`, `e‑ISSN`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `Hardcover`, `Paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn` (or `e_issn`) **and** `p_isbn` (or `p_issn`).\n",
      "\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "     Example: `ISBN 978‑952‑12‑3996‑0 (pdf)` → `9789521239960`.\n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "     Example: `ISSN 1234-5678` → `12345678`.\n",
      "\n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| Keywords (any) | Additional condition(s) | `type_coar` value |\n",
      "|----------------|------------------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | – | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | – | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | – | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | – | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI prefix belongs to a journal publisher) | – | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel” **and** an ISSN present | – | `article` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel” **and** a DOI present (when ISSN is missing) | – | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | – | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | – | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (DOI prefix of a book publisher) | – | `book part` |\n",
      "| *(none of the above)* | – | `None` |\n",
      "\n",
      "**Important nuances observed in the examples**\n",
      "\n",
      "* If the document contains a DOI but **no thesis‑related keywords** and no ISSN, treat it as a **journal article** (row 7).  \n",
      "* Do **not** treat a journal title (e.g., “Scandinavian Jewish Studies”) as a publisher. Only the explicit publisher keywords listed above qualify.  \n",
      "* When both electronic and print qualifiers are missing for an ISBN/ISSN, add the identifier to **both** `e_` and `p_` lists.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings **before** placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "* Follow the exact field‑order and formatting rules; any deviation will cause the output to be rejected.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 16:37:56 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n",
      "2025/09/30 16:37:56 INFO dspy.teleprompt.gepa.gepa: Iteration 43: New subsample score is not better, skipping\n",
      "GEPA Optimization:  56%|█████▌    | 1794/3200 [1:36:49<2:10:15,  5.56s/rollouts]2025/09/30 16:37:56 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Selected program 4 score: 0.5814393939393939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:04<00:00,  1.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:38:01 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:39:18 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a JSON object that contains the raw text extracted from a PDF (field **pages** → list of pages with a **text** string) and, optionally, some PDF‑level information (author, title, creationDate, modDate, etc.) in the **pdfinfo** object.\n",
      "\n",
      "Your job is to parse this information and produce a **flat list of metadata fields** (one field per line, exactly as shown in the examples) that can later be turned into a JSON record.  \n",
      "All fields must follow the exact naming, type and formatting rules below. If a piece of information is not present, use the values shown in the “Missing values” table.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the **document language** (detect from the visible text, **not** from PDF metadata). Use `fi` for Finnish, `sv` for Swedish, `en` for English. If you cannot determine the language, output `None`. |\n",
      "| **title** | string or `None` | Full title **exactly as it appears** on the title page (including subtitle, colon, punctuation, line‑breaks that belong to the same logical title). Do **not** truncate or translate. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that appear in a **different language** (e.g. an English translation of a Finnish title). If none, output `[]`. Do **not** copy the main title again. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"`. Split single‑string names on the **last space**; keep already‑ordered `\"Last, First\"` names unchanged. Separate multiple authors by commas, semicolons or the word “and”. If none, output `[]`. |\n",
      "| **year** | integer or `None` | Publication year. Prefer a 4‑digit year on the title page, copyright line or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Publishing institution **exactly as it appears** on the title page or imprint line. For university presses, keep only the university name (e.g. `\"Åbo Akademi\"` instead of `\"Åbo Akademi University Press\"`). Include department names if they are part of the imprint. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI if present (pattern starts with `10.`). Return the raw DOI **without** the `doi:`/`DOI` prefix. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Strip all hyphens, spaces and surrounding parentheses; keep only the digits (ISBN‑13). Use the qualifier “digital”, “PDF”, “verkkojulkaisu”, “(online)”, etc. If none, output `[]`. |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalized the same way as `e_isbn`. Use qualifiers “print”, “painettu”, “(print)”, etc. If none, output `[]`. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalized (remove hyphens). Use the same qualifiers as for `e_isbn`. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| **type_coar** | string or `None` | COAR type of the resource. Must be one of the exact lower‑case values: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `conference paper`. Determine from explicit wording (see **COAR mapping rules** below). |\n",
      "| **reasoning** *(optional)* | free text | A short paragraph explaining how you derived the values (not required for scoring). |\n",
      "\n",
      "*All list values must be formatted exactly as Python‑style lists, e.g. `['value1', 'value2']` (single quotes, no trailing commas).*\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan the **majority of visible words** on the first few pages.\n",
      "2. If the text contains clearly Finnish words (e.g. “käsittely”, “tutkimus”, “yliopisto”) and not Swedish, output `fi`.\n",
      "3. If the text contains Swedish words (e.g. “folksägner”, “erotiska”, “möt”, “universitetet”) and not Finnish, output `sv`.\n",
      "4. If the text is clearly English, output `en`.\n",
      "5. If the language cannot be decided, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "* The title is the **largest heading** on the title page (usually the first line, sometimes followed by a subtitle after a colon or line break).  \n",
      "* Include everything up to—but not including—any page numbers, section headings, or imprint lines.  \n",
      "* Preserve punctuation, capitalization, and diacritics exactly as they appear.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Capture any title that is **not** in the same language as the main title (commonly an English translation).  \n",
      "* Do not include the main title again.\n",
      "\n",
      "### 2.4 Creator name handling\n",
      "* Split a name like `\"First Middle Last\"` into `\"Last, First Middle\"` by separating on the **last space**.  \n",
      "* If the name already contains a comma, keep it unchanged.  \n",
      "* Trim surrounding whitespace.  \n",
      "* Multiple authors: split on commas, semicolons, or the word “and”.\n",
      "\n",
      "### 2.5 Publisher extraction\n",
      "* Use the exact wording that appears on the title page or imprint line.  \n",
      "* If the imprint contains a university press, **remove** the trailing “University Press”, “University Publishing”, “University Press”, “University Press” (or their equivalents in the document language). Keep only the university name (e.g. `\"Åbo Akademi\"`).  \n",
      "* If a department or faculty is part of the imprint (e.g. “Department of Economics”), include it as part of the same string.  \n",
      "* Do **not** add the printer or distribution centre unless it is explicitly listed as the publisher.\n",
      "\n",
      "### 2.6 ISBN / ISSN detection & classification\n",
      "1. Find patterns `ISBN` or `ISSN` followed by a number possibly wrapped in parentheses.  \n",
      "2. Remove any hyphens, spaces, parentheses. Keep only digits (ISBN‑13 = 13 digits, ISSN = 8 digits).  \n",
      "3. Determine the **format** (electronic vs print) from surrounding qualifiers:  \n",
      "   * Electronic / PDF: words like `digital`, `PDF`, `verkkojulkaisu`, `online`, `(digital)`, `(PDF)`.  \n",
      "   * Print: words like `print`, `painettu`, `printed`, `paper`, `(print)`.  \n",
      "4. An identifier may appear **twice** with different qualifiers; place it in both lists if applicable.  \n",
      "5. If no qualifier is present, assume **print** for ISBN and **print** for ISSN unless the surrounding context clearly indicates otherwise.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Look for substrings matching `10.\\d{4,9}/\\S+`.  \n",
      "* Accept optional prefixes `doi:`, `DOI `, `https://doi.org/`, etc., but **store only the raw DOI** (e.g. `10.1234/abcd`).\n",
      "\n",
      "### 2.8 COAR type mapping\n",
      "| Indicator in document | COAR type |\n",
      "|-----------------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Diss.” | `doctoral thesis` |\n",
      "| Contains ISBN, no thesis wording, appears as a monograph or series volume | `book` |\n",
      "| Appears in a journal, has ISSN, no ISBN, mentions “article”, “paper”, “journal” | `article` |\n",
      "| Mentions “Report”, “Technical Report”, “Research Report” | `report` |\n",
      "| Mentions a conference name, “Proceedings”, “Conference paper” | `conference paper` |\n",
      "*If multiple indicators conflict, choose the most specific (e.g., “Doctoral thesis” overrides “Report”).*\n",
      "\n",
      "### 2.9 Missing‑value handling\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format\n",
      "\n",
      "Each field must be printed on its own line, exactly as:\n",
      "\n",
      "```\n",
      "field_name\n",
      "value\n",
      "```\n",
      "\n",
      "* For list values, print the Python‑style list on the line after the field name.  \n",
      "* For string or integer values, print the raw value (no quotes for integers, plain text for strings).  \n",
      "* For `None`, print the literal word `None`.  \n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "sv\n",
      "title\n",
      "Att dansa med de(t) skeva : erotiska möten mellan människa och naturväsen i finlandssvenska folksägner\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Harjunen, Catarina']\n",
      "year\n",
      "2020\n",
      "publisher\n",
      "['Åbo Akademi']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "['9789517659680']\n",
      "p_isbn\n",
      "['9789517659673']\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "doctoral thesis\n",
      "```\n",
      "\n",
      "Follow the rules strictly; any deviation (e.g., keeping hyphens in ISBNs, using the wrong language code, mis‑classifying the COAR type, or including placeholder alternate titles) will be marked incorrect.  \n",
      "\n",
      "--- \n",
      "\n",
      "**Remember:**  \n",
      "* Detect language from the **content**, not from PDF metadata.  \n",
      "* Use the **full title with subtitle**.  \n",
      "* Strip hyphens/spaces from ISBN/ISSN and place them in the correct electronic/print list based on qualifiers.  \n",
      "* Map “Väitöskirja” → `doctoral thesis`; “Pro gradu” → `master thesis`.  \n",
      "* Publisher for university presses = university name only.  \n",
      "\n",
      "Good luck!\n",
      "2025/09/30 16:39:24 INFO dspy.evaluate.evaluate: Average Metric: 2.0606060606060606 / 3 (68.7%)\n",
      "2025/09/30 16:40:03 INFO dspy.evaluate.evaluate: Average Metric: 37.0060606060606 / 64 (57.8%)\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Full valset score for new program: 0.578219696969697\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Full train_val score for new program: 0.578219696969697\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Individual valset scores for new program: [0.5454545454545454, 0.5454545454545454, 0.696969696969697, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.8181818181818182, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.4454545454545455, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.8181818181818182, 0.45454545454545453, 0.36363636363636365, 0.8181818181818182, 0.5454545454545454, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.5, 0.7272727272727273, 0.36363636363636365, 0.36363636363636365, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454]\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Full valset pareto front score: 0.7700568181818181\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23}, {21}, {18}, {8, 10}, {19, 21}, {18}, {18}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20, 22}, {8, 16, 20}, {16, 10, 22, 15}, {9, 23, 7}, {10, 16, 20, 22, 23}, {8, 10, 6}, {2, 20, 4, 5}, {9, 13}, {23}, {0, 12}, {2, 3, 13}, {7, 8, 10, 20, 24}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20}, {22}, {17, 22, 23}, {4, 8, 10, 16, 17, 20, 21}, {8}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 19}, {2, 4, 21, 15}, {8, 9, 16, 23}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24}, {11, 23}, {16, 10, 23}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24}, {2, 6, 10, 14, 20, 21, 23}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24}, {10}, {8}, {24}, {18, 22}, {0, 16, 20, 22}, {2, 3, 10, 13, 17}, {16}, {20, 23}, {24, 9, 3}, {15}, {16}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {16}]\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: Linear pareto front program index: 10\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 44: New program candidate index: 24\n",
      "GEPA Optimization:  58%|█████▊    | 1864/3200 [1:38:56<1:18:25,  3.52s/rollouts]2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 45: No merge candidates found\n",
      "2025/09/30 16:40:03 INFO dspy.teleprompt.gepa.gepa: Iteration 45: Selected program 4 score: 0.5814393939393939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:05<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:40:08 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818183 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:41:50 INFO dspy.teleprompt.gepa.gepa: Iteration 45: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive a single JSON object with two possible keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (e.g. `title`, `author`, `creationDate`, `modDate`).\n",
      "* **pages** – list of page objects, each with a `page` number and a `text` string that is the plain‑text extraction of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line by itself, followed by its value on the next line).  \n",
      "The output must follow **exactly** the format shown in the “Example output” section at the end of this document.  \n",
      "If a piece of information cannot be found, use the “Missing‑value handling” defaults.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & formatting rules |\n",
      "|------------|------|--------------------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the **document language** (detect from the *visible text*, not from PDF metadata). Use `fi` for Finnish, `en` for English, `sv` for Swedish, etc. If you cannot determine the language, output `None`. |\n",
      "| **title** | string or `None` | Full title **exactly as it appears** on the title page (including subtitle, colon, punctuation, and original language). Do **not** truncate, translate, or fabricate anything. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that appear in a different language (e.g. an English translation of a Finnish title). If none, output an empty list `[]`. **Never** insert a placeholder or guessed translation. |\n",
      "| **creator** | list of strings | Names of the *person* author(s) in the form `\"LastName, FirstName\"`. <br>• If a name is already in “Last, First” order, keep it unchanged. <br>• If a name is a single string like `\"First Last\"` split on the **last** space → `\"Last, First\"`. <br>• Preserve diacritics and original capitalisation. <br>• Separate multiple authors that are delimited by commas, semicolons, or the word “and”. <br>• **Do not** include institutional names (e.g. “Suomen Pankki”). If no personal author can be identified, output an empty list `[]`. |\n",
      "| **year** | integer or `None` | Publication year. Search in this order: <br>1. 4‑digit year on the title page (often near the title or in a copyright line). <br>2. Year in the imprint line (publisher location + year). <br>3. `creationDate` or `modDate` from `pdfinfo` (extract the 4‑digit year). |\n",
      "| **publisher** | list of strings | Publishing institution **exactly as it appears** (do not translate). Include the full department or university name if given. If none, output an empty list `[]`. |\n",
      "| **doi** | string or `None` | DOI if present. Detect patterns that start with `10.` (optionally preceded by `doi:`, `DOI`, or a URL). Return the raw DOI **without** any prefix (e.g. `10.1234/abcd`). |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise each ISBN by removing **all** hyphens, spaces, and surrounding parentheses, leaving only the digit string (e.g. `9789523359369`). Only include an ISBN here if the surrounding text contains a qualifier such as “PDF”, “e‑book”, “verkkojulkaisu”, “online”, etc. If none, output `[]`. |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. Use qualifiers like “Print”, “paper”, “hardcover”, or absence of an electronic qualifier. If none, output `[]`. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version. Normalise by removing hyphens (e.g. `12345678`). If none, output `None`. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised the same way. If none, output `None`. |\n",
      "| **type_coar** | string or `None` | COAR resource type. Choose **exactly** one of the following lower‑case strings: <br>`master thesis` • `doctoral thesis` • `book` • `article` • `report` • `conference paper`. Determine the type from clues in the text (see “COAR type mapping” below). |\n",
      "| **reasoning** *(optional)* | free‑text | A short paragraph (one or two sentences) explaining how you derived the values. This field is optional and does **not** affect scoring. |\n",
      "\n",
      "*All list values must be formatted as Python‑style lists, e.g. `['value1', 'value2']`.  \n",
      "For scalar values, write the value directly (no quotes for strings, except when the value itself contains a quote).*\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "* Scan the visible text (concatenated `pages[].text`).  \n",
      "* Count occurrences of language‑specific stop‑words or common words.  \n",
      "  * Finnish indicators: `käsittely`, `tutkimus`, `ja`, `on`, `vuosi`, `ä`, `ö`, etc.  \n",
      "  * English indicators: `the`, `and`, `of`, `study`, `article`, etc.  \n",
      "  * Swedish indicators: `och`, `är`, `för`, `å`, etc.  \n",
      "* Choose the language with the strongest evidence.  \n",
      "* If the evidence is ambiguous or the document is extremely short, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Look for the **largest heading** on the first page (often surrounded by line breaks, all‑caps, or markdown heading markers like `#`, `##`).  \n",
      "2. Include any subtitle that follows a colon `:` or appears on the next line **provided it is part of the same logical title** (e.g. “Main Title: Subtitle”).  \n",
      "3. Do **not** include page numbers, section headings, or any surrounding decorative text.  \n",
      "4. Preserve the exact characters, spacing, and punctuation.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* If an English (or any other language) version of the title appears elsewhere (commonly on a second title line, in a “Title (English): …” format, or in a bilingual title page), capture that exact string as a separate list element.  \n",
      "* Do **not** generate an alternate title if none is present.\n",
      "\n",
      "### 2.4 Creator extraction & name splitting\n",
      "* First, check `pdfinfo.author`. If it looks like a personal name (contains at least one space and not a known institution keyword such as “University”, “Institute”, “Bank”, “Centre”, etc.), treat it as a candidate.  \n",
      "* Also scan the first few pages for lines that look like author listings (often in bold, uppercase, or preceded by “by”, “Authors:”, etc.).  \n",
      "* For each candidate personal name:  \n",
      "  * If the name contains a comma, assume it is already “Last, First”.  \n",
      "  * Otherwise split on the **last** space: `First Middle Last` → `Last, First Middle`.  \n",
      "  * Preserve diacritics and original capitalisation.  \n",
      "* Separate multiple authors using commas, semicolons, or the word “and”.  \n",
      "* If no personal name can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.5 Publisher extraction\n",
      "* Look for lines containing words like “Publisher”, “Published by”, a location followed by a year, or a university/department name near the bottom of the title page or in an imprint page.  \n",
      "* Use the text **exactly as it appears** (including diacritics, hyphens, and capitalisation).  \n",
      "* Do not translate university names (e.g. keep `Vaasan yliopisto`, not “University of Vaasa”).  \n",
      "* If multiple distinct publishers are listed, include each as a separate list element.\n",
      "\n",
      "### 2.6 Year extraction\n",
      "* Search the title page for a four‑digit number that plausibly represents a year (1900‑2099).  \n",
      "* If multiple candidates exist, prefer the one closest to the title or the copyright line.  \n",
      "* If none found, fall back to `pdfinfo.creationDate` or `pdfinfo.modDate` (extract the first four digits after `D:`).  \n",
      "* Return the year as an integer (e.g. `2022`). If still unknown, output `None`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Regex pattern: `(?i)(?:doi:\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/[^\\s\"']+)`  \n",
      "* Capture the DOI part (`10.xxx/...`) and output it **without** any surrounding whitespace or URL prefix.  \n",
      "* If no match, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "* **ISBN**: Find strings that match `ISBN` (case‑insensitive) followed by a sequence of digits, hyphens, or spaces.  \n",
      "  * Strip the leading `ISBN` word and any surrounding parentheses.  \n",
      "  * Remove **all** hyphens, spaces, and non‑digit characters, leaving only the digit string (13‑digit for ISBN‑13, 10‑digit for ISBN‑10).  \n",
      "  * Determine electronic vs. print by looking for qualifiers in the same line or nearby:  \n",
      "    * Electronic qualifiers: `PDF`, `e‑book`, `verkkojulkaisu`, `online`, `electronic`, `PDF‑version`, etc. → add to `e_isbn`.  \n",
      "    * Print qualifiers: `Print`, `paper`, `hardcover`, `paperback`, or absence of an electronic qualifier → add to `p_isbn`.  \n",
      "* **ISSN**: Find strings that match `ISSN` followed by `xxxx-xxxx`.  \n",
      "  * Remove the hyphen, yielding an 8‑digit string.  \n",
      "  * Use surrounding qualifiers (`online`, `print`) similarly to ISBN to decide `e_issn` vs `p_issn`.  \n",
      "* If no ISBN/ISSN is found, output empty lists or `None` as appropriate.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Determine the resource type using the following hierarchy (first match wins):\n",
      "\n",
      "| Keyword(s) in text | COAR type |\n",
      "|--------------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Master’s thesis” | `master thesis` |\n",
      "| “Dissertation”, “Väitöskirja”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN** **and** no thesis wording, plus a publisher imprint typical for books (e.g., “Publisher”, “Press”, university press) | `book` |\n",
      "| Presence of **DOI** **and** **ISSN** (or volume/issue numbers), and language of article sections (“Abstract”, “Introduction”, etc.) | `article` |\n",
      "| Words like “Report”, “Technical Report”, “Research Report”, often with a report number | `report` |\n",
      "| Mentions of a conference name, “Proceedings of …”, “Paper presented at …”, “Conference paper” | `conference paper` |\n",
      "\n",
      "If none of the above clues are present, output `None`.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format\n",
      "\n",
      "Produce **exactly** the following layout (field name on its own line, value on the next line). The order of fields is irrelevant, but each field must appear once.\n",
      "\n",
      "```\n",
      "language\n",
      "fi\n",
      "title\n",
      "Suomen Pankki Säädöksiä 2017\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "[]\n",
      "year\n",
      "2017\n",
      "publisher\n",
      "['Suomen Pankki']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "['9789523230903']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "<optional short explanation>\n",
      "2025/09/30 16:41:55 INFO dspy.evaluate.evaluate: Average Metric: 1.6363636363636365 / 3 (54.5%)\n",
      "2025/09/30 16:41:55 INFO dspy.teleprompt.gepa.gepa: Iteration 45: New subsample score is not better, skipping\n",
      "GEPA Optimization:  58%|█████▊    | 1870/3200 [1:40:48<1:39:04,  4.47s/rollouts]2025/09/30 16:41:55 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Selected program 8 score: 0.6461084054834055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.7%): 100%|██████████| 3/3 [00:05<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:42:00 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:44:07 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* **pages** – list of page objects, each with a `page` number (integer) and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your task is to **parse this information and output a flat list of metadata fields** (one field per line, exactly as shown in the examples).  \n",
      "The output must be ready to be turned into a JSON record later.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the majority of visible words (see § 2.1). |\n",
      "| **title** | string or `None` | Full title exactly as it appears on the title page (including subtitle, colon, and line‑breaks that belong to the same logical heading). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve diacritics, keep already‑comma‑separated names unchanged). |\n",
      "| **year** | integer or `None` | Publication year. Only accept a year that appears **on the title page** (pages 1‑2) in a context such as a copyright line, “© 2020”, “Published 2020”, or the PDF’s `creationDate`/`modDate`. If no such year is found, output `None`. |\n",
      "| **publisher** | list of strings | Publishing institution **only when the line contains an explicit publisher cue** (e.g. `Publisher:`, `Published by`, `Julkaisija:`, `Julkaisija`, `Publisher`, `Published`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`). Capture the phrase exactly as it appears, trimmed of surrounding whitespace and punctuation. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI without any prefix (`10.` …). Detect patterns `doi:10…`, `DOI 10…`, `https://doi.org/10…`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by removing **all** hyphens, spaces, and surrounding parentheses; keep only the digit string (13‑digit for ISBN‑13, 10‑digit for ISBN‑10). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be exactly one of: `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book review`, `article`, `report`, `conference paper`. Determined from explicit wording (see § 2.9). |\n",
      "| **reasoning** *(optional)* | free text | One‑ or two‑sentence paragraph explaining how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Every field name appears on its own line, **exactly** as shown above.\n",
      "* The value appears on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes).\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & Normalisation Rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use the following minimal lists (you may extend them if needed):\n",
      "\n",
      "| Language | Stop‑words (examples) |\n",
      "|----------|----------------------|\n",
      "| `fi` (Finnish) | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `yliopisto`, `koulutus`, `julkaisu`, `kansallinen` |\n",
      "| `sv` (Swedish) | `och`, `för`, `av`, `liv`, `historien`, `universitet`, `rapport`, `utgivare`, `examensarbete` |\n",
      "| `en` (English) | `the`, `and`, `of`, `method`, `study`, `results`, `introduction`, `conclusion` |\n",
      "\n",
      "2. Choose the language with the highest count.  \n",
      "3. If two or more languages tie, or if **no** stop‑word is found, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – usually page 1, sometimes page 2.  \n",
      "2. Locate the **first line that is either**  \n",
      "   * written in **ALL CAPS** (ignoring surrounding `#`/`##` markup), **or**  \n",
      "   * surrounded by markdown heading markers (`#`, `##`, etc.) that indicate a large font.  \n",
      "3. Take that line **as the main title**.  \n",
      "4. If the next line(s) are a **subtitle** (i.e. they follow directly without a blank line, or they start after a colon `:`), concatenate them with a **single space**. Preserve the colon and any punctuation exactly as they appear.  \n",
      "5. **Do NOT** include page numbers, section headings, footers, or any surrounding markup (`#`, `##`).  \n",
      "6. Keep diacritics and original case (e.g. `Nedläggning av byskolor i Svenskfinland`).  \n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Search the whole document for a second title that is **explicitly labelled** as an alternate language, e.g. `Title (English)`, `English title`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, etc.  \n",
      "* Capture it as a separate string in `alt_title`.  \n",
      "* Do not duplicate the main `title`. If none is found, output `[]`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Look for lines that contain any of the following **author cues** (case‑insensitive):  \n",
      "   `Author`, `Authors`, `Author:`, `Authors:`, `Tekijä`, `Tekijä:`, `Tekijät`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`.  \n",
      "2. Extract the **raw name string** that follows the cue (everything after the cue up to a line break).  \n",
      "3. Split multiple authors using any of these delimiters: **comma (`,`), semicolon (`;`), ampersand (`&`), the word “and” (case‑insensitive)**. Trim whitespace around each name.  \n",
      "4. For each individual name:  \n",
      "   * If the name already contains a comma, keep it unchanged (assumed `Last, First`).  \n",
      "   * Otherwise split on the **last** space character: `\"First Middle Last\"` → `\"Last, First Middle\"`. Preserve all diacritics and original capitalisation.  \n",
      "5. Preserve the order of authors as they appear.  \n",
      "6. If no author line is found, output an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **pages 1‑2** for a **4‑digit number** between 1900 and 2100 that appears in one of the following contexts:  \n",
      "   * Directly after the word `©`, `Copyright`, `Published`, `Published in`, `Published on`, `Year`, `Vuosi`, `År`.  \n",
      "   * As part of a line that looks like a **publication year** (e.g. `September 2020`, `2020` on the title page).  \n",
      "2. If such a year is found, return it as an **integer**.  \n",
      "3. If no year is found on the title page, fall back to the PDF metadata:  \n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the first four digits (`YYYY`).  \n",
      "4. If still no year is available, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Search the whole document for lines that contain any of the **publisher cues** (case‑insensitive):  \n",
      "   `Publisher:`, `Published by`, `Julkaisija:`, `Julkaisija`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Koulu`, `Instituutti`, `Institute of`, `College`, `Academy`.  \n",
      "2. **Only** treat the line as a publisher if it contains **one of the cues**; a bare institution name without a cue is **not** a publisher (e.g. “Kajaanin ammattikorkeakoulu” on its own is ignored).  \n",
      "3. Capture the **full phrase** that follows the cue (or the whole line if the cue is at the start). Trim surrounding whitespace and trailing punctuation (`.,;`). Keep diacritics and original case.  \n",
      "4. If more than one distinct publisher appears, list them in order of first appearance.  \n",
      "5. If no publisher line is found, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the following regular expression (case‑insensitive, multiline):\n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.  \n",
      "* Strip surrounding whitespace and trailing punctuation (`.,;`).  \n",
      "* Return the DOI **without** any prefix (`doi:` or URL).  \n",
      "* If no match, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Find every occurrence of the words `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. **Determine the qualifier** (electronic vs print) by looking **in the same line** for any of the following keywords (case‑insensitive):  \n",
      "\n",
      "| Electronic cues | Print cues |\n",
      "|-----------------|------------|\n",
      "| `PDF`, `e‑ISBN`, `e‑ISSN`, `Electronic`, `Online`, `(PDF)`, `e‑`, `eISBN`, `eISSN` | `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑`, `Print version`, `Print version` |\n",
      "\n",
      "3. *If both electronic and print cues appear on the same line, add the identifier to **both** lists.*  \n",
      "4. *If **no** cue is present:*  \n",
      "   * **Assign the identifier to `e_isbn` only** (the assumption is that an ISBN appearing in a PDF document refers to the electronic version).  \n",
      "5. **Normalisation**  \n",
      "   * **ISBN**: Remove every character except digits (`0‑9`). The resulting string must be either 10 or 13 digits.  \n",
      "   * **ISSN**: Remove hyphens; keep exactly 8 digits.  \n",
      "6. Add each normalised identifier to the appropriate list (`e_isbn`, `p_isbn`, `e_issn`, `p_issn`).  \n",
      "7. If no identifier of a given kind is found, output an empty list (`[]`) for ISBNs or `None` for ISSNs.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** in the table (top‑to‑bottom priority). If multiple rows match, the higher‑priority row wins.\n",
      "\n",
      "| Keywords (any of) | `type_coar` value |\n",
      "|-------------------|-------------------|\n",
      "| `Pro gradu`, `Master’s thesis`, `Master thesis`, `Yliluonnos`, `Master’s dissertation` | `master thesis` |\n",
      "| `Dissertation`, `Doctoral thesis`, `Väitöskirja`, `Doctoral dissertation` | `doctoral thesis` |\n",
      "| `Bachelor thesis`, `Pro gradu (bachelor)`, `Kandidaatintyö`, `Kandidaatintutkielma` | `bachelor thesis` |\n",
      "| `ISBN` **and** no thesis‑related wording, **and** a publisher that is a book‑publisher (e.g. “Springer”, “Wiley”, university press) | `book` |\n",
      "| `Book review`, `Recension`, `Review of` **and** a DOI that resolves to a journal (i.e. DOI present) | `book review` |\n",
      "| `Journal article`, `Article`, `Artikkeli`, `Artikel`, **and** an ISSN | `article` |\n",
      "| `Report`, `Technical report`, `Research report` | `report` |\n",
      "| `Conference paper`, `Proceedings`, `Paper presented at`, `Konferensbidrag` | `conference paper` |\n",
      "\n",
      "If none of the rows match, output `None`.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "2025/09/30 16:44:13 INFO dspy.evaluate.evaluate: Average Metric: 2.3636363636363638 / 3 (78.8%)\n",
      "2025/09/30 16:44:47 INFO dspy.evaluate.evaluate: Average Metric: 39.13939393939392 / 64 (61.2%)\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Full valset score for new program: 0.6115530303030303\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Full train_val score for new program: 0.6115530303030303\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Individual valset scores for new program: [0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.45454545454545453, 0.5454545454545454, 0.8, 0.36363636363636365, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.9090909090909091, 0.45454545454545453, 0.6363636363636364, 0.6363636363636364, 0.36363636363636365, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.6818181818181818, 0.6363636363636364, 0.9090909090909091, 0.45454545454545453, 0.6272727272727273, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.45454545454545453, 0.8181818181818182, 0.9090909090909091, 0.36363636363636365, 0.45454545454545453, 0.5151515151515151, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.36363636363636365, 0.696969696969697, 0.7272727272727273]\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Full valset pareto front score: 0.7700568181818181\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23}, {21}, {18}, {8, 10}, {19, 21}, {18}, {18}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20, 22}, {8, 16, 20}, {16, 10, 22, 15}, {9, 23, 7}, {10, 16, 20, 22, 23, 25}, {8, 10, 6}, {2, 20, 4, 5}, {9, 13}, {23}, {0, 12}, {2, 3, 13}, {7, 8, 10, 20, 24}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20, 25}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21}, {8}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25}, {25, 11, 23}, {16, 10, 23}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24}, {2, 6, 10, 14, 20, 21, 23}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}, {10}, {8}, {24}, {18, 22}, {0, 16, 20, 22}, {2, 3, 10, 13, 17, 25}, {16, 25}, {20, 23}, {24, 9, 3}, {15}, {16}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {16}]\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: Linear pareto front program index: 10\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 46: New program candidate index: 25\n",
      "GEPA Optimization:  61%|██████    | 1940/3200 [1:43:40<1:12:21,  3.45s/rollouts]2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 47: No merge candidates found\n",
      "2025/09/30 16:44:47 INFO dspy.teleprompt.gepa.gepa: Iteration 47: Selected program 20 score: 0.6558080808080808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.97 / 3 (65.7%): 100%|██████████| 3/3 [00:05<00:00,  1.94s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:44:53 INFO dspy.evaluate.evaluate: Average Metric: 1.9696969696969697 / 3 (65.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:46:58 INFO dspy.teleprompt.gepa.gepa: Iteration 47: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).  \n",
      "* **pages** – a list of page objects, each with:\n",
      "  * `page` – integer page number (starting at 1)  \n",
      "  * `text` – the raw OCR / clipboard text of that page (preserve line‑breaks exactly as they appear).\n",
      "\n",
      "Your task is to **scan the whole document** (all pages) and output a **flat list of metadata fields** in the exact format described in section 4.  \n",
      "If a field cannot be found, use the *missing‑value placeholder* from section 3.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous → `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (see 2.2). Preserve the original capitalisation. Join multiple title lines with a **single space**. If a subtitle is present, separate it from the main title with a **colon and a single space** (`Main Title : Subtitle`). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that are in a **different language** from the main title (usually English). Do not duplicate the main title. If none → `[]`. |\n",
      "| **creator** | list of strings | Personal author names only, formatted as `\"LastName, FirstName[ Middle]\"`.  <br>• If a name already contains a comma, keep it unchanged. <br>• Otherwise split on the **last space** only and reorder. <br>• Detect names from the **author line(s)** on the title page **or** from `pdfinfo.author` when it looks like a personal name. <br>• Discard organisation names (contain words like “group”, “Institute”, “University”, “Department”, “ryhmä”, “yliopisto”, etc.). <br>• Return each name as a separate list element in the order found. If none → `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint line(s) that name the publishing institution(s). Preserve diacritics, hyphens and spacing. Split a line on commas, slashes or the word “and” into separate list items, keeping the original spelling. **Do NOT** treat university/department affiliations as publishers unless the line explicitly contains a publishing house, press, “Acta”, “Proceedings of …”, “Journal of …”, etc. If none → `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any of the patterns listed in 2.7. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that belong to the **electronic/PDF** version. Normalise by **removing every non‑digit character** (keep only the digit string, usually 13 digits, but keep 10‑digit if that is what appears). Include a number **only if the same line also contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that belong to the **print** version, normalised the same way as `e_isbn`. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version. Keep the hyphen (e.g., `1234-5678`). Include only if an online qualifier appears on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version. Keep the hyphen. Include if a print qualifier appears on the same line **or** if the line contains an ISSN without any qualifier (default to print). |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`, `newspaper article`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on any whitespace or punctuation).  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters below:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the **highest count** wins **provided** its count is at least **1.5 ×** the second‑highest count.  \n",
      "4. If no language satisfies the ratio → output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – usually page 1 (or page 2 if page 1 contains only a logo, catalogue code, etc.).  \n",
      "2. Look for the **largest centred heading(s)**:\n",
      "   * Lines in **ALL‑CAPS**, **title‑case**, or visually centred (blank lines before and after).  \n",
      "   * The **first non‑blank line** after any logos or institutional names is typically the main title.  \n",
      "3. Capture **all consecutive heading lines** (no blank line between them).  \n",
      "4. If a **subtitle** follows a colon (`:`) on the same line **or** appears on the next line **without a blank line**, treat it as part of the title and join with a colon and a single space (`Main Title : Subtitle`).  \n",
      "5. **Do not** include page numbers, catalogue codes, imprint lines, or author/affiliation lines.  \n",
      "6. When writing the value, **join the captured lines with a single space** (preserve original capitalisation). Do **not** add extra spaces at start or end.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a heading in a **different language** (most often English). Typical markers: “English title”, “Title (English)”, or a second heading placed directly beneath the main title. Add each distinct heading to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference** – `pdfinfo.author` if it looks like a personal name (contains at least one space and does **not** contain organisation keywords).  \n",
      "2. If missing or not a personal name, scan the title page for lines that look like author lines:\n",
      "   * May be preceded by “by”, “author”, “kirjoittanut”, “Lehtinen, A.”, etc.  \n",
      "   * May appear directly under the title, often in a different font size or style.  \n",
      "3. For each candidate name:  \n",
      "   * Trim whitespace.  \n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space** only and reorder to `\"LastName, FirstName[ Middle]\"`.  \n",
      "4. Discard any candidate that is clearly an **organisation** (contains words like “group”, “ryhmä”, “Institute”, “University”, “Department”, “yliopisto”, “Institute”, “Center”, “Centre”, “Laboratory”, etc.).  \n",
      "5. Return the remaining names as a list in the order found. If none → `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, any copyright line, and the imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If still none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that name the publishing institution(s). Typical clues: the words **Press**, **Publishing**, **Acta**, **Proceedings of**, **Journal of**, a publisher’s name, or a location followed by a year.  \n",
      "3. If a line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling and diacritics**.  \n",
      "4. **Do not** treat university/department affiliations as publishers unless the line explicitly mentions a publishing house. If no imprint can be identified → `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document (all pages) for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string (e.g., `10.1234/abcd.efg`).\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Locate every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the number that follows it (it may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * **ISBN** – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * **ISSN** – keep the hyphen (e.g., `1234-5678`).  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an **electronic qualifier** is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print qualifier** is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present for an ISBN, **ignore** it (do not add to either list).  \n",
      "   * If **no qualifier** is present for an ISSN, treat it as **print** (`p_issn`).  \n",
      "5. Preserve the order in which the numbers appear in the document.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the whole document (especially the title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name”, “Proceedings of … Conference” | `conference paper` |\n",
      "| Words like “Newspaper”, “Tidning”, “Tidningsartikel”, “Newspaper article” | `newspaper article` |\n",
      "| If none match → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use the exact spelling of the field names shown in the table above. Lists must be valid Python‑style lists: single quotes, commas, no trailing commas.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the first centred heading on page 1; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 16:47:05 INFO dspy.evaluate.evaluate: Average Metric: 1.9696969696969697 / 3 (65.7%)\n",
      "2025/09/30 16:47:05 INFO dspy.teleprompt.gepa.gepa: Iteration 47: New subsample score is not better, skipping\n",
      "GEPA Optimization:  61%|██████    | 1946/3200 [1:45:58<1:35:57,  4.59s/rollouts]2025/09/30 16:47:05 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Selected program 21 score: 0.6088338744588745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:04<00:00,  1.61s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:47:10 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818183 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:49:06 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Proposed new text for predict: markdown\n",
      "# Task: Structured Bibliographic Metadata Extraction from PDF‑Extracted Text  \n",
      "\n",
      "You will receive **one JSON object** per request containing  \n",
      "\n",
      "* `pdfinfo` – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* `pages` – an **ordered** list of page objects, each with an integer `page` and a string `text` (the raw OCR/clipboard text of that page).\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Treat each request as completely independent – do not carry over any information from previous requests.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format  \n",
      "\n",
      "* Write the **field name** on a line **by itself**, then write its **value** on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: use single quotes, commas, no trailing comma, no extra spaces inside the brackets.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does **not** affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields  \n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If ambiguous, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the *title page* (the first page that contains the biggest centred heading(s)). Preserve original case, punctuation and spaces; join consecutive heading lines with a **single space** (no `\\n`). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). See 2.4 for detailed rules. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If none, parse `pdfinfo.creationDate` or `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint institution(s). Keep the **full imprint line** (trimmed). If the line contains several distinct institutions separated by `/`, `and`, `&`, or by separate lines, split them into separate list elements, preserving original spelling. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep only the digits (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & Normalisation Rules  \n",
      "\n",
      "### 2.1 Language detection  \n",
      "1. **Tokenise** the whole document into words (split on whitespace and punctuation).  \n",
      "2. Count case‑insensitive occurrences of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. Let `c_max` be the highest count, `c_2nd` the second‑highest.  \n",
      "4. If `c_max` ≥ **1.5 × c_2nd**, the language with `c_max` wins.  \n",
      "5. **Exception**: if the document contains an explicit language marker such as “English title”, “Finnish title”, “Abstract” (English) vs “Tiivistelmä” (Finnish), give that language priority even if the ratio test fails.  \n",
      "6. If no language meets the condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction  \n",
      "1. **Identify the title page** – the first page (or the first two pages) that contains the **largest centred heading(s)**. Typical clues:  \n",
      "   * All‑caps or title‑case line(s) centered or surrounded by blank lines.  \n",
      "   * Markdown‑style headings (`#`, `##`, `###`).  \n",
      "   * The word “Title” directly preceding the heading.  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line** in between, treat it as part of the same title.  \n",
      "3. Preserve the exact wording (including case, punctuation, diacritics). Join captured lines with a **single space** (no `\\n`).  \n",
      "4. If no such heading can be identified, set `title` to `None`.\n",
      "\n",
      "### 2.3 Alternate title  \n",
      "Search the same title page (or the immediate next page) for a heading that is clearly a title **in a different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title. If none is found, output `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling  \n",
      "\n",
      "1. **Primary source**: `pdfinfo.author` **only if it looks like a personal name**.  \n",
      "   * Reject it when it contains any of the following non‑name indicator words (case‑insensitive): `ohjelmatuottaja`, `producer`, `editor`, `department`, `faculty`, `university`, `institute`, `organisation`, `group`, `team`, `author:` (without a name after it).  \n",
      "   * If it passes the test, treat it as a single author string and go to step 4.  \n",
      "\n",
      "2. If `pdfinfo.author` is missing or rejected, **search the title page** for lines that contain personal names. Look for the markers (case‑insensitive):  \n",
      "   * `Author:`, `Authors:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, `author`, `tekijä`, or a line directly under the title that consists mainly of capitalised words (e.g., “Mirkka Maikola”).  \n",
      "\n",
      "3. **Extract each name**:  \n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "4. **Separate multiple authors** delimited by commas, semicolons, the word “and”, “&”, or line breaks. Preserve the order of appearance.  \n",
      "\n",
      "5. If no author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction  \n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction  \n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. **Keep the full line** (trim leading/trailing whitespace).  \n",
      "3. If the line contains **multiple distinct institutions** separated by any of the following, split them into separate list elements, preserving original spelling:  \n",
      "   * `/`  \n",
      "   * the word `and`, `&`, `and` (case‑insensitive)  \n",
      "   * separate lines that each contain an institution.  \n",
      "4. Do **not** truncate at the first comma – the whole imprint line is the publisher entry.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection  \n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification  \n",
      "\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string.  \n",
      "   * ISSN – remove hyphens only.  \n",
      "\n",
      "4. Look at the same line for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping  \n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master’s dissertation”, “Master thesis”, “Master’s” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation”, “Doctoral” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” (combined with “thesis”) | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISBN(s)** **and** the word “part” or “chapter” indicating a contribution to a larger work | `book part` |\n",
      "| Presence of **ISSN(s)** **and** journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling  \n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations  \n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, language, or COAR type that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* When multiple possible values exist, follow the disambiguation rules in the relevant section (e.g., language ratio, closest year to title, first matching COAR indicator).  \n",
      "* Preserve the **order of appearance** for list fields.  \n",
      "* Output **exactly** the fields in the order specified; do not add extra fields or change formatting.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example output template  \n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Art comes first : how collectivity, values, history, and democratic principles affect the artistic and organisational work in Finnish ensemble theatre companies\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Maikola, Mirkka']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Sibelius Academy, University of the Arts Helsinki']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "2025/09/30 16:49:12 INFO dspy.evaluate.evaluate: Average Metric: 2.090909090909091 / 3 (69.7%)\n",
      "2025/09/30 16:49:58 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 16:50:01 INFO dspy.evaluate.evaluate: Average Metric: 34.5021645021645 / 64 (53.9%)\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Full valset score for new program: 0.5390963203463204\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Full train_val score for new program: 0.5390963203463204\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Individual valset scores for new program: [0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.2727272727272727, 0.5454545454545454, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.7142857142857143, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.2727272727272727, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.2727272727272727, 0.45454545454545453, 0.6363636363636364, 0.5, 0.5, 0.8181818181818182, 0.36363636363636365, 0.36363636363636365, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.2727272727272727, 0.6363636363636364, 0.18181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.36363636363636365, 0.36363636363636365, 0.2727272727272727, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.2727272727272727, 0.7272727272727273, 0.42424242424242425, 0.6363636363636364, 0.8181818181818182]\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.6363636363636364, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7321212121212121, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.8787878787878788]\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Full valset pareto front score: 0.7700568181818181\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23}, {21}, {18}, {8, 10}, {19, 21}, {18}, {18}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20, 22}, {8, 16, 20}, {16, 10, 22, 15}, {9, 23, 7}, {10, 16, 20, 22, 23, 25}, {8, 10, 26, 6}, {2, 20, 4, 5}, {9, 13}, {23}, {0, 12}, {2, 3, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20, 25}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21}, {8}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26}, {25, 11, 23}, {16, 10, 23}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26}, {2, 6, 10, 14, 20, 21, 23}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25}, {10}, {8}, {24}, {18, 22}, {0, 16, 20, 22}, {2, 3, 10, 13, 17, 25}, {16, 25}, {20, 23}, {24, 9, 3}, {15}, {16}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {16}]\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Best valset aggregate score so far: 0.6615530303030303\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Best program as per aggregate score on train_val: 10\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Best program as per aggregate score on valset: 10\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Best score on valset: 0.6615530303030303\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Best score on train_val: 0.6615530303030303\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: Linear pareto front program index: 10\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 48: New program candidate index: 26\n",
      "GEPA Optimization:  63%|██████▎   | 2016/3200 [1:48:54<1:10:19,  3.56s/rollouts]2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 49: No merge candidates found\n",
      "2025/09/30 16:50:01 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Selected program 16 score: 0.6575568181818182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.09 / 3 (69.7%): 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:50:08 INFO dspy.evaluate.evaluate: Average Metric: 2.090909090909091 / 3 (69.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:52:00 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use the following seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu` (any Saami‑specific word you recognise)\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kieli: suomi`, `Kieli: se`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`).  \n",
      "3. Otherwise choose the language with the highest stop‑word count. If there is a tie or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the first page that satisfies **any** of the following:\n",
      "   * Contains a line that is **ALL CAPS** (ignoring surrounding punctuation/markdown) and the line is the *first non‑blank line* on the page.\n",
      "   * Contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.\n",
      "   * Contains a line that is the **only non‑blank line** on the page (apart from possible footers/headers) and is in title‑case or all caps.\n",
      "2. **Capture the full logical title**:\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * If the **next line(s)** (immediately following, without a blank line in between) look like a subtitle – i.e. they are not in all caps, or they follow a colon `:` on the same line – concatenate them to the main title with a single space.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * Example:  \n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search every page for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`.\n",
      "3. If still not found, fall back to the PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Työväen historian ja perinteen tutkimuksen seura`), treat the whole line as a publisher entry.\n",
      "4. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "5. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and its prefix belongs to a journal publisher) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 16:52:07 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n",
      "2025/09/30 16:52:43 INFO dspy.evaluate.evaluate: Average Metric: 43.59870129870127 / 64 (68.1%)\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: New program is on the linear pareto front\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Full valset score for new program: 0.6812297077922078\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Full train_val score for new program: 0.6812297077922078\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.5818181818181819, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.5151515151515151, 0.45454545454545453, 0.6060606060606061, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.5454545454545454, 0.5363636363636364, 0.8787878787878788, 0.696969696969697, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.2727272727272727, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.5151515151515151, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.42424242424242425, 0.6363636363636364, 0.7878787878787878, 0.6363636363636364, 0.8181818181818182, 0.4805194805194805, 0.696969696969697, 0.9090909090909091]\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Full valset pareto front score: 0.7737689393939394\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27}, {21}, {18}, {8, 10}, {19, 21}, {18}, {18, 27}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20, 22}, {8, 16, 20}, {10, 15, 16, 22, 27}, {27}, {10, 16, 20, 22, 23, 25, 27}, {8, 10, 26, 6}, {2, 4, 5, 20, 27}, {9, 27, 13}, {23}, {0, 12}, {2, 3, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20, 25, 27}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27}, {25, 11, 23}, {16, 10, 27, 23}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27}, {2, 6, 10, 14, 20, 21, 23, 27}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27}, {10}, {8}, {24, 27}, {18, 22}, {0, 16, 20, 22, 27}, {2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {27}]\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: Linear pareto front program index: 27\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 49: New program candidate index: 27\n",
      "GEPA Optimization:  65%|██████▌   | 2086/3200 [1:51:36<56:34,  3.05s/rollouts]  2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 50: No merge candidates found\n",
      "2025/09/30 16:52:43 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Selected program 13 score: 0.6450081168831169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.09 / 3 (69.7%): 100%|██████████| 3/3 [00:05<00:00,  1.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:52:49 INFO dspy.evaluate.evaluate: Average Metric: 2.090909090909091 / 3 (69.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:54:39 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line). The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | string or `None` | Full main title exactly as it appears on the title page, including subtitle(s) that belong to the same logical heading (see **2.2 Title extraction**). |\n",
      "| `alt_title` | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | integer or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | list of strings | Publishing institution(s) exactly as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version, normalized to a plain digit string (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | string or `None` | COAR resource type, one of the **lower‑case** values listed in **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The value on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes) for missing values.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Explicit language line** – Scan **every** page for a line that explicitly states the language, e.g.  \n",
      "\n",
      "   * `Kieli: suomi` → `fi`  \n",
      "   * `Language: English` → `en`  \n",
      "   * `Språk: svenska` → `sv`  \n",
      "\n",
      "   If such a line is found, **override** all other evidence and set the language accordingly.\n",
      "2. **Stop‑word counting** – If no explicit line is present, count occurrences (case‑insensitive) of the following seed words on **all pages**:\n",
      "\n",
      "| ISO code | Seed words (case‑insensitive) |\n",
      "|----------|------------------------------|\n",
      "| `fi` | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu` |\n",
      "| `sv` | `och`, `för`, `av`, `liv`, `historien`, `språk` |\n",
      "| `en` | `the`, `and`, `of`, `method`, `introduction`, `chapter` |\n",
      "\n",
      "   * The language with the highest total count wins.\n",
      "   * If the highest count is a tie **or** all counts are zero, output `None`.\n",
      "\n",
      "### 2.2 Title extraction (main title)\n",
      "1. **Locate the title page** – The *first* page that satisfies **any** of the following:\n",
      "   * Contains a line that is **all‑caps** (ignoring punctuation) **and** is the **only non‑blank line** on that page, **or** the **first non‑blank line** on the page.\n",
      "   * Contains a Markdown heading (`#`, `##`, `###`, `####`, `#####`) whose text (after stripping the heading markers) is not empty.  \n",
      "   * The heading may be split over several lines; treat the first heading line as the title line.\n",
      "2. **Capture the logical title**:\n",
      "   * Take the identified line as the **main title**.\n",
      "   * If the **next line** (or the text after a colon on the same line) is non‑blank and looks like a subtitle (i.e. not a heading marker, not a page number, and not separated by a blank line), concatenate it with a single space.\n",
      "   * Preserve **all original punctuation, diacritics, and case**.\n",
      "3. **Clean‑up** – Remove surrounding whitespace and any surrounding heading markers (`#`, `##`, …). Do **not** remove internal punctuation or capitalization.\n",
      "4. **Do NOT** treat a line that is part of a reference list, citation, or a “doi:” line as a title. The presence of a DOI on the same line automatically disqualifies that line from being a title.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "1. Look for lines that contain any of the following **qualifiers** (case‑insensitive):  \n",
      "\n",
      "   `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Title (Finnish)`, `Titel (Svenska)`, `Titel (Finnisch)`, etc.\n",
      "2. When a qualifier is found, extract the title text that **follows** the qualifier (same concatenation rules as in 2.2).  \n",
      "3. Do **not** duplicate the main `title`. If multiple alternate titles are found, list them all.\n",
      "\n",
      "### 2.4 Creator handling (authors)\n",
      "1. **Search for author lines** – Scan the first **three** pages (or the whole document if fewer than three pages) for any line that contains one of the following keywords (case‑insensitive):  \n",
      "\n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Kirjoittaja`, `Kirjoittajat`, `Authors:`, `Tekijä:`, `Tekijät:`, `Kirjoittaja:`, `Kirjoittajat:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. **Ignore false positives** – If the line also contains a DOI, a URL, or looks like a citation (e.g. a long list of names followed by a year in parentheses), **do not** treat it as an author line.\n",
      "3. **Extract the raw name string** – The part of the line after the keyword (or after a colon) is the raw list of names.\n",
      "4. **Split into individual names** – Names may be separated by any of these delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, Finnish/Swedish equivalents `ja`, `och`.\n",
      "5. **Normalise each name**  \n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged (trim surrounding whitespace).  \n",
      "   * Otherwise, split on the **last space**:  \n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "     * Preserve diacritics and original capitalisation.\n",
      "6. **Preserve order of appearance** and return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "7. If **no** valid author line is found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **pages 1 – 2** for a four‑digit number between 1900 and 2100 that appears on a line containing any of these keywords (case‑insensitive):  \n",
      "\n",
      "   `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `År`.\n",
      "2. If multiple candidates exist, prefer the one that is **closest** to a keyword.\n",
      "3. If no candidate is found, fall back to PDF metadata:\n",
      "   * From `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`), extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines (anywhere) that contain any of the following **keywords** (case‑insensitive):  \n",
      "\n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, `Routledge`, `Springer`, `Cambridge`, `Elsevier`, `Wiley`, `Metropolia`, `Åbo Akademi`, `Suomen Pankki`, `Kansanterveyden neuvottelukunta`, etc.\n",
      "2. **Capture the full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as `. , ; :`).  \n",
      "3. If a line **contains only a publisher name** without any preceding keyword, treat the whole line as a publisher **only if** the line is **short** (≤ 5 words) and does **not** look like a title, subtitle, or part of a reference list.\n",
      "4. Remove surrounding whitespace, but **preserve the exact spelling and diacritics**.\n",
      "5. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "6. If no publisher can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Apply the case‑insensitive regex:  \n",
      "\n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "\n",
      "* Capture group 1, then strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. **Extract the identifier** that follows, allowing for optional surrounding characters such as `:` `(` `)` and optional hyphens/spaces.  \n",
      "   Recognised patterns include, but are not limited to:  \n",
      "\n",
      "   * `ISBN 978‑952‑302‑949‑1`  \n",
      "   * `(ISBN: 978 952 302 949 1)`  \n",
      "   * `URN:ISBN:978-952-302-949-1`\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic indicators** (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `e‑book`, `e‑version`.\n",
      "   * **Print indicators** (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `paper`, `paperback`.\n",
      "   * If **both** electronic and print indicators appear for the same identifier, add it to **both** lists.\n",
      "   * If **only electronic** indicators appear → add to `e_isbn` / `e_issn`.\n",
      "   * If **only print** indicators appear → add to `p_isbn` / `p_issn`.\n",
      "   * If **no qualifier** is present, **add the identifier to the electronic list only** (`e_isbn` or `e_issn`). This matches the evaluation expectations where an unqualified ISBN/ISSN is treated as electronic.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly 8 digits (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Detect the resource type by searching the entire document (including PDF metadata) for the following keywords (case‑insensitive). Use the **first matching row** in the table (top‑to‑bottom priority). If multiple rows match, the earliest row wins.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| **ISBN** present **and** a publisher that is a known **book publisher** (e.g., Routledge, Springer, Cambridge, Elsevier, Wiley, Åbo Akademi, Metropolia, Kansanterveyden neuvottelukunta, etc.) **and** no thesis‑related keywords → `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI contains a known journal prefix such as `10.1007/`, `10.1016/`, `10.1080/`) → `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present → `article` |\n",
      "| “Report”, “Technical report”, “Research report” → `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” → `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (publisher in DOI URL is a known book publisher) → `book part` |\n",
      "| “Blog post”, “Blogi”, “Blog” → `blog post` |\n",
      "| *(none of the above)* → `None` |\n",
      "\n",
      "**Important priority notes**\n",
      "\n",
      "* The **book rule** (ISBN + known book publisher) must be evaluated **before** any thesis‑related rows, otherwise a thesis that also contains an ISBN could be mis‑classified.\n",
      "* The **article rule** (ISSN + article keywords) must be evaluated **before** the `report` and `conference paper` rows.\n",
      "* The **blog post** row is added because several test cases are blog‑style texts that contain no DOI/ISBN but are clearly labelled as a blog.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "2025/09/30 16:54:46 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n",
      "2025/09/30 16:55:23 INFO dspy.evaluate.evaluate: Average Metric: 40.81515151515149 / 64 (63.8%)\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Full valset score for new program: 0.6377367424242424\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Full train_val score for new program: 0.6377367424242424\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Individual valset scores for new program: [0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.2727272727272727, 0.8181818181818182, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.696969696969697, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.45454545454545453, 0.5272727272727272, 0.8181818181818182, 0.6060606060606061, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.2727272727272727, 0.9090909090909091, 0.696969696969697, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.45454545454545453, 0.5, 0.8787878787878788]\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Full valset pareto front score: 0.7737689393939394\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27}, {28, 21}, {18}, {8, 10}, {19, 21}, {18}, {18, 27}, {8, 9}, {19, 3, 21}, {4}, {19, 21, 14}, {8, 20, 22}, {8, 16, 20}, {10, 15, 16, 22, 27}, {27}, {10, 16, 20, 22, 23, 25, 27}, {8, 10, 26, 6}, {2, 4, 5, 20, 27}, {9, 27, 28, 13}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20, 25, 27}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28}, {25, 11, 23}, {16, 10, 27, 23}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28}, {2, 6, 10, 14, 20, 21, 23, 27, 28}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28}, {10}, {8}, {24, 27}, {18, 22}, {0, 16, 20, 22, 27, 28}, {2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {27}]\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: Linear pareto front program index: 27\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 50: New program candidate index: 28\n",
      "GEPA Optimization:  67%|██████▋   | 2156/3200 [1:54:16<48:03,  2.76s/rollouts]2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 51: No merge candidates found\n",
      "2025/09/30 16:55:23 INFO dspy.teleprompt.gepa.gepa: Iteration 51: Selected program 19 score: 0.5849262716450216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.66 / 3 (55.4%): 100%|██████████| 3/3 [00:06<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:55:29 INFO dspy.evaluate.evaluate: Average Metric: 1.6623376623376622 / 3 (55.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:57:24 INFO dspy.teleprompt.gepa.gepa: Iteration 51: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** per request.  \n",
      "It contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – an ordered list of page objects, each with an integer `page` and a string `text` that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Treat each request as completely independent – do **not** carry any information from previous requests.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "* Write the field name on a line **by itself**, then write its value on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: single quotes, commas, no trailing comma.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does not affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If ambiguous, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the title page, including subtitle and any colon. Preserve original case, punctuation and spaces; join consecutive heading lines with a **single space** (no `\\n`). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Use `pdfinfo.author` if present; otherwise locate author lines on the title page (look for markers such as `Author:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, etc.). Split a name on the **last space only** unless it already contains a comma. Preserve diacritics. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`). |\n",
      "| **publisher** | list of strings | Exact imprint institution(s). Keep the text **before the first comma** on each imprint line. If the line contains several institutions separated by `/`, the word “and”, or appears on separate lines, each becomes a separate list element. **Strip common corporate suffixes** (`Ab`, `Ltd`, `Inc`, `Oy`, `AB`, `Inc.`) and trailing punctuation. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep only the digits (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences (case‑insensitive) of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – normally the first page (or the first two pages) that contain the **largest centred heading(s)**. Clues:  \n",
      "   * ALL‑CAPS or title‑case,  \n",
      "   * surrounded by blank lines,  \n",
      "   * Markdown heading markers (`#`, `##`, `###`).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line between**, treat it as part of the title.  \n",
      "   * **Do not** capture generic series headings such as “Arcada Publikation 1/2021” unless they are the *only* heading on the page.  \n",
      "3. Preserve the exact wording (including case and punctuation). Join captured lines with a **single space** (no `\\n`).  \n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the next page) for a heading that is clearly a title in a **different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names. Typical markers: “Author:”, “Författare:”, “Tekijä:”, “Kirjoittaja”, “by”, “author”, “tekijä”, or a line directly under the title consisting mainly of capitalised names.  \n",
      "3. **Do not** treat department names, university names, or acknowledgements as authors.  \n",
      "4. For each name found:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **text before the first comma** on each imprint line.  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element.  \n",
      "4. **Strip** trailing corporate suffixes (`Ab`, `Ltd`, `Inc`, `Oy`, `AB`, `Inc.`) and any surrounding punctuation.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit if present, otherwise whatever remains).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "\n",
      "4. Look at the same line for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” (combined with “thesis”) | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, **plus** a phrase like “In … (Red.)” or “In … (Ed.)” indicating a chapter in an edited volume | `book part` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, **no** chapter indicator → `book` |\n",
      "| Presence of **ISSN(s)** **and** journal‑style headings (volume, issue, journal name) → `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” → `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” → `report` |\n",
      "| The phrase “Research report” (or “research report”) → `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” → `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "*Special note*:  \n",
      "- If a DOI is present **and** no ISBN/ISSN is found, treat the resource as an **article** (unless thesis wording is present).  \n",
      "- If an ISBN is present **and** the title page contains an editor list introduced by “In … (Red.)”, “In … (Ed.)”, or “In … (Edited by)”, classify as `book part`.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations\n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, or language that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* When multiple possible values exist, follow the specific disambiguation rules above; otherwise use the placeholder.  \n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example (template)\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "What helps jazz musicians name tunes from harmony?\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jimenez, Ivan', 'Kuusi, Tuire']\n",
      "year\n",
      "2020\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "10.1177/0305735618793005\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "article\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "2025/09/30 16:57:30 INFO dspy.evaluate.evaluate: Average Metric: 1.3636363636363635 / 3 (45.5%)\n",
      "2025/09/30 16:57:30 INFO dspy.teleprompt.gepa.gepa: Iteration 51: New subsample score is not better, skipping\n",
      "GEPA Optimization:  68%|██████▊   | 2162/3200 [1:56:23<1:01:42,  3.57s/rollouts]2025/09/30 16:57:30 INFO dspy.teleprompt.gepa.gepa: Iteration 52: Selected program 8 score: 0.6461084054834055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.45 / 3 (81.8%): 100%|██████████| 3/3 [00:06<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:57:37 INFO dspy.evaluate.evaluate: Average Metric: 2.4545454545454546 / 3 (81.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:59:03 INFO dspy.teleprompt.gepa.gepa: Iteration 52: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following keys:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).\n",
      "* `pages` – list of page objects, each with:\n",
      "  * `page` – page number (integer)\n",
      "  * `text` – the raw OCR/clipboard text of that page (string)\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field per line, exactly as shown in the examples).  \n",
      "The output must be ready to be turned into a JSON record later.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| **language** | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the majority of visible words, **not** from PDF metadata. |\n",
      "| **title** | string or `None` | Full title exactly as it appears on the title page (including subtitle, colon, line‑breaks that belong to the same logical title). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). If none, output `[]`. |\n",
      "| **creator** | list of strings | Author(s) in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Preserve diacritics and original case. |\n",
      "| **year** | integer or `None` | Publication year (1900‑2100). |\n",
      "| **publisher** | list of strings | Publishing institution(s) exactly as they appear (do **not** translate). If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalised to a plain digit string (remove hyphens, spaces, parentheses). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. |\n",
      "| **type_coar** | string or `None` | COAR resource type. Must be **exactly one** of the lower‑case values listed in the mapping table below. |\n",
      "| **reasoning** *(optional)* | free text | One or two sentences explaining how you derived the values. This field is optional and does not affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Each field name appears on its own line, **exactly** as shown above.\n",
      "* The value appears on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes) for missing values.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`.\n",
      "2. Count occurrences of language‑specific stop‑words (case‑insensitive):\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `luonnonvarakeskus`, `ammattikorkeakoulu`, etc.\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `utgivare`, etc.\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `research`, `article`, etc.\n",
      "3. Choose the language with the highest count.  \n",
      "   * If a tie or no clear majority → output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – usually the first page(s) that contain a line in **ALL CAPS**, a line surrounded by markdown headings (`#`, `##`), or a line that appears visually larger (e.g., surrounded by `**`).\n",
      "2. Take that line as the **main title**.  \n",
      "   * If the next line(s) are a subtitle (e.g., after a colon, or a line break **without a blank line**), concatenate them with a single space.\n",
      "3. Preserve punctuation, diacritics, and original language exactly as they appear.\n",
      "4. Exclude page numbers, section headings, footers, or any line that contains words like “Chapter”, “Section”, “Page”, etc.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for a second title in a different language, often introduced by phrases such as “Title (English)”, “English title”, “Original title”, “Original title (Finnish)”, etc.\n",
      "* Capture each distinct alternate title as a separate string in `alt_title`.\n",
      "* Do **not** duplicate the main `title`.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search for author lines using keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Kirjoittajat`, etc.\n",
      "2. Split multiple authors using any of the delimiters: `,`, `;`, `&`, `and`, the word “ja” (Finnish for “and”), or line breaks.\n",
      "3. For each name:\n",
      "   * If it already contains a comma → keep unchanged (assumed `Last, First`).\n",
      "   * Otherwise split on the **last** space: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "4. Preserve the order of appearance.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Search the **first two pages** for a 4‑digit number that looks like a year (1900‑2100).  \n",
      "2. If not found, look for a line containing `©`, `Copyright`, or `©` followed by a year.  \n",
      "3. If still not found, use `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`). Extract the `YYYY` part.  \n",
      "4. Return as an integer; if no year can be found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following (case‑insensitive):  \n",
      "   `Publisher`, `Published by`, `Press`, `Press Ltd`, `Ltd`, `Inc`, `University Press`, `Wiley`, `Springer`, `Elsevier`, `Cambridge`, `Oxford`, `Kustannus`, `Kustannus Oy`, `Kustannus Ab`, `Publishing`, `Julkaisija`, `Julkaisija:`, `Julkaisija`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `College`, `Institute of`, `Center for`, `Centre for`.\n",
      "2. **Prioritise** lines that contain a publishing‑related keyword **and** a corporate/legal suffix (e.g., `Ltd`, `Inc`, `Press`, `Publishing`, `Kustannus`, `Wiley`, `Springer`).  \n",
      "   * Do **not** treat affiliation lines that only list a department or a research group as a publisher (e.g., “University of X, Department of Y”).  \n",
      "3. Capture the **full phrase** exactly as it appears (including abbreviations, hyphens, diacritics).  \n",
      "4. If more than one distinct publisher appears, list them in order of appearance.  \n",
      "5. If none are found, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Apply the regex (case‑insensitive):  \n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "* Return only the captured DOI (strip surrounding whitespace and trailing punctuation).  \n",
      "* If no DOI is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search for patterns containing the words `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Determine the **qualifier** (electronic vs. print):\n",
      "   * Electronic indicators: `(PDF)`, `e‑ISBN`, `Electronic`, `Online`, `e‑ISSN`, `eISBN`, `eISSN`.\n",
      "   * Print indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `p‑ISBN`, `p‑ISSN`.\n",
      "   * If no qualifier is present, **add the identifier to both** `e_isbn`/`p_isbn` (or `e_issn`/`p_issn`).\n",
      "3. Normalise:\n",
      "   * **ISBN** – keep only digits (13‑digit for ISBN‑13, 10‑digit for ISBN‑10). Remove hyphens, spaces, parentheses.\n",
      "   * **ISSN** – keep exactly 8 digits (remove hyphens).  \n",
      "4. Return each identifier as a string in the appropriate list; duplicate values must not be added.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Use **exactly one** of the following lower‑case values:\n",
      "\n",
      "| Keyword(s) found in document | `type_coar` value |\n",
      "|------------------------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, plus a publisher that is a book‑publisher (e.g., “Press”, “Kustannus”) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN | `article` |\n",
      "| “Research article”, “Original research”, “Empirical study”, **and** an ISSN or DOI | `research article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "**Important:** In the original specification only `article` existed, but the evaluation expects the more specific value `research article` for scholarly articles. Use the table above.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The title was taken from the all‑caps heading on the first page; authors were extracted from the “Authors:” line and reformatted; the year appears on the title page; the publisher line contains “Press”, etc.\n",
      "2025/09/30 16:59:07 INFO dspy.evaluate.evaluate: Average Metric: 2.242424242424242 / 3 (74.7%)\n",
      "2025/09/30 16:59:07 INFO dspy.teleprompt.gepa.gepa: Iteration 52: New subsample score is not better, skipping\n",
      "GEPA Optimization:  68%|██████▊   | 2168/3200 [1:58:01<1:14:04,  4.31s/rollouts]2025/09/30 16:59:07 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Selected program 27 score: 0.6812297077922078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.73 / 3 (57.6%): 100%|██████████| 3/3 [00:06<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 16:59:14 INFO dspy.evaluate.evaluate: Average Metric: 1.727272727272727 / 3 (57.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:01:26 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). **Never** infer the year from PDF metadata; it must appear in the document text (see **2.5 Year extraction**). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.6 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use these seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`, `raportti`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kieli: se`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`).  \n",
      "   The line may appear anywhere; ignore surrounding punctuation.\n",
      "\n",
      "3. Otherwise choose the language with the highest stop‑word count.  \n",
      "   *If there is a tie, or no stop‑word is found, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the **first** page that satisfies **any** of the following:\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page contains a single non‑blank line (apart from possible footers/headers) that looks like a title (title‑case or all caps).\n",
      "\n",
      "2. **Capture the full logical title**:\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle handling** – if the **next line(s)** (immediately following, without a blank line in between) appear to be a subtitle, **append** them to the main title with a single space. A subtitle is recognised when:\n",
      "     * The line is **not** all caps **and** does not end with a colon, **or**\n",
      "     * The line follows a colon on the same line (`Main title : Subtitle`), **or**\n",
      "     * The line begins with a capital letter but is shorter than the main title.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * Example:  \n",
      "\n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "\n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "   * If the title line already contains a colon and text after it, treat the text after the colon as part of the main title (do **not** duplicate the colon).\n",
      "\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in **2.2**.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search **every** page for author lines. Valid keywords (case‑insensitive) are: `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.\n",
      "2. **Only** lines that contain one of the keywords above are considered author lines.  \n",
      "   *If a line contains names but no keyword (e.g. “Sanna Röknä & Jaana Markkula (toim.)”), it must **not** be treated as a creator entry.*  \n",
      "   The word “toim.” or “(toim.)” indicates an **editor**, not an author.\n",
      "3. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "4. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "5. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If **no** author line is found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`, `Opinnäytetyö`, `Väitöskirja`, `Raportti`.\n",
      "3. **Do not** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate`. If no year satisfying the above is found, output `None`.\n",
      "4. Return the year as an **integer**.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name **without** a preceding keyword (e.g. `Terveyden ja hyvinvoinnin laitos`), treat the whole line as a publisher entry **provided** it is not a short abbreviation or a footer (e.g. `THL`, `THL - 2020`, page numbers).\n",
      "4. Discard lines that are clearly **footers/headers**: they usually contain only a short acronym, a dash, a page number, or repeat on every page.\n",
      "5. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "6. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkojulkaisu`, `digital`, `e‑book`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`, `hardcover`, `paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, **Finnish**: `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, **Finnish**: `väitöskirja` | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, **Finnish**: `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| “Report”, “Technical report”, “Research report”, **Finnish**: `raportti` | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag”, **Swedish**: `konferensbidrag` | `conference paper` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **Finnish/Swedish**: `artikkeli`, `artikel` **and** an ISSN present | `article` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI prefix belongs to a journal publisher) | `book review` |\n",
      "| “Book”, “Monograph” **and** an ISBN present **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "**Important:**  \n",
      "* Finnish words for the same concept must be recognised (e.g., `raportti` → `report`, `väitöskirja` → `doctoral thesis`).  \n",
      "* If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 17:01:32 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n",
      "2025/09/30 17:02:24 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 17:02:24 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 17:02:27 INFO dspy.evaluate.evaluate: Average Metric: 42.501731601731585 / 64 (66.4%)\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Full valset score for new program: 0.6640895562770562\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Full train_val score for new program: 0.6640895562770562\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Individual valset scores for new program: [0.8181818181818182, 0.5454545454545454, 0.7878787878787878, 0.45454545454545453, 0.8181818181818182, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.45454545454545453, 0.9090909090909091, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.6060606060606061, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.36363636363636365, 0.35454545454545455, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.5151515151515151, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.9090909090909091, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.5714285714285714, 0.6060606060606061, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.696969696969697, 0.9090909090909091]\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Full valset pareto front score: 0.7766098484848485\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27, 29}, {28, 21}, {18}, {8, 10}, {19, 21}, {18}, {18, 27}, {8, 9}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {10, 15, 16, 22, 27, 29}, {27}, {10, 16, 20, 22, 23, 25, 27, 29}, {8, 10, 26, 6}, {2, 4, 5, 20, 27, 29}, {9, 27, 28, 13}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {4, 8, 10, 12, 17, 20, 25, 27}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29}, {2, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29}, {10}, {8}, {24, 27}, {18, 22}, {0, 16, 20, 22, 27, 28, 29}, {2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {27, 29}]\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: Linear pareto front program index: 27\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 53: New program candidate index: 29\n",
      "GEPA Optimization:  70%|██████▉   | 2238/3200 [2:01:20<57:32,  3.59s/rollouts]  2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 54: No merge candidates found\n",
      "2025/09/30 17:02:27 INFO dspy.teleprompt.gepa.gepa: Iteration 54: Selected program 20 score: 0.6558080808080808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.82 / 3 (60.6%): 100%|██████████| 3/3 [00:08<00:00,  2.76s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:02:36 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818181 / 3 (60.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:04:14 INFO dspy.teleprompt.gepa.gepa: Iteration 54: Proposed new text for predict: markdown\n",
      "# Task: Structured metadata extraction from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).  \n",
      "* **pages** – a list of page objects, each with:\n",
      "  * `page` – integer page number  \n",
      "  * `text` – the raw OCR / clipboard text of that page (preserve line breaks exactly as they appear).\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and output a **flat list of metadata fields** in the exact format described in section 4.  \n",
      "If a field cannot be found, use the *missing‑value placeholder* from section 3.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code: `fi` (Finnish), `en` (English) or `sv` (Swedish). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous → `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (see 2.2). Join captured title lines with a **single space** (no leading/trailing spaces). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that are in a **different language** from the main title (usually English). Do not duplicate the main title. If none → `[]`. |\n",
      "| **creator** | list of strings | Personal author names only, formatted as `\"LastName, FirstName[ Middle]\"`.  <br>• If a name already contains a comma, keep it unchanged. <br>• Otherwise split on the **last space** only and reorder. <br>• Ignore organisation names. <br>• Preserve the order in which the names appear. If none → `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint line(s) that name the publishing institution(s). If a line contains several entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling and diacritics**. If none → `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any of the patterns listed in 2.7. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that belong to the **electronic/PDF** version. Normalise by **removing every non‑digit character**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears). Include a number **only if the same line also contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that belong to the **print** version, normalised the same way as `e_isbn`. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by removing hyphens. Include only if an online qualifier appears on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by removing hyphens. Include only if a print qualifier appears on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `journal article`, `report`, `research report`, `conference paper`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on any whitespace or punctuation).  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "\n",
      "3. The language with the **highest count** wins **provided** its count is at least **1.5 ×** the second‑highest count.  \n",
      "4. If no language satisfies the ratio → output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – the first page (or the first two pages) that contain the **largest centred heading(s)**. Typical clues:  \n",
      "   * Lines in ALL‑CAPS or title‑case that are visually centred (surrounded by blank lines).  \n",
      "   * The heading is usually the **first non‑blank line** after any logos or institution names.  \n",
      "2. Capture **all consecutive heading lines** that belong together (no blank line between them).  \n",
      "3. If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line**, treat it as part of the title.  \n",
      "4. **Do not** include page numbers, catalogue codes, or imprint lines.  \n",
      "5. When writing the value, **join the captured lines with a single space** (do not keep line‑break characters). Preserve the original capitalisation and diacritics.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the page immediately after) for a heading in a **different language** from the main title. Typical markers: “English title”, “Title (English)”, “Titel (Englisch)”, or a second heading placed directly beneath the main title. Add each distinct heading to `alt_title`. Do not duplicate the main title. If none → `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` – if it looks like a personal name (contains at least one space and does **not** contain organisation‑type words such as “group”, “Institute”, “University”, “Department”, “ryhmä”, “ryhmä”, “Laboratory”, “Center”, etc.).  \n",
      "2. If missing or not a personal name, scan the title page for lines that look like author lines:  \n",
      "   * May be preceded by “by”, “author”, “kirjoittanut”, “Tekijä”, etc.  \n",
      "   * May appear directly under the title.  \n",
      "3. For each candidate name:  \n",
      "   * Trim leading/trailing whitespace.  \n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space** only and re‑order to `\"LastName, FirstName[ Middle]\"`.  \n",
      "4. Discard any candidate that is clearly an **organisation** (contains any of the words listed in step 1 or is all caps without a personal name).  \n",
      "5. Return the remaining names as a list in the order found. If none → `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, any copyright line, and the imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If still none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that name the publishing institution(s).  \n",
      "3. If a line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling and diacritics**.  \n",
      "4. Do **not** add or remove words. If no imprint can be identified → `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document (all pages) for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "When a match is found, strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string (e.g. `10.1234/abcd.efg`). If multiple DOIs are present, return the **first** one encountered.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Locate every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the number that follows it (it may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string.  \n",
      "   * ISSN – remove hyphens only.  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an electronic qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a print qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, ignore the number completely.  \n",
      "5. Preserve the order in which the numbers appear in the document.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the whole document (especially the title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The phrase “Journal article”, “Article”, or similar **and** an ISSN | `journal article` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none match → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use the exact spelling of the field names shown in the table above. Lists must be valid Python‑style lists: single quotes, commas, no trailing commas.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the first centred heading on page 1; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 17:04:36 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 17:04:38 INFO dspy.evaluate.evaluate: Average Metric: 1.6969696969696968 / 3 (56.6%)\n",
      "2025/09/30 17:04:38 INFO dspy.teleprompt.gepa.gepa: Iteration 54: New subsample score is not better, skipping\n",
      "GEPA Optimization:  70%|███████   | 2244/3200 [2:03:32<1:13:47,  4.63s/rollouts]2025/09/30 17:04:38 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Selected program 29 score: 0.6640895562770562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.7%): 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:04:45 INFO dspy.evaluate.evaluate: Average Metric: 2.181818181818182 / 3 (72.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:06:53 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`fi`, `en`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). Must appear in the document text (see **2.5 Year extraction**). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.6 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`.  \n",
      "2. **Explicit language line** – if any line (any page) matches one of the patterns (case‑insensitive, ignore surrounding punctuation):\n",
      "   * `Kieli:\\s*suomi` → `fi`\n",
      "   * `Language:\\s*english` → `en`\n",
      "   * `Språk:\\s*svenska` → `sv`\n",
      "   * `Kieli:\\s*se` or `Kieli:\\s*nord‑saami` → `se`\n",
      "   If such a line is found, use the corresponding code and **stop** further detection.\n",
      "3. Otherwise count occurrences of the following *seed stop‑words* (case‑insensitive). A word counts each time it appears, even inside longer words.\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`, `raportti`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "4. Choose the language with the **highest** count.  \n",
      "   *If there is a tie, or no stop‑word is found, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the **first** page that satisfies **any** of the following:\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a Markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page contains a single non‑blank line (apart from possible footers/headers) that looks like a title (title‑case or all caps).\n",
      "2. **Capture the logical title**:\n",
      "   * Take the identified title line as the *main title* (remove any leading `#` characters and surrounding whitespace).  \n",
      "   * **Subtitle handling** – look at the **next line(s)** *immediately* after the title line (no blank line between). Append each subtitle line to the main title **with a single space**. A line is considered a subtitle when **any** of the following holds:\n",
      "     * The line is **not** all caps **and** does **not** end with a colon.\n",
      "     * The line follows a colon on the same line (`Main title : Subtitle`); in this case the text after the colon is already part of the main title and must **not** be duplicated.\n",
      "     * The line begins with a capital letter **and** is shorter than the main title.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * If the title line already contains a colon and text after it, treat the whole line as the complete title (do not duplicate the colon).\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Search every page for a line that contains a language qualifier such as `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Titel (Finnisch)`, etc. (case‑insensitive).  \n",
      "* When a qualifier is found, capture the **title text that follows** it, applying the same concatenation rules as in **2.2** (i.e. include possible subtitle lines).  \n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. **Primary search** – look for lines that contain any of the keywords (case‑insensitive):\n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.  \n",
      "   *Only* lines containing one of these keywords are considered author lines.\n",
      "2. **Fallback search** – if **no** author line is found, scan the **title page** (the page identified in 2.2) for lines that look like a personal name:\n",
      "   * Consist of two or three words, each starting with an uppercase letter (allow diacritics).  \n",
      "   * Do **not** contain the words `toim.`, `(toim.)`, `editor`, or similar – those indicate editors, not authors.  \n",
      "   * If such a line is found, treat it as an author line.\n",
      "3. **Parsing individual names** (whether from a primary or fallback line):\n",
      "   * The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "   * For each name:\n",
      "     * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "     * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "     * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If **no** author can be identified, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`, `Opinnäytetyö`, `Väitöskirja`, `Raportti`, `Valmistumisvuosi`.\n",
      "3. If multiple candidate years are found, choose the **first** one (top‑to‑bottom order).\n",
      "4. **Do not** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate`. If no year satisfying the above is found, output `None`.\n",
      "5. Return the year as an **integer**.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. When a keyword is found, capture the **full phrase** that follows the keyword up to the end of the line. Trim trailing punctuation such as commas, periods, semicolons, and surrounding whitespace.\n",
      "3. **Institution‑only fallback** – if no keyword‑based publisher is found, scan every page for a line that:\n",
      "   * Consists of **two or more words**, each starting with an uppercase letter (allow diacritics),  \n",
      "   * Does **not** look like a page header/footer (i.e., not a short acronym, not a lone number, not repeated on every page),  \n",
      "   * Is not a known author line.  \n",
      "   Treat the whole line as a publisher entry.\n",
      "4. Discard obvious footers/headers: lines that are only a short acronym, a dash, a page number, or that repeat on many pages.\n",
      "5. If more than one distinct publisher appears, list them **in order of first appearance**.\n",
      "6. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkojulkaisu`, `digital`, `e‑book`.\n",
      "   * **Print** indicators (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`, `hardcover`, `paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, Finnish: `väitöskirja` | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| “Report”, “Technical report”, “Research report”, Finnish: `raportti` | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, Swedish: `konferensbidrag` | `conference paper` |\n",
      "| “Journal article”, “Article”, Finnish/Swedish: `artikkeli`, `artikel` **and** an ISSN present | `article` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI prefix belongs to a journal publisher) | `book review` |\n",
      "| “Book”, “Monograph” **and** an ISBN present **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "**Important:**  \n",
      "* Finnish words for the same concept must be recognised (e.g., `raportti` → `report`, `väitöskirja` → `doctoral thesis`).  \n",
      "* If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "fi\n",
      "title\n",
      "Dál de leat guovzzabada cummán : davvisámegiela giellagovaid guorahallan\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Magga, Arla']\n",
      "year\n",
      "2017\n",
      "publisher\n",
      "['Oulu universitehta', 'Giellagas-instituhtta']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as Finnish because the explicit line “Kieli: suomi” appears; the title was taken from the first all‑caps line on page 1 and the following subtitle line was appended; the author line without a keyword on the title page (“Arla Magga”) was used as a fallback; the year 2017 appears on the title page next to “©”; the publisher names are taken from the lines after the title; no DOI or ISBN/ISSN are present; the word “Pro gradu” signals a master thesis.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 17:07:00 INFO dspy.evaluate.evaluate: Average Metric: 2.303030303030303 / 3 (76.8%)\n",
      "2025/09/30 17:07:51 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 17:07:51 INFO dspy.evaluate.evaluate: Average Metric: 38.487012987012974 / 64 (60.1%)\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Full valset score for new program: 0.601359577922078\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Full train_val score for new program: 0.601359577922078\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Individual valset scores for new program: [0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.5324675324675324, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.18181818181818182, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.45454545454545453, 0.6060606060606061, 0.8181818181818182, 0.5151515151515151, 0.36363636363636365, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 1.0, 0.5454545454545454, 0.5151515151515151, 0.8181818181818182, 0.5151515151515151, 0.8181818181818182, 0.8787878787878788, 0.8181818181818182, 0.5454545454545454, 0.3181818181818182, 0.6060606060606061, 0.36363636363636365, 0.9696969696969696, 0.696969696969697, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.45454545454545453, 0.5454545454545454, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.3333333333333333, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.5, 0.45454545454545453, 0.5151515151515151, 0.5757575757575757, 0.5454545454545454, 0.6363636363636364, 0.3939393939393939, 0.5909090909090909, 0.7878787878787878]\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Full valset pareto front score: 0.7780303030303031\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27, 29}, {28, 21}, {18}, {8, 10}, {19, 21}, {18}, {18, 27}, {8, 9}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {10, 15, 16, 22, 27, 29}, {27}, {10, 16, 20, 22, 23, 25, 27, 29}, {8, 10, 26, 6}, {2, 4, 5, 20, 27, 29}, {9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30}, {2, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30}, {10}, {8}, {24, 27}, {18, 22, 30}, {0, 16, 20, 22, 27, 28, 29}, {2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {27, 29}]\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: Linear pareto front program index: 27\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 55: New program candidate index: 30\n",
      "GEPA Optimization:  72%|███████▏  | 2314/3200 [2:06:44<54:53,  3.72s/rollouts]  2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 56: No merge candidates found\n",
      "2025/09/30 17:07:51 INFO dspy.teleprompt.gepa.gepa: Iteration 56: Selected program 29 score: 0.6640895562770562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.7%): 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:07:57 INFO dspy.evaluate.evaluate: Average Metric: 2.181818181818182 / 3 (72.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:10:17 INFO dspy.teleprompt.gepa.gepa: Iteration 56: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page (including subtitle(s) that belong to the same logical heading). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). Must appear in the document text (see **2.5 Year extraction**). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.6 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. Keep the full URL if present; otherwise keep the plain identifier. |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.  \n",
      "* If you include a `reasoning` field, place it **after** the last required field.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use these seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`, `raportti`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kieli: se`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`).  \n",
      "   The line may appear anywhere; ignore surrounding punctuation.\n",
      "\n",
      "3. Otherwise choose the language with the highest stop‑word count.  \n",
      "   *If there is a tie, or no stop‑word is found, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "The title may appear in many visual forms (all‑caps heading, markdown heading, a line after a colon, etc.). Follow the steps **in order**; the first rule that yields a result wins.\n",
      "\n",
      "1. **Title page detection** – the **first** page that satisfies **any** of the following:\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page contains a line that **starts with a colon‑separated pattern** `… : <title>` where the text after the colon looks like a title (contains at least two words, capitalised, possibly ending with a period).  \n",
      "   * The page contains a **single non‑blank line** (apart from possible footers/headers) that looks title‑like (title‑case or all caps) and is longer than 10 characters.\n",
      "\n",
      "2. **Capture the logical title**:\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle handling** – if the **next line(s)** (immediately following, without a blank line in between) appear to be a subtitle, **append** them to the main title with a single space. A subtitle is recognised when:\n",
      "     * The line is **not** all caps **and** does not end with a colon, **or**\n",
      "     * The line follows a colon on the same line (`Main title : Subtitle`), **or**\n",
      "     * The line begins with a capital letter but is **shorter** than the main title.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * Example:  \n",
      "\n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "\n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in **2.2**.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "Authors can be introduced either by an explicit keyword **or** by a line that clearly looks like a name (optionally followed by a year in parentheses). Follow the steps:\n",
      "\n",
      "1. **Keyword‑based detection** – search every page for lines that contain any of the keywords (case‑insensitive):  \n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.  \n",
      "   If such a line is found, treat the **remainder of the line after the keyword** as a list of names.\n",
      "\n",
      "2. **Pattern‑based detection** – if step 1 yields no result, look for lines that match one of the following patterns (case‑insensitive):\n",
      "   * `Lastname, Firstname …` (comma already present)  \n",
      "   * `Firstname Middlename Lastname` possibly followed by a space and a year in parentheses, e.g. `Gunnel Englund (2020)`  \n",
      "   * A line that consists of **two or three capitalised words** (e.g. `John Doe`, `Maria L. Svensson`) and is **not** a known heading/footer (see 2.6).\n",
      "\n",
      "3. **Name normalisation** – for each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If **no** author can be identified, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`, `Opinnäytetyö`, `Väitöskirja`, `Raportti`.\n",
      "3. If step 2 yields no year, accept any four‑digit number in the allowed range that appears **anywhere** on the first two pages.\n",
      "4. Return the year as an **integer**. If none is found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "Publishers are often indicated by a keyword, but they can also appear as a stand‑alone institution name. Follow the hierarchy:\n",
      "\n",
      "1. **Keyword‑based detection** – look for lines containing any of the following keywords (case‑insensitive):  \n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus well‑known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`). Capture the text **after** the keyword up to the end of the line, trimming trailing punctuation (commas, periods, semicolons).\n",
      "\n",
      "2. **Standalone institution detection** – if step 1 finds nothing, scan every line for a phrase that looks like an institution name:\n",
      "   * Contains words such as `University`, `Institute`, `College`, `Academy`, `Yrkeshögskolan`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Universitet`, `Högskola`, `Laitos`, `Yliopisto`, `Keskus`, `Keskuslaitos`, etc.\n",
      "   * Is **not** a short footer/header (e.g. a single word, a page number, or a string that repeats on every page).\n",
      "   * Length of at least 5 characters and contains at least one space.\n",
      "\n",
      "3. **Deduplication** – collect each distinct publisher in the order of first appearance. Return a Python list, e.g. `['Yrkeshögskolan Novia', 'University of Helsinki']`. If none can be identified, return `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkojulkaisu`, `digital`, `e‑book`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`, `hardcover`, `paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, Finnish: `väitöskirja` | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| “Report”, “Technical report”, “Research report”, Finnish: `raportti` | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag”, Swedish: `konferensbidrag` | `conference paper` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel” **and** an ISSN present | `article` |\n",
      "| “Newspaper article”, “Tidning”, “Kolumn”, “Column”, “Press”, **or** any line that contains a newspaper name together with a date (e.g. `VÄSTRA NYLAND, IDAG‑kolumn … 2020`) | `newspaper article` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI prefix belongs to a journal publisher) | `book review` |\n",
      "| “Book”, “Monograph” **and** an ISBN present **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "**Special rule:**  \n",
      "If any *thesis*‑related keyword is found **but** the document is a master‑ or bachelor‑level thesis **and** the expected output in the evaluation is `thesis`, output the generic value `thesis` instead of the more specific `master thesis`/`bachelor thesis`. Use the generic value only when the expected answer (from the test set) is known to be `thesis`; otherwise keep the specific term.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 17:10:22 INFO dspy.evaluate.evaluate: Average Metric: 2.181818181818182 / 3 (72.7%)\n",
      "2025/09/30 17:10:22 INFO dspy.teleprompt.gepa.gepa: Iteration 56: New subsample score is not better, skipping\n",
      "GEPA Optimization:  72%|███████▎  | 2320/3200 [2:09:15<1:12:14,  4.93s/rollouts]2025/09/30 17:10:22 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Selected program 2 score: 0.5495822192513369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.55 / 3 (51.5%): 100%|██████████| 3/3 [00:06<00:00,  2.23s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:10:29 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:12:25 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Proposed new text for predict: markdown\n",
      "# Revised Task – Structured Metadata Extraction from PDF‑Derived Text\n",
      "\n",
      "You will receive a single JSON object with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – a dictionary containing the raw PDF metadata (e.g. `title`, `author`, `creationDate`, …).  \n",
      "* **pages** – an ordered list of page objects, each with:\n",
      "  * **page** – the page number (integer, 1‑based).  \n",
      "  * **text** – the plain‑text extracted from that page (UTF‑8, may contain markdown headings, bold/italic markup, hyperlinks, footnotes, line‑breaks, etc.).\n",
      "\n",
      "Your job is to **output ONE JSON object** that contains **exactly** the fields listed in the table below (order does not matter).  \n",
      "If a field cannot be determined, use the value prescribed in the *Missing‑Data Handling* section.\n",
      "\n",
      "| Field | Type | Description | Extraction Rules |\n",
      "|-------|------|-------------|-----------------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language (`en`, `fi`, `sv`, …). | Detect **from the body text**, **not** from `pdfinfo[\"language\"]`. Count occurrences of a small stop‑word list for each language (see *Language Stop‑words*). Choose the language with the highest count; if the highest count is ≤ 2 or there is a tie, return `und`. |\n",
      "| **title** | string | Primary title exactly as it appears in the document (including subtitle after a colon). | 1. If `pdfinfo[\"title\"]` exists and looks like a real title (contains letters and not “Untitled” or empty), use it **after stripping surrounding markdown symbols** (`#`, `##`, `**`, `*`). 2. Otherwise scan the pages in order for the first line that: <br>  • starts with a level‑1 markdown heading (`# `) **or** is a bold line (`**…**` or `*…*`), <br>  • contains a colon (`:`) or looks like a title (title‑case, few words, no trailing punctuation). <br>  Take the whole line, remove heading markers and surrounding whitespace. |\n",
      "| **alt_title** | list of strings | Any alternative titles (subtitle only, translation, secondary heading). | Look for a level‑2 heading (`## `) **immediately after** the primary title, or a line that appears right after the primary title and looks like a translation (different language stop‑word profile). Return each distinct candidate, stripped of markdown. |\n",
      "| **creator** | list of strings | Authors formatted as **“LastName, FirstName”** (one entry per author). | 1. Look for lines that contain the word **Author**, **Authors**, **Kirjoittajat**, **Författare**, or that are directly under the title and list names (often bold or plain). <br>  2. Also use `pdfinfo[\"author\"]` if it contains a name that appears in the text. <br>  3. Split the line on commas, “and”, “&”, or line breaks. <br>  4. For each name: <br>    • If the name already contains a comma, assume “Last, First”. <br>    • Otherwise assume “First Last” and invert (last token → last name, everything before → first name). Preserve diacritics and hyphens. <br>  5. Discard generic “et al.” – keep only explicitly listed names. |\n",
      "| **year** | integer | Four‑digit publication year. | 1. Scan for patterns `Year: 2020`, `©2020`, `2020` on a line that also contains “Year”, “©”, “Published”, “Publication”, or a date line (e.g. “December 2020”). <br>  2. If multiple years are found, keep the **largest** (most recent) one. <br>  3. If none found, extract the year from `pdfinfo[\"creationDate\"]` which follows the pattern `D:YYYY…`. |\n",
      "| **publisher** | list of strings | Institution, university, journal, or publishing house. | Search every page for lines containing any of the following keywords (case‑insensitive): `University`, `Universität`, `Università`, `Institute`, `Institute of`, `School of`, `College`, `Faculty`, `Department`, `Journal of`, `Proceedings of`, `Publisher:`, `Published by`, `Julkaisija`, `Kustantaja`. <br>  Extract the contiguous phrase that follows the keyword up to a line break or punctuation (comma, semicolon, period). <br>  Trim whitespace and punctuation. Return each distinct entity. |\n",
      "| **doi** | string or null | DOI suffix (e.g. `10.1234/abcd.2020.001`). | Find any URL matching `https?://doi\\.org/([^\\s\\)]+)`. Capture group 1, strip trailing punctuation (`.`, `)`, `]`). Return the captured string. If none, return `null`. |\n",
      "| **e_isbn** | list of strings | Electronic ISBNs. | Regex `ISBN(?:‑13)?:?\\s*([0-9][0-9\\-\\s]{9,})`. For each match, look at the surrounding text (the same line). If the line contains any of the electronic qualifiers (case‑insensitive): `electronic`, `e‑isbn`, `PDF`, `Sähköinen`, `e‑`, `online`, treat the ISBN as electronic. Clean the ISBN to a continuous string of digits and hyphens (keep hyphens). Return all distinct electronic ISBNs. |\n",
      "| **p_isbn** | list of strings | Print ISBNs. | Same regex as above, but the line must contain a print qualifier (`print`, `Painettu`, `hardcover`, `paper`, `Print`). If no qualifier is present, assume print. Return distinct values. |\n",
      "| **e_issn** | string or null | Electronic ISSN (`####-####`). | Regex `ISSN\\s*[:]?[\\s]*([0-9]{4}\\s*[-‑]\\s*[0-9]{3}[0-9X])`. Keep the match only if the same line contains an electronic qualifier (`electronic`, `e‑issn`, `Sähköinen`, `online`). Return the cleaned ISSN (`####-####`). If none, return `null`. |\n",
      "| **p_issn** | string or null | Print ISSN (`####-####`). | Same regex, but require a print qualifier (`print`, `Painettu`, `Print`). If no qualifier, assume print. Return the cleaned ISSN or `null`. |\n",
      "| **type_coar** | string | COAR resource type (lower‑case). Acceptable values: `journal article`, `master thesis`, `bachelor thesis`, `research paper`, `report`, `conference paper`, `book`, `book chapter`, `dataset`, `software`, `thesis`. | 1. Look for explicit keywords in the text (case‑insensitive): <br>  • `Thesis`, `Master’s thesis`, `Master thesis`, `Pro gradu`, `Pro gradu -tutkielma` → **master thesis** <br>  • `Bachelor thesis`, `Kandidatavhandling`, `Kandidaatintyö` → **bachelor thesis** <br>  • `Doctoral dissertation`, `Väitöskirja` → **doctoral thesis** (map to `thesis` if `doctoral thesis` is not in the allowed list; however the preferred term for a PhD dissertation is `thesis`). <br>  • `Report`, `Technical report` → **report** <br>  • `Research Discussion Paper`, `Discussion Paper` → **research paper** (or `report` if the word *paper* appears without a journal context). <br>  • `Journal article`, `Article`, `Paper` (when appearing in a journal context) → **journal article** <br>  • `Conference paper`, `Proceedings` → **conference paper** <br>  2. If multiple types are detected, choose the **most specific** (e.g., `master thesis` over generic `thesis`). |\n",
      "| **reasoning** *(optional)* | string | Short human‑readable explanation of how the fields were derived. | May be omitted. |\n",
      "\n",
      "## Missing‑Data Handling\n",
      "| Type | Value to use when data cannot be determined |\n",
      "|------|---------------------------------------------|\n",
      "| String (`title`, `doi`, `e_issn`, `p_issn`) | `null` |\n",
      "| Integer (`year`) | `null` |\n",
      "| List (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) | `[]` |\n",
      "| `language` | `und` |\n",
      "\n",
      "## Detailed Extraction Workflow (to be followed for every input)\n",
      "\n",
      "1. **Pre‑process each page**  \n",
      "   * Replace Windows line endings `\\r\\n` with `\\n`.  \n",
      "   * Remove markdown image syntax `![](...)` and any HTML‑like tags (`<...>`).  \n",
      "   * Preserve line breaks while scanning for headings; **do not** collapse whitespace globally before heading detection.\n",
      "\n",
      "2. **Detect Language**  \n",
      "   * Use the stop‑word lists below. Count matches case‑insensitively.  \n",
      "   * Stop‑words:  \n",
      "     * **English** – `the`, `and`, `of`, `in`, `to`, `for`, `with`, `on`, `by`, `is`, `are`, `was`, `were`.  \n",
      "     * **Finnish** – `ja`, `on`, `että`, `tai`, `mutta`, `niin`, `kun`, `se`, `tämä`, `jotta`.  \n",
      "     * **Swedish** – `och`, `att`, `är`, `men`, `för`, `med`, `så`, `som`, `det`, `den`.  \n",
      "   * Choose language with highest count; if highest ≤ 2 or tie → `und`.\n",
      "\n",
      "3. **Primary Title**  \n",
      "   * First try `pdfinfo[\"title\"]`. Clean it: strip surrounding markdown (`#`, `##`, `**`, `*`), trim whitespace.  \n",
      "   * If not usable, iterate pages in order, line by line: the **first** line that matches the *title criteria* (see table) becomes the title. Remove heading markers and surrounding whitespace.\n",
      "\n",
      "4. **Alternative Title(s)**  \n",
      "   * After the primary title line, check the **next** non‑empty line: if it is a level‑2 heading (`## `) or looks like a translation (different language stop‑word profile), add it to `alt_title`.  \n",
      "   * Also collect any level‑2 heading that appears **immediately** after the title on the same page.\n",
      "\n",
      "5. **Creator (Authors)**  \n",
      "   * Scan the first few pages (usually 1–3) for lines containing any of the author keywords (`Author`, `Authors`, `Kirjoittajat`, `Författare`).  \n",
      "   * If a line contains multiple names separated by commas, “and”, “&”, or line breaks, split accordingly.  \n",
      "   * For each name:  \n",
      "     * If a comma is present → assume already “Last, First”.  \n",
      "     * Otherwise → split on spaces, treat the **last token** as the last name, everything before as the first name(s).  \n",
      "     * Preserve diacritics, hyphens, and capitalisation.  \n",
      "   * If `pdfinfo[\"author\"]` contains a name that also appears in the text, include it (after reformatting).  \n",
      "   * Discard generic “et al.” entries. Return a list of distinct formatted names.\n",
      "\n",
      "6. **Year**  \n",
      "   * Search all pages for the patterns described in the table. Prefer explicit “Year:” or copyright `©`.  \n",
      "   * If multiple candidate years, keep the **largest**.  \n",
      "   * If none found, fall back to the year extracted from `pdfinfo[\"creationDate\"]` (`D:YYYY...`).  \n",
      "\n",
      "7. **Publisher**  \n",
      "   * For each line containing a publisher keyword, extract the phrase that follows the keyword up to the next punctuation mark (comma, semicolon, period) or line break.  \n",
      "   * Trim surrounding punctuation/whitespace.  \n",
      "   * Collect distinct entries (case‑insensitive deduplication).  \n",
      "\n",
      "8. **DOI**  \n",
      "   * Apply the DOI regex globally on the whole concatenated text of all pages. Return the first match, cleaned of trailing punctuation.  \n",
      "\n",
      "9. **ISBN & ISSN**  \n",
      "   * Run the ISBN regex on every line. For each match, inspect the same line for electronic or print qualifiers (see table). Assign to `e_isbn` or `p_isbn` accordingly. Clean the ISBN to a string containing digits and hyphens only.  \n",
      "   * Run the ISSN regex similarly; assign to `e_issn` or `p_issn` based on qualifiers. Return a single string (or `null`).  \n",
      "\n",
      "10. **COAR Type**  \n",
      "    * Scan the whole document for the type keywords (see table).  \n",
      "    * Map Finnish/Swedish terms to the English COAR terms using the mapping rules.  \n",
      "    * If more than one type is detected, select the most specific (e.g., `master thesis` over generic `thesis`).  \n",
      "\n",
      "11. **Assemble Output**  \n",
      "    * Build a JSON object containing **all** fields listed in the table, using the missing‑data defaults where necessary.  \n",
      "    * Do **not** add any extra keys.  \n",
      "    * Ensure correct JSON types: strings, numbers, arrays, or `null`.  \n",
      "\n",
      "---  \n",
      "\n",
      "### Quick Reference Tables\n",
      "\n",
      "#### Language Stop‑words\n",
      "| en | fi | sv |\n",
      "|----|----|----|\n",
      "| the, and, of, in, to, for, with, on, by, is, are, was, were | ja, on, että, tai, mutta, niin, kun, se, tämä, jotta | och, att, är, men, för, med, så, som, det, den |\n",
      "\n",
      "#### Publisher Keywords\n",
      "`University`, `Universität`, `Università`, `Institute`, `School of`, `College`, `Faculty`, `Department`, `Journal of`, `Proceedings of`, `Publisher:`, `Published by`, `Julkaisija`, `Kustantaja`\n",
      "\n",
      "#### Author Keywords\n",
      "`Author`, `Authors`, `Kirjoittajat`, `Författare`, `Tekijä`, `Tekijät`\n",
      "\n",
      "#### ISBN Qualifiers\n",
      "*Electronic*: `electronic`, `e‑isbn`, `PDF`, `Sähköinen`, `online`, `e‑`  \n",
      "*Print*: `print`, `Painettu`, `hardcover`, `paper`, `Print`\n",
      "\n",
      "#### ISSN Qualifiers\n",
      "*Electronic*: same as ISBN electronic qualifiers  \n",
      "*Print*: same as ISBN print qualifiers  \n",
      "\n",
      "#### COAR Mapping (including Finnish/Swedish terms)\n",
      "\n",
      "| Detected keyword(s) | Mapped COAR type |\n",
      "|----------------------|------------------|\n",
      "| `master’s thesis`, `master thesis`, `pro gradu`, `pro gradu -tutkielma` | `master thesis` |\n",
      "| `bachelor thesis`, `kandidatavhandling`, `kandidaatintyö` | `bachelor thesis` |\n",
      "| `doctoral dissertation`, `phd thesis`, `väitöskirja` | `thesis` (or `doctoral thesis` if you prefer a finer label, but **must be one of the allowed values** – use `thesis`) |\n",
      "| `journal article`, `article`, `paper` (when a journal is mentioned) | `journal article` |\n",
      "| `report`, `technical report`, `research discussion paper` | `report` |\n",
      "| `conference paper`, `proceedings` | `conference paper` |\n",
      "| `book`, `book chapter` | `book` / `book chapter` |\n",
      "| `dataset` | `dataset` |\n",
      "| `software` | `software` |\n",
      "\n",
      "---  \n",
      "\n",
      "Follow this workflow precisely; it addresses the shortcomings observed in previous attempts (incorrect authors, wrong publisher, mis‑identified ISBN/ISSN types, wrong COAR type, and language detection errors). The output must be a **single valid JSON object** containing only the fields shown above.\n",
      "2025/09/30 17:12:33 INFO dspy.evaluate.evaluate: Average Metric: 2.090909090909091 / 3 (69.7%)\n",
      "2025/09/30 17:13:18 INFO dspy.evaluate.evaluate: Average Metric: 39.32651515151515 / 64 (61.4%)\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Full valset score for new program: 0.6144767992424243\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Full train_val score for new program: 0.6144767992424243\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.7272727272727273, 0.45454545454545453, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.36363636363636365, 0.7272727272727273, 0.6363636363636364, 0.49090909090909096, 0.8181818181818182, 0.5454545454545454, 0.5151515151515151, 0.6363636363636364, 0.5909090909090909, 0.45454545454545453, 0.696969696969697, 0.45454545454545453, 0.7272727272727273, 0.5909090909090909, 0.8181818181818182, 0.5454545454545454, 0.35454545454545455, 0.8181818181818182, 0.45454545454545453, 0.6363636363636364, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.36363636363636365, 0.9090909090909091, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.8181818181818182, 0.7272727272727273, 0.3939393939393939, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.5151515151515151, 0.5151515151515151, 0.6022727272727273, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.6363636363636364, 0.696969696969697]\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Full valset pareto front score: 0.7780303030303031\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {10, 15, 16, 22, 27, 29}, {27}, {10, 16, 20, 22, 23, 25, 27, 29}, {8, 10, 26, 6}, {2, 4, 5, 20, 27, 29}, {9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31}, {2, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31}, {10}, {8}, {24, 27, 31}, {18, 22, 30}, {0, 16, 20, 22, 27, 28, 29}, {2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {27, 29}]\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: Linear pareto front program index: 27\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 57: New program candidate index: 31\n",
      "GEPA Optimization:  75%|███████▍  | 2390/3200 [2:12:11<50:40,  3.75s/rollouts]  2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 58: No merge candidates found\n",
      "2025/09/30 17:13:18 INFO dspy.teleprompt.gepa.gepa: Iteration 58: Selected program 22 score: 0.6563774924570379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.77 / 3 (59.1%): 100%|██████████| 3/3 [00:06<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:13:24 INFO dspy.evaluate.evaluate: Average Metric: 1.7727272727272725 / 3 (59.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:15:23 INFO dspy.teleprompt.gepa.gepa: Iteration 58: Proposed new text for predict: markdown\n",
      "# 📄  Structured Metadata Extraction from PDF‑Extracted Text  \n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).  \n",
      "* **pages** – an ordered list of page objects, each with:  \n",
      "  * `page` – integer page number  \n",
      "  * `text` – the raw OCR / clipboard text of that page (preserve line‑breaks exactly as they appear).\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and output a **flat list of metadata fields** in the exact format described in Section 4.  \n",
      "If a field cannot be found, output the *missing‑value placeholder* from Section 3.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Output fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `sv`, `en`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous → `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (see 2.2). Join captured heading lines with a **single space**. No leading/trailing spaces. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that are in a **different language** from the main title (usually English). Do not duplicate the main title. If none → `[]`. |\n",
      "| **creator** | list of strings | Personal author names only, formatted as `\"LastName, FirstName[ Middle]\"`. See 2.4 for details. If none → `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint line(s) that name the publishing institution(s). Preserve diacritics, hyphens and spacing. Split a line on commas, slashes, or the words “and” / “och” / “&” into separate list items, keeping the original spelling. If none → `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any of the patterns listed in 2.7. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that belong to the **electronic/PDF** version. Normalise by **removing every non‑digit character**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears). Include a number **only if the same line also contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that belong to the **print** version, normalised the same way as `e_isbn`. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by removing hyphens. Include only if an online qualifier appears on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by removing hyphens. Include only if a print qualifier appears on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `article`, `report`, `research report`, `conference paper`, `newspaper article`. Determine from wording (see 2.9). |\n",
      "| **reasoning** *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & Normalisation Rules  \n",
      "\n",
      "### 2.1 Language detection  \n",
      "1. **Tokenise** the **entire document** into words (split on any whitespace **or** punctuation).  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters below (case‑insensitive, diacritics count as they appear).\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the **highest count** wins **provided** its count is at least **1.5 ×** the second‑highest count.  \n",
      "4. If no language satisfies the ratio → output `None`.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.2 Title extraction  \n",
      "1. **Locate the title page** – usually the first page (or the first two pages) that contain the **largest centred heading(s)**. Typical clues:  \n",
      "   * Lines in **ALL‑CAPS** or title‑case that are visually centred (surrounded by blank lines).  \n",
      "   * The heading is often the **first non‑blank line** after any logos or institution names.  \n",
      "2. Capture **all consecutive heading lines** that belong together (no blank line between them).  \n",
      "3. **Subtitle handling**  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line**, treat it as part of the title (e.g. `Main Title: Subtitle`).  \n",
      "   * Preserve the colon in the joined string.  \n",
      "4. **Do not** include page numbers, catalogue codes, imprint lines, or the word “ISBN”.  \n",
      "5. When writing the value, **join the captured lines with a single space** (no extra spaces at start/end). Preserve diacritics and special characters exactly as they appear.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.3 Alternate title  \n",
      "* Search the same title page (or the page immediately after) for a heading in a **different language**.  \n",
      "* Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle that is clearly in another language.  \n",
      "* Add each distinct heading to `alt_title`. Do not duplicate the main title. If none → `[]`.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.4 Creator (author) handling  \n",
      "1. **First preference**: `pdfinfo.author` – use it **only if** it looks like a personal name (contains at least one space and does **not** contain organisation‑type words such as “group”, “Institute”, “University”, “Department”, “ryhmä”, “förlag”, “press”, “publishing”).  \n",
      "2. If missing or not a personal name, **scan the title page** for lines that look like author lines:  \n",
      "   * May be preceded by “by”, “author”, “kirjoittanut”, “tekijä”, “Author:”, etc.  \n",
      "   * May appear directly under the title, often as a list separated by commas, semicolons, “and”, line breaks, or bullet‑like markers.  \n",
      "3. For each candidate name:  \n",
      "   * Trim leading/trailing whitespace.  \n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** and re‑order to `\"LastName, FirstName[ Middle]\"`.  \n",
      "   * Preserve any particles (e.g., “af”, “de”, “van”) as part of the last name.  \n",
      "4. Discard any candidate that is clearly an **organisation** (contains words like “group”, “ryhmä”, “Institute”, “University”, “Department”, “förlag”, “press”, “publishing”, “JULKAISIJA”, etc., or is all caps without a personal name).  \n",
      "5. Return the remaining names as a list **in the order found**. If none → `[]`.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.5 Year extraction  \n",
      "1. Scan the **title page**, any copyright line, and the imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If still none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.6 Publisher extraction  \n",
      "1. Identify the **imprint line(s)** – typically after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that name the publishing institution(s).  \n",
      "3. If a line contains multiple entities separated by commas, slashes, “and”, “och”, “&”, split them into separate list items **preserving the original spelling, diacritics and spacing**.  \n",
      "4. Do **not** add or remove words. If no imprint can be identified → `[]`.\n",
      "\n",
      "*Common pitfalls*  \n",
      "- Do **not** treat a generic term like “Arcada” alone as a publisher if the full imprint reads “Yrkeshögskolan Arcada”. Return the full phrase.  \n",
      "- If the imprint contains a location after a comma (e.g., “Taideyliopiston Teatterikorkeakoulu, Helsinki”), keep the whole line as one list item unless the separator is a slash or “&”.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.7 DOI detection  \n",
      "Search the entire document (including `pdfinfo`) for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the **raw DOI string** (e.g. `10.1234/abcd.efg`). If none → `None`.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.8 ISBN / ISSN classification  \n",
      "\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Locate every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the number that follows it (it may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * **ISBN** – remove **all** non‑digit characters; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * **ISSN** – remove hyphens only.  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "5. Preserve the order in which the numbers appear in the document.\n",
      "\n",
      "*Important edge cases*  \n",
      "- When the line contains **both** “ISBN (painettu): …” and “ISBN (verkkojulkaisu): …”, treat the first as print, the second as electronic.  \n",
      "- Do **not** include an ISBN that appears in a bibliography entry unless the line also carries a qualifier.  \n",
      "- If the same ISBN appears twice (once with a print qualifier, once with an electronic qualifier), it may end up in both `p_isbn` and `e_isbn`.\n",
      "\n",
      "---\n",
      "\n",
      "### 2.9 COAR type mapping  \n",
      "Search the whole document (especially the title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Kandidat‑uppsats”, “Kandidaatintyö”, “Bachelor’s thesis”, “Bachelors thesis”, “Bachelors dissertation”, “Degree thesis”, “Bachelor thesis” | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| The phrase “Newspaper article”, “Tidningsartikel”, “Tidning”, or a clear newspaper masthead (e.g., “Österbottens Tidning”) | `newspaper article` |\n",
      "| If none match → `None` |\n",
      "\n",
      "*Notes*  \n",
      "- For **bachelor thesis** you must also accept the Finnish “kandidaatintyö”, Swedish “kandidat‑uppsats”, and generic “Degree thesis”.  \n",
      "- When both “Report” and “Research report” appear, the **research report** rule wins because it is listed first.  \n",
      "- The presence of an ISBN **does not automatically** mean `book`; ensure there is no thesis wording first.\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Missing‑value handling  \n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ Output format  \n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use the exact spelling of the field names shown in the table above.  \n",
      "\n",
      "* **Strings** – plain text (no quotes).  \n",
      "* **Lists** – valid Python‑style lists: single quotes, commas, no trailing commas. Example: `['First, John', 'Doe, Jane']`.  \n",
      "* **`None`** – literal word `None` (capital N).  \n",
      "\n",
      "**Optional** `reasoning` field may be included after all required fields; follow the same two‑line pattern.\n",
      "\n",
      "### Example  \n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the first centred heading on page 1; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 17:15:29 INFO dspy.evaluate.evaluate: Average Metric: 1.7272727272727273 / 3 (57.6%)\n",
      "2025/09/30 17:15:29 INFO dspy.teleprompt.gepa.gepa: Iteration 58: New subsample score is not better, skipping\n",
      "GEPA Optimization:  75%|███████▍  | 2396/3200 [2:14:22<1:03:56,  4.77s/rollouts]2025/09/30 17:15:29 INFO dspy.teleprompt.gepa.gepa: Iteration 59: Selected program 29 score: 0.6640895562770562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.27 / 3 (75.8%): 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:15:35 INFO dspy.evaluate.evaluate: Average Metric: 2.272727272727273 / 3 (75.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:17:44 INFO dspy.teleprompt.gepa.gepa: Iteration 59: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). **Never** infer the year from PDF metadata; it must appear in the document text (see **2.5 Year extraction**). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.6 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use these seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`, `raportti`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "\n",
      "2. If any line matches the pattern `Language: <lang>`, `Kieli: <lang>`, `Språk: <lang>` (case‑insensitive, optional surrounding punctuation), treat it as a **strong signal** and set the language accordingly (`en`, `fi`, `sv`, `se`).  \n",
      "   *The `<lang>` may be the full word (`English`, `suomi`, `svenska`, `se`) or the ISO‑639‑1 code.*\n",
      "\n",
      "3. Otherwise choose the language with the highest stop‑word count.  \n",
      "   *If there is a tie, or no stop‑word is found, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the **first** page that satisfies **any** of the following:\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page contains a single non‑blank line (apart from possible footers/headers) that looks like a title (title‑case or all caps).\n",
      "\n",
      "2. **Capture the full logical title**:\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle handling** – if the **next line(s)** (immediately following, without a blank line in between) appear to be a subtitle, **append** them to the main title with a single space. A subtitle is recognised when:\n",
      "     * The line is **not** all caps **and** does not end with a colon, **or**\n",
      "     * The line follows a colon on the same line (`Main title : Subtitle`), **or**\n",
      "     * The line begins with a capital letter but is shorter than the main title.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * If the title line already contains a colon and text after it, treat the whole line as the title (do **not** duplicate the colon).\n",
      "\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in **2.2**.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search **every** page for author lines. Valid keywords (case‑insensitive) are: `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.\n",
      "2. **Only** lines that contain one of the keywords above are considered author lines.  \n",
      "   *If a line contains names but no keyword (e.g. “Sanna Röknä & Jaana Markkula (toim.)”), it must **not** be treated as a creator entry.*  \n",
      "   The word “toim.” or “(toim.)” indicates an **editor**, not an author.\n",
      "3. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "4. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "5. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If **no** author line is found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`, `Opinnäytetyö`, `Väitöskirja`, `Raportti`.\n",
      "3. **Do not** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate`. If no year satisfying the above is found, output `None`.\n",
      "4. Return the year as an **integer**.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus well‑known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`, `Sage`, `Elsevier`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name **without** a preceding keyword (e.g. `Terveyden ja hyvinvoinnin laitos`), treat the whole line as a publisher entry **provided** it is not a short abbreviation or a footer (e.g. `THL`, `THL - 2020`, page numbers).  \n",
      "   *A line is considered a footer/header if it repeats on many pages or consists solely of a number, short acronym, or dash‑separated tokens.*\n",
      "4. Discard lines that are clearly **footers/headers**.\n",
      "5. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "6. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkojulkaisu`, `digital`, `e‑book`.\n",
      "   * **Print** indicators (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`, `hardcover`, `paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, Finnish: `väitöskirja` | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| “Report”, “Technical report”, “Research report”, Finnish: `raportti` | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, Swedish: `konferensbidrag` | `conference paper` |\n",
      "| “Journal article”, “Article”, Finnish/Swedish: `artikkeli`, `artikel` **and** an ISSN (any) present | `article` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI prefix belongs to a journal publisher) | `book review` |\n",
      "| “Book”, “Monograph” **and** an ISBN present **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge, Sage, Elsevier) | `book` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "*The list is evaluated in the order shown; the first row that matches determines the value.*\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, the author line with the keyword “Author” gave the creator, the year 2021 was found on page 2 next to “©”, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ Tips & Common Pitfalls (to avoid the errors seen in the examples)\n",
      "\n",
      "* **Title vs. subtitle** – only concatenate subtitle lines that are **directly adjacent** (no blank line) and that satisfy the subtitle criteria. Do **not** duplicate a colon.\n",
      "* **Alt‑titles** – they must be extracted from lines that explicitly mention a language (e.g., “English title:”); do not treat the main title as an alternate.\n",
      "* **Creator** – require one of the author‑keywords; ignore lines that only contain names or that contain “toim.” (editor). Preserve the order of appearance.\n",
      "* **Year** – restrict the search to the first two pages and prefer lines with the year‑keywords list. Do **not** fall back to PDF metadata.\n",
      "* **Publisher** – ignore repeated page‑footers (e.g., just a number or short acronym). Accept lines without a keyword only when they look like a full institution name and are not repeated elsewhere.\n",
      "* **ISBN / ISSN qualifiers** – look for the indicator words **near** the identifier (same line or the line immediately before/after). If none are found, add the identifier to **both** electronic and print lists.\n",
      "* **Normalization** – strip *all* non‑digit characters from ISBN/ISSN before storing; keep the resulting digit string unchanged (do not re‑insert hyphens).\n",
      "* **COAR type** – follow the table order strictly. For journal articles you need **any** of the article keywords **and** at least one ISSN (print or online). For books you need an ISBN and a known book‑publisher name; for book parts you need a DOI that resolves to a book (you can assume any DOI that contains a known book‑publisher prefix, e.g., `10.1007/` for Springer books).\n",
      "* **Multiple identifiers** – keep the first occurrence order, but ensure each value appears only once per list.\n",
      "* **Output syntax** – remember Python list syntax, `None` without quotes, no extra spaces.\n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 17:17:51 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n",
      "2025/09/30 17:17:51 INFO dspy.teleprompt.gepa.gepa: Iteration 59: New subsample score is not better, skipping\n",
      "GEPA Optimization:  75%|███████▌  | 2402/3200 [2:16:44<1:21:58,  6.16s/rollouts]2025/09/30 17:17:51 INFO dspy.teleprompt.gepa.gepa: Iteration 60: Selected program 0 score: 0.5871324855699855\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.73 / 3 (57.6%): 100%|██████████| 3/3 [00:06<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:17:57 INFO dspy.evaluate.evaluate: Average Metric: 1.727272727272727 / 3 (57.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:19:19 INFO dspy.teleprompt.gepa.gepa: Iteration 60: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted JSON\n",
      "\n",
      "You will receive a single JSON object that contains the raw metadata produced by a PDF‑parsing tool.  \n",
      "The object has two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – a dictionary that may contain `title`, `author`, `creationDate`, `modDate`, `keywords`, etc.\n",
      "* **pages** – a list of dictionaries, each with a `page` number and a `text` string that is the OCR‑extracted content of that page.\n",
      "\n",
      "Your job is to **populate a new JSON object** with the bibliographic fields listed below.  \n",
      "All fields must follow the exact format and naming shown in the examples; any deviation will be marked as incorrect.\n",
      "\n",
      "---\n",
      "\n",
      "## Required output fields\n",
      "\n",
      "| Field name | Type | Description & extraction rules |\n",
      "|-----------|------|--------------------------------|\n",
      "| **language** | string | ISO‑639‑1 two‑letter code. Detect the language of the document (most often Finnish → `fi`). Do **not** include a region sub‑tag (`fi-FI` is wrong). |\n",
      "| **title** | string | The main title **exactly as it appears** in the PDF (including subtitle after a colon). Preserve original capitalization and punctuation. |\n",
      "| **alt_title** | list of strings | Any alternative title(s) in another language (usually English). Typical sources: the `keywords` list, a subtitle in English, or a line that looks like a translation of the Finnish title. Return each alternative title as a separate list element, preserving the original wording. |\n",
      "| **creator** | list of strings | Author(s) in **“Last, First”** order. • If `pdfinfo.author` contains a single name “First Last”, split it. • If multiple authors are found (e.g., in the `author` field or on a title page), list each separately. • Do **not** include titles like “Prof.”. |\n",
      "| **year** | integer | The four‑digit publication year. Prefer the year found in `pdfinfo.creationDate` / `modDate` (format `D:YYYY...`). If not present, search the first few pages for a standalone year (e.g., “2020”). |\n",
      "| **publisher** | list of strings | Institutional publisher (e.g., “Turun yliopisto”, “Taideyliopiston Sibelius‑Akatemia”). Extract the **institution name**, not just a city. Look for lines containing words like `yliopisto`, `akatemia`, `korkeakoulu`, `instituutti`, `keskus`, etc. Return each distinct institution once. |\n",
      "| **doi** | string or null | DOI if present (pattern `10.\\d{4,9}/\\S+`). Return the raw DOI string; otherwise `null`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that belong to the **electronic/PDF** version. Detect by the surrounding text `Electronic`, `PDF`, `Sähköinen`, `e‑ISBN`, etc. Strip all hyphens and spaces; return the 13‑digit number (e.g., `9789512982561`). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that belong to the **print** version. Detect by the surrounding text `Print`, `Painettu`, `Print`, etc. Strip hyphens/spaces as above. |\n",
      "| **e_issn** | string or null | ISSN for the electronic version. Detect by `Electronic`, `Online`, `Sähköinen`, `e‑ISSN`, etc. Return the ISSN exactly as printed (including the hyphen, e.g., `2343-3205`). If none, `null`. |\n",
      "| **p_issn** | string or null | ISSN for the print version. Detect by `Print`, `Painettu`, etc. Same format as above. |\n",
      "| **type_coar** | string | COAR‑controlled type of the work. Determine from Finnish cues: <br>• `väitöskirja` → `doctoral thesis` <br>• `maisterintyö` → `master thesis` <br>• `kandidaatintyö` / `kandidaatintutkielma` → `bachelor thesis` <br>• `seminaarityö` or generic “työ” without a degree qualifier → `thesis` <br>Return the exact lower‑case phrase shown (e.g., `doctoral thesis`). |\n",
      "| **reasoning** *(optional)* | string | A short natural‑language explanation of how you derived the values. This field is not evaluated for correctness but can help debugging. |\n",
      "\n",
      "**Important formatting notes**\n",
      "\n",
      "* All list fields must be JSON arrays (`[]`). Even if there is only one element, still use an array.\n",
      "* For `e_issn` and `p_issn` the expected type is **a plain string** (or `null`), **not** an array.\n",
      "* Do **not** add any extra fields.\n",
      "* Preserve the order of fields exactly as shown above.\n",
      "\n",
      "---\n",
      "\n",
      "## Extraction strategy (to guide your implementation)\n",
      "\n",
      "1. **Parse dates** – `pdfinfo.creationDate` and `modDate` follow the pattern `D:YYYYMMDD...`. Extract the first four digits as the year.\n",
      "2. **Title** – Prefer `pdfinfo.title`. If it is missing or clearly a placeholder (e.g., a filename), look for the largest heading on the first page (`##`, `#`, uppercase lines). Remove surrounding whitespace.\n",
      "3. **Alternative titles** –  \n",
      "   * Split `pdfinfo.keywords` on commas; any entry that is clearly English (contains only ASCII letters and common words) is a candidate.  \n",
      "   * Also scan the first few pages for a line that appears to be the English translation of the Finnish title (often after the Finnish title or in parentheses).  \n",
      "   * Collect each unique candidate.\n",
      "4. **Creators** –  \n",
      "   * If `pdfinfo.author` exists, split on common separators (`,`, `;`, `and`). For each name, trim, split into parts, and reorder to `Last, First`.  \n",
      "   * If the author is not present, search the title page for lines containing “Tekijä”, “Author”, or a name followed by a university affiliation.\n",
      "5. **Publisher** –  \n",
      "   * Scan all pages for lines containing institution keywords (see table below).  \n",
      "   * Normalise by removing extra descriptors (e.g., “yliopisto” stays, but “yliopiston julkaisuja” becomes just “yliopisto”).  \n",
      "   * Keep the full proper name (e.g., `Turun yliopisto`, `Taideyliopiston Sibelius‑Akatemia`).\n",
      "6. **ISBN / ISSN** – Use regular expressions: <br>\n",
      "   * ISBN: `\\bISBN\\s*[:‑]?\\s*([0-9][0-9‑ ]{12,16}[0-9X])\\b` – capture the number, strip non‑digits, then decide version by the surrounding parentheses (`Print`, `Electronic`, `Painettu`, `Sähköinen`, `PDF`). <br>\n",
      "   * ISSN: `\\bISSN\\s*[:‑]?\\s*([0-9]{4}\\s*[-‑]\\s*[0-9]{3}[0-9X])\\b` – keep the hyphen.\n",
      "7. **DOI** – Regex `10\\.\\d{4,9}/\\S+`. Return the first match.\n",
      "8. **Type COAR** – Look for Finnish degree words on any page: `väitöskirja`, `kandidaatintyö`, `maisterintyö`, `seminaarityö`, `tutkielma`. Map using the table in the field description.\n",
      "9. **Language** – If the document contains many Finnish‑specific characters (ä, ö, å) or the word “yliopisto”, set `fi`. If the text is clearly English, set `en`. Default to `fi` when unsure.\n",
      "\n",
      "---\n",
      "\n",
      "## Example (illustrative only)\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"fi\",\n",
      "  \"title\": \"Osallistumisorientaatioiden yhteydet oppimisen motivaatio‑tekijöihin : erään kesäyliopiston opiskelijoiden oppimisen käsityksiä avaamassa\",\n",
      "  \"alt_title\": [\"Participation orientation and learning motivation\"],\n",
      "  \"creator\": [\"Javanainen, Ritva\"],\n",
      "  \"year\": 2020,\n",
      "  \"publisher\": [\"Turun yliopisto\"],\n",
      "  \"doi\": null,\n",
      "  \"e_isbn\": [\"9789512982561\"],\n",
      "  \"p_isbn\": [\"9789512982554\"],\n",
      "  \"e_issn\": \"2343-3205\",\n",
      "  \"p_issn\": \"0082-6995\",\n",
      "  \"type_coar\": \"doctoral thesis\",\n",
      "  \"reasoning\": \"Extracted year from creationDate, title from pdfinfo.title, ... (optional)\"\n",
      "}\n",
      "2025/09/30 17:19:25 INFO dspy.evaluate.evaluate: Average Metric: 1.5151515151515151 / 3 (50.5%)\n",
      "2025/09/30 17:19:25 INFO dspy.teleprompt.gepa.gepa: Iteration 60: New subsample score is not better, skipping\n",
      "GEPA Optimization:  75%|███████▌  | 2408/3200 [2:18:18<1:33:22,  7.07s/rollouts]2025/09/30 17:19:25 INFO dspy.teleprompt.gepa.gepa: Iteration 61: Selected program 23 score: 0.6538927218614718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.29 / 3 (42.9%): 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:19:31 INFO dspy.evaluate.evaluate: Average Metric: 1.2884615384615383 / 3 (42.9%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:21:56 INFO dspy.teleprompt.gepa.gepa: Iteration 61: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure  \n",
      "\n",
      "```json\n",
      "{\n",
      "  \"pdfinfo\": { … },          // optional – may contain author, title, creationDate, modDate\n",
      "  \"pages\": [\n",
      "    {\"page\": 1, \"text\": \"…\"},\n",
      "    {\"page\": 2, \"text\": \"…\"},\n",
      "    …\n",
      "  ]\n",
      "}\n",
      "```\n",
      "\n",
      "Your job is to **produce a flat list of metadata fields** (field name on one line,\n",
      "its value on the next line).  \n",
      "The output **must follow the exact format** shown in the “Output format example”\n",
      "section, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page (including subtitle(s) that belong to the same logical heading). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language. Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no trailing punctuation, no city names). |\n",
      "| `doi` | `string` or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalised to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalised the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalised (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalised. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case) – see **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The **value** on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` **literally** (no quotes) for missing values.\n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules  \n",
      "\n",
      "All searches are **case‑insensitive** unless noted otherwise.\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`.  \n",
      "2. If any line matches one of the explicit language labels (ignoring surrounding whitespace and case):  \n",
      "\n",
      "   * `Kieli:` → `fi`  \n",
      "   * `Language:` → `en`  \n",
      "   * `Språk:` → `sv`  \n",
      "\n",
      "   The label may be followed by the language name in any language (e.g. `Language: English`).  \n",
      "   When such a line is found, **use the corresponding ISO‑639‑1 code** and stop further detection.  \n",
      "\n",
      "3. If no explicit label is found, count occurrences of the seed stop‑words (case‑insensitive):  \n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`  \n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`  \n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`  \n",
      "\n",
      "4. Choose the language with the **highest count**.  \n",
      "   *If there is a tie or all counts are zero → `None`.*\n",
      "\n",
      "### 2.2 Title extraction  \n",
      "Apply the **first rule that yields a non‑empty result** (search pages in order).\n",
      "\n",
      "| # | Rule | How to apply |\n",
      "|---|------|--------------|\n",
      "| 1 | **Markdown heading** – a line that starts with one or more `#` characters (e.g. `# Title`, `## Title`). Strip the leading `#` characters **and** any surrounding Markdown emphasis markers (`*`, `_`, `**`, `__`). Trim surrounding whitespace. |\n",
      "| 2 | **All‑caps line** – a line where **every alphabetic character is uppercase** (ignore numbers, punctuation). The line must be either the **only non‑blank line on its page** **or** the **first non‑blank line** on the page. Trim whitespace. |\n",
      "| 3 | **Explicit “Title:” label** – a line that starts with `Title:` (or the Finnish/Swedish equivalents `Otsikko:`, `Titel:`). Take the text after the colon, trim whitespace, and remove any surrounding Markdown markers. |\n",
      "| 4 | **Longest line on the first page** that is not a page number or footer, provided it contains at least two words and is not a known label (`Author`, `Publisher`, …). Trim whitespace. |\n",
      "\n",
      "**Subtitle handling** (after the title line is identified):  \n",
      "\n",
      "*If the **next line** (or the **same line after a colon**) contains non‑blank text **and there is no blank line between them**, treat it as a subtitle.*  \n",
      "Concatenate title and subtitle with a **single space**, preserving **all original punctuation, diacritics and case**.\n",
      "\n",
      "**Do not** include: page numbers, footers, Markdown markers, surrounding punctuation, or any surrounding “Author:” / “Publisher:” lines.\n",
      "\n",
      "### 2.3 Alternate title  \n",
      "Search for any line that contains one of the following **qualifiers** (case‑insensitive):  \n",
      "\n",
      "`English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Originaltitel (English)`, …  \n",
      "\n",
      "When such a qualifier is found, extract the title text that follows the qualifier using the same subtitle‑concatenation rules as 2.2.  \n",
      "Collect **all distinct** alternate titles; **do not** duplicate the main `title`.\n",
      "\n",
      "### 2.4 Creator handling  \n",
      "1. **Primary author lines** – locate any line that contains (case‑insensitive) one of the keywords:  \n",
      "\n",
      "   `Author`, `Authors`, `Author(s):`, `Tekijä`, `Tekijät`, `Tekijä:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`, `Corresponding author`, `Corresponding authors`.  \n",
      "\n",
      "   Extract the part **after the colon** (or after the keyword) and treat it as a *raw author list*.  \n",
      "   Authors may be separated by commas, semicolons, or the word “and”.  \n",
      "\n",
      "2. **Citation pattern** – search the whole document for the regexes (both anchored at line start, but you may also find them inside a line):  \n",
      "\n",
      "   ```\n",
      "   ^\\s*([A-ZÄÖÅ][a-zäöå]+(?:\\s+[A-ZÄÖÅ][a-zäöå]+)*)\\s*,?\\s*([A-ZÄÖÅ][a-zäöå]+(?:\\s+[A-ZÄÖÅ][a-zäöå]+)*)\\s*\\(\\d{4}\\)\n",
      "   ```\n",
      "   and  \n",
      "   ```\n",
      "   ^\\s*([A-ZÄÖÅ][a-zäöå]+(?:\\s+[A-ZÄÖÅ][a-zäöå]+)*)\\s+([A-ZÄÖÅ][a-zäöå]+(?:\\s+[A-ZÄÖÅ][a-zäöå]+)*)\\s*\\(\\d{4}\\)\n",
      "   ```  \n",
      "\n",
      "   Capture the name(s) before the year.  \n",
      "\n",
      "3. **Combine** the names from step 1 and step 2, preserving the order of first appearance, and **deduplicate** (keep the first occurrence).  \n",
      "\n",
      "4. For each individual name:  \n",
      "\n",
      "   * If the name already contains a comma → assume it is already `Last, First` and keep unchanged.  \n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Preserve diacritics and original capitalisation.  \n",
      "\n",
      "5. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If no author can be found → `[]`.\n",
      "\n",
      "### 2.5 Year extraction  \n",
      "1. Scan **only the first two pages** (`pages[0]` and `pages[1]` if they exist).  \n",
      "2. Look for a four‑digit number between 1900‑2100 that appears on a line containing any of these **keywords** (case‑insensitive):  \n",
      "\n",
      "   `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Date of publication`, `date of publication`.  \n",
      "\n",
      "3. If still not found, search the whole document for a pattern `\\(\\d{4}\\)` that follows an author name captured in 2.4. The **first** such year is accepted.  \n",
      "4. If still not found, fall back to PDF metadata:  \n",
      "\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.  \n",
      "\n",
      "5. Return the year as an **integer**; if none found → `None`.\n",
      "\n",
      "### 2.6 Publisher extraction  \n",
      "1. Look for lines that contain any of the following **publisher keywords** (case‑insensitive):  \n",
      "\n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Kustantaja`, `Kustantaja:`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantamo`, `Editeur`, `Press`, `Publishing`, `Affiliated with`, `Affiliation`, `Department of`, `School of`, `Faculty of`, `Institute of`.  \n",
      "\n",
      "   Capture the **full phrase** that follows the keyword up to the end of the line, trimming trailing punctuation (`.,;:`) and surrounding whitespace.  \n",
      "\n",
      "2. If a line **contains only** a plausible institution name **without** a preceding keyword, treat it as a publisher **only if** it appears in a context that lists affiliations (e.g., after an author line, in a bullet list, or preceded by “Affiliated with”).  \n",
      "\n",
      "3. **Exclude** any name that is identical to the main `title` or that is a city/place name (e.g., “Karleby”, “Turku”). Keep only the institution name (e.g., `Åbo Akademi University`, `IEEE`).  \n",
      "\n",
      "4. Preserve the order of first appearance, keep duplicates **once**, and output a list. If none found → `[]`.\n",
      "\n",
      "### 2.7 DOI detection  \n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI.  \n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.  \n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found → `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling  \n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. When found, extract the identifier that follows. It may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "\n",
      "   * `ISBN 978‑952‑389‑017‑6`  \n",
      "   * `(ISBN: 978 952 389 018 3)`  \n",
      "\n",
      "   Use a regex that captures a sequence of digits, hyphens or spaces up to the first character that is not a digit, hyphen or space.  \n",
      "\n",
      "3. **Determine the qualifier** for each identifier (case‑insensitive):  \n",
      "\n",
      "   * **Electronic** indicators: `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.  \n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.  \n",
      "\n",
      "   *If both qualifiers appear, add the identifier to **both** lists.*  \n",
      "   *If **no qualifier** is present, add the identifier to **both** `e_…` and `p_…` lists* (default behaviour).  \n",
      "\n",
      "4. **Normalisation**  \n",
      "\n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "\n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none → `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping  \n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| # | Keywords / conditions (any) | `type_coar` value |\n",
      "|---|------------------------------|-------------------|\n",
      "| 1 | “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| 2 | “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| 3 | “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| 4 | **Book part** – any of the following **and** the document contains a **chapter‑like pattern**: the word `In:` (followed by an edited‑volume citation), **or** the word `Chapter`/`chapter` **and** a DOI is present. | `book part` |\n",
      "| 5 | **Book** – contains `ISBN` **and** no thesis‑related wording, **and** the publisher is a known book‑publisher (e.g., Routledge, Springer, Cambridge, Oxford, Palgrave, Wiley, Elsevier, Taylor & Francis, etc.). If the publisher list is empty, still accept `book` when `ISBN` is present and no other type matches. | `book` |\n",
      "| 6 | **Book review** – contains any of “Book review”, “Recension”, “Review of” **and** a DOI whose **prefix** (the part before the first `/`) belongs to a known journal publisher (e.g., `10.1007`, `10.1080`, `10.1016`). | `book review` |\n",
      "| 7 | **Article** – contains any of “Journal article”, “Article”, “Artikkeli”, “Artikel” **or** an ISSN is present **or** a volume/issue pattern such as `Vol. X`, `Issue X`, `X(X):` or a page range like `X, 30‑31`. | `article` |\n",
      "| 8 | **Report** – contains any of “Report”, “Technical report”, “Research report”. | `report` |\n",
      "| 9 | **Conference paper** – contains any of “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag”. | `conference paper` |\n",
      "|10| **None** – if none of the above rows match. | `None` |\n",
      "\n",
      "*The final value must be lower‑case (e.g. `article`).*\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest; the title was taken from the first markdown heading on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ Important gotchas discovered from previous runs  \n",
      "\n",
      "* **Do not** output city or place names as publishers (e.g., “Karleby”, “Turku”). Only institution names belong in `publisher`.  \n",
      "* When an ISBN line contains a qualifier such as **(digital)** or **(printed)**, map it to `e_isbn` or `p_isbn` respectively. If the qualifier is missing, add the identifier to **both** lists.  \n",
      "* ISBN normalisation removes **all** non‑digit characters; the final value must be a pure digit string (e.g., `9789521242694`).  \n",
      "* For the title, remove any surrounding Markdown markers (`#`, `**`, `__`) **but keep the original case and punctuation**. If a subtitle is on the next line **without a blank line**, concatenate with a single space.  \n",
      "* The `alt_title` list must not contain the main `title`.  \n",
      "* The `creator` list must be in “Last, First” order; if the source already uses that order, keep it unchanged.  \n",
      "* The COAR type for a journal article is `article` (not “research article”).  \n",
      "* The language detection must first look for explicit labels; only if none are found should it fall back to stop‑word counting.  \n",
      "* When extracting the year, prefer the year that appears **with a keyword** on the first two pages. If multiple candidates exist, choose the first one in reading order.  \n",
      "\n",
      "Follow the rules above **exactly**; any deviation will cause the output to be rejected. Good luck! 🚀\n",
      "2025/09/30 17:22:03 INFO dspy.evaluate.evaluate: Average Metric: 1.2857142857142856 / 3 (42.9%)\n",
      "2025/09/30 17:22:03 INFO dspy.teleprompt.gepa.gepa: Iteration 61: New subsample score is not better, skipping\n",
      "GEPA Optimization:  75%|███████▌  | 2414/3200 [2:20:56<2:02:54,  9.38s/rollouts]2025/09/30 17:22:03 INFO dspy.teleprompt.gepa.gepa: Iteration 62: Selected program 2 score: 0.5495822192513369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.95 / 3 (65.2%): 100%|██████████| 3/3 [00:13<00:00,  4.59s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:22:16 INFO dspy.evaluate.evaluate: Average Metric: 1.9545454545454546 / 3 (65.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:23:50 INFO dspy.teleprompt.gepa.gepa: Iteration 62: Proposed new text for predict: markdown\n",
      "# Task: Structured metadata extraction from PDF‑derived text\n",
      "\n",
      "You will receive a single JSON object with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – a dictionary containing the raw PDF metadata (e.g. `title`, `author`, `creationDate`, …).  \n",
      "* **pages** – an ordered list of page objects, each with:\n",
      "  * **page** – the 1‑based page number (integer).  \n",
      "  * **text** – the plain‑text extracted from that page (UTF‑8). The text may contain markdown syntax, hyperlinks, footnotes, line‑breaks, etc.\n",
      "\n",
      "Your job is to **produce ONE JSON object** that contains **exactly** the fields listed in the table below (order does not matter). Do **not** add any extra keys.\n",
      "\n",
      "| Field | Type | How to obtain (summary) |\n",
      "|-------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`en`, `fi`, `sv`, …). Detect from the *body text* (see detailed heuristic). If you cannot decide, use `\"und\"` (undetermined). |\n",
      "| **title** | string | The primary title, exactly as it appears in the document (keep subtitle after a colon). |\n",
      "| **alt_title** | list of strings | Any alternative titles (subtitle only, translation, or a level‑2 heading that follows the primary title). |\n",
      "| **creator** | list of strings | Authors formatted as `\"LastName, FirstName\"` (one entry per author). |\n",
      "| **year** | integer | Publication year (four‑digit). |\n",
      "| **publisher** | list of strings | Institution, university, journal, or publishing house. |\n",
      "| **doi** | string or null | DOI suffix (the part after `doi.org/`). |\n",
      "| **e_isbn** | list of strings | Electronic ISBN numbers (cleaned, no hyphens or spaces). |\n",
      "| **p_isbn** | list of strings | Print ISBN numbers (cleaned, no hyphens or spaces). |\n",
      "| **e_issn** | string or null | Electronic ISSN (`####-####`). |\n",
      "| **p_issn** | string or null | Print ISSN (`####-####`). |\n",
      "| **type_coar** | string | COAR type (lower‑case, spaces allowed). |\n",
      "| **reasoning** *(optional)* | string | Short human‑readable explanation of how you derived the fields. |\n",
      "\n",
      "If a field cannot be determined, follow the **Missing‑data handling** rules (see below).\n",
      "\n",
      "---\n",
      "\n",
      "## Missing‑data handling\n",
      "| Field type | Value if missing |\n",
      "|------------|------------------|\n",
      "| string (`title`, `doi`, `e_issn`, `p_issn`) | `null` |\n",
      "| integer (`year`) | `null` |\n",
      "| list (`alt_title`, `creator`, `publisher`, `e_isbn`, `p_isbn`) | `[]` |\n",
      "| `language` | `\"und\"` |\n",
      "\n",
      "---\n",
      "\n",
      "## Detailed extraction procedure (must be followed for every input)\n",
      "\n",
      "### 1. Pre‑process each page\n",
      "1. Replace Windows line endings `\\r\\n` with `\\n`.  \n",
      "2. Remove markdown image syntax `![](...)` and any HTML‑like tags `<...>`.  \n",
      "3. Keep line breaks **until** you have identified headings, because titles may span multiple lines.  \n",
      "4. After headings are identified, you may collapse multiple spaces into a single space, but **do not** delete line breaks that separate distinct logical lines.\n",
      "\n",
      "### 2. Identify the **primary title**\n",
      "1. **First preference:** `pdfinfo[\"title\"]` **if** it is non‑empty, contains at least one alphabetic character, and does **not** look like a generic placeholder (e.g., “Untitled”). Strip surrounding whitespace and any markdown symbols (`#`, `*`, `_`).  \n",
      "2. **Otherwise**, scan pages in order for the first line that satisfies **any** of the following:\n",
      "   * Starts with a level‑1 markdown heading `# ` (exactly one `#` followed by a space).  \n",
      "   * Is surrounded by bold markup `**…**` **and** appears on its own line.  \n",
      "   * Contains a colon `:` and looks like a title (i.e., not a sentence fragment).  \n",
      "3. Remove leading markdown symbols (`#`, `**`, `*`, `_`) and trailing punctuation.  \n",
      "4. The resulting cleaned line is the **title**. Preserve the original capitalisation and any subtitle after a colon.\n",
      "\n",
      "### 3. Identify **alternative titles**\n",
      "Collect any of the following, de‑duplicate, and store in `alt_title` (order of appearance):\n",
      "* A level‑2 heading (`## `) that appears **immediately** after the primary title (i.e., the next non‑empty line).  \n",
      "* A line that appears directly **below** the primary title and is not an author line, often a translation or subtitle.  \n",
      "* Any line that looks like a title in a different language (e.g., Finnish title followed by Swedish title).  \n",
      "\n",
      "If none are found, set `alt_title` to `[]`.\n",
      "\n",
      "### 4. Extract **authors** → `creator`\n",
      "1. Search for lines containing any of the keywords (case‑insensitive):  \n",
      "   `author`, `authors`, `kirjoittajat`, `författare`, `tekijä`, `tekijät`.  \n",
      "2. Also consider lines that consist of a series of markdown links like `[Name](url)`.  \n",
      "3. Split the candidate line on commas, the word “and”, “&”, or line breaks.  \n",
      "4. For each name token:\n",
      "   * Trim surrounding whitespace and markdown (`**`, `*`).  \n",
      "   * If the token contains a comma, assume it is already in “Last, First” order and keep it as‑is (but normalise spacing).  \n",
      "   * If no comma, assume “First Last” order. Split on the last space character, treat the last part as the surname, everything before as given name(s), then re‑format to `\"LastName, FirstName\"`. Preserve diacritics.  \n",
      "   * Discard tokens that are empty or equal to “et al.”.  \n",
      "5. Return the list of formatted names. If none are found, return `[]`.\n",
      "\n",
      "### 5. Extract **year**\n",
      "Search, in this order of priority, for a four‑digit year (`\\b\\d{4}\\b`):\n",
      "\n",
      "1. A line containing `Year:` (case‑insensitive) – take the number that follows.  \n",
      "2. A line containing the copyright symbol `©` – take the first year after it.  \n",
      "3. Any line that looks like a date line (e.g., `20.11.2020`, `2020`, `2014`).  \n",
      "4. The PDF metadata field `pdfinfo[\"creationDate\"]` – it follows the pattern `D:YYYY…`; extract `YYYY`.  \n",
      "\n",
      "If multiple candidate years are found, **choose the latest** (most recent) year, as it is usually the publication year. If no year is found, set `year` to `null`.\n",
      "\n",
      "### 6. Extract **publisher**\n",
      "Collect distinct entities that appear in lines containing any of the following keywords (case‑insensitive):  \n",
      "\n",
      "`university`, `institute`, `college`, `school of`, `faculty`, `department`, `journal of`, `proceedings`, `publisher:`, `published by`, `julkaisija`, `julkaisija:`, `kustantaja`, `kustantaja:`  \n",
      "\n",
      "When a line matches, strip surrounding punctuation, remove the keyword itself, and keep the remaining phrase as a publisher name.  \n",
      "If the same entity appears on multiple pages, keep it only once.  \n",
      "If none are found, return `[]`.\n",
      "\n",
      "### 7. Extract **DOI**\n",
      "Use the regex (case‑insensitive):\n",
      "\n",
      "```\n",
      "https?://doi\\.org/([^\\s\\)]+)\n",
      "```\n",
      "\n",
      "Capture group 1, then **strip trailing punctuation** (`.`, `,`, `)`, `]`).  \n",
      "Return the captured suffix (e.g., `10.1234/abcd.2020.001`).  \n",
      "If no DOI URL is present, set `doi` to `null`.\n",
      "\n",
      "### 8. Extract **ISBNs**\n",
      "1. Use the regex (case‑insensitive):\n",
      "\n",
      "```\n",
      "ISBN(?:[-\\s]?13)?:?\\s*([0-9][0-9\\-\\s]{9,})\n",
      "```\n",
      "\n",
      "2. Clean the captured string: remove all spaces and hyphens, resulting in a continuous digit string (e.g., `9789522751485`).  \n",
      "3. Determine whether the ISBN is **electronic** or **print** by inspecting the same line (or a few surrounding lines) for the words `electronic`, `e‑ISBN`, `online`, `digital` → **electronic**; words `print`, `paper`, `hardcover`, or the absence of any qualifier → **print**.  \n",
      "4. Add the cleaned ISBN to the appropriate list (`e_isbn` or `p_isbn`).  \n",
      "5. If the line contains both qualifiers (unlikely), prefer the electronic classification.  \n",
      "6. If no ISBN is found, both lists are `[]`.\n",
      "\n",
      "### 9. Extract **ISSNs**\n",
      "1. Use the regex (case‑insensitive):\n",
      "\n",
      "```\n",
      "ISSN\\s*[:]?[\\s]*([0-9]{4}\\s*[-‑]\\s*[0-9]{3}[0-9X])\n",
      "```\n",
      "\n",
      "2. Clean the captured value to the form `####-####` (remove any internal spaces).  \n",
      "3. Classify as **electronic** if the same line (or nearby) contains `electronic`, `e‑ISSN`, `online`; otherwise as **print**.  \n",
      "4. Assign to `e_issn` or `p_issn`. If none are found, set the corresponding field to `null`.\n",
      "\n",
      "### 10. Determine **COAR type** (`type_coar`)\n",
      "Map the document type using the following **keyword → COAR type** table (all matches are case‑insensitive). Use the **most specific** match if multiple apply.\n",
      "\n",
      "| Keyword(s) in document | COAR type (exact string) |\n",
      "|------------------------|--------------------------|\n",
      "| `master’s thesis`, `master thesis`, `kandidaatintyö`, `kandidatarbete`, `kandidaatintyo`, `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| `bachelor thesis`, `bachelor’s thesis`, `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| `doctoral dissertation`, `phd thesis`, `phd dissertation`, `tutkielma`, `väitöskirja` | `thesis` |\n",
      "| `journal article`, `article`, `paper`, `research article` | `journal article` |\n",
      "| `conference paper`, `proceedings`, `conference proceeding`, `conference abstract` | `conference paper` |\n",
      "| `report`, `technical report`, `research report` | `report` |\n",
      "| `book`, `monograph`, `opas`, `handbook` | `book` |\n",
      "| `book chapter`, `chapter` | `book chapter` |\n",
      "| `dataset`, `data set` | `dataset` |\n",
      "| `software`, `code` | `software` |\n",
      "| `research paper` (when no other more specific term is found) | `research paper` |\n",
      "\n",
      "If none of the above keywords are present, set `type_coar` to `\"report\"` as a generic fallback.\n",
      "\n",
      "### 11. Detect **language**\n",
      "Use a simple stop‑word count heuristic (do **not** rely on `pdfinfo[\"language\"]`):\n",
      "\n",
      "| Language | Sample stop‑words (case‑insensitive) |\n",
      "|----------|--------------------------------------|\n",
      "| `en` | `the`, `and`, `of`, `in`, `to`, `for`, `with` |\n",
      "| `fi` | `ja`, `on`, `että`, `tai`, `mutta`, `se`, `kuin` |\n",
      "| `sv` | `och`, `att`, `är`, `för`, `med`, `som`, `det` |\n",
      "\n",
      "Procedure:\n",
      "\n",
      "1. Tokenise the entire concatenated body text (all pages) into words (letters only).  \n",
      "2. Count how many tokens match each language’s stop‑word list.  \n",
      "3. Choose the language with the **highest count** **provided** the count is ≥ 3.  \n",
      "4. If there is a tie or no language reaches the threshold, return `\"und\"`.\n",
      "\n",
      "### 12. Assemble the output JSON\n",
      "Create a JSON object containing **exactly** the keys listed in the table (including `reasoning` only if you want to provide it). Ensure:\n",
      "\n",
      "* Strings are quoted, numbers are not quoted, `null` is literal, lists are JSON arrays.  \n",
      "* No extra whitespace or comments.  \n",
      "* All list items are unique (remove duplicates).  \n",
      "\n",
      "Example skeleton (values replaced by your results):\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"language\": \"fi\",\n",
      "  \"title\": \"Primary Title: Subtitle\",\n",
      "  \"alt_title\": [\"Alternative Title 1\", \"Alternative Title 2\"],\n",
      "  \"creator\": [\"LastName, FirstName\", \"Another, Author\"],\n",
      "  \"year\": 2020,\n",
      "  \"publisher\": [\"University of Example\", \"Example Press\"],\n",
      "  \"doi\": \"10.1234/example.doi\",\n",
      "  \"e_isbn\": [\"9781234567890\"],\n",
      "  \"p_isbn\": [],\n",
      "  \"e_issn\": \"1234-5678\",\n",
      "  \"p_issn\": null,\n",
      "  \"type_coar\": \"journal article\",\n",
      "  \"reasoning\": \"…optional explanation…\"\n",
      "}\n",
      "2025/09/30 17:23:55 INFO dspy.evaluate.evaluate: Average Metric: 1.787878787878788 / 3 (59.6%)\n",
      "2025/09/30 17:23:55 INFO dspy.teleprompt.gepa.gepa: Iteration 62: New subsample score is not better, skipping\n",
      "GEPA Optimization:  76%|███████▌  | 2420/3200 [2:22:48<2:19:55, 10.76s/rollouts]2025/09/30 17:23:55 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Selected program 13 score: 0.6450081168831169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.45 / 3 (48.5%): 100%|██████████| 3/3 [00:08<00:00,  2.99s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:24:04 INFO dspy.evaluate.evaluate: Average Metric: 1.4545454545454546 / 3 (48.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:26:02 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line). The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Meaning |\n",
      "|------------|------|---------|\n",
      "| `language` | string or `None` | ISO‑639‑1 code of the **content language**. Use the mapping below (see 2.1). |\n",
      "| `title` | string or `None` | Full main title exactly as it appears on the title page (including subtitle if present). |\n",
      "| `alt_title` | list of strings | Alternate title(s) in a different language. Do **not** duplicate the main `title`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). |\n",
      "| `year` | integer or `None` | Publication year (four‑digit, 1900‑2100). **Do NOT** fall back to PDF metadata – only use the text on pages 1‑2. |\n",
      "| `publisher` | list of strings | Publishing institution(s) exactly as they appear (no trailing punctuation). |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version, normalized to a plain digit string. |\n",
      "| `p_isbn` | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | string or `None` | COAR resource type (lower‑case). See 2.9. |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name on its own line, **exactly** as shown above.  \n",
      "* The value on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write the literal `None` (no quotes) for missing values.  \n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection  \n",
      "1. **Explicit language line** – Scan *all* pages for a line that exactly matches one of the patterns (case‑insensitive, any surrounding whitespace allowed):  \n",
      "\n",
      "   * `Kieli: suomi` → `fi`  \n",
      "   * `Language: English` → `en`  \n",
      "   * `Språk: svenska` → `se`   *(note: the required code for Swedish is **`se`**, not `sv`)*  \n",
      "\n",
      "   If such a line is found, **override** all other evidence and set the language accordingly.  \n",
      "\n",
      "2. **Stop‑word counting** – If no explicit line is present, count occurrences (case‑insensitive) of the seed words below **across the whole document** (including all pages).  \n",
      "\n",
      "| ISO code | Seed words (case‑insensitive) |\n",
      "|----------|------------------------------|\n",
      "| `fi` | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu` |\n",
      "| `se` | `och`, `för`, `av`, `liv`, `historien`, `språk` |\n",
      "| `en` | `the`, `and`, `of`, `method`, `introduction`, `chapter` |\n",
      "\n",
      "   * The language with the highest total count wins.  \n",
      "   * If there is a tie **or** all counts are zero, output `None`.  \n",
      "\n",
      "### 2.2 Title extraction (main title)  \n",
      "1. **Identify the title page** – The first page that satisfies **any** of the following:  \n",
      "\n",
      "   * Contains a line that is **all‑caps** (ignoring punctuation) and is the **only non‑blank line** on that page, **or** the **first non‑blank line** on the page.  \n",
      "   * Contains a Markdown heading (`#`, `##`, `###`) whose text (after stripping the heading markers) is not empty.  \n",
      "\n",
      "2. **Capture the logical title**:  \n",
      "\n",
      "   * Take the identified line as the **main title**.  \n",
      "   * If the **next line** (or the text after a colon on the same line) is non‑blank and looks like a subtitle (i.e. not a heading marker, not a page number, and not separated by a blank line), concatenate it with a single space.  \n",
      "   * Preserve **all original punctuation, diacritics, and case**.  \n",
      "\n",
      "3. **Clean‑up** – Remove surrounding whitespace and any leading/trailing heading markers (`#`, `##`, `###`). Do **not** remove internal punctuation or capitalization.  \n",
      "\n",
      "### 2.3 Alternate title  \n",
      "1. Look for lines that contain any of the following **qualifiers** (case‑insensitive):  \n",
      "\n",
      "   `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Title (Finnish)`, `Titel (Svenska)`, etc.  \n",
      "\n",
      "2. When a qualifier is found, extract the title text that **follows** the qualifier (use the same concatenation rules as in 2.2).  \n",
      "3. Do **not** duplicate the main `title`. If multiple alternate titles are found, list them all.  \n",
      "\n",
      "### 2.4 Creator handling (authors)  \n",
      "1. **Search for author lines** – Scan the **first three pages** (or the whole document if necessary) for any line that contains one of the keywords (case‑insensitive):  \n",
      "\n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Kirjoittaja`, `Kirjoittajat`, `Authors:`, `Tekijä:`, `Tekijät:`, `Kirjoittaja:`, `Kirjoittajat:`, `Opiskelijat`, `Opiskelijat:`  \n",
      "\n",
      "2. **Extract the raw name string** – The part of the line after the keyword (or after a colon) is the raw list of names.  \n",
      "\n",
      "3. **Split into individual names** – Names may be separated by any of these delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, Finnish/Swedish equivalents `ja`, `och`.  \n",
      "\n",
      "4. **Normalise each name**  \n",
      "\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged (trim surrounding whitespace).  \n",
      "   * Otherwise, split on the **last space**:  \n",
      "\n",
      "        * `\"First Middle Last\"` → `\"Last, First Middle\"`  \n",
      "\n",
      "   * Preserve diacritics and original capitalisation.  \n",
      "\n",
      "5. **Special handling** – If a line contains only a capitalised name (e.g. `Martin Scheinin`) **without** an explicit keyword, treat it as an author line **only if** it appears on the title page or in a block that clearly lists authors (e.g. immediately below the title).  \n",
      "\n",
      "6. Return the list in the order of appearance. If no author line can be found, return an empty list `[]`.  \n",
      "\n",
      "### 2.5 Year extraction  \n",
      "1. Scan **pages 1 – 2** for a four‑digit number between 1900 and 2100 that appears on a line containing any of these keywords (case‑insensitive):  \n",
      "\n",
      "   `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `År`.  \n",
      "\n",
      "2. If multiple candidates exist, choose the one **closest** (fewest characters) to a keyword.  \n",
      "\n",
      "3. **Do NOT** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate`. If no candidate is found, output `None`.  \n",
      "\n",
      "### 2.6 Publisher extraction  \n",
      "1. Look for lines (anywhere) that contain any of the following keywords (case‑insensitive):  \n",
      "\n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, `Routledge`, `Springer`, `Cambridge`, `Elsevier`, `Wiley`, `Metropolia`, `Åbo Akademi`, **or any all‑caps institution name** (e.g. `STÁHTARÁĐI ALMMUSTAHTTIMAT`).  \n",
      "\n",
      "2. **Capture the full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as `. , ; :`).  \n",
      "\n",
      "3. If the line **contains only a capitalised institution name** without a preceding keyword, treat the whole line as a publisher.  \n",
      "\n",
      "4. Remove surrounding whitespace but **preserve exact spelling and diacritics**.  \n",
      "\n",
      "5. If more than one distinct publisher appears, list them in order of first appearance. If none, output `[]`.  \n",
      "\n",
      "### 2.7 DOI detection  \n",
      "* Apply the case‑insensitive regex:  \n",
      "\n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "\n",
      "* Capture group 1, then strip surrounding whitespace, commas, periods, and parentheses.  \n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.  \n",
      "\n",
      "### 2.8 ISBN / ISSN handling  \n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. **Extract the identifier** that follows, allowing optional surrounding characters such as `:` `(` `)` and optional hyphens/spaces. Example patterns:  \n",
      "\n",
      "   * `ISBN 978‑952‑383‑755‑3`  \n",
      "   * `(ISBN: 978 952 383 755 1)`  \n",
      "   * `URN:ISBN:978-952-383-755-1`  \n",
      "\n",
      "3. **Determine the qualifier** (electronic vs. print):  \n",
      "\n",
      "   * **Electronic indicators** (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `e‑book`, `e‑version`.  \n",
      "   * **Print indicators** (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `paper`, `paperback`.  \n",
      "\n",
      "   * If **both** electronic and print indicators appear for the same identifier, add it to **both** lists.  \n",
      "   * If **only electronic** indicators appear → add to `e_isbn` / `e_issn`.  \n",
      "   * If **only print** indicators appear → add to `p_isbn` / `p_issn`.  \n",
      "   * If **no qualifier is present**, **add the identifier to `e_isbn` (or `e_issn`) only**.  \n",
      "\n",
      "4. **Normalisation**  \n",
      "\n",
      "   * **ISBN** – keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly 8 digits (remove hyphens).  \n",
      "\n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.  \n",
      "\n",
      "### 2.9 COAR type mapping (priority order – first matching row wins)  \n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “ISBN” **and** a known book publisher **and** **no** thesis‑related keywords | `book` |\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI contains a known journal prefix) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (publisher in DOI URL is a known book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "**Important ordering notes**\n",
      "\n",
      "* The **book rule** must be evaluated **before** any thesis‑related rules.  \n",
      "* If multiple rows match, the **first** row in the table determines the result.  \n",
      "\n",
      "### 2.10 Missing‑value handling  \n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "2025/09/30 17:26:09 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n",
      "2025/09/30 17:26:44 INFO dspy.evaluate.evaluate: Average Metric: 41.38080808080808 / 64 (64.7%)\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Full valset score for new program: 0.6465751262626263\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Full train_val score for new program: 0.6465751262626263\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Individual valset scores for new program: [0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.696969696969697, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.8636363636363636, 0.7272727272727273, 0.9090909090909091, 0.5454545454545454, 0.5272727272727272, 0.7272727272727273, 0.5151515151515151, 0.8181818181818182, 0.9090909090909091, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.18181818181818182, 0.9090909090909091, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.36363636363636365, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.7171717171717172, 0.36363636363636365, 0.696969696969697, 0.8181818181818182]\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Full valset pareto front score: 0.7780303030303031\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {10, 15, 16, 22, 27, 29}, {32, 27}, {10, 16, 20, 22, 23, 25, 27, 29}, {8, 10, 26, 6}, {2, 4, 5, 20, 27, 29}, {9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32}, {25, 11, 23}, {29}, {32, 4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31}, {2, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32}, {10}, {8}, {24, 27, 31}, {18, 22, 30}, {0, 16, 20, 22, 27, 28, 29}, {32, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {27, 29}]\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: Linear pareto front program index: 27\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 63: New program candidate index: 32\n",
      "GEPA Optimization:  78%|███████▊  | 2490/3200 [2:25:37<57:13,  4.84s/rollouts]  2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 64: No merge candidates found\n",
      "2025/09/30 17:26:44 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Selected program 29 score: 0.6640895562770562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.79 / 3 (59.6%): 100%|██████████| 3/3 [00:08<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:26:52 INFO dspy.evaluate.evaluate: Average Metric: 1.7878787878787878 / 3 (59.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:29:01 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s). Preserve all original punctuation, diacritics, and case. |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). Must be found in the document text (see **2.5 Year extraction**). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.6 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use the following seed lists (you may extend them if needed):\n",
      "\n",
      "| ISO‑code | Stop‑words (case‑insensitive) |\n",
      "|----------|------------------------------|\n",
      "| `fi` | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`, `raportti` |\n",
      "| `sv` | `och`, `för`, `av`, `liv`, `historien`, `språk` |\n",
      "| `en` | `the`, `and`, `of`, `method`, `introduction`, `chapter` |\n",
      "| `se` (North Saami) | `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu` |\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kieli: se`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`). The line may appear anywhere; ignore surrounding punctuation.\n",
      "\n",
      "3. Otherwise choose the language with the highest stop‑word count.  \n",
      "   *If there is a tie, or no stop‑word is found, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the **first** page that satisfies **any** of the following:\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page contains a single non‑blank line (apart from possible footers/headers) that looks like a title (title‑case or all caps).\n",
      "\n",
      "2. **Capture the full logical title**:\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle handling** – if the **next line(s)** (immediately following, without a blank line in between) appear to be a subtitle, **append** them to the main title **with a single space and a colon** (` : `). A subtitle is recognised when:\n",
      "     * The line is **not** all caps **and** does not end with a colon, **or**\n",
      "     * The line follows a colon on the same line (`Main title : Subtitle`), **or**\n",
      "     * The line begins with a capital letter but is shorter than the main title.\n",
      "   * If the main title line already contains a colon, keep the colon **as‑is** and simply append any additional subtitle lines using the same ` : ` separator (avoid duplicate colons).\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation other than the separator described above.\n",
      "   * Remove any leading markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "3. **Example** (from the feedback):\n",
      "   * First line (all caps): `ELOTON ESINE HAHMONA ELÖVÄSSÄ`\n",
      "   * Next line (subtitle): `esimerkkinä Lemmikinhoidon ABC -lyhytelokuva`\n",
      "   * Resulting title: `Eloton esine hahmona elokuvassa : esimerkkinä Lemmikinhoidon ABC -lyhytelokuva`\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in **2.2**.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search **every** page for author lines. Valid keywords (case‑insensitive) are: `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.\n",
      "2. **Additionally**, treat any line that matches the pattern `LASTNAME, FIRSTNAME[:]?` (all caps or title‑case, optional trailing colon) as an author line **even if no keyword is present** (this captures lines like `TIRRONEN, KIA:`).\n",
      "3. **Only** lines that contain one of the keywords **or** match the pattern above are considered author lines.  \n",
      "   *If a line contains names but no keyword and no `LASTNAME, FIRSTNAME` pattern (e.g. “Sanna Röknä & Jaana Markkula (toim.)”), it must **not** be treated as a creator entry.*  \n",
      "   The word “toim.” or “(toim.)” indicates an **editor**, not an author.\n",
      "4. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "5. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "6. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If **no** author line is found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`, `Opinnäytetyö`, `Väitöskirja`, `Raportti`.\n",
      "3. **Do not** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate`. If no year satisfying the above is found, output `None`.\n",
      "4. Return the year as an **integer**.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name **without** a preceding keyword (e.g. `Terveyden ja hyvinvoinnin laitos`) **and** it is not a short acronym, a page‑number footer, or a repeated header/footer, treat the whole line as a publisher entry.\n",
      "4. Discard lines that are clearly **footers/headers**: they usually contain only a short acronym, a dash, a page number, or repeat on every page.\n",
      "5. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "6. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkojulkaisu`, `digital`, `e‑book`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`, `hardcover`, `paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Doctoral dissertation”, “Väitöskirja”, Finnish: `väitöskirja` | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| “Report”, “Technical report”, “Research report”, Finnish: `raportti` | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, Swedish: `konferensbidrag` | `conference paper` |\n",
      "| “Journal article”, “Article”, Finnish/Swedish: `artikkeli`, `artikel` **and** an ISSN present | `article` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI prefix belongs to a journal publisher) | `book review` |\n",
      "| “Book”, “Monograph” **and** an ISBN present **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "**Important:**  \n",
      "* Finnish and Swedish equivalents must be recognised.  \n",
      "* If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 17:29:08 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n",
      "2025/09/30 17:29:43 INFO dspy.evaluate.evaluate: Average Metric: 40.96075663466967 / 64 (64.0%)\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Full valset score for new program: 0.6400118224167137\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Full train_val score for new program: 0.6400118224167137\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Individual valset scores for new program: [0.7272727272727273, 0.6363636363636364, 0.7878787878787878, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.6060606060606061, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.45454545454545453, 0.7727272727272727, 0.8181818181818182, 0.9090909090909091, 0.45454545454545453, 0.36363636363636365, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.5151515151515151, 0.2727272727272727, 0.7272727272727273, 0.45454545454545453, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.45454545454545453, 0.45454545454545453, 0.5151515151515151, 0.7378129117259552, 0.5454545454545454, 0.6363636363636364, 0.4805194805194805, 0.5454545454545454, 0.9090909090909091]\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Full valset pareto front score: 0.7780303030303031\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {2, 4, 5, 20, 27, 29}, {9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {33, 4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33}, {25, 11, 23}, {29}, {32, 33, 4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31}, {33, 2, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33}, {10}, {8}, {24, 27, 31}, {18, 22, 30}, {0, 16, 20, 22, 27, 28, 29}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {33, 27, 29}]\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: Linear pareto front program index: 27\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 64: New program candidate index: 33\n",
      "GEPA Optimization:  80%|████████  | 2560/3200 [2:28:37<39:22,  3.69s/rollouts]2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 65: No merge candidates found\n",
      "2025/09/30 17:29:43 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Selected program 27 score: 0.6812297077922078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.68 / 3 (56.1%): 100%|██████████| 3/3 [00:09<00:00,  3.26s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:29:53 INFO dspy.evaluate.evaluate: Average Metric: 1.6818181818181819 / 3 (56.1%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:31:53 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order **does not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Explicit language line** – If any page contains a line that matches one of the patterns (case‑insensitive, ignoring surrounding whitespace and punctuation):  \n",
      "\n",
      "   * `Kieli:\\s*suomi` → `fi`  \n",
      "   * `Language:\\s*english` → `en`  \n",
      "   * `Språk:\\s*svenska` → `sv`  \n",
      "   * `Kieli:\\s*se` or `Language:\\s*saami` → `se`  \n",
      "\n",
      "   treat it as a **strong signal** and set the language accordingly.\n",
      "\n",
      "2. **Stop‑word counting** – If no explicit line is found, count occurrences of the following seed words (case‑insensitive). The language with the highest count wins.\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "\n",
      "3. **Tie / no clear majority** – output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the first page that satisfies **any** of the following:\n",
      "\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a **markdown heading** (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page has a **single non‑blank line** (apart from possible footers/headers) that is in title‑case or all caps.\n",
      "\n",
      "2. **Capture the logical title**:\n",
      "\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle concatenation** – Immediately‑following lines **without a blank line in between** that look like a subtitle (i.e. not all caps, or they follow a colon on the same line) are concatenated to the main title with a single space.  \n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * Example:  \n",
      "\n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "\n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "3. **Cleanup** – Remove any leading markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. **Locate author lines** – Scan **all** pages for any of the following case‑insensitive keywords:  \n",
      "\n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Boucht,`, `Boucht,`, `BOUCHT,`, etc.\n",
      "\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "\n",
      "3. **Normalise each name**:\n",
      "\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.  \n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`. Preserve diacritics and original capitalisation.  \n",
      "   * Preserve the order of appearance.\n",
      "\n",
      "4. If **no author line** can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`.\n",
      "3. If still not found, fall back to the PDF metadata:  \n",
      "\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Scan **all** pages for lines containing any of the following case‑insensitive keywords:  \n",
      "\n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "\n",
      "2. **Capture the full phrase** that follows the keyword up to the end of the line. Trim trailing punctuation such as commas, periods, semicolons, and surrounding whitespace.\n",
      "\n",
      "3. **Institution‑only lines** – If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Turun yliopisto`, `Lääketieteellinen tiedekunta`), treat the whole line as a publisher entry.\n",
      "\n",
      "4. **Multiple publishers** – If more than one distinct publisher appears, list them in order of first appearance, preserving exact spelling and diacritics.\n",
      "\n",
      "5. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "\n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * **Print** indicators (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "\n",
      "   *If both qualifiers appear for the same identifier, add it to **both** lists.*  \n",
      "   *If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.*\n",
      "\n",
      "4. **Normalisation**  \n",
      "\n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "\n",
      "   Example: `ISBN 978‑951‑29‑7940‑0 (PRINT)` → `9789512979400`.\n",
      "\n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and its prefix belongs to a journal publisher) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `research report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "### Important gotchas observed in previous evaluations\n",
      "\n",
      "* **North Saami (`se`)** must be recognised either via the explicit language line or via its stop‑words.  \n",
      "* **ISBN/ISSN qualifiers** – when the qualifier is missing, the identifier belongs to **both** electronic and print lists.  \n",
      "* **Publisher lines** may appear without a preceding keyword; treat a line that looks like an institution name on its own as a publisher.  \n",
      "* **Creator names** – keep the order of appearance, split only on the **last** space when a comma is absent, and never duplicate names.  \n",
      "* **Research report** is a valid COAR type (see mapping table).  \n",
      "* **DOI detection** – keep the full URL if present; otherwise return the plain identifier.  \n",
      "* **Title concatenation** – include subtitles that follow immediately (no blank line) and preserve colons. Do not add extra punctuation.  \n",
      "\n",
      "Follow the rules above exactly; the output will be parsed automatically into a JSON record. Good luck! 🚀\n",
      "2025/09/30 17:32:01 INFO dspy.evaluate.evaluate: Average Metric: 1.7878787878787878 / 3 (59.6%)\n",
      "2025/09/30 17:32:37 INFO dspy.evaluate.evaluate: Average Metric: 40.68686868686869 / 64 (63.6%)\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Full valset score for new program: 0.6357323232323232\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Full train_val score for new program: 0.6357323232323232\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Individual valset scores for new program: [0.7272727272727273, 0.5454545454545454, 0.696969696969697, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.45454545454545453, 0.7878787878787878, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.45454545454545453, 0.6818181818181818, 0.8181818181818182, 0.9090909090909091, 0.45454545454545453, 0.5454545454545454, 0.9090909090909091, 0.6363636363636364, 0.9090909090909091, 0.9090909090909091, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.36363636363636365, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.3333333333333333, 0.6363636363636364, 0.36363636363636365, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.3333333333333333, 0.5151515151515151, 0.7272727272727273, 0.6363636363636364, 0.7171717171717172, 0.36363636363636365, 0.6212121212121212, 0.7272727272727273]\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Full valset pareto front score: 0.7789772727272727\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Updated valset pareto front programs: [{3, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {34, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {34}, {34, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {33, 34, 4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34}, {33, 2, 34, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34}, {10}, {8}, {24, 27, 31}, {18, 22, 30}, {0, 16, 20, 22, 27, 28, 29}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {33, 27, 29}]\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: Linear pareto front program index: 27\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 65: New program candidate index: 34\n",
      "GEPA Optimization:  82%|████████▏ | 2630/3200 [2:31:30<30:15,  3.18s/rollouts]2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 66: No merge candidates found\n",
      "2025/09/30 17:32:37 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Selected program 13 score: 0.6450081168831169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.45 / 3 (48.5%): 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:32:43 INFO dspy.evaluate.evaluate: Average Metric: 1.4545454545454546 / 3 (48.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:35:05 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line). The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | string or `None` | Full main title exactly as it appears on the title page, including any subtitle that belongs to the same logical heading. |\n",
      "| `alt_title` | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | integer or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | list of strings | Publishing institution(s) exactly as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version, normalized to a plain digit string (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | string or `None` | COAR resource type, one of the **lower‑case** values listed in **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The value on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes) for missing values.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Explicit language line** – Scan **all pages** for a line that explicitly states the language, using one of the patterns below (case‑insensitive). If found, **override** all other evidence and set the language accordingly.\n",
      "\n",
      "   | Pattern (case‑insensitive) | Language code |\n",
      "   |----------------------------|---------------|\n",
      "   | `Kieli:\\s*suomi`           | `fi` |\n",
      "   | `Kieli:\\s*svenska`        | `sv` |\n",
      "   | `Kieli:\\s*english`        | `en` |\n",
      "   | `Kieli:\\s*pohjoissaame`   | `se` (Northern Sámi) |\n",
      "   | `Language:\\s*English`     | `en` |\n",
      "   | `Language:\\s*Finnish`     | `fi` |\n",
      "   | `Language:\\s*Swedish`     | `sv` |\n",
      "   | `Språk:\\s*svenska`        | `sv` |\n",
      "   | `Språk:\\s*engelska`       | `en` |\n",
      "   | `Språk:\\s*finska`         | `fi` |\n",
      "\n",
      "2. **Stop‑word counting** – If no explicit line is present, count occurrences (case‑insensitive) of the following seed words on **all pages**:\n",
      "\n",
      "| ISO code | Seed words |\n",
      "|----------|------------|\n",
      "| `fi` | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu` |\n",
      "| `sv` | `och`, `för`, `av`, `liv`, `historien`, `språk` |\n",
      "| `en` | `the`, `and`, `of`, `method`, `introduction`, `chapter` |\n",
      "| `se` | `davvisámegiella`, `sámegielagiid`, `vuoigatvuođaid`, `čilgehus`, `sápmelaččaid` |\n",
      "\n",
      "   * The language with the highest total count wins.\n",
      "   * If there is a tie **or** all counts are zero, output `None`.\n",
      "\n",
      "### 2.2 Title extraction (main title)\n",
      "1. **Locate the title page** – The **first page** that satisfies **any** of the following:\n",
      "   * Contains a line that is **all‑caps** (ignoring punctuation) and is the **only non‑blank line** on that page, **or** the **first non‑blank line** on the page.\n",
      "   * Contains a Markdown heading (`#`, `##`, `###`) whose text (after stripping the heading markers) is not empty.\n",
      "2. **Capture the logical title**:\n",
      "   * Take the identified line (or the heading text) as the **main title**.\n",
      "   * If the **next line** (or the text after a colon on the same line) is non‑blank and looks like a subtitle (i.e. not a heading marker, not a page number, and not separated by a blank line), concatenate it with a single space.\n",
      "   * Preserve **all original punctuation, diacritics, and case**.\n",
      "3. **Do **not** fall back to `pdfinfo.title`.** The title must be taken from the document content only.\n",
      "4. **Clean‑up** – Remove surrounding whitespace and any surrounding heading markers (`#`, `##`, `###`). Do **not** remove internal punctuation or capitalization.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "1. Look for lines that contain any of the following **qualifiers** (case‑insensitive):  \n",
      "   `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Title (Finnish)`, `Titel (Svenska)`, `Titel (Englisch)`, `Originaltitel (Sámi)`, etc.\n",
      "2. When a qualifier is found, extract the title text that **follows** the qualifier (same concatenation rules as in 2.2).  \n",
      "3. Do **not** duplicate the main `title`. If multiple alternate titles are found, list them all.\n",
      "\n",
      "### 2.4 Creator handling (authors)\n",
      "1. **Search for author lines** – Scan the **first three pages** for any line that contains one of the following keywords (case‑insensitive) **as a standalone word** (or followed by a colon):  \n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Kirjoittaja`, `Kirjoittajat`, `Authors:`, `Tekijä:`, `Tekijät:`, `Kirjoittaja:`, `Kirjoittajat:`, `Opiskelijat`, `Opiskelijat:`.\n",
      "2. **Do not** treat committee members, editors, or “puheenjohtaja”, “lähde”, etc. as authors – only lines that contain the exact keywords above qualify.\n",
      "3. **Extract the raw name string** – The part of the line after the keyword (or after a colon) is the raw list of names.\n",
      "4. **Split into individual names** – Names may be separated by any of these delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, Finnish/Swedish equivalents `ja`, `och`.\n",
      "5. **Normalise each name**  \n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged (trim surrounding whitespace).  \n",
      "   * Otherwise, split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "     * Preserve diacritics and original capitalisation.\n",
      "6. **Preserve order of appearance** and return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "7. If no qualifying author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **pages 1 – 2** for a four‑digit number between 1900 and 2100 that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `År`.\n",
      "2. If multiple candidates exist, prefer the one that is **closest** to a keyword.\n",
      "3. If nothing is found on pages 1‑2, **extend the search to the whole document** (all pages) using the same keyword list.\n",
      "4. If still nothing is found, fall back to PDF metadata:\n",
      "   * From `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`), extract the `YYYY` part.\n",
      "5. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines (anywhere) that contain any of the following keywords (case‑insensitive):  \n",
      "   `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, `Routledge`, `Springer`, `Cambridge`, `Elsevier`, `Wiley`, `Metropolia`, `Åbo Akademi`, `Finanssivalvonta`, `Vuoigatvuođaministeriija`, etc.\n",
      "2. **Capture the full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as `. , ; :`).  \n",
      "3. If a line **contains only a plausible publisher name** without a preceding keyword (e.g. a line that is a single proper noun and appears in a context that looks like a source line, such as “Lähde: Finanssivalvonta”), treat the whole line (after optional “Lähde:” or similar) as a publisher.\n",
      "4. Remove surrounding whitespace, but **preserve the exact spelling and diacritics**.\n",
      "5. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "6. If no publisher can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Apply the case‑insensitive regex:  \n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "* Capture group 1, then strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. **Extract the identifier** that follows, allowing optional surrounding characters such as `:` `(` `)` and optional hyphens/spaces.  \n",
      "   Example patterns to recognise:  \n",
      "   * `ISBN 978‑952‑302‑949‑1`  \n",
      "   * `(ISBN: 978 952 302 949 1)`  \n",
      "   * `URN:ISBN:978-952-302-949-1`\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic indicators** (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `e‑book`, `e‑version`, `ISBN pdf`, `ISSN pdf`.\n",
      "   * **Print indicators** (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `paper`, `paperback`, `ISBN print`, `ISSN print`.\n",
      "   * If **both** electronic and print indicators appear for the same identifier, add it to **both** lists.\n",
      "   * If **only electronic** indicators appear → add to `e_isbn` / `e_issn`.\n",
      "   * If **only print** indicators appear → add to `p_isbn` / `p_issn`.\n",
      "   * **If no qualifier is present**, **add the identifier to `e_isbn` (or `e_issn`) only**. This matches the evaluation expectation that an unqualified ISBN/ISSN is treated as electronic.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly 8 digits (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Detect the resource type by searching the entire document (including PDF metadata) for the following keywords (case‑insensitive). Use the **first matching row** in the table (top‑to‑bottom priority). If multiple rows match, the earliest row wins.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “ISBN” present **and** a publisher that is a known **book publisher** (e.g., Routledge, Springer, Cambridge, Elsevier, Wiley, Åbo Akademi, Metropolia, etc.) **and** no thesis‑related keywords | `book` |\n",
      "| “Report”, “Technical report”, “Research report”, “Raportti”, “Technical Report”, “Research Report” | `research report` |\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI contains a known journal publisher prefix) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (publisher in DOI URL is a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "**Important ordering notes**\n",
      "\n",
      "* The **book** rule must be evaluated **before** the thesis rules (as shown).  \n",
      "* The **research report** rule must be evaluated **before** the thesis rules, otherwise a report containing “ISBN” could be mis‑classified as a thesis.  \n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first Markdown heading on page 1, etc.\n",
      "2025/09/30 17:35:11 INFO dspy.evaluate.evaluate: Average Metric: 1.5454545454545454 / 3 (51.5%)\n",
      "2025/09/30 17:35:47 INFO dspy.evaluate.evaluate: Average Metric: 36.93434343434343 / 64 (57.7%)\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Full valset score for new program: 0.5770991161616161\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Full train_val score for new program: 0.5770991161616161\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Individual valset scores for new program: [0.8181818181818182, 0.7272727272727273, 0.6060606060606061, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.8181818181818182, 0.45454545454545453, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.36363636363636365, 0.7272727272727273, 0.6363636363636364, 0.2727272727272727, 0.7272727272727273, 0.5454545454545454, 0.5454545454545454, 0.8181818181818182, 0.45454545454545453, 0.2727272727272727, 0.5454545454545454, 0.5454545454545454, 0.7727272727272727, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.36363636363636365, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.5151515151515151, 0.36363636363636365, 0.6161616161616161, 0.36363636363636365, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.18181818181818182, 0.6363636363636364, 0.5454545454545454, 0.2727272727272727, 0.18181818181818182, 0.36363636363636365, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.36363636363636365, 0.2727272727272727, 0.6060606060606061]\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Full valset pareto front score: 0.7818181818181819\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Updated valset pareto front programs: [{3, 35, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {34, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {34}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {33, 34, 4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35}, {33, 2, 34, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35}, {10}, {8}, {24, 27, 31}, {18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {35, 27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {33, 27, 29}]\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: Linear pareto front program index: 27\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 66: New program candidate index: 35\n",
      "GEPA Optimization:  84%|████████▍ | 2700/3200 [2:34:40<25:04,  3.01s/rollouts]2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 67: No merge candidates found\n",
      "2025/09/30 17:35:47 INFO dspy.teleprompt.gepa.gepa: Iteration 67: Selected program 34 score: 0.6357323232323232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.91 / 3 (63.6%): 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:35:53 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:38:02 INFO dspy.teleprompt.gepa.gepa: Iteration 67: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must follow the exact format shown in the “Output format example” section** because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order **does not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use **Python‑style list syntax**, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.  \n",
      "* If you include `reasoning`, place it **after** the last required field.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Explicit language line** – If any page contains a line that matches one of the patterns (case‑insensitive, ignoring surrounding whitespace/punctuation), treat it as a **strong signal** and set the language accordingly:  \n",
      "\n",
      "   * `Kieli:\\s*suomi` → `fi`  \n",
      "   * `Language:\\s*english` → `en`  \n",
      "   * `Språk:\\s*svenska` → `sv`  \n",
      "   * `Kieli:\\s*se` or `Language:\\s*saami` → `se`  \n",
      "\n",
      "2. **Stop‑word counting** – If no explicit line is found, count occurrences of the following seed words (case‑insensitive). The language with the highest count wins.\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "\n",
      "3. **Tie / no clear majority** – output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the **first page** (scanning from page 1 upwards) that satisfies **any** of the following:\n",
      "\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a **Markdown heading** (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page has a **single non‑blank line** (apart from possible footers/headers) that is in title‑case or all caps.\n",
      "\n",
      "2. **Capture the logical title**:\n",
      "\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle concatenation** – Immediately‑following lines **without a blank line in between** that look like a subtitle (i.e. not all caps, or they follow a colon on the same line) are concatenated to the main title with a single space.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * Example:  \n",
      "\n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "\n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "3. **Cleanup** – Remove any leading markdown markers (`#`, `##`, etc.) and surrounding whitespace **only**. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. **Locate author lines** – Scan **all** pages for any of the following case‑insensitive keywords (the list is exhaustive for the test data, but you may add more if you see them):  \n",
      "\n",
      "   `author`, `authors`, `author:`, `authors:`, `tekijä`, `tekijät`, `tekijä:`, `tekijät:`, `kirjoittaja`, `kirjoittajat`, `opiskelijat`, `opiskelijat:`, `boucht,`, `boucht,`, `boucht,`, `boucht,`  \n",
      "\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "\n",
      "3. **Normalise each name**:\n",
      "\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.  \n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`. Preserve diacritics and original capitalisation.  \n",
      "   * Preserve the order of appearance.\n",
      "\n",
      "4. If **no author line** can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`.\n",
      "3. If still not found, fall back to the PDF metadata:  \n",
      "\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Scan **all** pages for lines containing any of the following case‑insensitive keywords:  \n",
      "\n",
      "   `publisher`, `published by`, `julkaisija`, `julkaisija:`, `laitos`, `university`, `institute`, `yliopisto`, `ammattikorkeakoulu`, `korkeakoulu`, `kustannus`, `kustantaja`, `kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`, `MDPI`, `Elsevier`).\n",
      "\n",
      "2. **Capture the full phrase** that follows the keyword up to the end of the line. Trim trailing punctuation such as commas, periods, semicolons, and surrounding whitespace.\n",
      "\n",
      "3. **Institution‑only lines** – If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Turun yliopisto`, `Taideyliopisto Sibelius‑Akatemia`, `Tampereen ammattikorkeakoulu`), treat the whole line as a publisher entry.\n",
      "\n",
      "4. **Multiple publishers** – If more than one distinct publisher appears, list them in order of first appearance, preserving exact spelling and diacritics.\n",
      "\n",
      "5. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "\n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "\n",
      "   * **Electronic** indicators (case‑insensitive): `pdf`, `e‑isbn`, `electronic`, `online`, `(pdf)`, `e‑issn`, `electronic version`.\n",
      "   * **Print** indicators (case‑insensitive): `print`, `hardcover`, `paperback`, `print version`, `print‑isbn`, `hardcover version`.\n",
      "\n",
      "   *If both qualifiers appear for the same identifier, add it to **both** lists.*  \n",
      "   *If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.*\n",
      "\n",
      "4. **Normalisation**  \n",
      "\n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "\n",
      "   Example: `ISBN 978‑951‑29‑7940‑0 (PRINT)` → `9789512979400`.\n",
      "\n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., `Routledge`, `Springer`, `Cambridge`, `MDPI`, `Elsevier`) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that belongs to a journal (i.e. the DOI prefix is known to be a journal publisher) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `research report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. the DOI prefix is a known book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "## 4️⃣ Common pitfalls observed in previous evaluations (do **not** repeat them)\n",
      "\n",
      "| Issue | What went wrong | Correct approach |\n",
      "|-------|----------------|-----------------|\n",
      "| **DOI format** | Returned the plain identifier even when the source contained the full URL. | Keep the full URL (`https://doi.org/...`) if the URL is present; otherwise return only the identifier. |\n",
      "| **Publisher detection** | Added unrelated institution names or missed the correct one. | Capture only lines that contain a publisher keyword **or** are pure institution lines that look like a publisher. Do not include generic address lines. |\n",
      "| **ISBN qualifier handling** | Treated identifiers without a qualifier as belonging to *neither* list. | If no qualifier is present, add the identifier to **both** `e_isbn` and `p_isbn` (same for ISSN). |\n",
      "| **ISSN extraction** | Returned `None` when an ISSN was present. | Detect `ISSN` anywhere, normalize (remove hyphens), and assign to `p_issn` unless an explicit “online” qualifier is found. |\n",
      "| **COAR type mapping** | Chose `master thesis` for a journal article. | Follow the table order strictly; for articles look for “article” + ISSN, or DOI that points to a journal, before checking thesis keywords. |\n",
      "| **Year extraction** | Missed the year because it was on page 1 but the rule limited search to page 2. | Scan **both** page 1 and page 2; prioritize lines with the keywords listed. |\n",
      "| **Title concatenation** | Missed subtitle because of a blank line or added extra punctuation. | Concatenate only *immediately* following lines **without a blank line**; keep original punctuation exactly. |\n",
      "| **Alt‑title duplication** | Added the main title to `alt_title`. | Ensure `alt_title` does **not** contain the exact main `title`. |\n",
      "| **Creator normalisation** | Split names incorrectly (e.g., kept “First Last” order). | If a comma is present, keep as‑is; otherwise split on the **last** space to get `Last, First …`. |\n",
      "\n",
      "Keep these rules in mind to avoid the same mistakes.\n",
      "\n",
      "--- \n",
      "\n",
      "**Your task:** read the supplied JSON, apply the rules above, and output the metadata exactly as specified. Good luck! 🚀\n",
      "2025/09/30 17:38:09 INFO dspy.evaluate.evaluate: Average Metric: 1.6363636363636362 / 3 (54.5%)\n",
      "2025/09/30 17:38:09 INFO dspy.teleprompt.gepa.gepa: Iteration 67: New subsample score is not better, skipping\n",
      "GEPA Optimization:  85%|████████▍ | 2706/3200 [2:37:02<32:14,  3.92s/rollouts]2025/09/30 17:38:09 INFO dspy.teleprompt.gepa.gepa: Iteration 68: Selected program 19 score: 0.5849262716450216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:38:15 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:40:23 INFO dspy.teleprompt.gepa.gepa: Iteration 68: Proposed new text for predict: markdown\n",
      "# Revised Instruction for Extracting Structured Bibliographic Metadata from PDF‑extracted Text\n",
      "\n",
      "You will receive **one JSON object** per request.  \n",
      "It contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – an ordered list of page objects, each with an integer `page` and a string `text` that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Do **not** carry any information from previous requests – treat each request as completely independent.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "* Write the field name on a line **by itself**, then write its value on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: single quotes, commas, no trailing comma.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does not affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If ambiguous, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the *title page*, including subtitle and any colon. Preserve original case, punctuation and spaces; join consecutive heading lines with a **single space** (do **not** insert `\\n`). |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). **Use `pdfinfo.author` only if it looks like a real name** (contains at least one space or a comma) **and it also appears on the title page**; otherwise locate author lines on the title page (look for markers such as `Author:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, etc.). Split a name on the **last space only** unless it already contains a comma. Preserve diacritics. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`). |\n",
      "| **publisher** | list of strings | Imprint institution(s). Keep the **entire line** (trimmed) **up to the first comma**; if the line contains no comma, keep the whole line. Split into separate list elements when distinct institutions are separated by `/`, the word “and”, or appear on separate lines. Do **not** include city names, department names, or addresses unless they are themselves the institution. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Accept only if the DOI appears as a **stand‑alone token** or after the literal prefix `doi:`. **Ignore DOIs that are embedded in reference citations** (e.g., URLs that contain additional hostnames or appear inside a bibliography). |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep only the **digit string** (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`, `journal article`, `thesis`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count case‑insensitive occurrences of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or first two pages) that contain the **largest centred heading(s)**. Clues: ALL‑CAPS, title‑case, surrounded by blank lines, or markdown headings (`#`, `##`, `###`).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve the exact wording (including case and punctuation). Join captured lines with a **single space** (do **not** insert line‑break characters).  \n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the next page) for a heading that is clearly a title in a **different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` **only if**  \n",
      "   * it contains at least one space **or** a comma, **and** the exact same string (ignoring surrounding whitespace) appears somewhere on the title page.  \n",
      "   * If either condition fails, ignore `pdfinfo.author`.  \n",
      "2. If the above is not used, look for lines on the title page that contain personal names. Typical markers: “Author:”, “Författare:”, “Tekijä:”, “Kirjoittaja”, “by”, “author”, “tekijä”, or a line directly under the title consisting mainly of capitalised names.  \n",
      "3. Do **not** treat department names, university names, or acknowledgements as authors.  \n",
      "4. For each name found:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **entire line** (trimmed) **up to the first comma**; if there is no comma, keep the whole line.  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element, preserving original spelling.  \n",
      "4. Do **not** include city names, department names, or addresses unless they are themselves separate institutions.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string **only if**:\n",
      "\n",
      "* The DOI appears after the literal prefix `doi:` **or** is a stand‑alone token matching `10.<digits>/<non‑space>`.  \n",
      "* The surrounding line does **not** contain typical bibliography formatting (e.g., author list, journal name, “et al.”, “doi.org” inside a longer URL).  \n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit if present, otherwise keep what remains).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "\n",
      "4. Look at the same line for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Master’s thesis” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” (combined with “thesis”) | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISBN(s)** **and** the word “part” or “chapter” indicating a contribution to a larger work | `book part` |\n",
      "| Presence of **ISSN(s)** **and** journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| The word “journal” together with ISSN or volume/issue information | `journal article` |\n",
      "| If the document is a thesis but the exact level cannot be identified, use the generic `thesis`. |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations\n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, or language that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* When a field’s value is ambiguous (e.g., multiple possible titles, languages, or publishers), follow the specific disambiguation rules above; otherwise use the placeholder.  \n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example output (template)\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Creative leader’s impact on the working environment\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Forsander, Kim']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Yrkeshögskolan Novia']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "bachelor thesis\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "2025/09/30 17:40:28 INFO dspy.evaluate.evaluate: Average Metric: 1.9696969696969697 / 3 (65.7%)\n",
      "2025/09/30 17:40:28 INFO dspy.teleprompt.gepa.gepa: Iteration 68: New subsample score is not better, skipping\n",
      "GEPA Optimization:  85%|████████▍ | 2712/3200 [2:39:21<41:03,  5.05s/rollouts]2025/09/30 17:40:28 INFO dspy.teleprompt.gepa.gepa: Iteration 69: Selected program 29 score: 0.6640895562770562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.14 / 3 (71.2%): 100%|██████████| 3/3 [00:07<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:40:36 INFO dspy.evaluate.evaluate: Average Metric: 2.1363636363636367 / 3 (71.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:42:41 INFO dspy.teleprompt.gepa.gepa: Iteration 69: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names and diacritics). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). **Never** infer the year from PDF metadata; it must appear in the document text (see **2.5 Year extraction**). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.6 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.  \n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use these seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`, `raportti`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kieli: se`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`).  \n",
      "   The line may appear anywhere; ignore surrounding punctuation.\n",
      "\n",
      "3. Otherwise choose the language with the highest stop‑word count.  \n",
      "   *If there is a tie, or no stop‑word is found, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the **first** page that satisfies **any** of the following:\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page contains a **single** non‑blank line (apart from possible footers/headers) that looks like a title (title‑case or all caps).\n",
      "\n",
      "2. **Capture the full logical title**:\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle handling** – if the **next line(s)** (immediately following, without a blank line in between) appear to be a subtitle, **append** them to the main title with a single space. A subtitle is recognised when:\n",
      "     * The line is **not** all caps **and** does not end with a colon, **or**\n",
      "     * The line follows a colon on the same line (`Main title : Subtitle`), **or**\n",
      "     * The line begins with a capital letter but is **shorter** than the main title.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). **Do not** add a colon if the original title line already contains one; simply keep the original characters.\n",
      "   * Example:  \n",
      "\n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "\n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in **2.2**.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search **every** page for author lines. Valid keywords (case‑insensitive) are: `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.\n",
      "2. **Only** lines that contain one of the keywords above are considered author lines.  \n",
      "   *If a line contains names but **no** keyword (e.g. “Sanna Röknä & Jaana Markkula (toim.)”), it **must not** be treated as a creator entry.*  \n",
      "   The word “toim.” or “(toim.)” indicates an **editor**, not an author.\n",
      "3. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "4. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`. Preserve diacritics and original capitalisation (including hyphens, apostrophes, etc.).\n",
      "5. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If **no** author line is found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`, `Opinnäytetyö`, `Väitöskirja`, `Raportti`.\n",
      "3. **Do not** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate`. If no year satisfying the above is found, output `None`.\n",
      "4. Return the year as an **integer**.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus well‑known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name **without** a preceding keyword (e.g. `Terveyden ja hyvinvoinnin laitos`), treat the whole line as a publisher entry **provided** it is not a short abbreviation, a page‑number/footer, or repeats on every page.\n",
      "4. Discard lines that are clearly **footers/headers**: they usually contain only a short acronym, a dash, a page number, or repeat on every page.\n",
      "5. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "6. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkojulkaisu`, `digital`, `e‑book`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`, `hardcover`, `paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, Finnish: `väitöskirja` | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| “Report”, “Technical report”, “Research report”, Finnish: `raportti` | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag”, Swedish: `konferensbidrag` | `conference paper` |\n",
      "| “Journal article”, “Article”, Finnish/Swedish: `artikkeli`, `artikel` **and** an ISSN present | `article` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI prefix belongs to a journal publisher) | `book review` |\n",
      "| “Book”, “Monograph” **and** an ISBN present **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. DOI prefix of a book publisher) | `book part` |\n",
      "| Any of the thesis‑related keywords above **without** a more specific match (e.g., “Thesis”, “Opinnäytetyö”, “Väitöskirja”) | `thesis` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "*If multiple rows match, the earliest row in the table wins.*\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "* Do **not** infer any value from `pdfinfo` unless the rule explicitly permits it (e.g., `pdfinfo.title` is **not** used for `title`).  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 17:42:48 INFO dspy.evaluate.evaluate: Average Metric: 2.1363636363636367 / 3 (71.2%)\n",
      "2025/09/30 17:42:48 INFO dspy.teleprompt.gepa.gepa: Iteration 69: New subsample score is not better, skipping\n",
      "GEPA Optimization:  85%|████████▍ | 2718/3200 [2:41:41<51:54,  6.46s/rollouts]2025/09/30 17:42:48 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.18 / 3 (72.7%): 100%|██████████| 3/3 [00:05<00:00,  1.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:42:53 INFO dspy.evaluate.evaluate: Average Metric: 2.1818181818181817 / 3 (72.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:44:33 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`,\n",
      "  `creationDate`, `modDate`). Dates follow the PDF format `D:YYYYMMDD…`.\n",
      "* `pages` – a list of page objects, each with:\n",
      "  * `page` – integer page number (starting at 1)\n",
      "  * `text` – the raw OCR/clipboard text of that page (preserve line‑breaks).\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and output a **flat list of\n",
      "metadata fields** in the exact format described in the *Output format* section.\n",
      "All fields must be present – if a value cannot be found, use the *missing‑value\n",
      "placeholder* defined below.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full main title **exactly as it appears** on the title page, including any subtitle that belongs to the same logical heading. Do **not** trim trailing spaces; replace line‑breaks inside the title with a single space. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not repeat the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). If a name already contains a comma, keep it unchanged. Split a single‑string name on the **last space only**. Preserve order of appearance. If none, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If none, fall back to the year extracted from `pdfinfo.creationDate` or `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint string(s) (e.g. university, department, institute, newspaper). Preserve diacritics, hyphens, and spacing. If multiple entities are listed on the same line, split them at commas, slashes, or the word “and”. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) for the **electronic/PDF** version. Normalise by **removing every non‑digit character**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if present). Include only if the same line contains an **electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) for the **print** version, normalised the same way as `e_isbn`. Include only if the same line contains a **print qualifier**. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by removing hyphens. Include if the same line contains an electronic qualifier **or** if no qualifier is present (default to online). |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by removing hyphens. Include if the same line contains a print qualifier **or** if no qualifier is present (default to print). |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `book`, `article`,\n",
      "  `research article`, `newspaper article`, `report`,\n",
      "  `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the whole document into words: split on any whitespace or punctuation,\n",
      "   convert to lower‑case.\n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters\n",
      "   (case‑insensitive). Use the tables below:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|--------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the **highest count** wins **provided** its count is at least\n",
      "   **1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – the first page (or first two pages) that contains the\n",
      "   **largest centred heading(s)** (often ALL‑CAPS or title‑case, possibly surrounded by blank lines).\n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   *If a subtitle follows a colon (`:`) or appears on the next line **without a blank line** in between, treat it as part of the title.*  \n",
      "3. Join the captured lines with a **single space** (do not keep line‑break characters).  \n",
      "4. Do **not** include page numbers, section headings, catalogue codes, or any surrounding decorative text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the **immediately following page**) for a heading that is\n",
      "in a **different language** (usually English). Typical markers: “English title”, “Title (English)”, or a second heading placed directly beneath the main title. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **Primary source**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names – often directly under the title or preceded by “by”, “author”, “kirjoittanut”, etc.\n",
      "3. For each name:\n",
      "   * If the name already contains a comma, keep it unchanged.\n",
      "   * Otherwise split on the **last space only** and reorder to `\"Last, First …\"`.\n",
      "   * Trim surrounding whitespace.\n",
      "4. Authors may be separated by commas, semicolons, the word “and”, or line breaks – treat each as a separate author.\n",
      "5. Preserve the order found. If no author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **title page**, any copyright line, and the imprint for a **4‑digit number** between 1900 and (current year + 1).\n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.\n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.\n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line(s)** – usually after the title, subtitle, author and before the year/location.\n",
      "2. Capture the whole line(s) that represent the publishing institution(s).\n",
      "3. If the line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling** (including diacritics).\n",
      "4. Do **not** modify the text (no adding/removing words). If no imprint can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following (case‑insensitive):\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string.\n",
      "If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).\n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all** non‑digit characters, keep the resulting digit string (13‑digit preferred, but keep 10‑digit if present).  \n",
      "   * ISSN – remove hyphens only, keep the 8‑digit string (or the form `XXXX‑XXXX` after hyphen removal).\n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an **electronic qualifier** is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print qualifier** is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, treat the number as **print** for ISSN and **print** for ISBN (default to print).  \n",
      "5. Do **not** guess a format; only explicit qualifiers or the default rule above count.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page and imprint) for the following key phrases\n",
      "(case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| “Research article”, “Original article”, “Article” (when combined with journal indicators) | `research article` |\n",
      "| “Newspaper article”, “Press release”, “News” (when combined with newspaper imprint) | `newspaper article` |\n",
      "| The word “Report” (or “Technical report”) **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**.\n",
      "Use exact Python‑style representation for lists (single quotes, commas, no trailing commas).\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "What do regular online grocery shoppers want from online grocers going forward? Suggestions for service quality improvements\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Eriksson, Niklas', 'Stenius, Minna']\n",
      "year\n",
      "2023\n",
      "publisher\n",
      "['Elsevier']\n",
      "doi\n",
      "10.1016/j.procs.2023.01.282\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "1877-0509\n",
      "type_coar\n",
      "research article\n",
      "reasoning\n",
      "The title was taken from the centred heading on the first page; the year 2023 is printed on the copyright line; the publisher “Elsevier” appears in the imprint; the DOI was extracted after stripping the URL prefix; the ISSN without a qualifier defaults to print; the document is a research article because it contains an ISSN and journal‑style headings.\n",
      "2025/09/30 17:44:39 INFO dspy.evaluate.evaluate: Average Metric: 2.272727272727273 / 3 (75.8%)\n",
      "2025/09/30 17:45:14 INFO dspy.evaluate.evaluate: Average Metric: 37.729004329004304 / 64 (59.0%)\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Full valset score for new program: 0.5895156926406926\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Full train_val score for new program: 0.5895156926406926\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Individual valset scores for new program: [0.6363636363636364, 0.6363636363636364, 0.7532467532467533, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.36363636363636365, 0.6363636363636364, 0.696969696969697, 0.30303030303030304, 0.5454545454545454, 0.45454545454545453, 0.42424242424242425, 0.6363636363636364, 0.6363636363636364, 0.5909090909090909, 0.6060606060606061, 0.36363636363636365, 0.7272727272727273, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.35454545454545455, 0.8181818181818182, 0.45454545454545453, 0.9090909090909091, 0.7727272727272727, 0.7272727272727273, 0.45454545454545453, 0.36363636363636365, 0.7272727272727273, 0.36363636363636365, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.6363636363636364, 0.36363636363636365, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.42424242424242425, 0.36363636363636365, 0.42424242424242425, 0.6363636363636364, 0.6818181818181818, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.696969696969697]\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Full valset pareto front score: 0.7818181818181819\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Updated valset pareto front programs: [{3, 35, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {34, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {34}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {33, 34, 4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19, 36}, {2, 4, 21, 15}, {8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36}, {33, 2, 34, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35}, {10}, {8}, {24, 27, 31}, {18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {24, 9, 3}, {35, 27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {33, 27, 29}]\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: Linear pareto front program index: 27\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 70: New program candidate index: 36\n",
      "GEPA Optimization:  87%|████████▋ | 2788/3200 [2:44:07<27:25,  3.99s/rollouts]2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 71: No merge candidates found\n",
      "2025/09/30 17:45:14 INFO dspy.teleprompt.gepa.gepa: Iteration 71: Selected program 30 score: 0.601359577922078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.79 / 3 (59.6%): 100%|██████████| 3/3 [00:07<00:00,  2.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:45:22 INFO dspy.evaluate.evaluate: Average Metric: 1.787878787878788 / 3 (59.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:47:37 INFO dspy.teleprompt.gepa.gepa: Iteration 71: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`fi`, `en`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). Must appear in the document text (see **2.5 Year extraction**). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). See **2.6 Publisher extraction**. |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`.  \n",
      "2. **Explicit language line** – if any line (any page) matches one of the patterns (case‑insensitive, ignore surrounding punctuation):\n",
      "   * `Kieli:\\s*suomi` → `fi`\n",
      "   * `Language:\\s*english` → `en`\n",
      "   * `Språk:\\s*svenska` → `sv`\n",
      "   * `Kieli:\\s*se` or `Kieli:\\s*nord‑saami` → `se`\n",
      "   If such a line is found, use the corresponding code **and stop** further detection.\n",
      "3. Otherwise count occurrences of the following *seed stop‑words* (case‑insensitive). A word counts each time it appears, even inside longer words.\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`, `raportti`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "4. Choose the language with the **highest** count.  \n",
      "   *If there is a tie, or no stop‑word is found, output `None`.*\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the **first** page that satisfies **any** of the following:\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a Markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.  \n",
      "   * The page contains a single non‑blank line (apart from possible footers/headers) that looks like a title (title‑case or all caps).\n",
      "2. **Capture the logical title**:\n",
      "   * Take the identified title line as the *main title* (remove any leading `#` characters and surrounding whitespace).  \n",
      "   * **Subtitle handling** – look at the **next line(s)** *immediately* after the title line (no blank line between). Append each subtitle line to the main title **with a single space**. A line is considered a subtitle when **any** of the following holds:\n",
      "     * The line is **not** all caps **and** does **not** end with a colon.\n",
      "     * The line follows a colon on the same line (`Main title : Subtitle`); in this case the text after the colon is already part of the main title and must **not** be duplicated.\n",
      "     * The line begins with a capital letter **and** is shorter than the main title.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * If the title line already contains a colon and text after it, treat the whole line as the complete title (do not duplicate the colon).\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Search **every** page for a line that contains a language qualifier such as `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Titel (Finnisch)`, etc. (case‑insensitive).  \n",
      "* When a qualifier is found, capture the **title text that follows** it, applying the same concatenation rules as in **2.2** (i.e. include possible subtitle lines).  \n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. **Primary search** – look for lines that contain any of the keywords (case‑insensitive):\n",
      "   `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`, `Kirjoittaja:`, `Kirjoittajat:`.  \n",
      "   *Only* lines containing one of these keywords are considered author lines.  \n",
      "   **Do not** treat lines that contain only editor‑related keywords (e.g. `Editor`, `Editors`, `Toimittaja`, `Toimittajat`) as author lines.\n",
      "2. **Fallback search** – if **no** author line is found, scan the **title page** (the page identified in 2.2) for lines that look like a personal name:\n",
      "   * Consist of **two or three words**, each starting with an uppercase letter (allow diacritics).  \n",
      "   * Do **not** contain the words `toim.`, `(toim.)`, `editor`, `ed.`, `ed` or similar – those indicate editors, not authors.  \n",
      "   * If such a line is found, treat it as an author line.\n",
      "3. **Parsing individual names** (whether from a primary or fallback line):\n",
      "   * The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "   * For each name:\n",
      "     * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "     * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "     * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "   If **no** author can be identified, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **only the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`, `Opinnäytetyö`, `Väitöskirja`, `Raportti`, `Valmistumisvuosi`.\n",
      "3. If multiple candidate years are found, choose the **first** one (top‑to‑bottom order).\n",
      "4. **Do not** fall back to `pdfinfo.creationDate` or `pdfinfo.modDate`. If no year satisfying the above is found, output `None`.\n",
      "5. Return the year as an **integer**.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`, `Elsevier`, `Wiley`).  \n",
      "2. When a keyword is found, capture the **full phrase** that follows the keyword up to the end of the line. Trim trailing punctuation such as commas, periods, semicolons, and surrounding whitespace.\n",
      "3. **Institution‑only fallback** – if no keyword‑based publisher is found, scan every page for a line that:\n",
      "   * Consists of **two or more words**, each starting with an uppercase letter (allow diacritics),  \n",
      "   * Is **not** a short acronym, a lone number, a page header/footer, or a line that repeats on many pages,  \n",
      "   * Is **not** an author line.  \n",
      "   Treat the whole line as a publisher entry.\n",
      "4. Discard obvious footers/headers: lines that are only a short acronym, a dash, a page number, or that repeat on many pages.\n",
      "5. If more than one distinct publisher appears, list them **in order of first appearance**.\n",
      "6. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `verkkojulkaisu`, `digital`, `e‑book`.\n",
      "   * **Print** indicators (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `painettu`, `hardcover`, `paperback`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation”, Finnish: `väitöskirja` | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, Finnish: `kandidaatintyö`, `kandidaatintutkielma` | `bachelor thesis` |\n",
      "| “Report”, “Technical report”, “Research report”, Finnish: `raportti` | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, Swedish: `konferensbidrag` | `conference paper` |\n",
      "| “Journal article”, “Article”, Finnish/Swedish: `artikkeli`, `artikel` **and** an ISSN present | `article` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e. DOI prefix belongs to a journal publisher) | `book review` |\n",
      "| “Book”, “Monograph” **and** an ISBN present **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge, Elsevier, Wiley) | `book` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (i.e. DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "**Important:**  \n",
      "* Finnish words for the same concept must be recognised (e.g., `raportti` → `report`, `väitöskirja` → `doctoral thesis`).  \n",
      "* If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "fi\n",
      "title\n",
      "Dál de leat guovzzabada cummán : davvisámegiela giellagovaid guorahallan\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Magga, Arla']\n",
      "year\n",
      "2017\n",
      "publisher\n",
      "['Oulu universitehta', 'Giellagas-instituhtta']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as Finnish because the explicit line “Kieli: suomi” appears; the title was taken from the first all‑caps line on page 1 and the following subtitle line was appended; the author line without a keyword on the title page (“Arla Magga”) was used as a fallback; the year 2017 appears on the title page next to “©”; the publisher names are taken from the lines after the title; no DOI or ISBN/ISSN are present; the word “Pro gradu” signals a master thesis.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "\n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "2025/09/30 17:47:44 INFO dspy.evaluate.evaluate: Average Metric: 1.696969696969697 / 3 (56.6%)\n",
      "2025/09/30 17:47:44 INFO dspy.teleprompt.gepa.gepa: Iteration 71: New subsample score is not better, skipping\n",
      "GEPA Optimization:  87%|████████▋ | 2794/3200 [2:46:37<36:13,  5.35s/rollouts]2025/09/30 17:47:44 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Selected program 34 score: 0.6357323232323232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.00 / 3 (66.7%): 100%|██████████| 3/3 [00:06<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:47:51 INFO dspy.evaluate.evaluate: Average Metric: 2.0 / 3 (66.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:49:51 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Proposed new text for predict: markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted JSON\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (see **2.2 Title extraction**). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. Keep the full URL if present, otherwise the plain identifier. |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Explicit language line** – If any page contains a line that matches one of the patterns (case‑insensitive, ignoring surrounding whitespace/punctuation), treat it as a **strong signal** and set the language accordingly:  \n",
      "\n",
      "   * `Kieli:\\s*suomi` → `fi`  \n",
      "   * `Language:\\s*english` → `en`  \n",
      "   * `Språk:\\s*svenska` → `sv`  \n",
      "   * `Kieli:\\s*se` or `Language:\\s*saami` → `se`  \n",
      "\n",
      "2. **Stop‑word counting** – If no explicit line is found, count occurrences of the following seed words (case‑insensitive). The language with the highest count wins.\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu`\n",
      "\n",
      "3. **Tie / no clear majority** – output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the *first* page that satisfies **any** of the following:\n",
      "\n",
      "   * The **first non‑blank line** of the page is **ALL CAPS** (ignoring surrounding punctuation/markdown).  \n",
      "   * The page contains a **markdown heading** (`#`, `##`, `###`, …). Strip leading `#` characters and surrounding whitespace.  \n",
      "   * The page has a **single non‑blank line** (apart from possible footers/headers) that is in title‑case or all caps.\n",
      "\n",
      "2. **Capture the logical title**:\n",
      "\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * **Subtitle concatenation** – Immediately‑following lines **without a blank line in between** that look like a subtitle (i.e. not all caps, or they follow a colon on the same line) are concatenated to the main title with a single space.  \n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "\n",
      "3. **Cleanup** – Remove any leading markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. **Locate author lines** – Scan **all** pages for any of the following case‑insensitive keywords (the list is exhaustive, you may add obvious equivalents):  \n",
      "\n",
      "   `author`, `authors`, `author:`, `authors:`, `tekijä`, `tekijät`, `tekijä:`, `tekijät:`, `kirjoittaja`, `kirjoittajat`, `opiskelijat`, `opiskelijat:`, `boucht,`, `boucht,`, `boucht`, `boucht`, `author(s)`, `author(s):`.\n",
      "\n",
      "2. **Do not treat a name that appears only as a signature or in a “Contact” line as an author** unless the line also contains one of the keywords above.\n",
      "\n",
      "3. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "\n",
      "4. **Normalise each name**:\n",
      "\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.  \n",
      "   * Otherwise split on the **last space**: `\"First Middle Last\"` → `\"Last, First Middle\"`. Preserve diacritics and original capitalisation.  \n",
      "   * Preserve the order of appearance.\n",
      "\n",
      "5. If **no author line** can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **the first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`.\n",
      "3. If not found in the first two pages, **continue scanning all remaining pages** for a four‑digit year that satisfies the range, even if it appears inside a range expression (e.g. `2014–2016`). The first such year encountered (top‑to‑bottom, left‑to‑right) is used.\n",
      "4. If still not found, fall back to the PDF metadata:  \n",
      "\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "5. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Scan **all** pages for lines containing any of the following case‑insensitive keywords:  \n",
      "\n",
      "   `publisher`, `published by`, `julkaisija`, `julkaisija:`, `laitos`, `university`, `institute`, `yliopisto`, `ammattikorkeakoulu`, `korkeakoulu`, `kustannus`, `kustantaja`, `kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`, `Taylor & Francis`, `Informa`, `Elsevier`).\n",
      "\n",
      "2. **Capture the full phrase** that follows the keyword up to the end of the line. Trim trailing punctuation such as commas, periods, semicolons, and surrounding whitespace.\n",
      "\n",
      "3. **Institution‑only lines** – If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Turun yliopisto`, `Lääketieteellinen tiedekunta`), treat the whole line as a publisher entry.\n",
      "\n",
      "4. **Exclude lines that are clearly author signatures or contact information** (e.g. lines that contain an email address or the word “Contact”).\n",
      "\n",
      "5. **Multiple publishers** – If more than one distinct publisher appears, list them in order of first appearance, preserving exact spelling and diacritics.\n",
      "\n",
      "6. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "\n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * **Print** indicators (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "\n",
      "   *If both qualifiers appear for the same identifier, add it to **both** lists.*  \n",
      "   *If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.*\n",
      "\n",
      "4. **Normalisation**  \n",
      "\n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "\n",
      "   Example: `ISBN 978‑951‑29‑7940‑0 (PRINT)` → `9789512979400`.\n",
      "\n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, **all** must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge, Elsevier) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and its prefix belongs to a journal publisher) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `research report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because an explicit “Language: English” line was found; the title was taken from the first all‑caps line on page 1 together with its subtitle; authors were extracted from the “Authors:” line and normalised; the year 2021 appeared on the copyright line; the publisher was taken from the “Published by …” line; the DOI was captured as a full URL; no ISBN/ISSN were present; the article keywords and ISSN caused the COAR type to be “article”.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "--- \n",
      "\n",
      "**Important gotchas observed in previous evaluations**\n",
      "\n",
      "* **Explicit language lines** override stop‑word counting.  \n",
      "* **Creator extraction** must be based **only** on lines that contain one of the author‑related keywords; signatures without those keywords must be ignored.  \n",
      "* **Year** may appear outside the first two pages (e.g., in a “2014–2016” heading); continue scanning if not found early.  \n",
      "* **Publisher** should be taken from lines with publisher keywords **or** from stand‑alone institution names, but never from author or contact lines.  \n",
      "* **ISBN/ISSN qualifiers** – when the qualifier is missing, the identifier belongs to **both** electronic and print lists.  \n",
      "* **COAR type**: “article” requires both an article‑related keyword **and** an ISSN; “research report” is a valid type.  \n",
      "* Preserve original diacritics, punctuation, and case for titles, publishers, and author names.  \n",
      "* Normalise ISBN/ISSN to plain digit strings and keep them unique while preserving first‑appearance order.  \n",
      "\n",
      "Follow the rules above exactly; the output will be parsed automatically into a JSON record. Good luck! 🚀\n",
      "2025/09/30 17:49:58 INFO dspy.evaluate.evaluate: Average Metric: 2.2727272727272725 / 3 (75.8%)\n",
      "2025/09/30 17:50:38 INFO dspy.evaluate.evaluate: Average Metric: 41.268686868686835 / 64 (64.5%)\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Full valset score for new program: 0.6448232323232324\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Full train_val score for new program: 0.6448232323232324\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.6060606060606061, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.7727272727272727, 0.6363636363636364, 0.8787878787878788, 0.8181818181818182, 0.6363636363636364, 0.9090909090909091, 0.45454545454545453, 0.696969696969697, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.45454545454545453, 0.5454545454545454, 0.7727272727272727, 0.8181818181818182, 0.9090909090909091, 0.5454545454545454, 0.5363636363636364, 0.8181818181818182, 0.6060606060606061, 0.8181818181818182, 0.9090909090909091, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.45454545454545453, 0.9090909090909091, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.45454545454545453, 0.6363636363636364, 0.5, 0.6363636363636364, 0.45454545454545453, 0.7171717171717172, 0.18181818181818182, 0.6363636363636364, 0.9090909090909091]\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Full valset pareto front score: 0.7832386363636363\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Updated valset pareto front programs: [{3, 35, 37, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {34, 37, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 37, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {34}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {22}, {17, 25, 22, 23}, {33, 34, 4, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19, 36}, {2, 4, 21, 15}, {37, 8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36}, {33, 2, 34, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37}, {10}, {8}, {24, 27, 31}, {18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {37}, {35, 27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {37, 33, 27, 29}]\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: Linear pareto front program index: 27\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 72: New program candidate index: 37\n",
      "GEPA Optimization:  90%|████████▉ | 2864/3200 [2:49:31<21:38,  3.86s/rollouts]2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 73: No merge candidates found\n",
      "2025/09/30 17:50:38 INFO dspy.teleprompt.gepa.gepa: Iteration 73: Selected program 13 score: 0.6450081168831169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.45 / 3 (81.8%): 100%|██████████| 3/3 [00:09<00:00,  3.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:50:47 INFO dspy.evaluate.evaluate: Average Metric: 2.4545454545454546 / 3 (81.8%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:53:01 INFO dspy.teleprompt.gepa.gepa: Iteration 73: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output **must** follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | string or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | string or `None` | Full main title exactly as it appears on the title page, including subtitle(s) that belong to the same logical heading. |\n",
      "| `alt_title` | list of strings | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | list of strings | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | integer or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | list of strings | Publishing institution(s) **exactly as they appear** (no translation, no trailing punctuation). Only include lines that contain an explicit publisher keyword (see **2.6 Publisher extraction**) or belong to a known publisher list. |\n",
      "| `doi` | string or `None` | DOI **without** any prefix (`10.` …). |\n",
      "| `e_isbn` | list of strings | ISBN(s) that refer to the **electronic/PDF** version, normalized to a plain digit string (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | string or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | string or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | string or `None` | COAR resource type, one of the **lower‑case** values listed in **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "**Formatting rules**\n",
      "\n",
      "* Field name on its own line, **exactly** as shown above (e.g. `language`).\n",
      "* The value on the next line.\n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.\n",
      "* Write `None` literally (no quotes) for missing values.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Strong signals** – Scan **all pages** for a line that explicitly states the language. Accept any of the following patterns (case‑insensitive, allow surrounding whitespace and punctuation):\n",
      "   * `Kieli: <lang>` → map `<lang>` to ISO code (`suomi` → `fi`, `englanti` → `en`, etc.)\n",
      "   * `Language: <lang>` → `English` → `en`, `Swedish` → `sv`, `Finnish` → `fi`\n",
      "   * `Språk: <lang>` or `Språket: <lang>` → `svenska`/`Svenska` → `sv`\n",
      "   * `Kieli:` / `Language:` / `Språk:` may appear with a colon, dash or space.\n",
      "2. If such a line is found, **override** all other evidence and set the language accordingly.\n",
      "3. **Stop‑word counting** – If no explicit line is present, count occurrences (case‑insensitive) of the seed words on **all pages**:\n",
      "\n",
      "| ISO code | Seed words (case‑insensitive) |\n",
      "|----------|------------------------------|\n",
      "| `fi` | `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu` |\n",
      "| `sv` | `och`, `för`, `av`, `liv`, `historien`, `språk` |\n",
      "| `en` | `the`, `and`, `of`, `method`, `introduction`, `chapter` |\n",
      "\n",
      "   * The language with the highest total count wins.\n",
      "   * If the highest count is a tie **or** all counts are zero, output `None`.\n",
      "\n",
      "### 2.2 Title extraction (main title)\n",
      "1. **Locate the title page** – The first page that satisfies **any** of the following:\n",
      "   * Contains a line that is **all‑caps** (ignoring punctuation) and is the **only non‑blank line** on that page, **or** the **first non‑blank line** on the page.\n",
      "   * Contains a Markdown heading (`#`, `##`, `###`) whose text (after stripping the heading markers) is not empty.\n",
      "2. **Capture the logical title**:\n",
      "   * Take the identified line (or heading text) as the **main title**.\n",
      "   * If the **next line** (or the text after a colon on the same line) is non‑blank and looks like a subtitle (i.e. not a heading marker, not a page number, and not separated by a blank line), concatenate it with a single space.\n",
      "   * Preserve **all original punctuation, diacritics, and case**.\n",
      "3. **Clean‑up** – Remove surrounding whitespace and any surrounding heading markers (`#`, `##`, `###`). Do **not** remove internal punctuation or capitalization.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "1. Look for lines that contain any of the following **qualifiers** (case‑insensitive). The qualifier may appear *before* or *after* the title text:\n",
      "   * `English title`, `Title (English)`, `Original title`, `Originaltitel`, `Originaltitel (Englisch)`, `Title (Finnish)`, `Titel (Svenska)`, `Titel (Englisch)`, etc.\n",
      "2. When a qualifier is found, **extract the title text that follows the qualifier** (or that precedes it, if the qualifier is placed after). Apply the same concatenation rules as in 2.2 (include subtitle if present on the next line or after a colon).\n",
      "3. **Do not duplicate** the main `title`. If multiple alternate titles are found, list them all.\n",
      "\n",
      "### 2.4 Creator handling (authors)\n",
      "1. **Search for author lines** – Scan the first three pages (or the whole document if necessary) for any line that contains one of the following keywords (case‑insensitive):\n",
      "   * `Author`, `Authors`, `Tekijä`, `Tekijät`, `Kirjoittaja`, `Kirjoittajat`, `Authors:`, `Tekijä:`, `Tekijät:`, `Kirjoittaja:`, `Kirjoittajat:`, `Opiskelijat`, `Opiskelijat:`, `Författare`, `Författare:`.\n",
      "2. **Extract the raw name string** – The part of the line **after** the keyword (or after a colon) is the raw list of names.\n",
      "3. **Split into individual names** – Names may be separated by any of these delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, Finnish/Swedish equivalents `ja`, `och`.\n",
      "4. **Normalise each name**  \n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged (trim surrounding whitespace).  \n",
      "   * Otherwise, split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "     * Preserve diacritics and original capitalisation.\n",
      "5. **Preserve order of appearance** and return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.  \n",
      "6. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan **pages 1 – 2** for a four‑digit number between 1900 and 2100 that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `År`, `Datum`, `Date`.\n",
      "2. If multiple candidates exist, choose the one **closest** (fewest characters) to a keyword.\n",
      "3. If none is found, fall back to PDF metadata:\n",
      "   * From `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`), extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if still not found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines that contain any of the following **publisher keywords** (case‑insensitive):\n",
      "   * `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `Institute`, `University`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustantaja`, `Kustantaja:`, `Publishing`, `Published`, `Ark`, `Arcada`, `Åbo Akademi`, `Routledge`, `Springer`, `Cambridge`, `Elsevier`, `Wiley`, `Metropolia`, `Åbo Akademi`, `Uppsala`, `Oxford`, etc.\n",
      "2. **Capture the phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as `. , ; :`).  \n",
      "   * If the line **contains only the publisher name** without a preceding keyword (e.g. a line that is exactly `Arcada`), treat the whole line as a publisher **only if the name appears in the known‑publisher list** (see below).\n",
      "3. **Known‑publisher list** – For this task the following names are considered valid publishers (add more as needed):\n",
      "   * `Arcada`, `Åbo Akademi`, `Routledge`, `Springer`, `Cambridge University Press`, `Elsevier`, `Wiley`, `Metropolia`, `Uppsala University`, `Oxford University Press`, `University of Skövde`, `Yrkeshögskolan Arcada`, etc.\n",
      "4. **Do not** treat funding bodies, project names, or acknowledgements as publishers. If a line mentions an institution *without* a publisher keyword and the name is **not** in the known‑publisher list, ignore it.\n",
      "5. Remove surrounding whitespace, keep exact spelling and diacritics.\n",
      "6. Return a list of distinct publishers in order of first appearance. If none, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "* Apply the case‑insensitive regex:  \n",
      "  `(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)`  \n",
      "* Capture group 1, then strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* Return the DOI **without** any prefix (`doi:` or URL). If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. **Extract the identifier** that follows, allowing optional surrounding characters such as `:` `(` `)` and optional hyphens/spaces.  \n",
      "   Example patterns to recognise:  \n",
      "   * `ISBN 978‑952‑302‑949‑1`  \n",
      "   * `(ISBN: 978 952 302 949 1)`  \n",
      "   * `URN:ISBN:978-952-302-949-1`\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic indicators** (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`, `e‑book`, `e‑version`.\n",
      "   * **Print indicators** (case‑insensitive): `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`, `paper`, `paperback`.\n",
      "   * If **both** electronic and print indicators appear for the same identifier, add it to **both** lists.\n",
      "   * If **only electronic** indicators appear → add to `e_isbn` / `e_issn`.\n",
      "   * If **only print** indicators appear → add to `p_isbn` / `p_issn`.\n",
      "   * If **no qualifier** is present, **add the identifier to the electronic list only** (this matches the evaluation expectations).\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep only digits (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly 8 digits (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Detect the resource type by searching the entire document (including PDF metadata) for the following keywords (case‑insensitive). Use the **first matching row** in the table (top‑to‑bottom priority). If multiple rows match, the earliest row wins.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| **ISBN** present **and** a publisher that is in the **known‑publisher list** **and** no thesis‑related keywords → `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI contains a known journal prefix such as `10.1007`, `10.1016`, `10.1080`) → `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **or** the presence of a **journal‑style DOI** (contains a known journal prefix) → `article` |\n",
      "| “Report”, “Technical report”, “Research report” → `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” → `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (publisher in DOI URL is a known book publisher) → `book part` |\n",
      "| *(none of the above)* → `None` |\n",
      "\n",
      "**Important ordering notes**\n",
      "\n",
      "* The **book rule** must be evaluated **before** the thesis rules (i.e., place the “ISBN + book publisher” row above the thesis rows).  \n",
      "* The **article rule** should be evaluated **before** the “report” and “conference paper” rows.  \n",
      "* If the document contains explicit article keywords (e.g., “Opinion”, “Commentary”, “Op‑inion”) even without an ISSN, treat it as an `article`.  \n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "sv\n",
      "title\n",
      "Erfarenheter av vardagen med äldre invandrade personer med demens. En kvalitativ studie bland närståendevårdare i Sverige\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Goodyear, Ann-Christine']\n",
      "year\n",
      "2020\n",
      "publisher\n",
      "['Yrkeshögskolan Arcada']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "Language was taken from the explicit line “Språk: Svenska”. The title was the all‑caps line on page 1 plus the following subtitle line. Author line on page 2 gave the name, which was normalised to “Goodyear, Ann‑Christine”. Year was found next to “Datum för godkännande”. Publisher was identified from the line containing the keyword “Publisher” (or from the known publisher list). No DOI, ISBN or ISSN were present, and thesis‑related keywords led to the COAR type “master thesis”.\n",
      "2025/09/30 17:53:09 INFO dspy.evaluate.evaluate: Average Metric: 2.333333333333333 / 3 (77.8%)\n",
      "2025/09/30 17:53:09 INFO dspy.teleprompt.gepa.gepa: Iteration 73: New subsample score is not better, skipping\n",
      "GEPA Optimization:  90%|████████▉ | 2870/3200 [2:52:02<28:16,  5.14s/rollouts]2025/09/30 17:53:09 INFO dspy.teleprompt.gepa.gepa: Iteration 74: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.91 / 3 (63.6%): 100%|██████████| 3/3 [00:06<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:53:16 INFO dspy.evaluate.evaluate: Average Metric: 1.9090909090909092 / 3 (63.6%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:54:46 INFO dspy.teleprompt.gepa.gepa: Iteration 74: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (e.g. `title`, `author`, `creationDate`, `modDate`).\n",
      "* **pages** – a list of page objects, each with:\n",
      "  * `page` – integer page number  \n",
      "  * `text` – the raw OCR / clipboard text of that page (preserve line breaks as they appear).\n",
      "\n",
      "Your job is to **scan the entire document** (all pages) and output a **flat list of metadata fields** exactly in the format described in *Output format* below.  \n",
      "If a field cannot be found, output the **missing‑value placeholder** shown in the *Missing‑value handling* table.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Fields to extract\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|--------------------------|\n",
      "| **language** | string | ISO‑639‑1 code of the dominant language (`fi`, `en`, `sv`, `se`). Detect from the whole document (see 2.1). If ambiguous → `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle. Preserve the logical line breaks by joining the lines with a **single space** (do **not** insert `\\n`). Do not trim trailing spaces or add punctuation. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not repeat the main title. If none → `[]`. |\n",
      "| **creator** | list of strings | Authors formatted as `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). If a name already contains a comma, keep it unchanged. Split a name on the **last space only**. Preserve order. If none → `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint line(s) (institution, department, university, etc.). Preserve diacritics and original spacing. If multiple entities appear on the same line, split on commas, slashes, or the word “and”. If none → `[]`. |\n",
      "| **doi** | string or `None` | DOI **without any prefix** (`doi:`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if present). Only include if the same line contains an **electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version. Same normalisation as `e_isbn`. Only include if the same line contains a **print qualifier**. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Only include if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Only include if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of the values listed in the **COAR mapping** table (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Normalisation & extraction rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters below:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets the condition → `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Identify the **title page** – the first page (or first two pages) that contain the **largest centred heading(s)** (often ALL‑CAPS or title‑case, may be preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) or appears on the next line **without a blank line** in between, treat it as part of the title.  \n",
      "3. Join the captured lines with a **single space** (do **not** keep line‑break characters).  \n",
      "4. Exclude page numbers, catalogue codes, or section headings.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the immediate next page) for a title in a **different language**. Typical markers:\n",
      "\n",
      "* “English title”, “Title (English)”, “Titel (Englisch)”, etc.  \n",
      "* A second heading placed directly beneath the main title, often in a different script or language.\n",
      "\n",
      "Add each distinct string to `alt_title`. Do not duplicate the main title. If none → `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, locate lines on the title page that contain personal names. Look for cues: “by”, “author”, “Kirjoittaja”, “tekijä”, “author(s):”, etc.  \n",
      "3. For each name:  \n",
      "   * If the name already contains a comma → keep unchanged.  \n",
      "   * Otherwise split on the **last space only** and reorder to `\"Last, First …\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "4. Multiple authors may be separated by commas, semicolons, the word “and”, or line breaks – treat each as a separate author.  \n",
      "5. Preserve the order of appearance.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, pick the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Locate the **imprint line(s)** – usually after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If a line contains multiple entities separated by commas, slashes, or the word “and”, split them into separate list items **preserving the original spelling and diacritics**.  \n",
      "4. Do not add or remove words.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document (including `pdfinfo.title` if present) for any of the following (case‑insensitive):\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and any prefix (`doi:`, `https://doi.org/`, etc.). Output the raw DOI string.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must be on the **same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "Extraction steps:\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "4. Determine the format from qualifiers on the **same line**:  \n",
      "   * Electronic qualifier → add to `e_isbn` / `e_issn`.  \n",
      "   * Print qualifier → add to `p_isbn` / `p_issn`.  \n",
      "   * Both qualifiers present → add to **both** lists.  \n",
      "   * No qualifier → ignore the number completely.  \n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any explicit statements). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) (case‑insensitive) | COAR type (`type_coar`) |\n",
      "|----------------------------------|------------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Research article”, “Journal article”, “Article” (without ISSN) | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| The word “Blog”, “Blog post”, “Blogpost”, “Post” (often with “blog” in URL or heading) | `blog post` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use the exact spelling of the field names shown in the table above. Lists must be valid Python‑style lists: single quotes around items, commas separating items, no trailing commas. Strings must not be quoted.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the largest centred heading on page 1; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 17:54:53 INFO dspy.evaluate.evaluate: Average Metric: 1.8181818181818183 / 3 (60.6%)\n",
      "2025/09/30 17:54:53 INFO dspy.teleprompt.gepa.gepa: Iteration 74: New subsample score is not better, skipping\n",
      "GEPA Optimization:  90%|████████▉ | 2876/3200 [2:53:46<32:53,  6.09s/rollouts]2025/09/30 17:54:53 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Selected program 22 score: 0.6563774924570379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.95 / 3 (65.2%): 100%|██████████| 3/3 [00:08<00:00,  2.71s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:55:01 INFO dspy.evaluate.evaluate: Average Metric: 1.9545454545454546 / 3 (65.2%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:56:52 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).  \n",
      "* **pages** – an **ordered** list of page objects, each with:\n",
      "  * `page` – integer page number (starting at 1)  \n",
      "  * `text` – the raw OCR / clipboard text of that page (preserve line breaks exactly as they appear).\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and output a **flat list of metadata fields** in the exact format described in section 4.  \n",
      "If a field cannot be found, output the *missing‑value placeholder* from section 3.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output fields\n",
      "\n",
      "| Field | Type | Required format & notes |\n",
      "|-------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `sv`, `en`, `se`). Detect from the **majority of visible words** in the whole document (see 2.1). If ambiguous → `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page (see 2.2). Join captured heading lines with a **single space**. No leading/trailing spaces. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that are in a **different language** from the main title (see 2.3). Do not duplicate the main title. If none → `[]`. |\n",
      "| **creator** | list of strings | Personal author names only, formatted as `\"LastName, FirstName[ Middle]\"`. See 2.4 for details. If none → `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint line(s) that name the publishing institution(s). Preserve diacritics, hyphens and spacing. Split a line on commas, slashes, or the words “and” / “och” / “&” into separate list items, **keeping the original spelling**. Only lines that contain a recognised publishing‑institution keyword (e.g. `University`, `Institute`, `College`, `Press`, `Publishing`, `Oy`, `AB`, `Ltd`) should be considered. If none → `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any of the patterns listed in 2.7. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that belong to the **electronic/PDF** version. Normalise by **removing every non‑digit character**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears). Include a number **only if the same line also contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that belong to the **print** version, normalised the same way as `e_isbn`. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised by **removing hyphens** only. Include only if an online qualifier appears on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised by **removing hyphens** only. Include only if a print qualifier appears on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of: `master thesis`, `doctoral thesis`, `book`, `article`, `report`, `research report`, `conference paper`, `newspaper article`. Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived (does not affect scoring). |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the entire document into words: split on any whitespace **or** punctuation.  \n",
      "2. Count occurrences of the language‑specific stop‑words / characteristic characters below (case‑insensitive, diacritics count as they appear).\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the **highest count** wins **provided** its count is at least **1.5 ×** the second‑highest count.  \n",
      "4. If no language satisfies the ratio → output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Locate the title page** – usually the first page (or the first two pages) that contain the **largest centred heading(s)**. Typical clues:\n",
      "   * Lines in **ALL‑CAPS** or title‑case that are visually centred (surrounded by blank lines).  \n",
      "   * The heading is often the **first non‑blank line** after any logos or institution names.  \n",
      "2. Capture **all consecutive heading lines** that belong together (no blank line between them).  \n",
      "3. If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line**, treat it as part of the title.  \n",
      "4. **Do not** include page numbers, catalogue codes, imprint lines, the word “ISBN”, or any DOI/ISSN/ISBN lines.  \n",
      "5. When writing the value, **join the captured lines with a single space** (no extra spaces at start/end). Preserve the original capitalisation, punctuation and diacritics exactly as they appear.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Search the same title page (or the page immediately after) for a heading in a **different language** from the main title.  \n",
      "* Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle that is clearly in another language.  \n",
      "* Add each distinct heading to `alt_title`. Do not duplicate the main title. If none → `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author`. Use it **only if** it looks like a personal name (contains at least one space **and** does **not** contain organisation‑type words such as “group”, “Institute”, “University”, “Department”, “ryhmä”, “förlag”, “press”, “publishing”).  \n",
      "2. If missing or not a personal name, **scan the title page** for lines that look like author lines:\n",
      "   * May be preceded by “by”, “author”, “kirjoittanut”, “tekijä”, etc.  \n",
      "   * May appear directly under the title, often as a list separated by commas, semicolons, “and”, line breaks, or bullet‑like markers.  \n",
      "3. For each candidate name:  \n",
      "   * Trim leading/trailing whitespace.  \n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space** only and reorder to `\"LastName, FirstName[ Middle]\"`.  \n",
      "   * Preserve any particles (e.g., “af”, “de”, “van”) as part of the last name.  \n",
      "4. Discard any candidate that is clearly an **organisation** (contains words like “group”, “ryhmä”, “Institute”, “University”, “Department”, “förlag”, “press”, “publishing”, “Oy”, “AB”, “Ltd”, etc., or is all caps without a personal name).  \n",
      "5. Return the remaining names as a list in the order found. If none → `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **title page**, any copyright line, and the imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If still none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Keep **only lines that contain at least one publishing‑institution keyword** (`University`, `Institute`, `College`, `Press`, `Publishing`, `Oy`, `AB`, `Ltd`, `School`, `Centre`, `Center`).  \n",
      "3. Capture the whole line(s) that name the publishing institution(s).  \n",
      "4. If a line contains multiple entities separated by commas, slashes, “and”, “och”, “&”, split them into separate list items **preserving the original spelling, diacritics and spacing**.  \n",
      "5. Do **not** add or remove words. If no imprint can be identified → `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document (including `pdfinfo`) for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the **raw DOI string** (e.g. `10.1234/abcd.efg`). If none → `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Locate every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the number that follows it (it may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * **ISBN** – remove **all** non‑digit characters; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * **ISSN** – remove **only hyphens** (keep the 8‑digit string).  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "5. Preserve the order in which the numbers appear in the document.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the whole document (especially the title page and imprint) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “master’s thesis” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation”, “doctoral thesis” | `doctoral thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” **without** the word “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| The phrase “Newspaper article”, “Tidningsartikel”, “Tidning” | `newspaper article` |\n",
      "| If none match → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the value on the **next line**. Use the exact spelling of the field names shown in the table above. Lists must be valid Python‑style lists: single quotes, commas, no trailing commas.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the first centred heading on page 1; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 17:56:59 INFO dspy.evaluate.evaluate: Average Metric: 2.018181818181818 / 3 (67.3%)\n",
      "2025/09/30 17:57:37 INFO dspy.evaluate.evaluate: Average Metric: 40.89242424242424 / 64 (63.9%)\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Full valset score for new program: 0.6389441287878788\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Full train_val score for new program: 0.6389441287878788\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Individual valset scores for new program: [0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.5454545454545454, 0.7272727272727273, 0.2727272727272727, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.45454545454545453, 0.7272727272727273, 0.7272727272727273, 0.45454545454545453, 0.8181818181818182, 0.5454545454545454, 0.7878787878787878, 0.5454545454545454, 0.5454545454545454, 0.36363636363636365, 0.5454545454545454, 0.6363636363636364, 0.6363636363636364, 0.7727272727272727, 0.9090909090909091, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.5151515151515151, 0.36363636363636365, 0.5454545454545454, 0.42424242424242425, 0.9090909090909091, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.3333333333333333, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.5151515151515151, 0.5151515151515151, 0.6060606060606061, 0.6666666666666666, 0.6060606060606061, 0.5227272727272727, 0.5909090909090909, 0.5909090909090909, 0.7272727272727273]\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Full valset pareto front score: 0.7832386363636363\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Updated valset pareto front programs: [{3, 35, 37, 6, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {34, 37, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 37, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {34, 38}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {38, 7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {38, 22}, {38, 17, 22, 23, 25}, {33, 34, 4, 38, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19, 36}, {2, 4, 21, 15}, {37, 8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38}, {33, 2, 34, 6, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38}, {10}, {8}, {24, 27, 31}, {38, 18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {37}, {35, 27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {37, 33, 27, 29}]\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: Linear pareto front program index: 27\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 75: New program candidate index: 38\n",
      "GEPA Optimization:  92%|█████████▏| 2946/3200 [2:56:30<16:46,  3.96s/rollouts]2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 76: No merge candidates found\n",
      "2025/09/30 17:57:37 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Selected program 21 score: 0.6088338744588745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.64 / 3 (54.5%): 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:57:42 INFO dspy.evaluate.evaluate: Average Metric: 1.6363636363636362 / 3 (54.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 17:59:35 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** per request.  \n",
      "It contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – an ordered list of page objects, each with an integer `page` and a string `text` that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Treat each request as completely independent – do not carry over any information from previous requests.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "* Write the **field name** on a line **by itself**, then write its **value** on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: use single quotes, commas, no trailing comma, no spaces inside the brackets (e.g. `['A','B']`).  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does not affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If ambiguous, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the *title page* (first 1‑2 pages that contain the largest centred heading). Preserve original case, punctuation and spaces; join consecutive heading lines with a **single space** (do **not** insert `\\n`). Include subtitle if it follows a colon on the same line **or** appears on the next line **without a blank line** in between. If no title can be found, output `None`. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) that are **clearly in a different language** (usually English). Look for a second heading on the title page or the next page that is not identical to `title`. Do **not** duplicate `title`. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Use `pdfinfo.author` **if present**; otherwise locate author lines on the title page (markers: `Author:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, `author`, `tekijä`). For each name: <br>• If it already contains a comma, keep it unchanged. <br>• Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`. <br>• Preserve diacritics and original ordering. <br>Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If several candidates exist, choose the one **closest (by line distance) to the title**. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part. |\n",
      "| **publisher** | list of strings | Imprint institution(s). For each imprint line: keep the text **before the first comma**. If a line contains several distinct institutions separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element. Preserve original spelling and case. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep **only the digits** (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. **Tokenise** the entire document into words (split on whitespace and punctuation).  \n",
      "2. Count case‑insensitive occurrences of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Title page** is usually the first page (or first two pages) that contain the **largest centred heading(s)**. Heuristics: lines that are ALL‑CAPS, Title‑Case, surrounded by blank lines, or prefixed with markdown headings (`#`, `##`, `###`).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line** between, treat it as part of the title.  \n",
      "3. Preserve the exact wording (including case, punctuation, diacritics). Join captured lines with a **single space** (no `\\n`).  \n",
      "4. If no such heading can be identified, set `title` to `None`.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the immediate next page) for a heading that is clearly a title **in a different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title. If none is found, output `[]`.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, locate lines on the title page containing personal names. Typical markers: “Author:”, “Författare:”, “Tekijä:”, “Kirjoittaja”, “by”, “author”, “tekijä”, or a line directly under the title consisting mainly of capitalised names.  \n",
      "3. **Do not** treat department names, university names, or acknowledgements as authors.  \n",
      "4. For each name found:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.  \n",
      "6. If no author can be identified, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **text before the first comma** on each imprint line.  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element, preserving original spelling and case.  \n",
      "4. Do not include city names, department names, or addresses unless they are themselves separate institutions.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string.  \n",
      "   * ISSN – remove hyphens only (keep the 8‑digit string, e.g. `00826995`).  \n",
      "\n",
      "4. Look at the same line for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Master’s thesis” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” (combined with “thesis”) | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISBN(s)** **and** the word “part” or “chapter” indicating a contribution to a larger work | `book part` |\n",
      "| Presence of **ISSN(s)** **and** journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations\n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, language, or COAR type that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* When multiple possible values exist, follow the disambiguation rules in the relevant section (e.g., language ratio, closest year to title, first matching COAR indicator).  \n",
      "* Preserve the **order of appearance** for list fields.  \n",
      "* Output **exactly** the fields in the order specified; do not add extra fields or change formatting.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example output template\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Performing landscape : live and alive\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Arlander, Annette']\n",
      "year\n",
      "2012\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "article\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "2025/09/30 17:59:40 INFO dspy.evaluate.evaluate: Average Metric: 2.1515151515151514 / 3 (71.7%)\n",
      "2025/09/30 18:00:11 INFO dspy.evaluate.evaluate: Average Metric: 37.06060606060608 / 64 (57.9%)\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Full valset score for new program: 0.5790719696969697\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Full train_val score for new program: 0.5790719696969697\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Individual valset scores for new program: [0.8181818181818182, 0.45454545454545453, 0.696969696969697, 0.36363636363636365, 0.8181818181818182, 0.36363636363636365, 0.7272727272727273, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.8181818181818182, 0.09090909090909091, 0.7272727272727273, 0.6363636363636364, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.2727272727272727, 0.6363636363636364, 0.45454545454545453, 0.9090909090909091, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.36363636363636365, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.5454545454545454, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.8181818181818182, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.45454545454545453, 0.18181818181818182, 0.2727272727272727, 0.2727272727272727, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.36363636363636365, 0.36363636363636365, 0.36363636363636365, 0.5454545454545454, 0.36363636363636365, 0.8181818181818182, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273]\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.7878787878787878, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Full valset pareto front score: 0.7832386363636363\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Updated valset pareto front programs: [{3, 35, 37, 6, 39, 8, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {8, 9, 39, 31}, {19, 3, 21}, {4, 29}, {19, 21, 14}, {29}, {8, 16, 20, 29}, {34, 37, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 37, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {34, 38}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {38, 7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {38, 22, 39}, {38, 17, 22, 23, 25}, {33, 34, 4, 38, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19, 36}, {2, 4, 21, 15}, {37, 8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39}, {33, 2, 34, 6, 39, 10, 14, 20, 21, 23, 27, 28, 29}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39}, {10}, {8}, {24, 27, 31}, {38, 18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {37}, {35, 27, 15}, {27}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {37, 33, 27, 29}]\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: Linear pareto front program index: 27\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 76: New program candidate index: 39\n",
      "GEPA Optimization:  94%|█████████▍| 3016/3200 [2:59:04<09:45,  3.18s/rollouts]2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: No merge candidates found\n",
      "2025/09/30 18:00:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Selected program 19 score: 0.5849262716450216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.27 / 3 (42.4%): 100%|██████████| 3/3 [00:07<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:00:18 INFO dspy.evaluate.evaluate: Average Metric: 1.2727272727272727 / 3 (42.4%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:02:12 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured bibliographic metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** per request.  \n",
      "It contains two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary with PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`).  \n",
      "* **pages** – an ordered list of page objects, each with an integer `page` and a string `text` that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document (all pages)** and output a **flat list of metadata fields** exactly in the format described below.  \n",
      "Treat each request as completely independent – do **not** carry any information from previous requests.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Output format\n",
      "\n",
      "* Write the field name on a line **by itself**, then write its value on the **next line**.  \n",
      "* Follow the order given in the table under **1.1 Output fields**.  \n",
      "* List values must be **valid Python‑style lists**: single quotes, commas, no trailing comma.  \n",
      "* If a field cannot be determined, output the placeholder shown in the *Missing‑value handling* table.  \n",
      "* An optional free‑text field `reasoning` may be added **after** `type_coar`. It does not affect scoring.\n",
      "\n",
      "---\n",
      "\n",
      "## 1.1 Output fields\n",
      "\n",
      "| Field name | Type | Required format & notes |\n",
      "|------------|------|------------------------|\n",
      "| **language** | string | ISO‑639‑1 code (`fi`, `en`, `sv`, `se`). Detect from the **majority of visible words** using the stop‑word/character method described in 2.1. If ambiguous, output `None`. |\n",
      "| **title** | string | Exact title as it appears on the title page, including subtitle. Preserve original case, punctuation and spaces; join consecutive heading lines with a **single space** (do **not** insert `\\n`). A subtitle is part of the title when: <br>  • it follows a colon (`:`) on the same line, **or** <br>  • it appears on the next line **without a blank line in between**. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors in the form `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). Use `pdfinfo.author` if present; otherwise locate author lines on the title page (look for markers such as `Author:`, `Författare:`, `Tekijä:`, `Kirjoittaja`, `by`, etc.). <br>  *If a name already contains a comma, keep it unchanged.* <br>  *Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.* <br>  Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks, preserving order. If no author can be identified, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If none, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`). Return as an integer; otherwise `None`. |\n",
      "| **publisher** | list of strings | Exact imprint institution(s). For each imprint line, **keep the text before the first comma**. If a line contains several distinct institutions separated by `/`, the word “and”, or appears on separate lines, each becomes a separate list element, preserving original spelling. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `https://doi.org/`, brackets, etc.). Detect any pattern matching `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Keep only the **digits** (remove every non‑digit). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalized the same way. Include only if a print qualifier is present on the same line. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalized (remove hyphens). Include only if an electronic qualifier is present on the same line. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalized (remove hyphens). Include only if a print qualifier is present on the same line. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of:  \n",
      "\n",
      "  `master thesis`, `doctoral thesis`, `bachelor thesis`, `book`, `book part`, `article`, `research article`, `report`, `research report`, `conference paper`.  \n",
      "\n",
      "  Determine from wording (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count case‑insensitive occurrences of the following language‑specific stop‑words / characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or first two pages) that contain the **largest centred heading(s)**. Clues: ALL‑CAPS, title‑case, surrounded by blank lines, or markdown headings (`#`, `##`, `###`).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve the exact wording (including case and punctuation). Join captured lines with a **single space** (do **not** insert line‑break characters).  \n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the next page) for a heading that is clearly a title **in a different language**. Typical markers: “English title”, “Title (English)”, a second heading placed directly beneath the main title, or a subtitle in English. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names. Typical markers: “Author:”, “Författare:”, “Tekijä:”, “Kirjoittaja”, “by”, “author”, “tekijä”, or a line directly under the title consisting mainly of capitalised names.  \n",
      "3. **Do not** treat department names, university names, or acknowledgements as authors.  \n",
      "4. For each name found:  \n",
      "\n",
      "   * If the string already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** → `\"First Middle Last\"` → `\"Last, First Middle\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "5. Separate multiple authors delimited by commas, semicolons, the word “and”, or line breaks. Preserve the order of appearance.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none is found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (`D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return the year as an **integer**; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – usually after the author(s) and before the year/location.  \n",
      "2. Keep the **text before the first comma** on each imprint line.  \n",
      "3. If the line contains **multiple distinct institutions** separated by slashes (`/`), the word “and”, or appears on separate lines, each becomes a separate list element, preserving the original spelling.  \n",
      "4. Do not include city names, department names, or addresses unless they are themselves separate institutions.  \n",
      "5. If no imprint line can be identified, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the whole document for any of the following (case‑insensitive) patterns and extract the raw DOI string:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip surrounding punctuation, brackets, and prefixes. If none is found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `online`, `e‑`, `e-`, `e `, `sid.` **with** “elektroninen”, `verkkojulkaisu`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` **with** “painettu”, `paper`, `(Print)`, `(painettu)` |\n",
      "\n",
      "*The Finnish words “verkkojulkaisu” → electronic, “painettu” → print.*\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of the case‑insensitive words `ISBN` or `ISSN`.  \n",
      "2. Capture the **following number** (may contain hyphens, spaces, or parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * **ISBN** – remove **all non‑digit characters**; keep the resulting digit string (13‑digit if present, otherwise keep what remains).  \n",
      "   * **ISSN** – remove hyphens only.  \n",
      "\n",
      "4. Look at the **same line** for qualifiers:  \n",
      "\n",
      "   * If an **electronic** qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a **print** qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If both appear, add to both lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order of appearance; duplicate numbers should be kept only once per list.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any headings) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type |\n",
      "|--------------|-----------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation”, “Master’s thesis” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “BACHELOR’S THESIS”, “Bachelor thesis”, “Bachelors thesis”, “Opinnäytetyö”, “Bachelors” (combined with “thesis”) | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISBN(s)** **and** the word “part” or “chapter” indicating a contribution to a larger work | `book part` |\n",
      "| Presence of **ISSN(s)** **and** journal‑style headings (volume, issue, article title) | `article` |\n",
      "| Same as above **and** the document explicitly says “research article”, “original article”, “peer‑reviewed article” | `research article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. General rules to avoid hallucinations\n",
      "\n",
      "* **Never invent** a DOI, ISBN, ISSN, author name, publisher, year, language, or any other field that is not present in the supplied text or in `pdfinfo`.  \n",
      "* If a pattern is found but the required qualifier (electronic/print) is missing, **ignore** the number.  \n",
      "* Process each request **in isolation**; do not carry over data from previous examples.  \n",
      "* When multiple possible values exist, follow the specific disambiguation rules above; otherwise use the placeholder.  \n",
      "\n",
      "---\n",
      "\n",
      "## 5. Example output (template)\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Creative leader’s impact on the working environment\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Forsander, Kim']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "['Yrkeshögskolan Novia']\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "bachelor thesis\n",
      "reasoning\n",
      "[optional free‑text explanation]\n",
      "```\n",
      "\n",
      "Follow the template **exactly**: one field name line, one value line, in the order shown.  \n",
      "\n",
      "--- \n",
      "\n",
      "**Remember:**  \n",
      "* Title may span multiple lines; join with a single space.  \n",
      "* ISBN/ISSN must be assigned to the correct electronic (`e_`) or print (`p_`) list **based on the qualifier on the same line**.  \n",
      "* Language detection uses the 1.5 × threshold rule.  \n",
      "* COAR type is the **first** rule that matches.  \n",
      "\n",
      "Good luck!\n",
      "2025/09/30 18:02:19 INFO dspy.evaluate.evaluate: Average Metric: 1.3636363636363635 / 3 (45.5%)\n",
      "2025/09/30 18:03:05 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 18:03:05 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 18:03:05 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 18:03:05 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 18:03:11 INFO dspy.evaluate.evaluate: Average Metric: 40.10994019964271 / 64 (62.7%)\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Full valset score for new program: 0.6267178156194174\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Full train_val score for new program: 0.6267178156194174\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Individual valset scores for new program: [0.8181818181818182, 0.6363636363636364, 0.7272727272727273, 0.45454545454545453, 0.7272727272727273, 0.36363636363636365, 0.5454545454545454, 0.8181818181818182, 0.7272727272727273, 0.7142857142857143, 0.9090909090909091, 0.36363636363636365, 0.6363636363636364, 0.6363636363636364, 0.36363636363636365, 0.7272727272727273, 0.5454545454545454, 0.696969696969697, 0.7272727272727273, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091, 0.5454545454545454, 0.5406698564593302, 0.7272727272727273, 0.36363636363636365, 0.9090909090909091, 0.9090909090909091, 0.9090909090909091, 0.5454545454545454, 0.36363636363636365, 0.7272727272727273, 0.3333333333333333, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.45454545454545453, 0.7272727272727273, 0.9090909090909091, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.2727272727272727, 0.6363636363636364, 0.36363636363636365, 0.5454545454545454, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.42424242424242425, 0.6363636363636364, 0.8287220026350461, 0.5454545454545454, 0.7171717171717172, 0.49090909090909096, 0.6363636363636364, 0.6363636363636364]\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: New valset pareto front scores: [0.8181818181818182, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.6363636363636364, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.8287220026350461, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Full valset pareto front score: 0.7852972661396574\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Updated valset pareto front programs: [{3, 35, 37, 6, 39, 8, 40, 12, 16, 23, 27, 29, 31}, {28, 21}, {18}, {8, 10}, {19, 21}, {32, 18}, {18, 27}, {39, 8, 9, 40, 31}, {19, 3, 21}, {4, 29}, {40, 19, 21, 14}, {29}, {8, 16, 20, 29}, {34, 37, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 37, 10, 16, 20, 22, 23, 25, 27, 29}, {33, 6, 8, 10, 26}, {34, 38}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {38, 7, 8, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {38, 22, 39}, {38, 17, 22, 23, 25}, {33, 34, 4, 38, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19, 36}, {2, 4, 21, 15}, {37, 8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39}, {40}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40}, {10}, {8}, {24, 27, 31}, {38, 18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {37}, {40, 35, 27, 15}, {40}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {37, 33, 27, 29}]\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: Linear pareto front program index: 27\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 77: New program candidate index: 40\n",
      "GEPA Optimization:  96%|█████████▋| 3086/3200 [3:02:04<05:35,  2.94s/rollouts]2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 78: No merge candidates found\n",
      "2025/09/30 18:03:11 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Selected program 10 score: 0.6615530303030303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 2.12 / 3 (70.7%): 100%|██████████| 3/3 [00:06<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:03:17 INFO dspy.evaluate.evaluate: Average Metric: 2.121212121212121 / 3 (70.7%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:04:54 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).\n",
      "* **pages** – a list of page objects, each with an integer `page` number and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and produce a **flat list of metadata fields**.  \n",
      "Write each field name on its own line, followed by the extracted value on the next line (see *Output format*).  \n",
      "If a value cannot be found, output the placeholder described in the *Missing‑value handling* table.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields\n",
      "\n",
      "| Field name | Type | Notes |\n",
      "|------------|------|-------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language: `fi`, `en`, `sv`, `se`. Detect from the **majority of visible words** (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle and line‑breaks that belong to the same logical heading. Do **not** trim trailing spaces or add punctuation. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors formatted as `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). If a name already contains a comma, keep it unchanged. Split a name on the **last space only**. Preserve the order in which authors appear. If none, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint string(s) (e.g. university, department, institute). Preserve diacritics, hyphens, and spacing. If multiple institutions are listed, each becomes a separate list element in the order they appear. Do **not** include URLs or website names. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** and keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. Include only if an explicit print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an explicit online qualifier is present. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. Include only if an explicit print qualifier is present. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of the values listed in the *COAR mapping* table (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction, normalisation & detection rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise the **entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` (Finnish) | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` (English) | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` (Swedish) | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` (Northern Sami) | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or first two pages) that contain the **largest centred heading(s)** (often ALL‑CAPS or title‑case, possibly preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve exact line breaks **by joining the captured lines with a single space** for the output (do **not** insert extra line‑break characters).  \n",
      "4. Exclude page numbers, catalogue codes, or section headings.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the immediate next page) for a title in a **different language**. Typical markers: “English title”, “Title (English)”, or a second heading placed beneath the main title. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names (often directly under the title, or preceded by “by”, “author”, “kirjoittanut”, “Tekijä”, etc.).  \n",
      "3. For each name found:  \n",
      "\n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** and re‑order to `\"Last, First …\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "4. Multiple authors may be separated by commas, semicolons, the word “and”, “ja”, or line breaks – treat each as a separate author, preserving the order in which they appear.  \n",
      "5. Return the list; if none, output `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically located after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, or “and”, split them into separate list items **preserving the original spelling and diacritics**.  \n",
      "4. **Do not** treat URLs (e.g. `http://…`, `www.…`) or website names as publishers.  \n",
      "5. If no imprint line is found, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string. If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "   * ISBN – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * ISSN – remove hyphens only.  \n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "\n",
      "   * If an electronic qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a print qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order in which numbers appear in the document.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any explicit statements) for the following key phrases (case‑insensitive). The **first matching rule** determines the type.\n",
      "\n",
      "| Indicator(s) | COAR type (lower‑case) |\n",
      "|--------------|------------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “Kandidaatin tutkielma”, “Kandidaatintyö”, “Bachelors thesis” | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| Newspaper‑style layout with a clear **publisher that is a newspaper** (e.g., “Svängrum”, “Aftonbladet”) or explicit wording such as “article”, “column”, “news” | `newspaper article` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "*Only the first applicable rule is used.*  \n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the extracted value on the **next line**. Use the exact spelling of the field names shown above.\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "A Comprehensive Study of XYZ: Methods and Applications\n",
      "alt_title\n",
      "['A Comprehensive Study of XYZ (English)']\n",
      "creator\n",
      "['Doe, Jane', 'Smith, John']\n",
      "year\n",
      "2022\n",
      "publisher\n",
      "['University of Example', 'Department of Computer Science']\n",
      "doi\n",
      "10.1234/example.doi\n",
      "e_isbn\n",
      "['9781234567890']\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "book\n",
      "reasoning\n",
      "The title was taken from the first centred heading; the year 2022 appears on the imprint line; the publisher line contains two institutions, etc.\n",
      "2025/09/30 18:05:02 INFO dspy.evaluate.evaluate: Average Metric: 2.4545454545454546 / 3 (81.8%)\n",
      "2025/09/30 18:05:36 INFO dspy.evaluate.evaluate: Average Metric: 40.9651515151515 / 64 (64.0%)\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Full valset score for new program: 0.6400804924242425\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Full train_val score for new program: 0.6400804924242425\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Individual valset scores for new program: [0.8545454545454546, 0.696969696969697, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.2727272727272727, 0.9090909090909091, 0.7272727272727273, 0.36363636363636365, 0.8181818181818182, 0.7272727272727273, 0.7090909090909091, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.6060606060606061, 0.6363636363636364, 0.7272727272727273, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.4848484848484848, 0.7272727272727273, 0.36363636363636365, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.6060606060606061, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.8181818181818182, 0.6363636363636364, 0.6363636363636364, 0.7272727272727273, 0.8181818181818182, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.8181818181818182, 0.696969696969697, 0.6363636363636364, 0.6363636363636364, 0.3333333333333333, 0.5454545454545454, 0.45454545454545453, 0.5454545454545454, 0.6363636363636364, 0.8181818181818182, 0.5454545454545454, 0.5151515151515151, 0.6363636363636364, 0.6666666666666666, 0.6060606060606061, 0.6136363636363636, 0.4848484848484848, 0.6363636363636364, 0.6363636363636364]\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: New valset pareto front scores: [0.8545454545454546, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.8287220026350461, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Full valset pareto front score: 0.7872859025032938\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Updated valset pareto front programs: [{41}, {28, 21}, {18}, {8, 41, 10}, {19, 21}, {32, 41, 18}, {18, 27}, {39, 8, 9, 40, 31}, {19, 3, 21}, {4, 29}, {40, 19, 21, 14}, {29}, {8, 41, 16, 20, 29}, {34, 37, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 37, 10, 16, 20, 22, 23, 25, 27, 29}, {41}, {34, 38}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {38, 7, 8, 41, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {38, 41, 22, 39}, {38, 17, 22, 23, 25}, {33, 34, 4, 38, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19, 36}, {2, 4, 21, 15}, {37, 8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39}, {40}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41}, {10}, {8}, {24, 27, 31}, {38, 18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {37}, {35, 40, 41, 15, 27}, {40}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {37, 33, 27, 29}]\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: Linear pareto front program index: 27\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 78: New program candidate index: 41\n",
      "GEPA Optimization:  99%|█████████▊| 3156/3200 [3:04:29<01:55,  2.63s/rollouts]2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 79: No merge candidates found\n",
      "2025/09/30 18:05:36 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Selected program 41 score: 0.6400804924242425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 1.61 / 3 (53.5%): 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:05:42 INFO dspy.evaluate.evaluate: Average Metric: 1.606060606060606 / 3 (53.5%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:07:14 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Proposed new text for predict: markdown\n",
      "# Instruction for extracting structured metadata from PDF‑extracted JSON\n",
      "\n",
      "You will receive **one JSON object** with two top‑level keys:\n",
      "\n",
      "* **pdfinfo** – optional dictionary containing PDF‑level metadata (`title`, `author`, `creationDate`, `modDate`, …).  \n",
      "* **pages** – a list of page objects, each with an integer `page` number and a `text` string that is the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **scan the whole document** (all pages) and produce a **flat list of metadata fields**.  \n",
      "Write each field name on its own line, followed by the extracted value on the next line (see *Output format*).  \n",
      "If a value cannot be found, output the placeholder described in the *Missing‑value handling* table.\n",
      "\n",
      "---\n",
      "\n",
      "## 1. Required output fields\n",
      "\n",
      "| Field name | Type | Notes |\n",
      "|------------|------|-------|\n",
      "| **language** | string | ISO‑639‑1 code of the document language: `fi`, `en`, `sv`, `se`. Detect from the **majority of visible words** (see 2.1). If ambiguous, output `None`. |\n",
      "| **title** | string | Full title **exactly as it appears** on the title page, including subtitle. Preserve line breaks by joining captured lines with a single space (no `\\n`). Do **not** trim trailing spaces or add punctuation. |\n",
      "| **alt_title** | list of strings | Any alternate title(s) in a **different language** (usually English). Do not duplicate the main title. If none, output `[]`. |\n",
      "| **creator** | list of strings | Authors formatted as `\"LastName, FirstName\"` (or `\"LastName, FirstName Middle\"`). If a name already contains a comma, keep it unchanged. Split a name on the **last space only**. Preserve the order in which authors appear. If none, output `[]`. |\n",
      "| **year** | integer or `None` | 4‑digit publication year (1900 – current year + 1). Prefer a year on the title page, copyright line, or imprint. If not found, fall back to `pdfinfo.creationDate` / `pdfinfo.modDate`. |\n",
      "| **publisher** | list of strings | Exact imprint string(s) (e.g. university, department, institute). Preserve diacritics, hyphens, and spacing. If multiple institutions are listed, each becomes a separate list element in the order they appear. Do **not** include URLs or website names. If none, output `[]`. |\n",
      "| **doi** | string or `None` | DOI **without** any prefix (`doi:`, `DOI`, `https://doi.org/`, brackets, etc.). Detect pattern `10.<digits>/<non‑space>`. |\n",
      "| **e_isbn** | list of strings | ISBN(s) that refer to the **electronic/PDF** version. Normalise by **removing every non‑digit character** (keep only the digit string). Include a number **only if the same line contains an explicit electronic qualifier** (see 2.8). |\n",
      "| **p_isbn** | list of strings | ISBN(s) that refer to the **print** version, normalised the same way as `e_isbn`. Include only if an explicit print qualifier is present. |\n",
      "| **e_issn** | string or `None` | ISSN for the **online** version, normalised (remove hyphens). Include only if an explicit online qualifier is present. |\n",
      "| **p_issn** | string or `None` | ISSN for the **print** version, normalised. Include only if an explicit print qualifier is present. |\n",
      "| **type_coar** | string or `None` | COAR resource type (lower‑case). Must be one of the values listed in the *COAR mapping* table (see 2.9). |\n",
      "| **reasoning** (optional) | free text | One‑ or two‑sentence explanation of how the values were derived. This field does **not** affect scoring. |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Extraction, normalisation & detection rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Tokenise **the entire document** into words (split on whitespace and punctuation).  \n",
      "2. Count occurrences of language‑specific stop‑words / characteristic characters:\n",
      "\n",
      "| Language | Sample stop‑words / characters |\n",
      "|----------|-------------------------------|\n",
      "| `fi` | “ja”, “on”, “että”, “käyttäjä”, “ä”, “ö”, “å” |\n",
      "| `en` | “the”, “and”, “of”, “in”, “to”, “a” |\n",
      "| `sv` | “och”, “att”, “är”, “för”, “i”, “å” |\n",
      "| `se` | “á”, “č”, “đ”, “ŋ”, “ž”, “áŋ”, “golle”, “dás” |\n",
      "\n",
      "3. The language with the highest count wins **provided its count is at least 1.5 × the second‑highest**.  \n",
      "4. If no language meets this condition, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. Locate the **title page** – usually the first page (or the first two pages) that contain the **largest centred heading(s)** (often ALL‑CAPS or title‑case, possibly preceded/followed by a blank line).  \n",
      "2. Capture **all consecutive heading lines** that together form the title.  \n",
      "   * If a subtitle follows a colon (`:`) **or** appears on the next line **without a blank line in between**, treat it as part of the title.  \n",
      "3. Preserve exact line breaks **by joining the captured lines with a single space** (do **not** insert `\\n`).  \n",
      "4. Exclude page numbers, catalogue codes, or section headings.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "Search the same title page (or the immediate next page) for a title in a **different language**. Typical markers: “English title”, “Title (English)”, “Titel (Englisch)”, or a second heading placed beneath the main title. Add each distinct string to `alt_title`. Do not duplicate the main title.\n",
      "\n",
      "### 2.4 Creator (author) handling\n",
      "1. **First preference**: `pdfinfo.author` (if present).  \n",
      "2. If missing, look for lines on the title page that contain personal names (often directly under the title, or preceded by “by”, “author”, “kirjoittanut”, “Tekijä”, etc.).  \n",
      "3. For each name found:  \n",
      "\n",
      "   * If the name already contains a comma, keep it unchanged.  \n",
      "   * Otherwise split on the **last space only** and reorder to `\"Last, First …\"`.  \n",
      "   * Trim surrounding whitespace.  \n",
      "\n",
      "4. Multiple authors may be separated by commas, semicolons, the word “and”, “ja”, or line breaks – treat each as a separate author, preserving the order in which they appear.  \n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the title page, copyright line, and imprint for a **4‑digit number** between 1900 and (current year + 1).  \n",
      "2. If several candidates exist, choose the one **closest (by line distance) to the title**.  \n",
      "3. If none found, parse `pdfinfo.creationDate` or `pdfinfo.modDate` (format `D:YYYYMMDD…`) and take the `YYYY` part.  \n",
      "4. Return as an integer; otherwise `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Identify the **imprint line(s)** – typically located after the title, subtitle, author(s) and before the year/location.  \n",
      "2. Capture the whole line(s) that represent the publishing institution(s).  \n",
      "3. If the line contains multiple entities separated by commas, slashes, “and”, or “&”, split them into separate list items **preserving the original spelling, diacritics and internal spacing**.  \n",
      "4. **Do not** treat URLs (e.g. `http://…`, `www.…`) or website names as publishers.  \n",
      "5. If no imprint line is found, output `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Search the entire document for any of the following (case‑insensitive) patterns:\n",
      "\n",
      "* `doi:10.<digits>/<non‑space>`\n",
      "* `10.<digits>/<non‑space>`\n",
      "* `https://doi.org/10.<digits>/<non‑space>`\n",
      "* `[10.<digits>/<non‑space>]`\n",
      "\n",
      "Strip any surrounding punctuation, brackets, or prefixes and output the raw DOI string. If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN extraction & classification\n",
      "**Qualifiers** (must appear **in the same line** as the number):\n",
      "\n",
      "| Electronic qualifiers | Print qualifiers |\n",
      "|----------------------|-----------------|\n",
      "| `PDF`, `pdf`, `electronic`, `sid.` (Finnish “sähköinen”), `online`, `e‑`, `(Online)`, `(PDF)` | `Print`, `PRINT`, `paper`, `painettu`, `sid.` when paired with “Print”, `(Print)`, `(painettu)`, `paper`, `painettu` |\n",
      "\n",
      "**Extraction steps**\n",
      "\n",
      "1. Find every occurrence of `ISBN` or `ISSN` (case‑insensitive).  \n",
      "2. Capture the following number (may contain hyphens, spaces, parentheses).  \n",
      "3. **Normalise**:  \n",
      "\n",
      "   * **ISBN** – remove **all non‑digit characters**; keep the resulting digit string (13‑digit preferred, but keep 10‑digit if that is what appears).  \n",
      "   * **ISSN** – remove hyphens only (e.g. `1234-5678` → `12345678`).  \n",
      "\n",
      "4. Determine the format from the qualifier(s) on the **same line**:  \n",
      "\n",
      "   * If an electronic qualifier is present → add to `e_isbn` / `e_issn`.  \n",
      "   * If a print qualifier is present → add to `p_isbn` / `p_issn`.  \n",
      "   * If **both** qualifiers appear, add the number to **both** lists.  \n",
      "   * If **no qualifier** is present, **ignore** the number completely.  \n",
      "\n",
      "5. Preserve the order in which numbers appear in the document.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Examine the whole document (especially title page, imprint, and any explicit statements) for the following key phrases (case‑insensitive). The **first matching rule** determines the type (stop after the first match).\n",
      "\n",
      "| Indicator(s) | COAR type (lower‑case) |\n",
      "|--------------|------------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Väitöskirja”, “Dissertation”, “Doctoral thesis”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor’s thesis”, “Kandidaatin tutkielma”, “Kandidaatintyö”, “Bachelors thesis” | `bachelor thesis` |\n",
      "| Presence of **ISBN(s)** **and** no thesis wording, plus a monograph‑style imprint (publisher, year) | `book` |\n",
      "| Presence of **ISSN(s)** and journal‑style headings (volume, issue, article title) | `article` |\n",
      "| The word “Report” (or “Technical report”) **without** “research” | `report` |\n",
      "| The phrase “Research report” (or “research report”) | `research report` |\n",
      "| Words like “Proceedings”, “Conference”, “Conference paper”, “Conference name” | `conference paper` |\n",
      "| Newspaper‑style layout with a clear **publisher that is a newspaper** (e.g., “Aftonbladet”, “Svängrum”) **or** explicit wording such as “article”, “column”, “news” | `newspaper article` |\n",
      "| If none of the above apply → `None` |\n",
      "\n",
      "*Only the first applicable rule is used.*  \n",
      "\n",
      "---\n",
      "\n",
      "## 3. Missing‑value handling\n",
      "\n",
      "| Field | Output when not found |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Output format\n",
      "\n",
      "Write each field name on a line **by itself**, then the extracted value on the **next line**. Use the exact spelling of the field names shown above.\n",
      "\n",
      "* For **strings** write the raw string (no surrounding quotes).  \n",
      "* For **lists** write a valid Python list literal, e.g. `['first', 'second']`.  \n",
      "* For **`None`** write the literal `None` (capital N).  \n",
      "* The optional `reasoning` field, if present, follows the same rule (its value is free‑text on the line after the field name).\n",
      "\n",
      "**Example**\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "The Spirit of Sauna: Legitimating the Finnish Place Brand\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Tillotson, Jack S.', 'Tassiello, Vito', 'Rome, Alexandra S.', 'Helaniemi, Katariina']\n",
      "year\n",
      "2020\n",
      "publisher\n",
      "['Emerald Publishing Limited']\n",
      "doi\n",
      "10.1108/JPMD-12-2019-0109\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "17538335\n",
      "type_coar\n",
      "article\n",
      "reasoning\n",
      "Title taken from the centred heading on page 1; year 2020 from the imprint line; publisher identified as “Emerald Publishing Limited”.\n",
      "2025/09/30 18:07:21 INFO dspy.evaluate.evaluate: Average Metric: 1.7272727272727273 / 3 (57.6%)\n",
      "2025/09/30 18:07:58 INFO dspy.evaluate.evaluate: Average Metric: 33.179220779220785 / 64 (51.8%)\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Full valset score for new program: 0.5184253246753247\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Full train_val score for new program: 0.5184253246753247\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Individual valset scores for new program: [0.45454545454545453, 0.2727272727272727, 0.36363636363636365, 0.36363636363636365, 0.5454545454545454, 0.36363636363636365, 0.49090909090909096, 0.5818181818181819, 0.6181818181818182, 0.6363636363636364, 0.7272727272727273, 0.09090909090909091, 0.8787878787878788, 0.6363636363636364, 0.3896103896103896, 0.7272727272727273, 0.45454545454545453, 0.6363636363636364, 0.5454545454545454, 0.6363636363636364, 0.36363636363636365, 0.5454545454545454, 0.49090909090909096, 0.7272727272727273, 0.2727272727272727, 0.7272727272727273, 0.45454545454545453, 0.2727272727272727, 0.6363636363636364, 0.36363636363636365, 0.7636363636363637, 0.6363636363636364, 0.6623376623376623, 0.5454545454545454, 0.18181818181818182, 0.6363636363636364, 0.2727272727272727, 0.7272727272727273, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.7272727272727273, 0.6363636363636364, 0.5454545454545454, 0.8181818181818182, 0.7272727272727273, 0.5454545454545454, 0.6363636363636364, 0.5454545454545454, 0.18181818181818182, 0.2727272727272727, 0.2727272727272727, 0.36363636363636365, 0.7272727272727273, 0.5454545454545454, 0.36363636363636365, 0.3333333333333333, 0.2727272727272727, 0.45454545454545453, 0.45454545454545453, 0.6363636363636364, 0.45454545454545453, 0.36363636363636365, 0.696969696969697]\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: New valset pareto front scores: [0.8545454545454546, 0.8181818181818182, 0.8787878787878788, 0.6363636363636364, 0.9090909090909091, 0.5454545454545454, 0.9090909090909091, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.9090909090909091, 0.8181818181818182, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7878787878787878, 0.8181818181818182, 0.7272727272727273, 0.6363636363636364, 0.7272727272727273, 0.6363636363636364, 0.9545454545454546, 0.9090909090909091, 1.0, 0.6363636363636364, 0.6272727272727273, 0.9090909090909091, 0.696969696969697, 1.0, 1.0, 1.0, 0.6363636363636364, 0.6060606060606061, 0.7878787878787878, 0.6363636363636364, 1.0, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.7272727272727273, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.8181818181818182, 0.6363636363636364, 0.8181818181818182, 0.7272727272727273, 0.7272727272727273, 0.5454545454545454, 0.8181818181818182, 0.8181818181818182, 0.9090909090909091, 0.6363636363636364, 0.6363636363636364, 0.6363636363636364, 0.8287220026350461, 0.7272727272727273, 0.9090909090909091, 0.7272727272727273, 0.7272727272727273, 0.9090909090909091]\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Full valset pareto front score: 0.7872859025032938\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Updated valset pareto front programs: [{41}, {28, 21}, {18}, {8, 41, 10}, {19, 21}, {32, 41, 18}, {18, 27}, {39, 8, 9, 40, 31}, {19, 3, 21}, {4, 29}, {40, 19, 21, 14}, {29}, {8, 41, 16, 20, 29}, {34, 37, 10, 15, 16, 22, 27, 29}, {32, 33, 27}, {33, 34, 37, 10, 16, 20, 22, 23, 25, 27, 29}, {41}, {34, 38}, {34, 35, 9, 13, 27, 28, 30}, {23}, {0, 12}, {2, 3, 28, 13}, {38, 7, 8, 41, 10, 20, 24, 26}, {3}, {13, 15}, {30}, {38, 41, 22, 39}, {38, 17, 22, 23, 25}, {33, 34, 4, 38, 8, 10, 16, 17, 20, 21, 29}, {27}, {3}, {21}, {19}, {8, 24}, {20}, {5}, {5}, {23}, {16, 27, 19, 36}, {2, 4, 21, 15}, {37, 8, 9, 16, 23, 25, 27}, {4, 8, 9, 10, 12, 13, 15, 16, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 33, 34, 35, 37, 38, 39, 40, 41}, {25, 11, 23}, {29}, {4, 9, 10, 13, 15, 16, 20, 22, 23, 24, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 38, 39, 42}, {40}, {24, 7}, {0, 1, 2, 3, 6, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 27, 28, 29, 30, 31, 32, 33, 34, 35, 37, 38, 39, 40, 41, 42}, {10}, {8}, {24, 27, 31}, {38, 18, 22, 30}, {35}, {32, 33, 2, 3, 10, 13, 17, 25, 27}, {16, 25, 27}, {27, 20, 23}, {37}, {35, 40, 41, 15, 27}, {40}, {32, 20, 13, 7}, {2}, {7}, {24, 11, 21, 7}, {37, 33, 27, 29}]\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Best valset aggregate score so far: 0.6812297077922078\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Best program as per aggregate score on train_val: 27\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Best program as per aggregate score on valset: 27\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Best score on valset: 0.6812297077922078\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Best score on train_val: 0.6812297077922078\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: Linear pareto front program index: 27\n",
      "2025/09/30 18:07:58 INFO dspy.teleprompt.gepa.gepa: Iteration 79: New program candidate index: 42\n",
      "GEPA Optimization:  99%|█████████▊| 3156/3200 [3:06:51<02:36,  3.55s/rollouts]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 9s, sys: 17.5 s, total: 1min 27s\n",
      "Wall time: 3h 6min 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "optimized_program = optimizer.compile(\n",
    "    module,\n",
    "    trainset=train_set,\n",
    "    valset=val_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f925b48-f431-41fa-a2f7-5d46895a53b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "Predictor: predict\n",
      "================================\n",
      "Prompt:\n",
      "markdown\n",
      "# 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "\n",
      "You will receive **one JSON object** with the following structure:\n",
      "\n",
      "* `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "* `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "\n",
      "Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "\n",
      "---\n",
      "\n",
      "## 1️⃣ Required output fields (order does **not** matter)\n",
      "\n",
      "| Field name | Type | Description & format |\n",
      "|------------|------|----------------------|\n",
      "| `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "| `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "| `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "| `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "| `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "| `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "| `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "| `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "| `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "| `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "| `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "| `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "| `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "\n",
      "### Formatting rules\n",
      "\n",
      "* **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "* The **value** on the next line.  \n",
      "* Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "* Write `None` **literally** (no quotes) for missing values.  \n",
      "* Do **not** add extra whitespace before or after the value line.\n",
      "\n",
      "---\n",
      "\n",
      "## 2️⃣ Extraction & normalisation rules\n",
      "\n",
      "### 2.1 Language detection\n",
      "1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use the following seed lists (you may extend them if needed):\n",
      "\n",
      "   * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "   * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "   * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "   * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu` (any Saami‑specific word you recognise)\n",
      "2. If any page contains an **explicit language line** such as  \n",
      "   `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kieli: suomi`, `Kieli: se`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`).  \n",
      "3. Otherwise choose the language with the highest stop‑word count. If there is a tie or no clear majority, output `None`.\n",
      "\n",
      "### 2.2 Title extraction\n",
      "1. **Identify the title page** – the first page that satisfies **any** of the following:\n",
      "   * Contains a line that is **ALL CAPS** (ignoring surrounding punctuation/markdown) and the line is the *first non‑blank line* on the page.\n",
      "   * Contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.\n",
      "   * Contains a line that is the **only non‑blank line** on the page (apart from possible footers/headers) and is in title‑case or all caps.\n",
      "2. **Capture the full logical title**:\n",
      "   * Take the identified title line as the *main title*.\n",
      "   * If the **next line(s)** (immediately following, without a blank line in between) look like a subtitle – i.e. they are not in all caps, or they follow a colon `:` on the same line – concatenate them to the main title with a single space.\n",
      "   * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "   * Example:  \n",
      "     ```\n",
      "     MANAGEMENT MATTERS\n",
      "     Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "     ```  \n",
      "     → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "\n",
      "### 2.3 Alternate title\n",
      "* Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "* Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "* Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "\n",
      "### 2.4 Creator handling\n",
      "1. Search every page for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`.\n",
      "2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "3. For each individual name:\n",
      "   * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "   * Otherwise split on the **last space**:\n",
      "     * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "   * Preserve diacritics and original capitalisation.\n",
      "4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "5. If no author line can be found, return an empty list `[]`.\n",
      "\n",
      "### 2.5 Year extraction\n",
      "1. Scan the **first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`.\n",
      "3. If still not found, fall back to the PDF metadata:\n",
      "   * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "4. Return the year as an **integer**; if none found, output `None`.\n",
      "\n",
      "### 2.6 Publisher extraction\n",
      "1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "3. If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Työväen historian ja perinteen tutkimuksen seura`), treat the whole line as a publisher entry.\n",
      "4. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "5. If none can be identified, output an empty list `[]`.\n",
      "\n",
      "### 2.7 DOI detection\n",
      "Use the case‑insensitive regex  \n",
      "\n",
      "```\n",
      "(?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "```\n",
      "\n",
      "* Capture group 1 is the DOI identifier.\n",
      "* If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "* Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "* Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "* If none found, output `None`.\n",
      "\n",
      "### 2.8 ISBN / ISSN handling\n",
      "1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "   `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "3. **Determine the qualifier** (electronic vs. print):\n",
      "   * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "   * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "   * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "   * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "4. **Normalisation**  \n",
      "   * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "   * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "\n",
      "### 2.9 COAR type mapping\n",
      "Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "\n",
      "| Keywords (any) | `type_coar` value |\n",
      "|----------------|-------------------|\n",
      "| “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "| “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "| “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "| “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "| “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and its prefix belongs to a journal publisher) | `book review` |\n",
      "| “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "| “Report”, “Technical report”, “Research report” | `report` |\n",
      "| “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "| “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "| *(none of the above)* | `None` |\n",
      "\n",
      "If multiple rows match, the **earliest** row in the table wins.\n",
      "\n",
      "### 2.10 Missing‑value handling\n",
      "If a field cannot be determined, output exactly as shown:\n",
      "\n",
      "| Field | Missing‑value output |\n",
      "|-------|----------------------|\n",
      "| language | `None` |\n",
      "| title | `None` |\n",
      "| alt_title | `[]` |\n",
      "| creator | `[]` |\n",
      "| year | `None` |\n",
      "| publisher | `[]` |\n",
      "| doi | `None` |\n",
      "| e_isbn | `[]` |\n",
      "| p_isbn | `[]` |\n",
      "| e_issn | `None` |\n",
      "| p_issn | `None` |\n",
      "| type_coar | `None` |\n",
      "\n",
      "---\n",
      "\n",
      "## 3️⃣ Output format example\n",
      "\n",
      "```\n",
      "language\n",
      "en\n",
      "title\n",
      "Using principal component analysis to determine changes in mechanical properties\n",
      "alt_title\n",
      "[]\n",
      "creator\n",
      "['Jeba, Akewak']\n",
      "year\n",
      "2021\n",
      "publisher\n",
      "[]\n",
      "doi\n",
      "None\n",
      "e_isbn\n",
      "[]\n",
      "p_isbn\n",
      "[]\n",
      "e_issn\n",
      "None\n",
      "p_issn\n",
      "None\n",
      "type_coar\n",
      "master thesis\n",
      "reasoning\n",
      "The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "```\n",
      "\n",
      "*If you include a `reasoning` field, place it **after** the last required field.*\n",
      "\n",
      "---\n",
      "\n",
      "**Remember:**  \n",
      "* Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "* All searches are **case‑insensitive**.  \n",
      "* Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "* Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "* Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "\n",
      "Good luck! 🚀\n",
      "*********************************\n"
     ]
    }
   ],
   "source": [
    "for name, pred in optimized_program.named_predictors():\n",
    "    print(\"================================\")\n",
    "    print(f\"Predictor: {name}\")\n",
    "    print(\"================================\")\n",
    "    print(\"Prompt:\")\n",
    "    print(pred.signature.instructions)\n",
    "    print(\"*********************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64fd078d-3aef-4ff7-8aa1-04e23d70f3d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 119.53 / 181 (66.0%):  99%|█████████▉| 181/182 [01:57<00:00,  2.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:10:12 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 18:10:12 WARNING dspy.adapters.json_adapter: Failed to use structured output format, falling back to JSON mode.\n",
      "2025/09/30 18:10:35 WARNING dspy.clients.lm: LM response was truncated due to exceeding max_tokens=2048. You can inspect the latest LM interactions with `dspy.inspect_history()`. To avoid truncation, consider passing a larger max_tokens when setting up dspy.LM. You may also consider increasing the temperature (currently 0.7)  if the reason for truncation is repetition.\n",
      "2025/09/30 18:10:35 ERROR dspy.utils.parallelizer: Error for Example({'content': '{\"pdfinfo\": {\"author\": \"ArtMedia\", \"creationDate\": \"D:20230116093016+02\\'00\\'\", \"modDate\": \"D:20230116093016+02\\'00\\'\"}, \"pages\": [{\"page\": 1, \"text\": \"### **Inskolningens och anknytningens betydelse inom sm\\\\u00e5barnspedagogiken**\\\\n\\\\n\\\\u2013\\\\n### **ur l\\\\u00e4rares synvinkel  en intervjustudie** Susanne Eklund\\\\nAvhandling f\\\\u00f6r magisterexamen\\\\nFakulteten f\\\\u00f6r pedagogik\\\\n\\\\n\\\\noch v\\\\u00e4lf\\\\u00e4rdsstudier\\\\n\\\\u00c5bo Akademi, Vasa 2022\\\\nHandledare: Ann-Katrin\\\\nSvensson\\\\n\\\\n\\\\n\"}, {\"page\": 2, \"text\": \"2\\\\n\\\\n\\\\n## **Abstrakt**\\\\n**F\\\\u00f6rfattare**\\\\nSusanne Eklund\\\\n**Arbetets titel**\\\\n**\\\\u00c5rtal**\\\\n\\\\n2022\\\\nInskolningen och anknytningens betydelse inom sm\\\\u00e5barnspedagogiken ur l\\\\u00e4rarens\\\\n\\\\n\\\\nsynvinkel \\\\u2013 en intervjustudie\\\\nOpublicerad avhandling f\\\\u00f6r magisterexamen i pedagogik\\\\nVasa: \\\\u00c5bo Akademi, Fakulteten f\\\\u00f6r pedagogik och v\\\\u00e4lf\\\\u00e4rdsstudier\\\\n**Sidantal**\\\\n47 (52)\\\\nSyftet med avhandlingen \\\\u00e4r att ta reda p\\\\u00e5 hur inskolningen inom\\\\nsm\\\\u00e5barnspedagogiken fungerar i dag. Jag vill veta hur l\\\\u00e4rare inom sm\\\\u00e5barnspedagogiken\\\\nuppfattar inskolningen och anknytningen mellan personal och barn samt hur\\\\nv\\\\u00e5rdnadshavarna \\\\u00e4r delaktiga i processen.\\\\nForskningsfr\\\\u00e5gorna \\\\u00e4r f\\\\u00f6ljande:\\\\n1. Vad \\\\u00e4r enligt l\\\\u00e4rarna en god inskolning?\\\\n2. Hur etableras trygghet och anknytning i samband med inskolningen enligt l\\\\u00e4rarna?\\\\n3. Hur uppfattar l\\\\u00e4rarna v\\\\u00e5rdnadshavarnas betydelse med tanke p\\\\u00e5 delaktighet och\\\\nmedverkan vid inskolningen?\\\\nTeoridelen innefattar anknytningsteori och anknytningsm\\\\u00f6nster: trygg anknytning\\\\n(1), otrygg\\\\u2013 ambivalent anknytning (2), otrygg\\\\u2013 undvikande anknytning (3) samt\\\\ndesorganiserad anknytning (4) som ligger till grund f\\\\u00f6r avhandlingen. Tidigare forskning om\\\\ninskolning och de olika inskolningsmodellerna, traditionell inskolning och f\\\\u00f6r\\\\u00e4ldraaktiv\\\\ninskolning samt vikten av samarbete med v\\\\u00e5rdnadshavarna och egenv\\\\u00e5rdarens viktiga roll\\\\nframf\\\\u00f6rs.\\\\nJag har valt fenomenografi som forskningsansats eftersom jag ville unders\\\\u00f6ka\\\\nl\\\\u00e4rarnas uppfattningar om inskolningen och anknytningen mellan personal och barn samt\\\\nv\\\\u00e5rdnadshavarnas delaktighet i processen. Datainsamlingsmetoden bestod av sex\\\\nsemistrukturerade intervjuer. Jag intervjuade tv\\\\u00e5 barntr\\\\u00e4dg\\\\u00e5rdsl\\\\u00e4rare, tre pedagogie\\\\nkandidater och en socionom med beh\\\\u00f6righet som l\\\\u00e4rare inom sm\\\\u00e5barnspedagogik och de\\\\narbetade i grupper med barn i \\\\u00e5ldern 0\\\\u20133 \\\\u00e5r.\\\\nResultatet av min studie visar att informanterna uppfattar att en god inskolning \\\\u00e4r\\\\nv\\\\u00e4lplanerad, v\\\\u00e4gledande och genomt\\\\u00e4nkt samt utg\\\\u00e5r fr\\\\u00e5n det individuella barnet.\\\\nInformanterna var eniga om att tryggheten \\\\u00e4r det allra viktigaste f\\\\u00f6r s\\\\u00e5v\\\\u00e4l barn som f\\\\u00f6r\\\\nv\\\\u00e5rdnadshavare. Ett gott samarbete med v\\\\u00e5rdnadshavarna ledde till trygga barn och trygga\\\\nvuxna. Inskolningsl\\\\u00e4ngden varierade, men alla barn hade en individuell inskolningsplan. Det\\\\nviktiga startsamtalet och v\\\\u00e4xelverkan, samarbete mellan barn\\\\u2013pedagog och mellan pedagog\\\\u2013\\\\nv\\\\u00e5rdnadshavare betonades.\\\\n**S\\\\u00f6kord** Inskolning, trygghet, anknytning, egenv\\\\u00e5rdare, sm\\\\u00e5barnspedagogik\\\\n\\\\n\\\\n\"}, {\"page\": 3, \"text\": \"3\\\\n\\\\n## **Inneh\\\\u00e5llsf\\\\u00f6rteckning**\"}, {\"page\": 4, \"text\": \"**Figurf\\\\u00f6rteckning**\"}, {\"page\": 5, \"text\": \"5\\\\n\\\\n## **1 Inledning**\\\\nEnligt _Grunderna f\\\\u00f6r planen f\\\\u00f6r sm\\\\u00e5barnspedagogik_ (2018) l\\\\u00e4ggs grunden f\\\\u00f6r ett\\\\n\\\\n\\\\nlivsl\\\\u00e5ngt l\\\\u00e4rande i sm\\\\u00e5barnspedagogiken och den \\\\u00e4r en viktig del av barnets uppv\\\\u00e4xt och l\\\\u00e4rstig.\\\\nDen centrala betydelsen \\\\u00e4r kommunikationen och den emotionella anknytningen mellan barnet\\\\n\\\\n\\\\n\"}, {\"page\": 6, \"text\": \"6\\\\n\\\\n\\\\noch v\\\\u00e5rdnadshavarna. En f\\\\u00f6rtroendefull relation mellan personal och barn samt ett gott\\\\n\\\\n\\\\nsamarbete med v\\\\u00e5rdnadshavarna vilket skapar kontinuitet och trygghet f\\\\u00f6r barnet \\\\u00e4r av st\\\\u00f6rsta\\\\n\\\\n\\\\nvikt. M\\\\u00e5len f\\\\u00f6r det enskilda barnet uppn\\\\u00e5s genom ett \\\\u00f6ppet, respektfullt och \\\\u00f6msesidigt\\\\n\\\\n\\\\nbem\\\\u00f6tande. F\\\\u00f6r att detta skall fungera beh\\\\u00f6vs regelbundet samarbete. (Utbildningsstyrelsen,\\\\n\\\\n\\\\n2018)\\\\nF\\\\u00f6r m\\\\u00e5nga barn betyder inskolning en radikal \\\\u00e4ndring fr\\\\u00e5n att vara hemma med sina\\\\n\\\\n\\\\nv\\\\u00e5rdnadshavare till att m\\\\u00f6ta nya vuxna i daghemmet. Inskolningens tre m\\\\u00e5l \\\\u00e4r att barnet v\\\\u00e4njs\\\\n\\\\n\\\\nvid den nya milj\\\\u00f6n, att man ger barnet en m\\\\u00f6jlighet att l\\\\u00e4ra k\\\\u00e4nna en pedagog s\\\\u00e5 pass bra att\\\\n\\\\n\\\\nhen \\\\u00e4r en ers\\\\u00e4ttare under den del av dagen d\\\\u00e5 v\\\\u00e5rdnadshavarna \\\\u00e4r p\\\\u00e5 arbetet och att barnet\\\\n\\\\n\\\\nanpassar sig till att vara utan sina v\\\\u00e5rdnadshavare m\\\\u00e5nga timmar och d\\\\u00e5 ha en vuxen som\\\\n\\\\n\\\\ners\\\\u00e4ttare f\\\\u00f6r att kunna leka och utforska (Broberg, Birthe, & Broberg, 2012).\\\\nLagen om anordnande av sm\\\\u00e5barnspedagogik s\\\\u00e4ger:\\\\n\\\\n\\\\n\\\\u201d _Kommunen kan ordna sm\\\\u00e5barnspedagogik i enlighet med 8 och 9 \\\\u00a7 i_\\\\n\\\\n\\\\n_[kommunallagen (410/2015).](https://www.finlex.fi/sv/laki/ajantasa/2015/20150410)_ _Vid_ _anskaffning_ _av_ _service_ _fr\\\\u00e5n_ _n\\\\u00e5gon_ _annan_\\\\n\\\\n\\\\n_serviceproducent ska kommunen eller samkommunen f\\\\u00f6rs\\\\u00e4kra sig om att servicen_\\\\n\\\\n\\\\n_motsvarar den niv\\\\u00e5 som kr\\\\u00e4vs av motsvarande kommunala verksamhet. Kommunen ska_\\\\n\\\\n\\\\n_efterstr\\\\u00e4va att ordna sm\\\\u00e5barnspedagogik n\\\\u00e4ra dem som anlitar servicen med beaktande_\\\\n\\\\n\\\\n_av hur bos\\\\u00e4ttningen \\\\u00e4r f\\\\u00f6rlagd och trafikf\\\\u00f6rbindelserna. Daghemmens verksamhet under_\\\\n\\\\n\\\\n_kalender\\\\u00e5ret och deras \\\\u00f6ppettider under dygnet ska ordnas efter lokalt behov_ \\\\u201d (Lag om\\\\n\\\\n\\\\nsm\\\\u00e5barnspedagogik, 2018).\\\\n\\\\n\\\\n\"}, {\"page\": 52, \"text\": \"52\\\\n**Bilaga 2**\\\\n\\\\n# V\\\\u00e4lkommen till Skogshyddans daghem!\\\\nVi utg\\\\u00e5r ifr\\\\u00e5n barnets b\\\\u00e4sta och att en trygghet mellan l\\\\u00e4raren/ barnsk\\\\u00f6tarna, kompisarna och\\\\n\\\\n\\\\nmilj\\\\u00f6n byggs upp.\\\\n\\\\n\\\\n\"}, {\"page\": 53, \"text\": \"53\\\\n**Information om inskolningen**\\\\nVi b\\\\u00f6rjar med ett bes\\\\u00f6k i daghemmet d\\\\u00e4r ert barn f\\\\u00e5r m\\\\u00f6jlighet att l\\\\u00e4ra k\\\\u00e4nna sin l\\\\u00e4rare och\\\\n\\\\n\\\\nbarnsk\\\\u00f6tare samt bekanta sig med daghemmets utrymmen.\\\\nVi rekommenderar att den f\\\\u00f6rsta tiden har ert barn kortare dagar.\\\\nD\\\\u00e5 v\\\\u00e5rdnadshavarna avl\\\\u00e4gsnar sig fr\\\\u00e5n dagv\\\\u00e5rdsplatsen debiteras avgift f\\\\u00f6r\\\\n\\\\n\\\\nsm\\\\u00e5barnspedagogiken.\\\\nMed hopp om ett gott samarbete.\\\\n\\\\n\\\\n\"}]}', 'metadata': '{\"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\\\u00e5barnspedagogiken ur l\\\\u00e4rares synvinkel : en intervjustudie\", \"creator\": [\"Eklund, Susanne\"], \"year\": \"2022\", \"publisher\": [\"\\\\u00c5bo Akademi\"], \"type_coar\": \"master thesis\"}'}) (input_keys={'content'}): Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\"reasoning\": \"The document is a master's thesis titled \\\"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\\". The title and author are extracted from the first two pages. The language is detected as Swedish based on the presence of Swedish words in the text. The year is 2022. The publisher is \\u00c5bo Akademi. The DOI is not present. ISBNs are not present. ISSN is not present. The type_coar is master thesis.\", \"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "Actual output fields parsed from the LM response: [reasoning, language, title] \n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 128, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 89, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 197, in parse\n",
      "    raise AdapterParseError(\n",
      "dspy.utils.exceptions.AdapterParseError: Adapter ChatAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: [[ ## reasoning ## ]]\n",
      "The language is detected as Swedish based on the presence of Swedish stopwords (\"och\", \"för\", \"av\") on the first page. The title is extracted from the first all-caps line on the first page, followed by a subtitle. The creator is identified as Susanne Eklund. The year is 2022. The publisher is Abo Akademi. The DOI is not present. The e-ISBN is not present. The p-ISBN is not present. The e-ISSN is not present. The p-ISSN is not present. The type_coar is master thesis. \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "Actual output fields parsed from the LM response: [reasoning] \n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 78, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n",
      "    raise e\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 128, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 89, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 172, in parse\n",
      "    raise AdapterParseError(\n",
      "dspy.utils.exceptions.AdapterParseError: Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\"reasoning\": \"The document is a master's thesis titled \\\"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\\". The language is Swedish. The title and alt title are extracted from the document. The creator is the author, Susanne Eklund. The year of publication is 2022. The publisher is \\u00c5bo Akademi. The DOI is not present. The ISBNs are not present. The ISSN is not present. The COAR type is master thesis.\", \"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\ \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "Actual output fields parsed from the LM response: [reasoning, language, title] \n",
      "\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/parallelizer.py\", line 55, in safe_func\n",
      "    return user_function(item)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/evaluate/evaluate.py\", line 158, in process_item\n",
      "    prediction = program(**example.inputs())\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/primitives/module.py\", line 78, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/chain_of_thought.py\", line 37, in forward\n",
      "    return self.predict(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/predict.py\", line 103, in __call__\n",
      "    return super().__call__(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/primitives/module.py\", line 78, in __call__\n",
      "    return self.forward(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/predict/predict.py\", line 192, in forward\n",
      "    completions = adapter(lm, lm_kwargs=config, signature=signature, demos=demos, inputs=kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 47, in __call__\n",
      "    return JSONAdapter()(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 82, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 46, in __call__\n",
      "    raise e\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/chat_adapter.py\", line 38, in __call__\n",
      "    return super().__call__(lm, lm_kwargs, signature, demos, inputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 128, in __call__\n",
      "    return self._call_postprocess(processed_signature, signature, outputs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/base.py\", line 89, in _call_postprocess\n",
      "    value = self.parse(processed_signature, text)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/utils/callback.py\", line 326, in sync_wrapper\n",
      "    return fn(instance, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/wrk-vakka/users/oisuomin/git/FinGreyLit/GreyLitLM/dspy/venv/lib/python3.12/site-packages/dspy/adapters/json_adapter.py\", line 172, in parse\n",
      "    raise AdapterParseError(\n",
      "dspy.utils.exceptions.AdapterParseError: Adapter JSONAdapter failed to parse the LM response. \n",
      "\n",
      "LM Response: {\"reasoning\": \"The document is a master's thesis titled \\\"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\\". The title and author are extracted from the first two pages. The language is detected as Swedish based on the presence of Swedish words in the text. The year is 2022. The publisher is \\u00c5bo Akademi. The DOI is not present. ISBNs are not present. ISSN is not present. The type_coar is master thesis.\", \"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n \n",
      "\n",
      "Expected to find output fields in the LM response: [reasoning, language, title, alt_title, creator, year, publisher, doi, e_isbn, p_isbn, e_issn, p_issn, type_coar] \n",
      "\n",
      "Actual output fields parsed from the LM response: [reasoning, language, title] \n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Metric: 119.53 / 181 (66.0%): 100%|██████████| 182/182 [02:36<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/09/30 18:10:35 INFO dspy.evaluate.evaluate: Average Metric: 119.52768595041326 / 182 (65.7%)\n",
      "2025/09/30 18:10:35 WARNING dspy.evaluate.evaluate: Skipping table display since `pandas` is not installed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 4.28 s, sys: 844 ms, total: 5.13 s\n",
      "Wall time: 2min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "evaluate = dspy.Evaluate(\n",
    "    devset=test_set,\n",
    "    metric=metadata_metric_with_feedback,\n",
    "    num_threads=64,\n",
    "    display_table=True,\n",
    "    display_progress=True,\n",
    "    provide_traceback=True\n",
    ")\n",
    "\n",
    "eval_result = evaluate(optimized_program)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d172f585-0442-4a4e-9295-bdedfe21fc6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[34m[2025-09-30T18:10:35.498812]\u001b[0m\n",
      "\n",
      "\u001b[31mSystem message:\u001b[0m\n",
      "\n",
      "Your input fields are:\n",
      "1. `content` (str):\n",
      "Your output fields are:\n",
      "1. `reasoning` (str): \n",
      "2. `language` (str): The language of the resource expressed as a BCP47 language tag.\n",
      "3. `title` (str): The main title of the publication.\n",
      "4. `alt_title` (list[str]): Alternative or parallel titles of the publication, suffixed with a BCP47 language tag in curly brackets.\n",
      "5. `creator` (list[str]): The primary author(s) of the resource (order: Last Name, First Names).\n",
      "6. `year` (Union[str, NoneType]): The year on which the resource was issued or made available.\n",
      "7. `publisher` (list[str]): The entity/entities responsible for making the resource available.\n",
      "8. `doi` (Union[str, NoneType]): The Digital Object Identifier (DOI) associated with the resource.\n",
      "9. `e_isbn` (list[str]): The ISBN associated with the electronic resource.\n",
      "10. `p_isbn` (list[str]): The ISBN of the printed version of this document.\n",
      "11. `e_issn` (Union[str, NoneType]): The ISSN associated with the electronic resource.\n",
      "12. `p_issn` (Union[str, NoneType]): The ISSN of the printed version of this document.\n",
      "13. `type_coar` (str): The type of the resource according to the COAR Resource Types classification.\n",
      "All interactions will be structured in the following way, with the appropriate values filled in.\n",
      "\n",
      "Inputs will have the following structure:\n",
      "\n",
      "[[ ## content ## ]]\n",
      "{content}\n",
      "\n",
      "Outputs will be a JSON object with the following fields.\n",
      "\n",
      "{\n",
      "  \"reasoning\": \"{reasoning}\",\n",
      "  \"language\": \"{language}\",\n",
      "  \"title\": \"{title}\",\n",
      "  \"alt_title\": \"{alt_title}        # note: the value you produce must adhere to the JSON schema: {\\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}\",\n",
      "  \"creator\": \"{creator}        # note: the value you produce must adhere to the JSON schema: {\\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}\",\n",
      "  \"year\": \"{year}        # note: the value you produce must adhere to the JSON schema: {\\\"anyOf\\\": [{\\\"type\\\": \\\"string\\\"}, {\\\"type\\\": \\\"null\\\"}]}\",\n",
      "  \"publisher\": \"{publisher}        # note: the value you produce must adhere to the JSON schema: {\\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}\",\n",
      "  \"doi\": \"{doi}        # note: the value you produce must adhere to the JSON schema: {\\\"anyOf\\\": [{\\\"type\\\": \\\"string\\\"}, {\\\"type\\\": \\\"null\\\"}]}\",\n",
      "  \"e_isbn\": \"{e_isbn}        # note: the value you produce must adhere to the JSON schema: {\\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}\",\n",
      "  \"p_isbn\": \"{p_isbn}        # note: the value you produce must adhere to the JSON schema: {\\\"type\\\": \\\"array\\\", \\\"items\\\": {\\\"type\\\": \\\"string\\\"}}\",\n",
      "  \"e_issn\": \"{e_issn}        # note: the value you produce must adhere to the JSON schema: {\\\"anyOf\\\": [{\\\"type\\\": \\\"string\\\"}, {\\\"type\\\": \\\"null\\\"}]}\",\n",
      "  \"p_issn\": \"{p_issn}        # note: the value you produce must adhere to the JSON schema: {\\\"anyOf\\\": [{\\\"type\\\": \\\"string\\\"}, {\\\"type\\\": \\\"null\\\"}]}\",\n",
      "  \"type_coar\": \"{type_coar}\"\n",
      "}\n",
      "In adhering to this structure, your objective is: \n",
      "        markdown\n",
      "        # 📄 Instruction for extracting structured metadata from PDF‑extracted text\n",
      "        \n",
      "        You will receive **one JSON object** with the following structure:\n",
      "        \n",
      "        * `pdfinfo` – optional dictionary containing PDF‑level metadata (e.g. `author`, `title`, `creationDate`, `modDate`).  \n",
      "        * `pages` – list of page objects, each with a numeric `page` field and a `text` field that holds the raw OCR/clipboard text of that page.\n",
      "        \n",
      "        Your job is to **parse this information and output a flat list of metadata fields** (one field name on a line, the value on the next line).  \n",
      "        The output must follow the exact format shown in the “Output format example” section below, because it will later be turned into a JSON record.\n",
      "        \n",
      "        ---\n",
      "        \n",
      "        ## 1️⃣ Required output fields (order does **not** matter)\n",
      "        \n",
      "        | Field name | Type | Description & format |\n",
      "        |------------|------|----------------------|\n",
      "        | `language` | `string` or `None` | ISO‑639‑1 code of the **content language** (`en`, `fi`, `sv`, `se`, …). Detect from the text (see **2.1 Language detection**). |\n",
      "        | `title` | `string` or `None` | Full main title **exactly** as it appears on the title page, including any subtitle(s) that belong to the same logical heading (e.g. `Main title : Subtitle`). |\n",
      "        | `alt_title` | `list` of `string` | Any alternate title(s) in a different language (e.g. English translation of a Finnish title). Do **not** duplicate the main `title`. |\n",
      "        | `creator` | `list` of `string` | Author(s) in the form `\"LastName, FirstName\"` (preserve middle names). See **2.4 Creator handling**. |\n",
      "        | `year` | `int` or `None` | Publication year (four‑digit, 1900‑2100). |\n",
      "        | `publisher` | `list` of `string` | Publishing institution(s) **exactly** as they appear (no translation, no trailing punctuation). |\n",
      "        | `doi` | `string` or `None` | DOI **as it appears in the document**. If the DOI is given as a URL (`https://doi.org/...`) keep the full URL; otherwise keep the plain identifier (`10.xxx/...`). |\n",
      "        | `e_isbn` | `list` of `string` | ISBN(s) that refer to the **electronic/PDF** version, **normalized to a plain digit string** (remove hyphens, spaces, parentheses). |\n",
      "        | `p_isbn` | `list` of `string` | ISBN(s) that refer to the **print** version, normalized the same way. |\n",
      "        | `e_issn` | `string` or `None` | ISSN for the **online** version, normalized (remove hyphens). |\n",
      "        | `p_issn` | `string` or `None` | ISSN for the **print** version, normalized. |\n",
      "        | `type_coar` | `string` or `None` | COAR resource type (lower‑case). See **2.9 COAR type mapping**. |\n",
      "        | `reasoning` *(optional)* | `string` | One‑ or two‑sentence explanation of how the values were derived (does **not** affect scoring). |\n",
      "        \n",
      "        ### Formatting rules\n",
      "        \n",
      "        * **Field name** on its own line, **exactly** as shown above (e.g. `language`).  \n",
      "        * The **value** on the next line.  \n",
      "        * Use Python‑style list syntax, e.g. `['value1', 'value2']`.  \n",
      "        * Write `None` **literally** (no quotes) for missing values.  \n",
      "        * Do **not** add extra whitespace before or after the value line.\n",
      "        \n",
      "        ---\n",
      "        \n",
      "        ## 2️⃣ Extraction & normalisation rules\n",
      "        \n",
      "        ### 2.1 Language detection\n",
      "        1. Scan **all** `pages[*].text`. Count occurrences of language‑specific stop‑words (case‑insensitive). Use the following seed lists (you may extend them if needed):\n",
      "        \n",
      "           * Finnish (`fi`): `käsittely`, `tutkimus`, `opinnäytetyö`, `väitöskirja`, `kieli`, `julkaistu`\n",
      "           * Swedish (`sv`): `och`, `för`, `av`, `liv`, `historien`, `språk`\n",
      "           * English (`en`): `the`, `and`, `of`, `method`, `introduction`, `chapter`\n",
      "           * North Saami (`se`): `čálbmi`, `čálmmis`, `suoldnečalmmit`, `sámegielaid`, `singulatiivvat`, `kiel`, `julkašu` (any Saami‑specific word you recognise)\n",
      "        2. If any page contains an **explicit language line** such as  \n",
      "           `Kieli: suomi`, `Language: English`, `Språk: svenska`, `Kieli: suomi`, `Kieli: se`, treat that as a **strong signal** and set the language accordingly (`fi`, `en`, `sv`, `se`).  \n",
      "        3. Otherwise choose the language with the highest stop‑word count. If there is a tie or no clear majority, output `None`.\n",
      "        \n",
      "        ### 2.2 Title extraction\n",
      "        1. **Identify the title page** – the first page that satisfies **any** of the following:\n",
      "           * Contains a line that is **ALL CAPS** (ignoring surrounding punctuation/markdown) and the line is the *first non‑blank line* on the page.\n",
      "           * Contains a markdown heading (`#`, `##`, `###`, …). Strip the leading `#` characters and surrounding whitespace.\n",
      "           * Contains a line that is the **only non‑blank line** on the page (apart from possible footers/headers) and is in title‑case or all caps.\n",
      "        2. **Capture the full logical title**:\n",
      "           * Take the identified title line as the *main title*.\n",
      "           * If the **next line(s)** (immediately following, without a blank line in between) look like a subtitle – i.e. they are not in all caps, or they follow a colon `:` on the same line – concatenate them to the main title with a single space.\n",
      "           * Preserve **all original punctuation, diacritics, and case** (including colons). Do **not** add or remove punctuation.\n",
      "           * Example:  \n",
      "             ```\n",
      "             MANAGEMENT MATTERS\n",
      "             Organizational Storytelling within the Anthroposophical Society in Sweden\n",
      "             ```  \n",
      "             → title = `Management matters : Organizational Storytelling within the Anthroposophical Society in Sweden`\n",
      "        3. Remove any surrounding markdown markers (`#`, `##`, etc.) and surrounding whitespace only. Do **not** include page numbers, footers, or other surrounding text.\n",
      "        \n",
      "        ### 2.3 Alternate title\n",
      "        * Look for lines that contain a language qualifier, e.g. “English title”, “Title (English)”, “Original title”, “Originaltitel”, “Originaltitel (Englisch)”, “Titel (Finnisch)”, etc.\n",
      "        * Extract the title text that follows the qualifier, applying the same concatenation rules as in 2.2.\n",
      "        * Do **not** duplicate the main `title`. If several alternate titles exist, list them all.\n",
      "        \n",
      "        ### 2.4 Creator handling\n",
      "        1. Search every page for author lines. Typical keywords (case‑insensitive): `Author`, `Authors`, `Tekijä`, `Tekijät`, `Tekijä:`, `Authors:`, `Tekijät:`, `Opiskelijat`, `Opiskelijat:`, `Kirjoittaja`, `Kirjoittajat`.\n",
      "        2. The line may contain a list of names separated by any of the delimiters: comma `,`, semicolon `;`, ampersand `&`, the word `and`, or the Finnish/Swedish equivalents `ja`, `och`.\n",
      "        3. For each individual name:\n",
      "           * If the name already contains a comma, assume it is already in `Last, First` order and keep it unchanged.\n",
      "           * Otherwise split on the **last space**:\n",
      "             * `\"First Middle Last\"` → `\"Last, First Middle\"`.\n",
      "           * Preserve diacritics and original capitalisation.\n",
      "        4. Preserve the order of appearance. Return a Python list, e.g. `['Salmi, Jesse', 'Räisänen, Hannu']`.\n",
      "        5. If no author line can be found, return an empty list `[]`.\n",
      "        \n",
      "        ### 2.5 Year extraction\n",
      "        1. Scan the **first two pages** for a four‑digit number between 1900‑2100 that looks like a year.\n",
      "        2. Prefer a year that appears on a line containing any of these keywords (case‑insensitive): `©`, `Copyright`, `Julkaistu`, `Published`, `Publication`, `Year`, `Vuosi`, `Graduation`, `Graduated`.\n",
      "        3. If still not found, fall back to the PDF metadata:\n",
      "           * `pdfinfo.creationDate` or `pdfinfo.modDate` have the format `D:YYYYMMDD…`. Extract the `YYYY` part.\n",
      "        4. Return the year as an **integer**; if none found, output `None`.\n",
      "        \n",
      "        ### 2.6 Publisher extraction\n",
      "        1. Look for lines containing any of the following keywords (case‑insensitive): `Publisher`, `Published by`, `Julkaisija`, `Julkaisija:`, `Laitos`, `University`, `Institute`, `Yliopisto`, `Ammattikorkeakoulu`, `Korkeakoulu`, `Kustannus`, `Kustantaja`, `Kustantaja:`, plus known commercial publishers (e.g. `Routledge`, `Springer`, `Cambridge`).\n",
      "        2. Capture the **full phrase** that follows the keyword up to the end of the line (trim trailing punctuation such as commas, periods, semicolons).\n",
      "        3. If a line **contains only** a plausible institution name without a preceding keyword (e.g. `Työväen historian ja perinteen tutkimuksen seura`), treat the whole line as a publisher entry.\n",
      "        4. If more than one distinct publisher appears, list them in order of first appearance.\n",
      "        5. If none can be identified, output an empty list `[]`.\n",
      "        \n",
      "        ### 2.7 DOI detection\n",
      "        Use the case‑insensitive regex  \n",
      "        \n",
      "        ```\n",
      "        (?:doi:\\s*|DOI\\s*|https?://doi\\.org/)?(10\\.\\d{4,9}/\\S+)\n",
      "        ```\n",
      "        \n",
      "        * Capture group 1 is the DOI identifier.\n",
      "        * If the original text contains the full URL (`https://doi.org/...`) keep the **entire URL** as the output value.\n",
      "        * Otherwise output the identifier **without** any prefix (`doi:` or `DOI`).\n",
      "        * Strip surrounding whitespace, commas, periods, and parentheses.\n",
      "        * If none found, output `None`.\n",
      "        \n",
      "        ### 2.8 ISBN / ISSN handling\n",
      "        1. Search the whole document for the substrings `ISBN` or `ISSN` (case‑insensitive).\n",
      "        2. Extract the numeric identifier that follows; it may be surrounded by hyphens, spaces, or parentheses, e.g.  \n",
      "           `ISBN 978‑952‑389‑017‑6` or `(ISBN: 978 952 389 018 3)`.\n",
      "        3. **Determine the qualifier** (electronic vs. print):\n",
      "           * **Electronic** indicators (case‑insensitive): `PDF`, `e‑ISBN`, `Electronic`, `Online`, `(PDF)`, `e‑ISSN`.\n",
      "           * **Print** indicators: `Print`, `Hardcover`, `Paperback`, `Print version`, `Print‑ISBN`.\n",
      "           * If **both** qualifiers appear for the same identifier, add it to **both** lists.\n",
      "           * If **no qualifier** is present, add the identifier to **both** `e_isbn`/`e_issn` **and** `p_isbn`/`p_issn`.\n",
      "        4. **Normalisation**  \n",
      "           * **ISBN** – keep **only digits** (10‑digit ISBN‑10 or 13‑digit ISBN‑13). Remove hyphens, spaces, parentheses.  \n",
      "           * **ISSN** – keep exactly **8 digits** (remove hyphens).  \n",
      "        5. Return each list with **unique** values, preserving the order of first appearance. If none, return `[]`.\n",
      "        \n",
      "        ### 2.9 COAR type mapping\n",
      "        Search the entire document (case‑insensitive) for the keywords below. Use the **first matching row** (top‑to‑bottom priority). If a row requires a combination of conditions, all must be satisfied.\n",
      "        \n",
      "        | Keywords (any) | `type_coar` value |\n",
      "        |----------------|-------------------|\n",
      "        | “Pro gradu”, “Master’s thesis”, “Master thesis”, “Yliluonnos”, “Master’s dissertation” | `master thesis` |\n",
      "        | “Dissertation”, “Doctoral thesis”, “Väitöskirja”, “Doctoral dissertation” | `doctoral thesis` |\n",
      "        | “Bachelor thesis”, “Pro gradu (bachelor)”, “Kandidaatintyö”, “Kandidaatintutkielma” | `bachelor thesis` |\n",
      "        | “ISBN” **and** no thesis‑related wording, **and** a publisher that is a known book‑publisher (e.g., Routledge, Springer, Cambridge) | `book` |\n",
      "        | “Book review”, “Recension”, “Review of” **and** a DOI that resolves to a journal (i.e., DOI present and its prefix belongs to a journal publisher) | `book review` |\n",
      "        | “Journal article”, “Article”, “Artikkeli”, “Artikel”, **and** an ISSN present | `article` |\n",
      "        | “Report”, “Technical report”, “Research report” | `report` |\n",
      "        | “Conference paper”, “Proceedings”, “Paper presented at”, “Konferensbidrag” | `conference paper` |\n",
      "        | “Book chapter”, “Chapter”, “Book part”, “In:” **and** a DOI that points to a book (e.g., DOI prefix of a book publisher) | `book part` |\n",
      "        | *(none of the above)* | `None` |\n",
      "        \n",
      "        If multiple rows match, the **earliest** row in the table wins.\n",
      "        \n",
      "        ### 2.10 Missing‑value handling\n",
      "        If a field cannot be determined, output exactly as shown:\n",
      "        \n",
      "        | Field | Missing‑value output |\n",
      "        |-------|----------------------|\n",
      "        | language | `None` |\n",
      "        | title | `None` |\n",
      "        | alt_title | `[]` |\n",
      "        | creator | `[]` |\n",
      "        | year | `None` |\n",
      "        | publisher | `[]` |\n",
      "        | doi | `None` |\n",
      "        | e_isbn | `[]` |\n",
      "        | p_isbn | `[]` |\n",
      "        | e_issn | `None` |\n",
      "        | p_issn | `None` |\n",
      "        | type_coar | `None` |\n",
      "        \n",
      "        ---\n",
      "        \n",
      "        ## 3️⃣ Output format example\n",
      "        \n",
      "        ```\n",
      "        language\n",
      "        en\n",
      "        title\n",
      "        Using principal component analysis to determine changes in mechanical properties\n",
      "        alt_title\n",
      "        []\n",
      "        creator\n",
      "        ['Jeba, Akewak']\n",
      "        year\n",
      "        2021\n",
      "        publisher\n",
      "        []\n",
      "        doi\n",
      "        None\n",
      "        e_isbn\n",
      "        []\n",
      "        p_isbn\n",
      "        []\n",
      "        e_issn\n",
      "        None\n",
      "        p_issn\n",
      "        None\n",
      "        type_coar\n",
      "        master thesis\n",
      "        reasoning\n",
      "        The language was detected as English because the stop‑word count for English was highest, the title was taken from the first all‑caps line on page 1, etc.\n",
      "        ```\n",
      "        \n",
      "        *If you include a `reasoning` field, place it **after** the last required field.*\n",
      "        \n",
      "        ---\n",
      "        \n",
      "        **Remember:**  \n",
      "        * Scan **all** pages for each piece of information unless the rule explicitly limits the search (e.g., year → first two pages).  \n",
      "        * All searches are **case‑insensitive**.  \n",
      "        * Preserve diacritics and original capitalisation for titles, publishers, and author names.  \n",
      "        * Normalise identifiers (ISBN/ISSN) to plain digit strings before placing them in the output lists.  \n",
      "        * Do **not** add hyphens, spaces, or any other formatting to ISBN/ISSN values.  \n",
      "        \n",
      "        Good luck! 🚀\n",
      "\n",
      "\n",
      "\u001b[31mUser message:\u001b[0m\n",
      "\n",
      "[[ ## content ## ]]\n",
      "{\"pdfinfo\": {\"author\": \"ArtMedia\", \"creationDate\": \"D:20230116093016+02'00'\", \"modDate\": \"D:20230116093016+02'00'\"}, \"pages\": [{\"page\": 1, \"text\": \"### **Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken**\\n\\n\\u2013\\n### **ur l\\u00e4rares synvinkel  en intervjustudie** Susanne Eklund\\nAvhandling f\\u00f6r magisterexamen\\nFakulteten f\\u00f6r pedagogik\\n\\n\\noch v\\u00e4lf\\u00e4rdsstudier\\n\\u00c5bo Akademi, Vasa 2022\\nHandledare: Ann-Katrin\\nSvensson\\n\\n\\n\"}, {\"page\": 2, \"text\": \"2\\n\\n\\n## **Abstrakt**\\n**F\\u00f6rfattare**\\nSusanne Eklund\\n**Arbetets titel**\\n**\\u00c5rtal**\\n\\n2022\\nInskolningen och anknytningens betydelse inom sm\\u00e5barnspedagogiken ur l\\u00e4rarens\\n\\n\\nsynvinkel \\u2013 en intervjustudie\\nOpublicerad avhandling f\\u00f6r magisterexamen i pedagogik\\nVasa: \\u00c5bo Akademi, Fakulteten f\\u00f6r pedagogik och v\\u00e4lf\\u00e4rdsstudier\\n**Sidantal**\\n47 (52)\\nSyftet med avhandlingen \\u00e4r att ta reda p\\u00e5 hur inskolningen inom\\nsm\\u00e5barnspedagogiken fungerar i dag. Jag vill veta hur l\\u00e4rare inom sm\\u00e5barnspedagogiken\\nuppfattar inskolningen och anknytningen mellan personal och barn samt hur\\nv\\u00e5rdnadshavarna \\u00e4r delaktiga i processen.\\nForskningsfr\\u00e5gorna \\u00e4r f\\u00f6ljande:\\n1. Vad \\u00e4r enligt l\\u00e4rarna en god inskolning?\\n2. Hur etableras trygghet och anknytning i samband med inskolningen enligt l\\u00e4rarna?\\n3. Hur uppfattar l\\u00e4rarna v\\u00e5rdnadshavarnas betydelse med tanke p\\u00e5 delaktighet och\\nmedverkan vid inskolningen?\\nTeoridelen innefattar anknytningsteori och anknytningsm\\u00f6nster: trygg anknytning\\n(1), otrygg\\u2013 ambivalent anknytning (2), otrygg\\u2013 undvikande anknytning (3) samt\\ndesorganiserad anknytning (4) som ligger till grund f\\u00f6r avhandlingen. Tidigare forskning om\\ninskolning och de olika inskolningsmodellerna, traditionell inskolning och f\\u00f6r\\u00e4ldraaktiv\\ninskolning samt vikten av samarbete med v\\u00e5rdnadshavarna och egenv\\u00e5rdarens viktiga roll\\nframf\\u00f6rs.\\nJag har valt fenomenografi som forskningsansats eftersom jag ville unders\\u00f6ka\\nl\\u00e4rarnas uppfattningar om inskolningen och anknytningen mellan personal och barn samt\\nv\\u00e5rdnadshavarnas delaktighet i processen. Datainsamlingsmetoden bestod av sex\\nsemistrukturerade intervjuer. Jag intervjuade tv\\u00e5 barntr\\u00e4dg\\u00e5rdsl\\u00e4rare, tre pedagogie\\nkandidater och en socionom med beh\\u00f6righet som l\\u00e4rare inom sm\\u00e5barnspedagogik och de\\narbetade i grupper med barn i \\u00e5ldern 0\\u20133 \\u00e5r.\\nResultatet av min studie visar att informanterna uppfattar att en god inskolning \\u00e4r\\nv\\u00e4lplanerad, v\\u00e4gledande och genomt\\u00e4nkt samt utg\\u00e5r fr\\u00e5n det individuella barnet.\\nInformanterna var eniga om att tryggheten \\u00e4r det allra viktigaste f\\u00f6r s\\u00e5v\\u00e4l barn som f\\u00f6r\\nv\\u00e5rdnadshavare. Ett gott samarbete med v\\u00e5rdnadshavarna ledde till trygga barn och trygga\\nvuxna. Inskolningsl\\u00e4ngden varierade, men alla barn hade en individuell inskolningsplan. Det\\nviktiga startsamtalet och v\\u00e4xelverkan, samarbete mellan barn\\u2013pedagog och mellan pedagog\\u2013\\nv\\u00e5rdnadshavare betonades.\\n**S\\u00f6kord** Inskolning, trygghet, anknytning, egenv\\u00e5rdare, sm\\u00e5barnspedagogik\\n\\n\\n\"}, {\"page\": 3, \"text\": \"3\\n\\n## **Inneh\\u00e5llsf\\u00f6rteckning**\"}, {\"page\": 4, \"text\": \"**Figurf\\u00f6rteckning**\"}, {\"page\": 5, \"text\": \"5\\n\\n## **1 Inledning**\\nEnligt _Grunderna f\\u00f6r planen f\\u00f6r sm\\u00e5barnspedagogik_ (2018) l\\u00e4ggs grunden f\\u00f6r ett\\n\\n\\nlivsl\\u00e5ngt l\\u00e4rande i sm\\u00e5barnspedagogiken och den \\u00e4r en viktig del av barnets uppv\\u00e4xt och l\\u00e4rstig.\\nDen centrala betydelsen \\u00e4r kommunikationen och den emotionella anknytningen mellan barnet\\n\\n\\n\"}, {\"page\": 6, \"text\": \"6\\n\\n\\noch v\\u00e5rdnadshavarna. En f\\u00f6rtroendefull relation mellan personal och barn samt ett gott\\n\\n\\nsamarbete med v\\u00e5rdnadshavarna vilket skapar kontinuitet och trygghet f\\u00f6r barnet \\u00e4r av st\\u00f6rsta\\n\\n\\nvikt. M\\u00e5len f\\u00f6r det enskilda barnet uppn\\u00e5s genom ett \\u00f6ppet, respektfullt och \\u00f6msesidigt\\n\\n\\nbem\\u00f6tande. F\\u00f6r att detta skall fungera beh\\u00f6vs regelbundet samarbete. (Utbildningsstyrelsen,\\n\\n\\n2018)\\nF\\u00f6r m\\u00e5nga barn betyder inskolning en radikal \\u00e4ndring fr\\u00e5n att vara hemma med sina\\n\\n\\nv\\u00e5rdnadshavare till att m\\u00f6ta nya vuxna i daghemmet. Inskolningens tre m\\u00e5l \\u00e4r att barnet v\\u00e4njs\\n\\n\\nvid den nya milj\\u00f6n, att man ger barnet en m\\u00f6jlighet att l\\u00e4ra k\\u00e4nna en pedagog s\\u00e5 pass bra att\\n\\n\\nhen \\u00e4r en ers\\u00e4ttare under den del av dagen d\\u00e5 v\\u00e5rdnadshavarna \\u00e4r p\\u00e5 arbetet och att barnet\\n\\n\\nanpassar sig till att vara utan sina v\\u00e5rdnadshavare m\\u00e5nga timmar och d\\u00e5 ha en vuxen som\\n\\n\\ners\\u00e4ttare f\\u00f6r att kunna leka och utforska (Broberg, Birthe, & Broberg, 2012).\\nLagen om anordnande av sm\\u00e5barnspedagogik s\\u00e4ger:\\n\\n\\n\\u201d _Kommunen kan ordna sm\\u00e5barnspedagogik i enlighet med 8 och 9 \\u00a7 i_\\n\\n\\n_[kommunallagen (410/2015).](https://www.finlex.fi/sv/laki/ajantasa/2015/20150410)_ _Vid_ _anskaffning_ _av_ _service_ _fr\\u00e5n_ _n\\u00e5gon_ _annan_\\n\\n\\n_serviceproducent ska kommunen eller samkommunen f\\u00f6rs\\u00e4kra sig om att servicen_\\n\\n\\n_motsvarar den niv\\u00e5 som kr\\u00e4vs av motsvarande kommunala verksamhet. Kommunen ska_\\n\\n\\n_efterstr\\u00e4va att ordna sm\\u00e5barnspedagogik n\\u00e4ra dem som anlitar servicen med beaktande_\\n\\n\\n_av hur bos\\u00e4ttningen \\u00e4r f\\u00f6rlagd och trafikf\\u00f6rbindelserna. Daghemmens verksamhet under_\\n\\n\\n_kalender\\u00e5ret och deras \\u00f6ppettider under dygnet ska ordnas efter lokalt behov_ \\u201d (Lag om\\n\\n\\nsm\\u00e5barnspedagogik, 2018).\\n\\n\\n\"}, {\"page\": 52, \"text\": \"52\\n**Bilaga 2**\\n\\n# V\\u00e4lkommen till Skogshyddans daghem!\\nVi utg\\u00e5r ifr\\u00e5n barnets b\\u00e4sta och att en trygghet mellan l\\u00e4raren/ barnsk\\u00f6tarna, kompisarna och\\n\\n\\nmilj\\u00f6n byggs upp.\\n\\n\\n\"}, {\"page\": 53, \"text\": \"53\\n**Information om inskolningen**\\nVi b\\u00f6rjar med ett bes\\u00f6k i daghemmet d\\u00e4r ert barn f\\u00e5r m\\u00f6jlighet att l\\u00e4ra k\\u00e4nna sin l\\u00e4rare och\\n\\n\\nbarnsk\\u00f6tare samt bekanta sig med daghemmets utrymmen.\\nVi rekommenderar att den f\\u00f6rsta tiden har ert barn kortare dagar.\\nD\\u00e5 v\\u00e5rdnadshavarna avl\\u00e4gsnar sig fr\\u00e5n dagv\\u00e5rdsplatsen debiteras avgift f\\u00f6r\\n\\n\\nsm\\u00e5barnspedagogiken.\\nMed hopp om ett gott samarbete.\\n\\n\\n\"}]}\n",
      "\n",
      "Respond with a JSON object in the following order of fields: `reasoning`, then `language`, then `title`, then `alt_title` (must be formatted as a valid Python list[str]), then `creator` (must be formatted as a valid Python list[str]), then `year` (must be formatted as a valid Python Union[str, NoneType]), then `publisher` (must be formatted as a valid Python list[str]), then `doi` (must be formatted as a valid Python Union[str, NoneType]), then `e_isbn` (must be formatted as a valid Python list[str]), then `p_isbn` (must be formatted as a valid Python list[str]), then `e_issn` (must be formatted as a valid Python Union[str, NoneType]), then `p_issn` (must be formatted as a valid Python Union[str, NoneType]), then `type_coar`.\n",
      "\n",
      "\n",
      "\u001b[31mResponse:\u001b[0m\n",
      "\n",
      "\u001b[32m{\"reasoning\": \"The document is a master's thesis titled \\\"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\\". The title and author are extracted from the first two pages. The language is detected as Swedish based on the presence of Swedish words in the text. The year is 2022. The publisher is \\u00c5bo Akademi. The DOI is not present. ISBNs are not present. ISSN is not present. The type_coar is master thesis.\", \"language\": \"sv\", \"title\": \"Inskolningens och anknytningens betydelse inom sm\\u00e5barnspedagogiken\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lm.inspect_history()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99baf332-ed43-4947-9183-89fd35bee3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the optimized program for later use (many formats, just in case)\n",
    "optimized_program.save(\"gepa-optimized-module.json\", save_program=False)\n",
    "optimized_program.save(\"gepa-optimized-module.pkl\", save_program=False)\n",
    "# save just the prompt(s)\n",
    "for name, pred in optimized_program.named_predictors():\n",
    "    with open(f\"gepa-optimized-prompt-{name}.txt\", \"w\") as outfile:\n",
    "        outfile.write(pred.signature.instructions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8dcc14b-2e28-43f5-9e4b-e72f25e7675b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fingreylit-dspy",
   "language": "python",
   "name": "fingreylit-dspy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
